\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{natbib}

\title{Budgeted Context Assembly: Constrained Submodular Optimization\\
for LLM Code Context Selection}

\author{%
  Anonymous
}

\date{}

\begin{document}

\maketitle

\begin{abstract}
Code-generation LLMs require relevant source code as context, but context
windows are finite.  We formalize \emph{budgeted context assembly} (BCA): given
a code knowledge graph, a task description, and a token budget, select a subset
of code symbols that maximizes a submodular utility function subject to budget
and dependency closure constraints.  Dependency closure ensures that every
selected symbol's type hierarchy is co-included, preventing undefined
references.  We present a greedy algorithm with a $(1 - 1/e)$ approximation
guarantee under the knapsack constraint.  On a benchmark of 12 coding tasks at
4 budget levels, BCA enforces the token budget on all tasks (0 violations),
while graph traversal without closure violates the budget on 92\% of tasks.
Lexical retrieval (BM25) achieves higher keyword recall but provides no budget
or dependency guarantees.  The implementation is released as
\textsc{CeGraph}, supporting Python, JavaScript, and TypeScript.
\end{abstract}

\input{introduction}
\input{related}
\input{method}
\input{evaluation}
\input{conclusion}

\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
