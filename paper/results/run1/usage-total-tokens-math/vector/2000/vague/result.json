{
  "task_id": "usage-total-tokens-math",
  "method": "vector",
  "budget": 2000,
  "query_type": "vague",
  "tokens_used": 2000,
  "symbols_selected": 42,
  "files_included": 26,
  "assembly_time_ms": 154.9,
  "llm_time_ms": 3111.9,
  "llm_input_tokens": 2821,
  "llm_output_tokens": 42,
  "tests_passed": false,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: pydantic_ai_slim/pydantic_ai/usage.py\nSEARCH:\n        total_tokens = usage.total_tokens\nREPLACE:\n        total_tokens = input_tokens + output_tokens\n",
  "error": "",
  "test_time_ms": 1000.9,
  "failure_mode": "test_fail",
  "target_file_hit": true,
  "target_symbol_hit": true,
  "context_patch_overlap": 0.038,
  "patch_files_changed": 1,
  "patch_lines_changed": 1,
  "edit_distance_lines": 312,
  "entity_count_extracted": 0,
  "entity_count_mapped": 0,
  "query_identifier_density": 0.0,
  "seed_symbol_keys": [],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.total_tokens",
  "min_hops_seed_to_mutation": -1,
  "median_hops_seed_to_mutation": -1.0,
  "bca_closure_added_symbols": 0,
  "bca_closure_added_tokens": 0,
  "bca_frontier_visited": 0,
  "context_symbol_keys": [
    "pydantic_ai_slim/pydantic_ai/_agent_graph.py::GraphAgentState.usage",
    "pydantic_ai_slim/pydantic_ai/_run_context.py::RunContext.usage",
    "pydantic_ai_slim/pydantic_ai/direct.py::model_request",
    "pydantic_ai_slim/pydantic_ai/direct.py::StreamedResponseSync.usage",
    "pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py::DBOSStreamedResponse.usage",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.usage",
    "pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_model.py::TemporalStreamedResponse.usage",
    "pydantic_ai_slim/pydantic_ai/embeddings/__init__.py::Embedder.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/__init__.py::Embedder.count_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/base.py::EmbeddingModel.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/base.py::EmbeddingModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/result.py::EmbeddingResult.usage",
    "pydantic_ai_slim/pydantic_ai/embeddings/result.py::EmbeddingResult.__getitem__",
    "pydantic_ai_slim/pydantic_ai/messages.py::FinishReason",
    "pydantic_ai_slim/pydantic_ai/messages.py::SystemPromptPart",
    "pydantic_ai_slim/pydantic_ai/messages.py::VideoUrl",
    "pydantic_ai_slim/pydantic_ai/messages.py::AudioUrl",
    "pydantic_ai_slim/pydantic_ai/messages.py::ImageUrl",
    "pydantic_ai_slim/pydantic_ai/messages.py::DocumentUrl",
    "pydantic_ai_slim/pydantic_ai/messages.py::BinaryContent",
    "pydantic_ai_slim/pydantic_ai/messages.py::CachePoint",
    "pydantic_ai_slim/pydantic_ai/messages.py::ToolReturn",
    "pydantic_ai_slim/pydantic_ai/messages.py::UserPromptPart",
    "pydantic_ai_slim/pydantic_ai/messages.py::ToolReturnPart",
    "pydantic_ai_slim/pydantic_ai/messages.py::BuiltinToolReturnPart",
    "pydantic_ai_slim/pydantic_ai/messages.py::RetryPromptPart",
    "pydantic_ai_slim/pydantic_ai/messages.py::ModelRequest",
    "pydantic_ai_slim/pydantic_ai/messages.py::TextPart",
    "pydantic_ai_slim/pydantic_ai/messages.py::ThinkingPart",
    "pydantic_ai_slim/pydantic_ai/messages.py::ToolCallPart",
    "pydantic_ai_slim/pydantic_ai/messages.py::BuiltinToolCallPart",
    "pydantic_ai_slim/pydantic_ai/messages.py::ModelResponsePart",
    "pydantic_ai_slim/pydantic_ai/messages.py::ModelResponse",
    "pydantic_ai_slim/pydantic_ai/messages.py::ModelResponse.usage",
    "pydantic_ai_slim/pydantic_ai/messages.py::ModelMessage",
    "pydantic_ai_slim/pydantic_ai/messages.py::ModelResponseStreamEvent",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::ModelRequestParameters",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.count_tokens",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.usage",
    "pydantic_ai_slim/pydantic_ai/models/anthropic.py::AnthropicModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/models/bedrock.py::BedrockModelSettings",
    "pydantic_ai_slim/pydantic_ai/models/bedrock.py::BedrockConverseModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/models/google.py::GoogleModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/result.py::AgentStream.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.usage",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRun.usage",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResult.usage",
    "pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py::FinishReason",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::Usage",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.check_tokens"
  ],
  "mutation_symbol_lines": 3,
  "mutation_symbol_kind": "method",
  "mutation_file_symbols": 65,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.062255,
  "retrieval_softmax_entropy": 4.2951,
  "retrieval_softmax_tau": 0.163695,
  "retrieval_effective_candidates": 19.63,
  "retrieval_top5_ratio": 0.7928,
  "retrieval_within95_count": 1,
  "retrieval_scored_symbols": 50,
  "retrieval_top1_score": 0.262676,
  "retrieval_top5_mean_score": 0.208259,
  "retrieval_budget_utilization": 1.0,
  "retrieval_file_concentration": 0.1905,
  "repo_name": "pydantic-ai"
}