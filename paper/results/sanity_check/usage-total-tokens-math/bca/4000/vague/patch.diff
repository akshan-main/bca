FILE: pydantic_ai_slim/pydantic_ai/embeddings/google.py
SEARCH:
    total_tokens = 0
REPLACE:
    total_tokens = sum(int(emb.statistics.token_count) for emb in response.embeddings if emb.statistics and emb.statistics.token_count)

FILE: pydantic_ai_slim/pydantic_ai/models/xai.py
SEARCH:
    if extracted.input_tokens == 0 and usage_data['prompt_tokens']:
        extracted.input_tokens = usage_data['prompt_tokens']
    if extracted.output_tokens == 0 and usage_data['completion_tokens']:
        extracted.output_tokens = usage_data['completion_tokens']
REPLACE:
    if extracted.input_tokens < usage_data['prompt_tokens']:
        extracted.input_tokens = usage_data['prompt_tokens']
    if extracted.output_tokens < usage_data['completion_tokens']:
        extracted.output_tokens = usage_data['completion_tokens']

FILE: pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py
SEARCH:
        input_tokens = int(
            response.get('ResponseMetadata', {}).get('HTTPHeaders', {}).get('x-amzn-bedrock-input-token-count', '0')
        )
REPLACE:
        input_tokens = max(
            int(response.get('ResponseMetadata', {}).get('HTTPHeaders', {}).get('x-amzn-bedrock-input-token-count', '0')),
            len(body.get('input', ''))
        )

FILE: pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py
SEARCH:
    return RequestUsage(input_tokens=total_tokens)
REPLACE:
    return RequestUsage(input_tokens=total_tokens, output_tokens=0, total_tokens=total_tokens)
