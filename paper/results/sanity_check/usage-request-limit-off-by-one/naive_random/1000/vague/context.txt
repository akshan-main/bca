# tests/test_embeddings.py:4-4
import sys

# tests/models/mock_xai.py:17-17
from ..conftest import raise_if_exception, try_import

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_toolset.py:6-6
from typing import Annotated, Any, Literal

# pydantic_ai_slim/pydantic_ai/direct.py:400-402
    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._ensure_stream_ready().timestamp

# pydantic_ai_slim/pydantic_ai/ui/__init__.py:4-4
from ._event_stream import SSE_CONTENT_TYPE, NativeEvent, OnCompleteFunc, UIEventStream

# tests/test_agent.py:3413-3491
    def test_early_strategy_does_not_call_additional_output_tools(self):
        """Test that 'early' strategy does not execute additional output tool functions."""
        output_tools_called: list[str] = []

        def process_first(output: OutputType) -> OutputType:
            """Process first output."""
            output_tools_called.append('first')
            return output

        def process_second(output: OutputType) -> OutputType:  # pragma: no cover
            """Process second output."""
            output_tools_called.append('second')
            return output

        def return_model(_: list[ModelMessage], info: AgentInfo) -> ModelResponse:
            assert info.output_tools is not None
            return ModelResponse(
                parts=[
                    ToolCallPart('first_output', {'value': 'first'}),
                    ToolCallPart('second_output', {'value': 'second'}),
                ],
            )

        agent = Agent(
            FunctionModel(return_model),
            output_type=[
                ToolOutput(process_first, name='first_output'),
                ToolOutput(process_second, name='second_output'),
            ],
            end_strategy='early',
        )

        result = agent.run_sync('test early output tools')

        # Verify the result came from the first output tool
        assert isinstance(result.output, OutputType)
        assert result.output.value == 'first'

        # Verify only the first output tool was called
        assert output_tools_called == ['first']

        # Verify we got tool returns in the correct order
        assert result.all_messages() == snapshot(
            [
                ModelRequest(
                    parts=[UserPromptPart(content='test early output tools', timestamp=IsNow(tz=timezone.utc))],
                    timestamp=IsNow(tz=timezone.utc),
                    run_id=IsStr(),
                ),
                ModelResponse(
                    parts=[
                        ToolCallPart(tool_name='first_output', args={'value': 'first'}, tool_call_id=IsStr()),
                        ToolCallPart(tool_name='second_output', args={'value': 'second'}, tool_call_id=IsStr()),
                    ],
                    usage=RequestUsage(input_tokens=54, output_tokens=10),
                    model_name='function:return_model:',
                    timestamp=IsNow(tz=timezone.utc),
                    run_id=IsStr(),
                ),
                ModelRequest(
                    parts=[
                        ToolReturnPart(
                            tool_name='first_output',
                            content='Final result processed.',
                            tool_call_id=IsStr(),
                            timestamp=IsNow(tz=timezone.utc),
                        ),
                        ToolReturnPart(
                            tool_name='second_output',
                            content='Output tool not used - a final result was already processed.',
                            tool_call_id=IsStr(),
                            timestamp=IsNow(tz=timezone.utc),
                        ),
                    ],
                    timestamp=IsNow(tz=timezone.utc),
                    run_id=IsStr(),
                ),
            ]
        )

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:151-151
    error_text: str

# pydantic_ai_slim/pydantic_ai/common_tools/tavily.py:44-44
    client: AsyncTavilyClient

# pydantic_graph/pydantic_graph/beta/graph.py:539-539
    result: EndMarker[Any] | Sequence[GraphTask] | JoinItem

# tests/test_utils.py:26-26
from .models.mock_async_stream import MockAsyncStream

# tests/models/test_mistral.py:1925-1929
def test_generate_user_output_format_multiple(mistral_api_key: str):
    schema = {'properties': {'prop_anyOf': {'anyOf': [{'type': 'string'}, {'type': 'integer'}]}}}
    m = MistralModel('', json_mode_schema_prompt='{schema}', provider=MistralProvider(api_key=mistral_api_key))
    result = m._generate_user_output_format([schema, schema])  # pyright: ignore[reportPrivateUsage]
    assert result.content == "[{'prop_anyOf': 'Optional[str]'}, {'prop_anyOf': 'Optional[str]'}]"

# tests/test_parts_manager.py:4-4
from typing import Any

# pydantic_graph/pydantic_graph/_utils.py:4-4
import inspect

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_agent.py:7-7
from dbos import DBOS, DBOSConfiguredInstance

# pydantic_ai_slim/pydantic_ai/models/instrumented.py:343-343
GEN_AI_REQUEST_MODEL_ATTRIBUTE = 'gen_ai.request.model'

# pydantic_ai_slim/pydantic_ai/_json_schema.py:7-7
from typing import Any, Literal