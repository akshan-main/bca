# pydantic_ai_slim/pydantic_ai/usage.py:260-260
    request_limit: int | None = 50

# pydantic_ai_slim/pydantic_ai/usage.py:270-270
    count_tokens_before_request: bool = False

# tests/models/test_google.py:21-53
from pydantic_ai import (
    AgentRunResult,
    AgentRunResultEvent,
    AgentStreamEvent,
    AudioUrl,
    BinaryContent,
    BinaryImage,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    DocumentUrl,
    FilePart,
    FinalResultEvent,
    FunctionToolCallEvent,
    FunctionToolResultEvent,
    ImageUrl,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    PartDeltaEvent,
    PartEndEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolReturnPart,
    UsageLimitExceeded,
    UserPromptPart,
    VideoUrl,
)

# tests/test_usage_limits.py:14-24
from pydantic_ai import (
    Agent,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    RunContext,
    ToolCallPart,
    ToolReturnPart,
    UsageLimitExceeded,
    UserPromptPart,
)

# tests/test_exceptions.py:11-22
from pydantic_ai.exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ToolRetryError,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# tests/models/test_bedrock.py:41-41
from pydantic_ai.exceptions import ModelAPIError, ModelHTTPError, ModelRetry, UsageLimitExceeded, UserError

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# tests/models/test_anthropic.py:18-47
from pydantic_ai import (
    Agent,
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentUrl,
    FinalResultEvent,
    ImageUrl,
    ModelAPIError,
    ModelHTTPError,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    ModelRetry,
    PartDeltaEvent,
    PartEndEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolCallPartDelta,
    ToolReturnPart,
    UsageLimitExceeded,
    UserPromptPart,
)

# pydantic_ai_slim/pydantic_ai/usage.py:13-13
from .exceptions import UsageLimitExceeded

# pydantic_ai_slim/pydantic_ai/usage.py:287-288
    def request_tokens_limit(self) -> int | None:
        return self.input_tokens_limit

# pydantic_ai_slim/pydantic_ai/models/concurrency.py:11-18
from ..concurrency import (
    AbstractConcurrencyLimiter,
    AnyConcurrencyLimit,
    ConcurrencyLimit,
    ConcurrencyLimiter,
    get_concurrency_context,
    normalize_to_limiter,
)

# tests/test_concurrency.py:12-12
from pydantic_ai import Agent, ConcurrencyLimit, ConcurrencyLimiter, ConcurrencyLimitExceeded

# pydantic_ai_slim/pydantic_ai/__init__.py:23-28
from .concurrency import (
    AbstractConcurrencyLimiter,
    AnyConcurrencyLimit,
    ConcurrencyLimit,
    ConcurrencyLimiter,
)

# tests/test_concurrency.py:12-12
from pydantic_ai import Agent, ConcurrencyLimit, ConcurrencyLimiter, ConcurrencyLimitExceeded

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# pydantic_ai_slim/pydantic_ai/usage.py:262-262
    tool_calls_limit: int | None = None

# pydantic_ai_slim/pydantic_ai/usage.py:366-382
    def check_before_request(self, usage: RunUsage) -> None:
        """Raises a `UsageLimitExceeded` exception if the next request would exceed any of the limits."""
        request_limit = self.request_limit
        if request_limit is not None and usage.requests > request_limit:
            raise UsageLimitExceeded(f'The next request would exceed the request_limit of {request_limit}')

        input_tokens = usage.input_tokens
        if self.input_tokens_limit is not None and input_tokens > self.input_tokens_limit:
            raise UsageLimitExceeded(
                f'The next request would exceed the input_tokens_limit of {self.input_tokens_limit} ({input_tokens=})'
            )

        total_tokens = usage.total_tokens
        if self.total_tokens_limit is not None and total_tokens > self.total_tokens_limit:
            raise UsageLimitExceeded(  # pragma: lax no cover
                f'The next request would exceed the total_tokens_limit of {self.total_tokens_limit} ({total_tokens=})'
            )

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_utils.py:9-9
    max_attempts: int

# tests/test_usage_limits.py:41-47
def test_request_token_limit() -> None:
    test_agent = Agent(TestModel())

    with pytest.raises(UsageLimitExceeded, match=re.escape('Exceeded the input_tokens_limit of 5 (input_tokens=59)')):
        test_agent.run_sync(
            'Hello, this prompt exceeds the request tokens limit.', usage_limits=UsageLimits(input_tokens_limit=5)
        )

# pydantic_ai_slim/pydantic_ai/concurrency.py:75-75
    max_running: int

# pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py:21-21
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/embeddings/test.py:6-6
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/models/__init__.py:53-53
from ..usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/models/mistral.py:43-43
from ..usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/models/wrapper.py:13-13
from ..usage import RequestUsage

# tests/models/test_huggingface.py:39-39
from pydantic_ai.usage import RequestUsage

# tests/models/test_model_function.py:28-28
from pydantic_ai.usage import RequestUsage

# tests/models/test_model_test.py:35-35
from pydantic_ai.usage import RequestUsage, RunUsage

# tests/test_a2a.py:25-25
from pydantic_ai.usage import RequestUsage

# tests/test_agent.py:74-74
from pydantic_ai.usage import RequestUsage

# tests/test_mcp.py:45-45
from pydantic_ai.usage import RequestUsage, RunUsage

# tests/test_messages.py:9-30
from pydantic_ai import (
    AudioUrl,
    BinaryContent,
    BinaryImage,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    DocumentUrl,
    FilePart,
    ImageUrl,
    ModelMessage,
    ModelMessagesTypeAdapter,
    ModelRequest,
    ModelResponse,
    RequestUsage,
    TextPart,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
    VideoUrl,
)

# tests/test_streaming.py:56-56
from pydantic_ai.usage import RequestUsage

# tests/test_usage_limits.py:29-29
from pydantic_ai.usage import RequestUsage, RunUsage, UsageLimits

# tests/test_dbos.py:38-38
from pydantic_ai.usage import RequestUsage

# tests/models/test_fallback.py:33-33
from pydantic_ai.usage import RequestUsage

# tests/models/test_openai.py:51-51
from pydantic_ai.usage import RequestUsage

# tests/test_tools.py:39-39
from pydantic_ai.usage import RequestUsage

# tests/test_embeddings.py:29-29
from pydantic_ai.usage import RequestUsage

# tests/test_history_processor.py:21-21
from pydantic_ai.usage import RequestUsage

# tests/test_direct.py:35-35
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/embeddings/google.py:7-7
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:20-20
from pydantic_ai.usage import RequestUsage

# tests/models/test_xai.py:71-71
from pydantic_ai.usage import RequestUsage, RunUsage

# tests/models/test_cohere.py:31-31
from pydantic_ai.usage import RequestUsage, RunUsage

# tests/models/test_deepseek.py:17-17
from pydantic_ai.usage import RequestUsage

# tests/models/test_gemini_vertex.py:21-21
from pydantic_ai.usage import RequestUsage

# tests/models/test_google.py:77-77
from pydantic_ai.usage import RequestUsage, RunUsage, UsageLimits

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_model.py:24-24
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:17-17
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/embeddings/openai.py:8-8
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py:9-9
from pydantic_ai.usage import RequestUsage

# tests/models/test_instrumented.py:45-45
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/direct.py:19-19
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/models/test.py:36-36
from ..usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/models/concurrency.py:21-21
from ..usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/models/xai.py:54-54
from ..usage import RequestUsage

# tests/test_temporal.py:55-55
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/embeddings/cohere.py:7-7
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/__init__.py:129-129
from .usage import RequestUsage, RunUsage, UsageLimits

# pydantic_ai_slim/pydantic_ai/embeddings/result.py:9-9
from pydantic_ai.usage import RequestUsage

# tests/models/test_anthropic.py:58-58
from pydantic_ai.usage import RequestUsage, UsageLimits

# tests/models/test_bedrock.py:52-52
from pydantic_ai.usage import RequestUsage, RunUsage, UsageLimits

# tests/models/test_mistral.py:34-34
from pydantic_ai.usage import RequestUsage

# tests/test_prefect.py:35-35
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/messages.py:28-28
from .usage import RequestUsage

# tests/models/test_gemini.py:63-63
from pydantic_ai.usage import RequestUsage

# tests/models/test_groq.py:50-50
from pydantic_ai.usage import RequestUsage, RunUsage

# pydantic_ai_slim/pydantic_ai/usage.py:334-352
    def __init__(
        self,
        *,
        request_limit: int | None = 50,
        tool_calls_limit: int | None = None,
        input_tokens_limit: int | None = None,
        output_tokens_limit: int | None = None,
        total_tokens_limit: int | None = None,
        count_tokens_before_request: bool = False,
        # deprecated:
        request_tokens_limit: int | None = None,
        response_tokens_limit: int | None = None,
    ):
        self.request_limit = request_limit
        self.tool_calls_limit = tool_calls_limit
        self.input_tokens_limit = input_tokens_limit if input_tokens_limit is not None else request_tokens_limit
        self.output_tokens_limit = output_tokens_limit if output_tokens_limit is not None else response_tokens_limit
        self.total_tokens_limit = total_tokens_limit
        self.count_tokens_before_request = count_tokens_before_request

# pydantic_ai_slim/pydantic_ai/concurrency.py:76-76
    max_queued: int | None = None

# pydantic_ai_slim/pydantic_ai/models/gemini.py:53-53
from . import Model, ModelRequestParameters, StreamedResponse, check_allow_model_requests, download_item, get_user_agent

# pydantic_ai_slim/pydantic_ai/models/google.py:53-60
from . import (
    Model,
    ModelRequestParameters,
    StreamedResponse,
    check_allow_model_requests,
    download_item,
    get_user_agent,
)

# pydantic_ai_slim/pydantic_ai/models/groq.py:46-52
from . import (
    Model,
    ModelRequestParameters,
    StreamedResponse,
    check_allow_model_requests,
    get_user_agent,
)

# pydantic_ai_slim/pydantic_ai/models/huggingface.py:43-48
from . import (
    Model,
    ModelRequestParameters,
    StreamedResponse,
    check_allow_model_requests,
)

# pydantic_ai_slim/pydantic_ai/models/mistral.py:44-51
from . import (
    Model,
    ModelRequestParameters,
    StreamedResponse,
    check_allow_model_requests,
    download_item,
    get_user_agent,
)

# pydantic_ai_slim/pydantic_ai/usage.py:292-293
    def response_tokens_limit(self) -> int | None:
        return self.output_tokens_limit

# pydantic_ai_slim/pydantic_ai/models/xai.py:43-49
from ..models import (
    Model,
    ModelRequestParameters,
    StreamedResponse,
    check_allow_model_requests,
    download_item,
)

# pydantic_ai_slim/pydantic_ai/models/openai.py:64-73
from . import (
    Model,
    ModelRequestParameters,
    OpenAIChatCompatibleProvider,
    OpenAIResponsesCompatibleProvider,
    StreamedResponse,
    check_allow_model_requests,
    download_item,
    get_user_agent,
)

# pydantic_ai_slim/pydantic_ai/models/anthropic.py:52-52
from . import Model, ModelRequestParameters, StreamedResponse, check_allow_model_requests, download_item, get_user_agent

# pydantic_ai_slim/pydantic_ai/models/cohere.py:34-34
from . import Model, ModelRequestParameters, check_allow_model_requests

# pydantic_ai_slim/pydantic_ai/models/concurrency.py:56-56
    _limiter: AbstractConcurrencyLimiter

# pydantic_ai_slim/pydantic_ai/usage.py:268-268
    total_tokens_limit: int | None = None

# tests/models/test_bedrock.py:189-208
async def test_bedrock_model_usage_limit_not_exceeded(
    allow_model_requests: None,
    bedrock_provider: BedrockProvider,
):
    model = BedrockConverseModel('us.anthropic.claude-sonnet-4-20250514-v1:0', provider=bedrock_provider)
    agent = Agent(model=model)

    result = await agent.run(
        'The quick brown fox jumps over the lazydog.',
        usage_limits=UsageLimits(input_tokens_limit=25, count_tokens_before_request=True),
    )

    assert result.output == snapshot(
        'I notice there\'s a small typo in your message - it should be "lazy dog" (two words) rather than '
        '"lazydog."\n\nThe corrected version is: "The quick brown fox jumps over the lazy dog."\n\n'
        'This is a famous pangram - a sentence that contains every letter of the English alphabet at least once. '
        "It's commonly used for testing typewriters, keyboards, fonts, and other applications where you want to "
        "display all the letters.\n\nIs there something specific you'd like to know about this phrase, or were you "
        'perhaps testing something?'
    )

# tests/models/test_bedrock.py:171-185
async def test_bedrock_model_usage_limit_exceeded(
    allow_model_requests: None,
    bedrock_provider: BedrockProvider,
):
    model = BedrockConverseModel('us.anthropic.claude-sonnet-4-20250514-v1:0', provider=bedrock_provider)
    agent = Agent(model=model)

    with pytest.raises(
        UsageLimitExceeded,
        match='The next request would exceed the input_tokens_limit of 18 \\(input_tokens=23\\)',
    ):
        await agent.run(
            ['The quick brown fox jumps over the lazydog.', CachePoint(), 'What was next?'],
            usage_limits=UsageLimits(input_tokens_limit=18, count_tokens_before_request=True),
        )

# pydantic_ai_slim/pydantic_ai/__init__.py:103-103
from .models.concurrency import ConcurrencyLimitedModel, limit_model_concurrency

# tests/models/test_anthropic.py:1030-1078
async def test_limit_cache_points_all_settings(allow_model_requests: None):
    """Test cache point limiting with all cache settings enabled."""
    c = completion_message(
        [BetaTextBlock(text='Response', type='text')],
        usage=BetaUsage(input_tokens=10, output_tokens=5),
    )
    mock_client = MockAnthropic.create_mock(c)
    m = AnthropicModel('claude-haiku-4-5', provider=AnthropicProvider(anthropic_client=mock_client))

    agent = Agent(
        m,
        system_prompt='System instructions.',
        model_settings=AnthropicModelSettings(
            anthropic_cache_instructions=True,  # 1 cache point
            anthropic_cache_tool_definitions=True,  # 1 cache point
        ),
    )

    @agent.tool_plain
    def my_tool() -> str:  # pragma: no cover
        return 'result'

    # Add 3 CachePoint markers (total would be 5: 2 from settings + 3 from markers)
    # Only 2 CachePoint markers should be kept
    await agent.run(
        [
            'Context 1',
            CachePoint(),  # Oldest, should be removed
            'Context 2',
            CachePoint(),  # Should be kept
            'Context 3',
            CachePoint(),  # Should be kept
            'Question',
        ]
    )

    completion_kwargs = get_mock_chat_completion_kwargs(mock_client)[0]
    messages = completion_kwargs['messages']

    # Count cache_control in messages (excluding system and tools)
    cache_count = 0
    for msg in messages:
        for block in msg['content']:
            if 'cache_control' in block:
                cache_count += 1

    # Should have exactly 2 cache points in messages
    # (4 total - 1 system - 1 tool = 2 available for messages)
    assert cache_count == 2

# pydantic_ai_slim/pydantic_ai/builtin_tools.py:207-207
    max_uses: int | None = None

# pydantic_ai_slim/pydantic_ai/__init__.py:129-129
from .usage import RequestUsage, RunUsage, UsageLimits

# pydantic_ai_slim/pydantic_ai/ag_ui.py:23-23
from .usage import RunUsage, UsageLimits

# pydantic_ai_slim/pydantic_ai/result.py:28-28
from .usage import RunUsage, UsageLimits

# tests/models/test_anthropic.py:58-58
from pydantic_ai.usage import RequestUsage, UsageLimits

# pydantic_ai_slim/pydantic_ai/ui/ag_ui/app.py:20-20
from pydantic_ai.usage import RunUsage, UsageLimits

# tests/test_cli.py:17-17
from pydantic_ai.usage import UsageLimits

# pydantic_ai_slim/pydantic_ai/ui/_adapter.py:32-32
from pydantic_ai.usage import RunUsage, UsageLimits

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:45-45
from ..usage import RunUsage, UsageLimits

# tests/models/test_bedrock.py:52-52
from pydantic_ai.usage import RequestUsage, RunUsage, UsageLimits