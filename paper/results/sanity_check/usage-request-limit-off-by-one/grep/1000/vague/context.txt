# .github/set_docs_pr_preview_url.py
import os
import re

import httpx

DEPLOY_OUTPUT = os.environ['DEPLOY_OUTPUT']
GITHUB_TOKEN = os.environ['GITHUB_TOKEN']
REPOSITORY = os.environ['REPOSITORY']
PULL_REQUEST_NUMBER = os.environ['PULL_REQUEST_NUMBER']
REF = os.environ['REF']

m = re.search(r'https://(\S+)\.workers\.dev', DEPLOY_OUTPUT)
assert m, f'Could not find worker URL in {DEPLOY_OUTPUT!r}'

worker_name = m.group(1)
m = re.search(r'Current Version ID: ([^-]+)', DEPLOY_OUTPUT)
assert m, f'Could not find version ID in {DEPLOY_OUTPUT!r}'

version_id = m.group(1)
preview_url = f'https://{version_id}-{worker_name}.workers.dev'
print('Docs preview URL:', preview_url, flush=True)

gh_headers = {
    'Accept': 'application/vnd.github+json',
    'Authorization': f'Bearer {GITHUB_TOKEN}',
    'X-GitHub-Api-Version': '2022-11-28',
}

# now create or update a comment on the PR with the preview URL
if not PULL_REQUEST_NUMBER:
    print('Pull request number not set', flush=True)
    exit(1)

comments_url = f'https://api.github.com/repos/{REPOSITORY}/issues/{PULL_REQUEST_NUMBER}/comments'
r = httpx.get(comments_url, headers=gh_headers)
print(f'{r.request.method} {r.request.url} {r.status_code}', flush=True)
if r.status_code != 200:
    print(f'Failed to get comments, status {r.status_code}, response:\n{r.text}', flush=True)
    exit(1)

comment_update_url = None

for comment in r.json():
    if comment['user']['login'] == 'github-actions[bot]' and comment['body'].startswith('## Docs Preview'):
        comment_update_url = comment['url']
        break

body = f"""\
## Docs Preview

<table>
<tr>
<td><strong>commit:</strong></td>
<td><code>{REF:.7}</code></td>
</tr>
<tr>
<td><strong>Preview URL:</strong></td>
<td><a href="{preview_url}">{preview_url}</a></td>
</tr>
</table>
"""
comment_data = {'body': body}

if comment_update_url:
    print('Updating existing comment...', flush=True)
    r = httpx.patch(comment_update_url, headers=gh_headers, json=comment_data)
else:
    print('Creating new comment...', flush=True)
    r = httpx.post(comments_url, headers=gh_headers, json=comment_data)

print(f'{r.request.method} {r.request.url} {r.status_code}', flush=True)
r.raise_for_status()


# clai/clai/__init__.py
from importlib.metadata import version as _metadata_version

from pydantic_ai import _cli

__all__ = '__version__', 'cli'
__version__ = _metadata_version('clai')


def cli():
    """Run the clai CLI and exit."""
    _cli.cli_exit('clai')


# clai/clai/__main__.py
"""This means `python -m clai` should run the CLI."""

from pydantic_ai import _cli

if __name__ == '__main__':
    _cli.cli_exit('clai')


# docs/.hooks/algolia.py
# pyright: reportUnknownMemberType=false
from __future__ import annotations as _annotations

import os
import sys
from pathlib import Path
from typing import TYPE_CHECKING, cast

from pydantic import TypeAdapter
from typing_extensions import TypedDict

if TYPE_CHECKING:
    from mkdocs.config import Config
    from mkdocs.structure.files import Files
    from mkdocs.structure.pages import Page


class AlgoliaRecord(TypedDict):
    content: str
    pageID: str
    abs_url: str
    title: str
    objectID: str
    rank: int


records: list[AlgoliaRecord] = []
records_ta = TypeAdapter(list[AlgoliaRecord])
# these values should match docs/javascripts/search-worker.js.
ALGOLIA_APP_ID = 'KPPUDTIAVX'
ALGOLIA_INDEX_NAME = 'pydantic-ai-docs'

# Algolia has a limit of 100kb per record in the paid plan,
# leave some space for the other fields as well.
MAX_CONTENT_LENGTH = 90_000


def on_page_content(html: str, page: Page, config: Config, files: Files) -> str:
    if not os.getenv('CI'):
        return html

    from bs4 import BeautifulSoup

    assert page.title is not None, 'Page title must not be None'
    title = cast(str, page.title)

    soup = BeautifulSoup(html, 'html.parser')

    # If the page does not start with a heading, add the h1 with the title
    # Some examples don't have a heading. or start with h2
    first_element = soup.find()

    if not first_element or not first_element.name or first_element.name not in ['h1', 'h2', 'h3']:
  