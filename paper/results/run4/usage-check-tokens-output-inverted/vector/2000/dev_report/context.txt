# tests/test_usage_limits.py:50-56
def test_response_token_limit() -> None:
    test_agent = Agent(
        TestModel(custom_output_text='Unfortunately, this response exceeds the response tokens limit by a few!')
    )

    with pytest.raises(UsageLimitExceeded, match=re.escape('Exceeded the output_tokens_limit of 5 (output_tokens=11)')):
        test_agent.run_sync('Hello', usage_limits=UsageLimits(output_tokens_limit=5))

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# pydantic_ai_slim/pydantic_ai/usage.py:13-13
from .exceptions import UsageLimitExceeded

# tests/models/test_anthropic.py:18-47
from pydantic_ai import (
    Agent,
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentUrl,
    FinalResultEvent,
    ImageUrl,
    ModelAPIError,
    ModelHTTPError,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    ModelRetry,
    PartDeltaEvent,
    PartEndEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolCallPartDelta,
    ToolReturnPart,
    UsageLimitExceeded,
    UserPromptPart,
)

# tests/models/test_bedrock.py:41-41
from pydantic_ai.exceptions import ModelAPIError, ModelHTTPError, ModelRetry, UsageLimitExceeded, UserError

# tests/models/test_google.py:21-53
from pydantic_ai import (
    AgentRunResult,
    AgentRunResultEvent,
    AgentStreamEvent,
    AudioUrl,
    BinaryContent,
    BinaryImage,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    DocumentUrl,
    FilePart,
    FinalResultEvent,
    FunctionToolCallEvent,
    FunctionToolResultEvent,
    ImageUrl,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    PartDeltaEvent,
    PartEndEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolReturnPart,
    UsageLimitExceeded,
    UserPromptPart,
    VideoUrl,
)

# tests/test_exceptions.py:11-22
from pydantic_ai.exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ToolRetryError,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# tests/test_usage_limits.py:14-24
from pydantic_ai import (
    Agent,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    RunContext,
    ToolCallPart,
    ToolReturnPart,
    UsageLimitExceeded,
    UserPromptPart,
)

# pydantic_ai_slim/pydantic_ai/exceptions.py:129-130
class UsageLimitExceeded(AgentRunError):
    """Error raised when a Model's usage exceeds the specified limits."""

# examples/pydantic_ai_examples/flight_booking.py:109-110
class Failed(BaseModel):
    """Unable to extract a seat selection."""

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:28-28
from . import _output, _system_prompt, exceptions, messages as _messages, models, result, usage as _usage

# pydantic_ai_slim/pydantic_ai/_mcp.py:9-9
from . import exceptions, messages

# pydantic_ai_slim/pydantic_ai/_utils.py:41-41
from . import exceptions

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:20-30
from .. import (
    _agent_graph,
    _output,
    _system_prompt,
    _utils,
    concurrency as _concurrency,
    exceptions,
    messages as _messages,
    models,
    usage as _usage,
)

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:17-27
from .. import (
    _agent_graph,
    _system_prompt,
    _tool_manager,
    _utils,
    exceptions,
    messages as _messages,
    models,
    result,
    usage as _usage,
)

# pydantic_ai_slim/pydantic_ai/mcp.py:46-46
from . import _mcp, _utils, exceptions, messages, models

# pydantic_ai_slim/pydantic_ai/models/mcp_sampling.py:8-8
from .. import _mcp, exceptions

# pydantic_ai_slim/pydantic_ai/output.py:12-12
from . import _utils, exceptions

# pydantic_ai_slim/pydantic_ai/result.py:12-12
from . import _utils, exceptions, messages as _messages, models

# pydantic_ai_slim/pydantic_ai/run.py:13-19
from . import (
    _agent_graph,
    _utils,
    exceptions,
    messages as _messages,
    usage as _usage,
)

# pydantic_graph/pydantic_graph/beta/graph.py:21-21
from pydantic_graph import exceptions

# pydantic_graph/pydantic_graph/beta/graph_builder.py:19-19
from pydantic_graph import _utils, exceptions

# pydantic_graph/pydantic_graph/graph.py:15-15
from . import _utils, exceptions, mermaid

# pydantic_graph/pydantic_graph/nodes.py:12-12
from . import _utils, exceptions

# pydantic_graph/pydantic_graph/persistence/file.py:14-14
from .. import _utils as _graph_utils, exceptions

# pydantic_graph/pydantic_graph/persistence/in_mem.py:17-17
from .. import exceptions

# tests/test_dbos.py:193-194
class Response:
    answers: list[Answer]

# tests/test_prefect.py:180-181
class Response:
    answers: list[Answer]

# tests/test_temporal.py:274-275
class Response:
    answers: list[Answer]

# tests/models/mock_xai.py:493-524
def create_failed_builtin_tool_response(
    tool_name: str,
    tool_type: chat_pb2.ToolCallType,
    *,
    tool_call_id: str = 'failed_tool_001',
    error_message: str = 'tool failed',
    content: ToolCallOutputType | None = None,
) -> chat_types.Response:
    """Create a Response representing a failed builtin tool call."""
    output = chat_pb2.CompletionOutput(
        index=0,
        finish_reason=sample_pb2.FinishReason.REASON_STOP,
        message=chat_pb2.CompletionMessage(
            role=chat_pb2.MessageRole.ROLE_ASSISTANT,
            content=_serialize_content(content or ''),
            tool_calls=[
                create_server_tool_call(
                    tool_name,
                    {},
                    tool_call_id=tool_call_id,
                    tool_type=tool_type,
                    status=chat_pb2.ToolCallStatus.TOOL_CALL_STATUS_FAILED,
                    error_message=error_message,
                )
            ],
        ),
    )

    return _build_response_with_outputs(
        response_id=f'grok-{tool_call_id}',
        outputs=[output],
    )

# pydantic_ai_slim/pydantic_ai/models/test.py:76-76
    custom_output_text: str | None = None

# pydantic_ai_slim/pydantic_ai/direct.py:385-387
    def response(self) -> messages.ModelResponse:
        """Get the current state of the response."""
        return self.get()

# pydantic_ai_slim/pydantic_ai/result.py:157-159
    def response(self) -> _messages.ModelResponse:
        """Get the current state of the response."""
        return self.get()