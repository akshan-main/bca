tic_ai_slim/pydantic_ai/_agent_graph.py:501: in _make_request
    model_response = await ctx.deps.model.request(message_history, model_settings, model_request_parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = TestModel(call_tools='all', custom_output_text=None, custom_output_args=None, seed=0, last_model_request_parameters=ModelRequestParameters(function_tools=[], builtin_tools=[], output_tools=[]))
messages = [ModelRequest(parts=[UserPromptPart(content='Hello, this prompt exceeds the request tokens limit.', timestamp=datetime....datetime(2026, 2, 13, 1, 6, 37, 216395, tzinfo=datetime.timezone.utc), run_id='e2fd1145-0379-4100-8b1c-98dd28ed6a70')]
model_settings = None
model_request_parameters = ModelRequestParameters(function_tools=[], builtin_tools=[], output_tools=[])

    async def request(
        self,
        messages: list[ModelMessage],
        model_settings: ModelSettings | None,
        model_request_parameters: ModelRequestParameters,
    ) -> ModelResponse:
        model_settings, model_request_parameters = self.prepare_request(
            model_settings,
            model_request_parameters,
        )
        self.last_model_request_parameters = model_request_parameters
        model_response = self._request(messages, model_settings, model_request_parameters)
        model_response.usage = _estimate_usage([*messages, model_response])
>       if model_response.usage.output_tokens > model_request_parameters.output_tokens_limit:
E       AttributeError: 'ModelRequestParameters' object has no attribute 'output_tokens_limit'

pydantic_ai_slim/pydantic_ai/models/test.py:126: AttributeError
=========================== short test summary info ============================
FAILED tests/test_usage_limits.py::test_request_token_limit - AttributeError:...
!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!
========================= 1 failed, 1 passed in 0.68s ==========================

/Users/akshankrithick/anaconda3/envs/vvenv/lib/python3.11/site-packages/pytest_asyncio/plugin.py:247: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))