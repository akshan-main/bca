# tests/test_tools.py:129-155
def test_docstring_google(docstring_format: Literal['google', 'auto']):
    agent = Agent(FunctionModel(get_json_schema))
    agent.tool_plain(docstring_format=docstring_format)(google_style_docstring)

    result = agent.run_sync('Hello')
    json_schema = json.loads(result.output)
    assert json_schema == snapshot(
        {
            'name': 'google_style_docstring',
            'description': 'Do foobar stuff, a lot.',
            'parameters_json_schema': {
                'properties': {
                    'foo': {'description': 'The foo thing.', 'type': 'integer'},
                    'bar': {'description': 'The bar thing.', 'type': 'string'},
                },
                'required': ['foo', 'bar'],
                'type': 'object',
                'additionalProperties': False,
            },
            'outer_typed_dict_key': None,
            'strict': None,
            'kind': 'function',
            'sequential': False,
            'metadata': None,
            'timeout': None,
        }
    )

# tests/test_tools.py:110-117
async def google_style_docstring(foo: int, bar: str) -> str:  # pragma: no cover
    """Do foobar stuff, a lot.

    Args:
        foo: The foo thing.
        bar: The bar thing.
    """
    return f'{foo} {bar}'

# pydantic_ai_slim/pydantic_ai/tools.py:276-276
    docstring_format: DocstringFormat

# pydantic_ai_slim/pydantic_ai/toolsets/function.py:47-47
    docstring_format: DocstringFormat

# pydantic_ai_slim/pydantic_ai/tools.py:274-274
    description: str | None

# pydantic_ai_slim/pydantic_ai/tools.py:488-488
    description: str | None = None

# pydantic_ai_slim/pydantic_ai/ext/langchain.py:24-24
    def description(self) -> str: ...

# examples/pydantic_ai_examples/ag_ui/api/agentic_generative_ui.py:20-20
    description: str = Field(description='The description of the step')

# tests/test_tools.py:429-438
async def google_style_docstring_no_body(
    foo: int, bar: Annotated[str, Field(description='from fields')]
) -> str:  # pragma: no cover
    """
    Args:
        foo: The foo thing.
        bar: The bar thing.
    """

    return f'{foo} {bar}'

# pydantic_ai_slim/pydantic_ai/output.py:164-164
    description: str | None

# pydantic_ai_slim/pydantic_ai/output.py:113-113
    description: str | None

# pydantic_ai_slim/pydantic_ai/output.py:265-265
    description: str | None = None

# pydantic_ai_slim/pydantic_ai/builtin_tools.py:403-403
    description: str | None = None

# pydantic_ai_slim/pydantic_ai/output.py:237-237
    description: str | None

# pydantic_ai_slim/pydantic_ai/_function_schema.py:39-39
    description: str | None

# pydantic_evals/pydantic_evals/reporting/analyses.py:23-23
    description: str | None = None

# pydantic_evals/pydantic_evals/reporting/analyses.py:54-54
    description: str | None = None

# pydantic_evals/pydantic_evals/reporting/analyses.py:64-64
    description: str | None = None

# pydantic_evals/pydantic_evals/reporting/analyses.py:75-75
    description: str | None = None

# pydantic_ai_slim/pydantic_ai/mcp.py:137-137
    description: str | None = None

# tests/ext/test_langchain.py:15-15
    description: str

# examples/pydantic_ai_examples/stream_whales.py:39-39
    description: NotRequired[Annotated[str, Field(description='Short Description')]]

# pydantic_ai_slim/pydantic_ai/models/gemini.py:823-823
    description: str

# tests/test_logfire.py:1384-1384
    description: str

# pydantic_ai_slim/pydantic_ai/output.py:296-360
def StructuredDict(
    json_schema: JsonSchemaValue, name: str | None = None, description: str | None = None
) -> type[JsonSchemaValue]:
    """Returns a `dict[str, Any]` subclass with a JSON schema attached that will be used for structured output.

    Args:
        json_schema: A JSON schema of type `object` defining the structure of the dictionary content.
        name: Optional name of the structured output. If not provided, the `title` field of the JSON schema will be used if it's present.
        description: Optional description of the structured output. If not provided, the `description` field of the JSON schema will be used if it's present.

    Example:
    ```python {title="structured_dict.py"}
    from pydantic_ai import Agent, StructuredDict

    schema = {
        'type': 'object',
        'properties': {
            'name': {'type': 'string'},
            'age': {'type': 'integer'}
        },
        'required': ['name', 'age']
    }

    agent = Agent('openai:gpt-5.2', output_type=StructuredDict(schema))
    result = agent.run_sync('Create a person')
    print(result.output)
    #> {'name': 'John Doe', 'age': 30}
    ```
    """
    json_schema = _utils.check_object_json_schema(json_schema)

    # Pydantic `TypeAdapter` fails when `object.__get_pydantic_json_schema__` has `$defs`, so we inline them
    # See https://github.com/pydantic/pydantic/issues/12145
    if '$defs' in json_schema:
        json_schema = InlineDefsJsonSchemaTransformer(json_schema).walk()
        if '$defs' in json_schema:
            raise exceptions.UserError(
                '`StructuredDict` does not currently support recursive `$ref`s and `$defs`. See https://github.com/pydantic/pydantic/issues/12145 for more information.'
            )

    if name:
        json_schema['title'] = name

    if description:
        json_schema['description'] = description

    class _StructuredDict(JsonSchemaValue):
        __is_model_like__ = True

        @classmethod
        def __get_pydantic_core_schema__(
            cls, source_type: Any, handler: GetCoreSchemaHandler
        ) -> core_schema.CoreSchema:
            return core_schema.dict_schema(
                keys_schema=core_schema.str_schema(),
                values_schema=core_schema.any_schema(),
            )

        @classmethod
        def __get_pydantic_json_schema__(
            cls, core_schema: core_schema.CoreSchema, handler: GetJsonSchemaHandler
        ) -> JsonSchemaValue:
            return json_schema

    return _StructuredDict

# pydantic_ai_slim/pydantic_ai/embeddings/google.py:105-134
    def __init__(
        self,
        model_name: GoogleEmbeddingModelName,
        *,
        provider: Literal['google-gla', 'google-vertex'] | Provider[Client] = 'google-gla',
        settings: EmbeddingSettings | None = None,
    ):
        """Initialize a Google embedding model.

        Args:
            model_name: The name of the Google model to use.
                See [Google Embeddings documentation](https://ai.google.dev/gemini-api/docs/embeddings)
                for available models.
            provider: The provider to use for authentication and API access. Can be:

                - `'google-gla'` (default): Uses the Gemini API (Google AI Studio)
                - `'google-vertex'`: Uses Vertex AI
                - A [`GoogleProvider`][pydantic_ai.providers.google.GoogleProvider] instance
                  for custom configuration
            settings: Model-specific [`EmbeddingSettings`][pydantic_ai.embeddings.EmbeddingSettings]
                to use as defaults for this model.
        """
        self._model_name = model_name

        if isinstance(provider, str):
            provider = infer_provider(provider)
        self._provider = provider
        self._client = provider.client

        super().__init__(settings=settings)

# tests/test_tools.py:193-203
def numpy_style_docstring(*, foo: int, bar: str) -> str:  # pragma: no cover
    """Numpy style docstring.

    Parameters
    ----------
    foo : int
        The foo thing.
    bar : str
        The bar thing.
    """
    return f'{foo} {bar}'

# tests/graph/test_mermaid.py:39-41
class Bar(BaseNode[None, None, None]):
    async def run(self, ctx: GraphRunContext) -> End[None]:
        return End(None)

# tests/graph/test_persistence.py:45-48
class Bar(BaseNode[MyState, None, int]):
    async def run(self, ctx: GraphRunContext[MyState]) -> End[int]:
        ctx.state.y += 'y'
        return End(ctx.state.x * 2)

# tests/test_agent.py:4922-4924
class Bar(BaseModel):
    c: int
    d: str

# tests/test_agent_output_schemas.py:19-20
class Bar(BaseModel):
    answer: str

# tests/typed_agent.py:158-159
class Bar:
    b: str

# tests/test_tools.py:443-469
def test_docstring_google_no_body(docstring_format: Literal['google', 'auto']):
    agent = Agent(FunctionModel(get_json_schema))
    agent.tool_plain(docstring_format=docstring_format)(google_style_docstring_no_body)

    result = agent.run_sync('')
    json_schema = json.loads(result.output)
    assert json_schema == snapshot(
        {
            'name': 'google_style_docstring_no_body',
            'description': '',
            'parameters_json_schema': {
                'properties': {
                    'foo': {'description': 'The foo thing.', 'type': 'integer'},
                    'bar': {'description': 'from fields', 'type': 'string'},
                },
                'required': ['foo', 'bar'],
                'type': 'object',
                'additionalProperties': False,
            },
            'outer_typed_dict_key': None,
            'strict': None,
            'kind': 'function',
            'sequential': False,
            'metadata': None,
            'timeout': None,
        }
    )

# tests/graph/test_mermaid.py:33-35
class Foo(BaseNode):
    async def run(self, ctx: GraphRunContext) -> Bar:
        return Bar()

# tests/graph/test_persistence.py:38-41
class Foo(BaseNode[MyState]):
    async def run(self, ctx: GraphRunContext[MyState]) -> Bar:
        ctx.state.x += 1
        return Bar()

# tests/models/test_model_function.py:503-504
class Foo(BaseModel):
    x: int

# tests/test_agent.py:149-151
class Foo(BaseModel):
    a: int
    b: str

# tests/test_agent_output_schemas.py:23-25
class Foo(BaseModel):
    a: list[Bar]
    b: int

# tests/test_streaming.py:64-66
class Foo(BaseModel):
    a: int
    b: str

# tests/test_tools.py:472-474
class Foo(BaseModel):
    x: int
    y: str

# tests/typed_agent.py:153-154
class Foo:
    a: int

# pydantic_ai_slim/pydantic_ai/models/google.py:212-237
    def __init__(
        self,
        model_name: GoogleModelName,
        *,
        provider: Literal['google-gla', 'google-vertex', 'gateway'] | Provider[Client] = 'google-gla',
        profile: ModelProfileSpec | None = None,
        settings: ModelSettings | None = None,
    ):
        """Initialize a Gemini model.

        Args:
            model_name: The name of the model to use.
            provider: The provider to use for authentication and API access. Can be either the string
                'google-gla' or 'google-vertex' or an instance of `Provider[google.genai.AsyncClient]`.
                Defaults to 'google-gla'.
            profile: The model profile to use. Defaults to a profile picked by the provider based on the model name.
            settings: The model settings to use. Defaults to None.
        """
        self._model_name = model_name

        if isinstance(provider, str):
            provider = infer_provider('gateway/google-vertex' if provider == 'gateway' else provider)
        self._provider = provider
        self.client = provider.client

        super().__init__(settings=settings, profile=profile or provider.model_profile)

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:1287-1377
    def tool_plain(
        self,
        func: ToolFuncPlain[ToolParams] | None = None,
        /,
        *,
        name: str | None = None,
        description: str | None = None,
        retries: int | None = None,
        prepare: ToolPrepareFunc[AgentDepsT] | None = None,
        docstring_format: DocstringFormat = 'auto',
        require_parameter_descriptions: bool = False,
        schema_generator: type[GenerateJsonSchema] = GenerateToolJsonSchema,
        strict: bool | None = None,
        sequential: bool = False,
        requires_approval: bool = False,
        metadata: dict[str, Any] | None = None,
        timeout: float | None = None,
    ) -> Any:
        """Decorator to register a tool function which DOES NOT take `RunContext` as an argument.

        Can decorate a sync or async functions.

        The docstring is inspected to extract both the tool description and description of each parameter,
        [learn more](../tools.md#function-tools-and-schema).

        We can't add overloads for every possible signature of tool, since the return type is a recursive union
        so the signature of functions decorated with `@agent.tool` is obscured.

        Example:
        ```python
        from pydantic_ai import Agent, RunContext

        agent = Agent('test')

        @agent.tool
        def foobar(ctx: RunContext[int]) -> int:
            return 123

        @agent.tool(retries=2)
        async def spam(ctx: RunContext[str]) -> float:
            return 3.14

        result = agent.run_sync('foobar', deps=1)
        print(result.output)
        #> {"foobar":123,"spam":3.14}
        ```

        Args:
            func: The tool function to register.
            name: The name of the tool, defaults to the function name.
            description: The description of the tool, defaults to the function docstring.
            retries: The number of retries to allow for this tool, defaults to the agent's default retries,
                which defaults to 1.
            prepare: custom method to prepare the tool definition for each step, return `None` to omit this
                tool from a given step. This is useful if you want to customise a tool at call time,
                or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].
            docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].
                Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.
            require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.
            schema_generator: The JSON schema generator class to use for this tool. Defaults to `GenerateToolJsonSchema`.
            strict: Whether to enforce JSON schema compliance (only affects OpenAI).
                See [`ToolDefinition`][pydantic_ai.tools.ToolDefinition] for more info.
            sequential: Whether the function requires a sequential/serial execution environment. Defaults to False.
            requires_approval: Whether this tool requires human-in-the-loop approval. Defaults to False.
                See the [tools documentation](../deferred-tools.md#human-in-the-loop-tool-approval) for more info.
            metadata: Optional metadata for the tool. This is not sent to the model but can be used for filtering and tool behavior customization.
            timeout: Timeout in seconds for tool execution. If the tool takes longer, a retry prompt is returned to the model.
                Overrides the agent-level `tool_timeout` if set. Defaults to None (no timeout).
        """

        def tool_decorator(func_: ToolFuncPlain[ToolParams]) -> ToolFuncPlain[ToolParams]:
            # noinspection PyTypeChecker
            self._function_toolset.add_function(
                func_,
                takes_ctx=False,
                name=name,
                description=description,
                retries=retries,
                prepare=prepare,
                docstring_format=docstring_format,
                require_parameter_descriptions=require_parameter_descriptions,
                schema_generator=schema_generator,
                strict=strict,
                sequential=sequential,
                requires_approval=requires_approval,
                metadata=metadata,
                timeout=timeout,
            )
            return func_

        return tool_decorator if func is None else tool_decorator(func)

# tests/test_deps.py:10-10
    bar: int

# tests/typed_agent.py:26-26
    bar: int

# examples/pydantic_ai_examples/ag_ui/api/agentic_chat.py:8-8
from pydantic_ai import Agent

# examples/pydantic_ai_examples/ag_ui/api/agentic_chat.py:11-11
agent = Agent('openai:gpt-5-mini')

# examples/pydantic_ai_examples/ag_ui/api/agentic_generative_ui.py:11-11
from pydantic_ai import Agent

# examples/pydantic_ai_examples/ag_ui/api/agentic_generative_ui.py:53-69
agent = Agent(
    'openai:gpt-5-mini',
    instructions=dedent(
        """
        When planning use tools only, without any other messages.
        IMPORTANT:
        - Use the `create_plan` tool to set the initial state of the steps
        - Use the `update_plan_step` tool to update the status of each step
        - Do NOT repeat the plan or summarise it in a message
        - Do NOT confirm the creation or updates in a message
        - Do NOT ask the user for additional information or next steps

        Only one plan can be active at a time, so do not call the `create_plan` tool
        again until all the steps in current plan are completed.
        """
    ),
)

# examples/pydantic_ai_examples/ag_ui/api/human_in_the_loop.py:10-10
from pydantic_ai import Agent

# examples/pydantic_ai_examples/ag_ui/api/human_in_the_loop.py:13-25
agent = Agent(
    'openai:gpt-5-mini',
    instructions=dedent(
        """
        When planning tasks use tools only, without any other messages.
        IMPORTANT:
        - Use the `generate_task_steps` tool to display the suggested steps to the user
        - Never repeat the plan, or send a message detailing steps
        - If accepted, confirm the creation of the plan and the number of selected (enabled) steps only
        - If not accepted, ask the user for more information, DO NOT use the `generate_task_steps` tool again
        """
    ),
)

# examples/pydantic_ai_examples/ag_ui/api/predictive_state_updates.py:10-10
from pydantic_ai import Agent, RunContext

# examples/pydantic_ai_examples/ag_ui/api/predictive_state_updates.py:21-21
agent = Agent('openai:gpt-5-mini', deps_type=StateDeps[DocumentState])

# examples/pydantic_ai_examples/ag_ui/api/shared_state.py:11-11
from pydantic_ai import Agent, RunContext

# examples/pydantic_ai_examples/ag_ui/api/shared_state.py:88-88
agent = Agent('openai:gpt-5-mini', deps_type=StateDeps[RecipeSnapshot])

# examples/pydantic_ai_examples/ag_ui/api/tool_based_generative_ui.py:8-8
from pydantic_ai import Agent

# examples/pydantic_ai_examples/ag_ui/api/tool_based_generative_ui.py:11-11
agent = Agent('openai:gpt-5-mini')

# examples/pydantic_ai_examples/bank_support.py:13-13
from pydantic_ai import Agent, RunContext

# examples/pydantic_ai_examples/chat_app.py:28-37
from pydantic_ai import (
    Agent,
    ModelMessage,
    ModelMessagesTypeAdapter,
    ModelRequest,
    ModelResponse,
    TextPart,
    UnexpectedModelBehavior,
    UserPromptPart,
)

# examples/pydantic_ai_examples/chat_app.py:43-43
agent = Agent('openai:gpt-5.2')

# examples/pydantic_ai_examples/data_analyst.py:7-7
from pydantic_ai import Agent, ModelRetry, RunContext

# examples/pydantic_ai_examples/evals/agent.py:6-6
from pydantic_ai import Agent, RunContext

# examples/pydantic_ai_examples/flight_booking.py:14-21
from pydantic_ai import (
    Agent,
    ModelMessage,
    ModelRetry,
    RunContext,
    RunUsage,
    UsageLimits,
)

# examples/pydantic_ai_examples/pydantic_model.py:13-13
from pydantic_ai import Agent

# examples/pydantic_ai_examples/pydantic_model.py:27-27
agent = Agent(model, output_type=MyModel)

# examples/pydantic_ai_examples/question_graph.py:16-16
from pydantic_ai import Agent, ModelMessage, format_as_xml

# examples/pydantic_ai_examples/rag.py:38-38
from pydantic_ai import Agent, RunContext

# examples/pydantic_ai_examples/rag.py:52-52
agent = Agent('openai:gpt-5.2', deps_type=Deps)

# examples/pydantic_ai_examples/roulette_wheel.py:13-13
from pydantic_ai import Agent, RunContext

# examples/pydantic_ai_examples/slack_lead_qualifier/agent.py:7-7
from pydantic_ai import Agent, NativeOutput

# examples/pydantic_ai_examples/slack_lead_qualifier/agent.py:13-40
agent = Agent(
    'openai:gpt-5.2',
    instructions=dedent(
        """
        When a new person joins our public Slack, please put together a brief snapshot so we can be most useful to them.

        **What to include**

        1. **Who they are:**  Any details about their professional role or projects (e.g. LinkedIn, GitHub, company bio).
        2. **Where they work:**  Name of the organisation and its domain.
        3. **How we can help:**  On a scale of 1–5, estimate how likely they are to benefit from **Pydantic Logfire**
           (our paid observability tool) based on factors such as company size, product maturity, or AI usage.
           *1 = probably not relevant, 5 = very strong fit.*

        **Our products (for context only)**
        • **Pydantic Validation** – Python data-validation (open source)
        • **Pydantic AI** – Python agent framework (open source)
        • **Pydantic Logfire** – Observability for traces, logs & metrics with first-class AI support (commercial)

        **How to research**

        • Use the provided DuckDuckGo search tool to research the person and the organization they work for, based on the email domain or what you find on e.g. LinkedIn and GitHub.
        • If you can't find enough to form a reasonable view, return **None**.
        """
    ),
    tools=[duckduckgo_search_tool()],
    output_type=NativeOutput([Analysis, NoneType]),
)  ### [/agent]

# examples/pydantic_ai_examples/sql_gen.py:27-27
from pydantic_ai import Agent, ModelRetry, RunContext, format_as_xml

# examples/pydantic_ai_examples/sql_gen.py:94-99
agent = Agent[Deps, Response](
    'google-gla:gemini-3-flash-preview',
    # Type ignore while we wait for PEP-0747, nonetheless unions will work fine everywhere else
    output_type=Response,  # type: ignore
    deps_type=Deps,
)

# examples/pydantic_ai_examples/stream_markdown.py:18-18
from pydantic_ai import Agent

# examples/pydantic_ai_examples/stream_markdown.py:25-25
agent = Agent()

# examples/pydantic_ai_examples/stream_whales.py:20-20
from pydantic_ai import Agent

# examples/pydantic_ai_examples/stream_whales.py:42-42
agent = Agent('openai:gpt-5.2', output_type=list[Whale])

# examples/pydantic_ai_examples/weather_agent.py:22-22
from pydantic_ai import Agent, RunContext

# pydantic_ai_slim/pydantic_ai/__init__.py:3-11
from .agent import (
    Agent,
    CallToolsNode,
    EndStrategy,
    InstrumentationSettings,
    ModelRequestNode,
    UserPromptNode,
    capture_run_messages,
)

# pydantic_ai_slim/pydantic_ai/_cli/__init__.py:18-18
from ..agent import AbstractAgent, Agent

# pydantic_ai_slim/pydantic_ai/_cli/web.py:5-5
from pydantic_ai import Agent

# pydantic_ai_slim/pydantic_ai/direct.py:22-22
from . import agent, messages, models, settings

# pydantic_ai_slim/pydantic_ai/ui/_web/api.py:13-13
from pydantic_ai import Agent

# pydantic_ai_slim/pydantic_ai/ui/_web/app.py:11-11
from pydantic_ai import Agent

# pydantic_evals/pydantic_evals/evaluators/llm_as_a_judge.py:10-10
from pydantic_ai import Agent, UserContent, models

# pydantic_evals/pydantic_evals/generation.py:16-16
from pydantic_ai import Agent, models

# tests/conftest.py:27-27
from pydantic_ai import Agent, BinaryContent, BinaryImage, Embedder

# tests/ext/test_langchain.py:8-8
from pydantic_ai import Agent

# tests/models/anthropic/test_output.py:22-22
from pydantic_ai import Agent

# tests/models/test_anthropic.py:18-47
from pydantic_ai import (
    Agent,
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentUrl,
    FinalResultEvent,
    ImageUrl,
    ModelAPIError,
    ModelHTTPError,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    ModelRetry,
    PartDeltaEvent,
    PartEndEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolCallPartDelta,
    ToolReturnPart,
    UsageLimitExceeded,
    UserPromptPart,
)

# tests/models/test_bedrock.py:39-39
from pydantic_ai.agent import Agent

# tests/models/test_cerebras.py:7-7
from pydantic_ai import Agent, ModelRequest, TextPart

# tests/models/test_cohere.py:12-27
from pydantic_ai import (
    Agent,
    ImageUrl,
    ModelAPIError,
    ModelHTTPError,
    ModelRequest,
    ModelResponse,
    ModelRetry,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
)

# tests/models/test_deepseek.py:8-15
from pydantic_ai import (
    Agent,
    ModelRequest,
    ModelResponse,
    TextPart,
    ThinkingPart,
    UserPromptPart,
)

# tests/models/test_fallback.py:15-27
from pydantic_ai import (
    Agent,
    ModelAPIError,
    ModelHTTPError,
    ModelMessage,
    ModelProfile,
    ModelRequest,
    ModelResponse,
    TextPart,
    ToolCallPart,
    ToolDefinition,
    UserPromptPart,
)

# tests/models/test_gemini.py:19-36
from pydantic_ai import (
    Agent,
    BinaryContent,
    DocumentUrl,
    ImageUrl,
    ModelRequest,
    ModelResponse,
    ModelRetry,
    RetryPromptPart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UnexpectedModelBehavior,
    UserError,
    UserPromptPart,
    VideoUrl,
)

# tests/models/test_gemini_vertex.py:9-19
from pydantic_ai import (
    Agent,
    AudioUrl,
    DocumentUrl,
    ImageUrl,
    ModelRequest,
    ModelResponse,
    TextPart,
    UserPromptPart,
    VideoUrl,
)

# tests/models/test_google.py:54-54
from pydantic_ai.agent import Agent

# tests/models/test_groq.py:18-43
from pydantic_ai import (
    Agent,
    BinaryContent,
    BinaryImage,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    FinalResultEvent,
    ImageUrl,
    ModelAPIError,
    ModelHTTPError,
    ModelRequest,
    ModelResponse,
    ModelRetry,
    PartDeltaEvent,
    PartEndEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
)

# tests/models/test_huggingface.py:15-33
from pydantic_ai import (
    Agent,
    AudioUrl,
    BinaryContent,
    CachePoint,
    DocumentUrl,
    ImageUrl,
    ModelRequest,
    ModelResponse,
    ModelRetry,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
    VideoUrl,
)

# tests/models/test_mcp_sampling.py:10-10
from pydantic_ai.agent import Agent

# tests/models/test_mistral.py:31-31
from pydantic_ai.agent import Agent

# tests/models/test_model_function.py:12-24
from pydantic_ai import (
    Agent,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    ModelRetry,
    RunContext,
    SystemPromptPart,
    TextPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
)

# tests/models/test_model_settings.py:7-7
from pydantic_ai import Agent

# tests/models/test_model_test.py:17-32
from pydantic_ai import (
    Agent,
    AudioUrl,
    BinaryContent,
    ImageUrl,
    ModelRequest,
    ModelResponse,
    ModelRetry,
    RetryPromptPart,
    RunContext,
    TextPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
    VideoUrl,
)

# tests/models/test_openai.py:19-40
from pydantic_ai import (
    Agent,
    AudioUrl,
    BinaryContent,
    CachePoint,
    DocumentUrl,
    ImageUrl,
    ModelAPIError,
    ModelHTTPError,
    ModelProfile,
    ModelRequest,
    ModelResponse,
    ModelRetry,
    RetryPromptPart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UnexpectedModelBehavior,
    UserError,
    UserPromptPart,
)

# tests/models/test_openrouter.py:11-27
from pydantic_ai import (
    Agent,
    BinaryContent,
    DocumentUrl,
    ModelHTTPError,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    PartEndEvent,
    PartStartEvent,
    RunUsage,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolDefinition,
    UnexpectedModelBehavior,
)

# tests/models/test_outlines.py:18-18
from pydantic_ai import Agent, ModelRetry, UnexpectedModelBehavior

# tests/models/test_xai.py:29-60
from pydantic_ai import (
    Agent,
    AudioUrl,
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CodeExecutionTool,
    DocumentUrl,
    FilePart,
    FinalResultEvent,
    ImageUrl,
    MCPServerTool,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    ModelRetry,
    PartDeltaEvent,
    PartEndEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolCallPartDelta,
    ToolReturnPart,
    UserPromptPart,
    VideoUrl,
    WebSearchTool,
)

# tests/providers/test_azure.py:8-8
from pydantic_ai.agent import Agent

# tests/providers/test_gateway.py:12-12
from pydantic_ai import Agent, UserError

# tests/providers/test_google_vertex.py:15-15
from pydantic_ai.agent import Agent

# tests/providers/test_heroku.py:7-7
from pydantic_ai.agent import Agent

# tests/providers/test_openrouter.py:9-9
from pydantic_ai.agent import Agent

# tests/test_a2a.py:12-23
from pydantic_ai import (
    Agent,
    BinaryContent,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    TextPart as PydanticAITextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
)

# tests/test_ag_ui.py:45-45
from pydantic_ai.agent import Agent, AgentRunResult

# tests/test_agent.py:18-52
from pydantic_ai import (
    AbstractToolset,
    Agent,
    AgentStreamEvent,
    AudioUrl,
    BinaryContent,
    BinaryImage,
    CallDeferred,
    CombinedToolset,
    DocumentUrl,
    ExternalToolset,
    FunctionToolset,
    ImageUrl,
    IncompleteToolCall,
    ModelMessage,
    ModelMessagesTypeAdapter,
    ModelProfile,
    ModelRequest,
    ModelResponse,
    ModelResponsePart,
    ModelRetry,
    PrefixedToolset,
    RetryPromptPart,
    RunContext,
    SystemPromptPart,
    TextPart,
    ToolCallPart,
    ToolReturn,
    ToolReturnPart,
    UnexpectedModelBehavior,
    UserError,
    UserPromptPart,
    VideoUrl,
    capture_run_messages,
)

# tests/test_agent_output_schemas.py:5-14
from pydantic_ai import (
    Agent,
    BinaryImage,
    DeferredToolRequests,
    NativeOutput,
    PromptedOutput,
    StructuredDict,
    TextOutput,
    ToolOutput,
)

# tests/test_builtin_tools.py:6-6
from pydantic_ai.agent import Agent

# tests/test_cli.py:14-14
from pydantic_ai import Agent, ModelMessage, ModelResponse, TextPart, ToolCallPart

# tests/test_concurrency.py:12-12
from pydantic_ai import Agent, ConcurrencyLimit, ConcurrencyLimiter, ConcurrencyLimitExceeded

# tests/test_deps.py:3-3
from pydantic_ai import Agent, RunContext

# tests/test_deps.py:13-13
agent = Agent(TestModel(), deps_type=MyDeps)

# tests/test_direct.py:10-10
from pydantic_ai import Agent