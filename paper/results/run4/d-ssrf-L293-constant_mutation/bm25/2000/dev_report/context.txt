# tests/models/test_mistral.py:2278-2290
async def test_txt_url_input(allow_model_requests: None):
    c = completion_message(MistralAssistantMessage(content='world', role='assistant'))
    mock_client = MockMistralAI.create_mock(c)
    m = MistralModel('mistral-large-latest', provider=MistralProvider(mistral_client=mock_client))
    agent = Agent(m)

    with pytest.raises(RuntimeError, match='DocumentUrl other than PDF is not supported in Mistral.'):
        await agent.run(
            [
                'hello',
                DocumentUrl(url='https://examplefiles.org/files/documents/plaintext-example-file-download.txt'),
            ]
        )

# tests/test_examples.py:67-67
    known_local_folder: list[str] = field(default_factory=list[str])

# docs/.hooks/test_snippets.py:403-494
def test_complicated_example():
    """Test extracting multiple overlapping sections."""
    content = """line 1
### [fragment1]
line 2
### [fragment2]
line 3
### [highlight1,highlight2]
line 4
### [/fragment1,/highlight1]
line 5
### [/fragment2]
line 6
### [/highlight2]
"""

    with temp_text_file(content) as temp_path:
        parsed = parse_file_sections(temp_path)

    assert parsed.render([], []) == snapshot(
        RenderedSnippet(
            content="""\
line 1
line 2
line 3
line 4
line 5
line 6\
""",
            highlights=[],
            original_range=LineRange(start_line=0, end_line=11),
        )
    )

    assert parsed.render(['fragment1'], ['highlight1']) == snapshot(
        RenderedSnippet(
            content="""\
line 2
line 3
line 4

...\
""",
            highlights=[LineRange(start_line=2, end_line=3)],
            original_range=LineRange(start_line=2, end_line=7),
        )
    )

    assert parsed.render(['fragment1'], ['highlight2']) == snapshot(
        RenderedSnippet(
            content="""\
line 2
line 3
line 4

...\
""",
            highlights=[LineRange(start_line=2, end_line=5)],
            original_range=LineRange(start_line=2, end_line=7),
        )
    )

    assert parsed.render(['fragment2'], ['highlight2']) == snapshot(
        RenderedSnippet(
            content="""\
...

line 3
line 4
line 5

...\
""",
            highlights=[LineRange(start_line=2, end_line=5)],
            original_range=LineRange(start_line=4, end_line=9),
        )
    )

    assert parsed.render(['fragment1', 'fragment2'], []) == snapshot(
        RenderedSnippet(
            content="""\
line 2
line 3
line 4
line 5

...\
""",
            highlights=[],
            original_range=LineRange(start_line=2, end_line=9),
        )
    )

# tests/test_ssrf.py:290-293
    def test_relative_path(self) -> None:
        """Test that relative paths are resolved against the current URL."""
        result = resolve_redirect_url('https://example.com/old/path', 'new-file.txt')
        assert result == 'https://example.com/old/new-file.txt'

# docs/.hooks/main.py:89-95
def sub_example(m: re.Match[str]) -> str:
    example_path = EXAMPLES_DIR / m.group(1)
    content = example_path.read_text(encoding='utf-8').strip()
    # remove leading docstring which duplicates what's in the docs page
    content = re.sub(r'^""".*?"""', '', content, count=1, flags=re.S).strip()

    return content

# tests/test_examples.py:19-19
from pytest_examples import CodeExample, EvalExample, find_examples

# tests/test_examples.py:19-19
from pytest_examples import CodeExample, EvalExample, find_examples

# tests/test_format_as_xml.py:30-32
class ExampleEnum(Enum):
    FOO = 1
    BAR = 2

# docs/.hooks/main.py:82-82
EXAMPLES_DIR = Path(__file__).parent.parent.parent / 'examples'

# examples/pydantic_ai_examples/sql_gen.py:53-70
SQL_EXAMPLES = [
    {
        'request': 'show me records where foobar is false',
        'response': "SELECT * FROM records WHERE attributes->>'foobar' = false",
    },
    {
        'request': 'show me records where attributes include the key "foobar"',
        'response': "SELECT * FROM records WHERE attributes ? 'foobar'",
    },
    {
        'request': 'show me records from yesterday',
        'response': "SELECT * FROM records WHERE start_timestamp::date > CURRENT_TIMESTAMP - INTERVAL '1 day'",
    },
    {
        'request': 'show me error records with the tag "foobar"',
        'response': "SELECT * FROM records WHERE level = 'error' and 'foobar' = ANY(tags)",
    },
]

# tests/test_deps.py:17-18
async def example_tool(ctx: RunContext[MyDeps]) -> str:
    return f'{ctx.deps}'

# tests/evals/test_dataset.py:89-103
def example_cases() -> list[Case[TaskInput, TaskOutput, TaskMetadata]]:
    return [
        Case(
            name='case1',
            inputs=TaskInput(query='What is 2+2?'),
            expected_output=TaskOutput(answer='4'),
            metadata=TaskMetadata(difficulty='easy'),
        ),
        Case(
            name='case2',
            inputs=TaskInput(query='What is the capital of France?'),
            expected_output=TaskOutput(answer='Paris'),
            metadata=TaskMetadata(difficulty='medium', category='geography'),
        ),
    ]

# tests/models/test_gemini.py:547-548
def example_usage() -> _GeminiUsageMetaData:
    return _GeminiUsageMetaData(prompt_token_count=1, candidates_token_count=2, total_token_count=3)

# tests/test_examples.py:19-19
from pytest_examples import CodeExample, EvalExample, find_examples

# tests/test_examples.py:61-61
code_examples: dict[str, CodeExample] = {}

# pydantic_ai_slim/pydantic_ai/models/gemini.py:701-705
class _GeminiFileData(_BasePart):
    """See <https://ai.google.dev/api/caching#FileData>."""

    file_uri: Annotated[str, pydantic.Field(alias='fileUri')]
    mime_type: Annotated[str, pydantic.Field(alias='mimeType')]

# tests/test_examples.py:65-75
class ExamplesConfig(BaseExamplesConfig):
    known_first_party: list[str] = field(default_factory=list[str])
    known_local_folder: list[str] = field(default_factory=list[str])

    def ruff_config(self) -> tuple[str, ...]:
        config = super().ruff_config()
        if self.known_first_party:  # pragma: no branch
            config = (*config, '--config', f'lint.isort.known-first-party = {self.known_first_party}')
        if self.known_local_folder:
            config = (*config, '--config', f'lint.isort.known-local-folder = {self.known_local_folder}')
        return config

# tests/test_format_as_xml.py:35-37
class ExampleStrEnum(str, Enum):
    FOO = 'foo'
    BAR = 'bar'

# docs/.hooks/main.py:85-86
def render_examples(markdown: str) -> str:
    return re.sub(r'^#! *examples/(.+)', sub_example, markdown, flags=re.M)

# tests/evals/test_dataset.py:107-110
def example_dataset(
    example_cases: list[Case[TaskInput, TaskOutput, TaskMetadata]],
) -> Dataset[TaskInput, TaskOutput, TaskMetadata]:
    return Dataset[TaskInput, TaskOutput, TaskMetadata](name='example', cases=example_cases)

# pydantic_graph/pydantic_graph/persistence/file.py:57-63
    async def snapshot_node_if_new(
        self, snapshot_id: str, state: StateT, next_node: BaseNode[StateT, Any, RunEndT]
    ) -> None:
        async with self._lock():
            snapshots = await self.load_all()
            if not any(s.id == snapshot_id for s in snapshots):  # pragma: no branch
                await self._append_save(NodeSnapshot(state=state, node=next_node), lock=False)

# tests/test_format_as_xml.py:20-22
class ExampleDataclass:
    name: str
    age: int

# tests/test_examples.py:20-20
from pytest_examples.config import ExamplesConfig as BaseExamplesConfig

# docs/.hooks/snippets.py:8-8
PYDANTIC_AI_EXAMPLES_ROOT = REPO_ROOT / 'examples' / 'pydantic_ai_examples'

# tests/test_format_as_xml.py:31-31
    FOO = 1