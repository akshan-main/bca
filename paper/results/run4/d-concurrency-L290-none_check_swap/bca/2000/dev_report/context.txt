## tests/test_concurrency.py

pytestmark = pytest.mark.anyio

class AsyncBarrier:
    """A simple asyncio.Barrier-like implementation compatible with Python 3.10 using anyio."""

    def __init__(self, parties: int):
        self._parties = parties
        self._count = 0
        self._lock = anyio.Lock()
        self._event = anyio.Event()

    async def wait(self) -> None:
        async with self._lock:
            self._count += 1
            if self._count >= self._parties:
                self._event.set()
        await self._event.wait()

    async def wait(self) -> None:
        async with self._lock:
            self._count += 1
            if self._count >= self._parties:
                self._event.set()
        await self._event.wait()

    async def test_backpressure_raises(self):
        """Test that exceeding max_queued raises ConcurrencyLimitExceeded."""
        limiter = ConcurrencyLimiter(max_running=1, max_queued=2)
        hold = anyio.Event()

        async def holder():
            async with get_concurrency_context(limiter, 'test'):
                await hold.wait()

        async with anyio.create_task_group() as tg:
            # Fill the running slot
            tg.start_soon(holder)
            await anyio.sleep(0.01)

            # Fill the queue (2 allowed)
            tg.start_soon(holder)
            tg.start_soon(holder)
            await anyio.sleep(0.01)

            # This should raise - queue is full
            with pytest.raises(ConcurrencyLimitExceeded):
                async with get_concurrency_context(limiter, 'test'):
                    pass

            hold.set()

    async def test_backpressure_race_condition(self):
        """Test that max_queued is enforced atomically under concurrent load.

        This test verifies the fix for a race condition where multiple tasks could
        simultaneously pass the max_queued check before any of them actually started
        waiting on the limiter.
        """
        limiter = ConcurrencyLimiter(max_running=1, max_queued=1)
        hold = anyio.Event()
        started = anyio.Event()

        async def holder():
            async with get_concurrency_context(limiter, 'holder'):
                started.set()
                await hold.wait()

        # Now launch multiple tasks simultaneously that all try to queue.
        # With max_queued=1, exactly one should succeed in queuing.
        num_concurrent = 5
        results: list[str] = []
        barrier = AsyncBarrier(num_concurrent)

        async def try_acquire(idx: int):
            # Use barrier to ensure all tasks try to acquire at the same time
            await barrier.wait()
            try:
                async with get_concurrency_context(limiter, f'task-{idx}'):
                    results.append(f'acquired-{idx}')
            except ConcurrencyLimitExceeded:
                results.append(f'rejected-{idx}')

        async with anyio.create_task_group() as tg:
            # Fill the running slot and wait for it to be held
            tg.start_soon(holder)
            await started.wait()

            # Launch all tasks simultaneously
            for i in range(num_concurrent):
                tg.start_soon(try_acquire, i)
            await anyio.sleep(0.1)  # Give tasks time to hit the barrier and try to acquire

            # Release the holder
            hold.set()

        # Verify: exactly one task should have been allowed to queue and acquire
        # The rest should have been rejected
        acquired = [r for r in results if r.startswith('acquired-')]
        rejected = [r for r in results if r.startswith('rejected-')]
        assert len(acquired) == 1, f'Expected exactly 1 acquired, got {len(acquired)}: {acquired}'
        assert len(rejected) == num_concurrent - 1, f'Expected {num_concurrent - 1} rejected, got {len(rejected)}'

class TestGetConcurrencyContext:
    """Tests for the get_concurrency_context helper."""

    async def test_returns_context_when_provided(self):
        """Test that get_concurrency_context returns a working context."""
        limiter = ConcurrencyLimiter(max_running=1)
        async with get_concurrency_context(limiter, 'test'):
            pass  # Should acquire and release

    async def test_returns_null_context_when_none(self):
        """Test that get_concurrency_context returns a no-op context when None."""
        async with get_concurrency_context(None, 'test'):
            pass  # Should be a no-op

    async def test_agent_concurrency_backpressure(self):
        """Test that agent raises when queue exceeds max_queued."""
        agent = Agent(TestModel(), max_concurrency=ConcurrencyLimit(max_running=1, max_queued=1))
        hold = anyio.Event()

        @agent.tool_plain
        async def hold_tool() -> str:
            await hold.wait()
            return 'done'

        async def run_agent():
            await agent.run('x', model=TestModel(call_tools=['hold_tool']))

        async with anyio.create_task_group() as tg:
            # Start 2 runs (1 running + 1 queued = at limit)
            tg.start_soon(run_agent)
            tg.start_soon(run_agent)
            await anyio.sleep(0.05)

            # Third should raise
            with pytest.raises(ConcurrencyLimitExceeded):
                await agent.run('x', model=TestModel(call_tools=['hold_tool']))

            hold.set()

class TestConcurrencyLimiterWithTracer:
    """Tests for ConcurrencyLimiter with custom tracer."""

    async def test_custom_tracer_is_stored(self):
        """Test that custom tracer is stored and returned by _get_tracer."""
        from opentelemetry.trace import NoOpTracer

        custom_tracer = NoOpTracer()
        limiter = ConcurrencyLimiter(max_running=5, tracer=custom_tracer)

        # Verify the tracer is stored and returned
        assert limiter._get_tracer() is custom_tracer

    async def test_from_limit_with_tracer(self):
        """Test that from_limit passes tracer to the created limiter."""
        from opentelemetry.trace import NoOpTracer

        custom_tracer = NoOpTracer()
        limiter = ConcurrencyLimiter.from_limit(5, tracer=custom_tracer)
        assert limiter._get_tracer() is custom_tracer

class TestConcurrencyLimitedModelMethods:
    """Tests for ConcurrencyLimitedModel count_tokens and request_stream methods."""

    async def test_count_tokens(self):
        """Test that count_tokens delegates to wrapped model with concurrency limiting."""
        from unittest.mock import AsyncMock

        from pydantic_ai.models import ModelRequestParameters
        from pydantic_ai.models.concurrency import ConcurrencyLimitedModel
        from pydantic_ai.usage import RequestUsage

        base_model = TestModel()
        # Mock count_tokens to return a value
        base_model.count_tokens = AsyncMock(return_value=RequestUsage())
        model = ConcurrencyLimitedModel(base_model, limiter=5)

        # count_tokens should delegate to wrapped model
        usage = await model.count_tokens([], None, ModelRequestParameters())
        assert usage is not None
        base_model.count_tokens.assert_called_once()

    async def test_request_stream(self):
        """Test that request_stream is called with concurrency limiting."""
        from pydantic_ai.models import ModelRequestParameters
        from pydantic_ai.models.concurrency import ConcurrencyLimitedModel

        base_model = TestModel()
        model = ConcurrencyLimitedModel(base_model, limiter=5)

        # request_stream should work
        async with model.request_stream([], None, ModelRequestParameters()) as stream:
            # Consume the stream
            async for _ in stream:
                pass
