# tests/test_direct.py:216-229
def test_prepare_model():
    with set_instrument_default(False):
        model = _prepare_model('test', None)
        assert isinstance(model, TestModel)

        model = _prepare_model('test', True)
        assert isinstance(model, InstrumentedModel)

    with set_instrument_default(True):
        model = _prepare_model('test', None)
        assert isinstance(model, InstrumentedModel)

        model = _prepare_model('test', False)
        assert isinstance(model, TestModel)

# pydantic_evals/pydantic_evals/evaluators/__init__.py:1-10
from .common import (
    Contains,
    Equals,
    EqualsExpected,
    HasMatchingSpan,
    IsInstance,
    LLMJudge,
    MaxDuration,
    OutputConfig,
)

# tests/models/test_anthropic.py:60-60
from ..conftest import IsDatetime, IsInstance, IsNow, IsStr, TestEnv, raise_if_exception, try_import

# tests/models/test_bedrock.py:54-54
from ..conftest import IsDatetime, IsInstance, IsNow, IsStr, try_import

# tests/models/test_cohere.py:33-33
from ..conftest import IsDatetime, IsInstance, IsNow, IsStr, raise_if_exception, try_import

# tests/models/test_download_item.py:6-6
from ..conftest import IsInstance, IsStr

# tests/models/test_gemini_vertex.py:23-23
from ..conftest import IsDatetime, IsInstance, IsStr, try_import

# tests/models/test_google.py:79-79
from ..conftest import IsDatetime, IsInstance, IsNow, IsStr, try_import

# tests/models/test_groq.py:52-52
from ..conftest import IsDatetime, IsInstance, IsStr, raise_if_exception, try_import

# tests/models/test_huggingface.py:41-41
from ..conftest import IsDatetime, IsInstance, IsNow, IsStr, raise_if_exception, try_import

# tests/models/test_outlines.py:42-42
from ..conftest import IsDatetime, IsInstance, IsStr, try_import

# tests/models/test_xai.py:73-73
from ..conftest import IsDatetime, IsInstance, IsNow, IsStr, try_import

# tests/test_cli.py:8-8
from dirty_equals import IsInstance, IsStr

# tests/test_mcp.py:47-47
from .conftest import IsDatetime, IsInstance, IsNow, IsStr, try_import

# pydantic_ai_slim/pydantic_ai/direct.py:270-279
def _prepare_model(
    model: models.Model | models.KnownModelName | str,
    instrument: instrumented_models.InstrumentationSettings | bool | None,
) -> models.Model:
    model_instance = models.infer_model(model)

    if instrument is not None:
        instrument = agent.Agent._instrument_default  # pyright: ignore[reportPrivateUsage]

    return instrumented_models.instrument_model(model_instance, instrument)

# pydantic_ai_slim/pydantic_ai/models/test.py:92-111
    def __init__(
        self,
        *,
        call_tools: list[str] | Literal['all'] = 'all',
        custom_output_text: str | None = None,
        custom_output_args: Any | None = None,
        seed: int = 0,
        model_name: str = 'test',
        profile: ModelProfileSpec | None = None,
        settings: ModelSettings | None = None,
    ):
        """Initialize TestModel with optional settings and profile."""
        self.call_tools = call_tools
        self.custom_output_text = custom_output_text
        self.custom_output_args = custom_output_args
        self.seed = seed
        self.last_model_request_parameters = None
        self._model_name = model_name
        self._system = 'test'
        super().__init__(settings=settings, profile=profile)

# tests/test_direct.py:11-18
from pydantic_ai.direct import (
    StreamedResponseSync,
    _prepare_model,  # pyright: ignore[reportPrivateUsage]
    model_request,
    model_request_stream,
    model_request_stream_sync,
    model_request_sync,
)

# examples/pydantic_ai_examples/pydantic_model.py:25-25
model = os.getenv('PYDANTIC_AI_MODEL', 'openai:gpt-5.2')

# pydantic_ai_slim/pydantic_ai/ag_ui.py:18-18
from .models import KnownModelName, Model

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_agent.py:29-29
from pydantic_ai.models import Model

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_agent.py:25-25
from pydantic_ai.models import Model

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_agent.py:30-30
from pydantic_ai.models import Model

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_model.py:19-19
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/models/anthropic.py:52-52
from . import Model, ModelRequestParameters, StreamedResponse, check_allow_model_requests, download_item, get_user_agent

# pydantic_ai_slim/pydantic_ai/models/bedrock.py:46-46
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse, download_item

# pydantic_ai_slim/pydantic_ai/models/cohere.py:34-34
from . import Model, ModelRequestParameters, check_allow_model_requests

# pydantic_ai_slim/pydantic_ai/models/concurrency.py:22-22
from . import KnownModelName, Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/models/fallback.py:16-16
from . import KnownModelName, Model, ModelRequestParameters, StreamedResponse, infer_model

# pydantic_ai_slim/pydantic_ai/models/function.py:39-39
from . import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/models/gemini.py:53-53
from . import Model, ModelRequestParameters, StreamedResponse, check_allow_model_requests, download_item, get_user_agent

# pydantic_ai_slim/pydantic_ai/models/google.py:53-60
from . import (
    Model,
    ModelRequestParameters,
    StreamedResponse,
    check_allow_model_requests,
    download_item,
    get_user_agent,
)

# pydantic_ai_slim/pydantic_ai/models/groq.py:46-52
from . import (
    Model,
    ModelRequestParameters,
    StreamedResponse,
    check_allow_model_requests,
    get_user_agent,
)

# pydantic_ai_slim/pydantic_ai/models/huggingface.py:43-48
from . import (
    Model,
    ModelRequestParameters,
    StreamedResponse,
    check_allow_model_requests,
)

# pydantic_ai_slim/pydantic_ai/models/instrumented.py:35-35
from . import KnownModelName, Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/models/mcp_sampling.py:12-12
from . import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/models/mistral.py:44-51
from . import (
    Model,
    ModelRequestParameters,
    StreamedResponse,
    check_allow_model_requests,
    download_item,
    get_user_agent,
)

# pydantic_ai_slim/pydantic_ai/models/openai.py:64-73
from . import (
    Model,
    ModelRequestParameters,
    OpenAIChatCompatibleProvider,
    OpenAIResponsesCompatibleProvider,
    StreamedResponse,
    check_allow_model_requests,
    download_item,
    get_user_agent,
)

# pydantic_ai_slim/pydantic_ai/models/outlines.py:43-49
from . import (
    DownloadedItem,
    Model,
    ModelRequestParameters,
    StreamedResponse,
    download_item,
)

# pydantic_ai_slim/pydantic_ai/models/test.py:37-37
from . import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/models/wrapper.py:14-14
from . import KnownModelName, Model, ModelRequestParameters, StreamedResponse, infer_model

# pydantic_ai_slim/pydantic_ai/models/xai.py:43-49
from ..models import (
    Model,
    ModelRequestParameters,
    StreamedResponse,
    check_allow_model_requests,
    download_item,
)

# pydantic_ai_slim/pydantic_ai/ui/_adapter.py:27-27
from pydantic_ai.models import KnownModelName, Model

# pydantic_ai_slim/pydantic_ai/ui/_web/api.py:15-15
from pydantic_ai.models import KnownModelName, Model, infer_model

# pydantic_ai_slim/pydantic_ai/ui/ag_ui/app.py:15-15
from pydantic_ai.models import KnownModelName, Model

# tests/conftest.py:28-28
from pydantic_ai.models import Model

# tests/evals/test_evaluators.py:12-12
from pydantic_ai.models import Model, ModelRequestParameters

# tests/models/test_instrumented.py:42-42
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# tests/models/test_model.py:9-9
from pydantic_ai.models import Model, infer_model

# tests/test_a2a.py:48-48
model = FunctionModel(return_string)

# tests/test_builtin_tools.py:16-16
from pydantic_ai.models import Model

# tests/test_dbos.py:129-135
model = OpenAIChatModel(
    'gpt-4o',
    provider=OpenAIProvider(
        api_key=os.getenv('OPENAI_API_KEY', 'mock-api-key'),
        http_client=http_client,
    ),
)

# tests/test_examples.py:44-44
from pydantic_ai.models import KnownModelName, Model, infer_model

# tests/test_mcp.py:42-42
from pydantic_ai.models import Model, cached_async_http_client

# tests/test_prefect.py:119-125
model = OpenAIChatModel(
    'gpt-4o',
    provider=OpenAIProvider(
        api_key=os.getenv('OPENAI_API_KEY', 'mock-api-key'),
        http_client=http_client,
    ),
)

# tests/test_settings.py:6-6
from pydantic_ai.models import Model

# tests/test_temporal.py:50-50
from pydantic_ai.models import Model, ModelRequestParameters, cached_async_http_client

# tests/test_temporal.py:201-207
model = OpenAIChatModel(
    'gpt-4o',
    provider=OpenAIProvider(
        api_key=os.getenv('OPENAI_API_KEY', 'mock-api-key'),
        http_client=http_client,
    ),
)

# pydantic_evals/pydantic_evals/evaluators/common.py:132-147
class IsInstance(Evaluator[object, object, object]):
    """Check if the output is an instance of a type with the given name."""

    type_name: str
    evaluation_name: str | None = field(default=None)

    def evaluate(self, ctx: EvaluatorContext[object, object, object]) -> EvaluationReason:
        output = ctx.output
        for cls in type(output).__mro__:
            if cls.__name__ == self.type_name or cls.__qualname__ == self.type_name:
                return EvaluationReason(value=True)

        reason = f'output is of type {type(output).__name__}'
        if type(output).__qualname__ != type(output).__name__:
            reason += f' (qualname: {type(output).__qualname__})'
        return EvaluationReason(value=False, reason=reason)

# tests/test_mcp.py:83-84
def model(openai_api_key: str) -> Model:
    return OpenAIChatModel('gpt-4o', provider=OpenAIProvider(api_key=openai_api_key))

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_agent.py:216-217
    def model(self) -> Model:
        return self._temporal_model

# pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_agent.py:133-134
    def model(self) -> Model:
        return self._model

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_agent.py:241-242
    def model(self) -> Model:
        return self._model

# pydantic_ai_slim/pydantic_ai/_run_context.py:35-35
    model: Model

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:43-43
from ..models.instrumented import InstrumentationSettings, InstrumentedModel, instrument_model

# pydantic_ai_slim/pydantic_ai/models/fallback.py:12-12
from pydantic_ai.models.instrumented import InstrumentedModel

# tests/models/test_instrumented.py:43-43
from pydantic_ai.models.instrumented import InstrumentationSettings, InstrumentedModel

# tests/models/test_model_settings.py:12-12
from pydantic_ai.models.instrumented import InstrumentedModel

# tests/test_direct.py:32-32
from pydantic_ai.models.instrumented import InstrumentedModel

# tests/test_logfire.py:17-17
from pydantic_ai.models.instrumented import InstrumentationSettings, InstrumentedModel

# pydantic_ai_slim/pydantic_ai/agent/wrapper.py:39-40
    def model(self) -> models.Model | models.KnownModelName | str | None:
        return self.wrapped.model

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:86-88
    def model(self) -> models.Model | models.KnownModelName | str | None:
        """The default model configured for this agent."""
        raise NotImplementedError

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:136-136
    model: models.Model

# tests/models/test_model_function.py:26-26
from pydantic_ai.models.test import TestModel

# tests/models/test_model_settings.py:13-13
from pydantic_ai.models.test import TestModel

# tests/models/test_model_test.py:34-34
from pydantic_ai.models.test import TestModel, _chars, _JsonSchemaTestData  # pyright: ignore[reportPrivateUsage]

# tests/test_ag_ui.py:56-56
from pydantic_ai.models.test import TestModel

# tests/test_agent.py:69-69
from pydantic_ai.models.test import TestModel

# tests/test_cli.py:15-15
from pydantic_ai.models.test import TestModel

# tests/test_concurrency.py:14-14
from pydantic_ai.models.test import TestModel

# tests/test_dbos.py:36-36
from pydantic_ai.models.test import TestModel

# tests/test_deps.py:4-4
from pydantic_ai.models.test import TestModel

# tests/test_direct.py:33-33
from pydantic_ai.models.test import TestModel

# tests/test_examples.py:47-47
from pydantic_ai.models.test import TestModel

# tests/test_fastmcp.py:16-16
from pydantic_ai.models.test import TestModel

# tests/test_logfire.py:18-18
from pydantic_ai.models.test import TestModel

# tests/test_mcp.py:43-43
from pydantic_ai.models.test import TestModel

# tests/test_native_output_schema.py:4-4
from pydantic_ai.models.test import TestModel

# tests/test_prefect.py:33-33
from pydantic_ai.models.test import TestModel

# tests/test_streaming.py:52-52
from pydantic_ai.models.test import TestModel, TestStreamedResponse as ModelTestStreamedResponse

# tests/test_temporal.py:52-52
from pydantic_ai.models.test import TestModel

# tests/test_tools.py:36-36
from pydantic_ai.models.test import TestModel

# tests/test_toolsets.py:27-27
from pydantic_ai.models.test import TestModel

# tests/test_ui.py:44-44
from pydantic_ai.models.test import TestModel

# tests/test_ui_web.py:16-16
from pydantic_ai.models.test import TestModel

# tests/test_usage_limits.py:27-27
from pydantic_ai.models.test import TestModel

# tests/test_vercel_ai.py:46-46
from pydantic_ai.models.test import TestModel

# pydantic_ai_slim/pydantic_ai/models/test.py:82-82
    last_model_request_parameters: ModelRequestParameters | None = field(default=None, init=False)

# pydantic_ai_slim/pydantic_ai/models/test.py:74-74
    call_tools: list[str] | Literal['all'] = 'all'

# pydantic_ai_slim/pydantic_ai/models/test.py:76-76
    custom_output_text: str | None = None

# pydantic_ai_slim/pydantic_ai/models/test.py:78-78
    custom_output_args: Any | None = None

# pydantic_ai_slim/pydantic_ai/models/test.py:80-80
    seed: int = 0

# pydantic_evals/pydantic_evals/evaluators/common.py:194-194
    model: models.Model | models.KnownModelName | str | None = None

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_model.py:264-284
    def resolve_model(self, model: models.Model | models.KnownModelName | str | None = None) -> Model:
        """Resolve a model parameter to a Model instance.

        This is typically used outside of a workflow to resolve model parameters
        before passing them to the underlying agent methods.

        Args:
            model: The model to resolve. Can be a Model instance, model name string,
                   or None for the default model.

        Returns:
            The resolved Model instance.
        """
        # Handle Model instances directly - outside a workflow, unregistered
        # Model instances are allowed since there's no serialization constraint.
        if isinstance(model, Model):
            return model

        # For strings and None, use _get_model_id + _resolve_model
        model_id = self._get_model_id(model)
        return self._resolve_model_id(model_id)

# tests/models/test_huggingface.py:83-83
    model: str = 'https://api-inference.huggingface.co'

# pydantic_ai_slim/pydantic_ai/embeddings/sentence_transformers.py:88-107
    def __init__(self, model: SentenceTransformer | str, *, settings: EmbeddingSettings | None = None) -> None:
        """Initialize a Sentence-Transformers embedding model.

        Args:
            model: The model to use. Can be:

                - A model name from Hugging Face (e.g., `'all-MiniLM-L6-v2'`)
                - A local path to a saved model
                - An existing `SentenceTransformer` instance
            settings: Model-specific
                [`SentenceTransformersEmbeddingSettings`][pydantic_ai.embeddings.sentence_transformers.SentenceTransformersEmbeddingSettings]
                to use as defaults for this model.
        """
        if isinstance(model, str):
            self._model_name = model
        else:
            self._model = deepcopy(model)
            self._model_name = model.model_card_data.model_id or model.model_card_data.base_model or 'unknown'

        super().__init__(settings=settings)

# pydantic_ai_slim/pydantic_ai/models/instrumented.py:380-386
    def __init__(
        self,
        wrapped: Model | KnownModelName,
        options: InstrumentationSettings | None = None,
    ) -> None:
        super().__init__(wrapped)
        self.instrumentation_settings = options or InstrumentationSettings()

# tests/profiles/test_openai.py:26-26
    model: str

# pydantic_ai_slim/pydantic_ai/ui/_web/api.py:51-51
    model: str | None = None

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:1429-1459
    def _get_model(self, model: models.Model | models.KnownModelName | str | None) -> models.Model:
        """Create a model configured for this agent.

        Args:
            model: model to use for this run, required if `model` was not set when creating the agent.

        Returns:
            The model used
        """
        model_: models.Model
        if some_model := self._override_model.get():
            # we don't want `override()` to cover up errors from the model not being defined, hence this check
            if model is None and self.model is None:
                raise exceptions.UserError(
                    '`model` must either be set on the agent or included when calling it. '
                    '(Even when `override(model=...)` is customizing the model that will actually be called)'
                )
            model_ = some_model.value
        elif model is not None:
            model_ = models.infer_model(model)
        elif self.model is not None:
            # noinspection PyTypeChecker
            model_ = self.model = models.infer_model(self.model)
        else:
            raise exceptions.UserError('`model` must either be set on the agent or included when calling it.')

        instrument = self.instrument
        if instrument is None:
            instrument = self._instrument_default

        return instrument_model(model_, instrument)

# pydantic_ai_slim/pydantic_ai/models/__init__.py:631-644
    def __init__(
        self,
        *,
        settings: ModelSettings | None = None,
        profile: ModelProfileSpec | None = None,
    ) -> None:
        """Initialize the model with optional settings and profile.

        Args:
            settings: Model-specific settings that will be used as defaults for this model.
            profile: The model profile to use.
        """
        self._settings = settings
        self._profile = profile

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:431-436
    def model(self, value: models.Model | models.KnownModelName | str | None) -> None:
        """Set the default model configured for this agent.

        We allow `str` here since the actual list of allowed models changes frequently.
        """
        self._model = value

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_model.py:287-297
    def using_model(self, model: models.Model | models.KnownModelName | str | None) -> Iterator[None]:
        """Context manager to set the model for the duration of a block.

        Accepts a Model instance, model name string, or None for the default model.
        """
        model_id = self._get_model_id(model)
        token = self._model_id_var.set(model_id)
        try:
            yield
        finally:
            self._model_id_var.reset(token)

# pydantic_ai_slim/pydantic_ai/embeddings/__init__.py:216-218
    def model(self) -> EmbeddingModel | KnownEmbeddingModelName | str:
        """The embedding model used by this embedder."""
        return self._model

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_model.py:243-262
    def _get_model_id(self, model: models.Model | models.KnownModelName | str | None = None) -> str | None:
        """Get the model ID for the given model parameter.

        Returns a string that will be checked against registered model IDs,
        or passed to infer_model if not found. Returns None to use the default model.
        """
        if model in (None, 'default'):
            return None

        if isinstance(model, Model):
            # Check if this model instance is already registered
            model_id = next((model_id for model_id, m in self._models_by_id.items() if m is model), ...)
            if model_id is ...:
                raise UserError(
                    'Arbitrary model instances cannot be used at runtime inside a Temporal workflow. '
                    'Register the model via `models` or reference a registered model by id.'
                )
            return None if model_id == 'default' else model_id

        return model

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:1613-1629
    def set_mcp_sampling_model(self, model: models.Model | models.KnownModelName | str | None = None) -> None:
        """Set the sampling model on all MCP servers registered with the agent.

        If no sampling model is provided, the agent's model will be used.
        """
        try:
            sampling_model = models.infer_model(model) if model else self._get_model(None)
        except exceptions.UserError as e:
            raise exceptions.UserError('No sampling model provided and no model set on the agent.') from e

        from ..mcp import MCPServer

        def _set_sampling_model(toolset: AbstractToolset[AgentDepsT]) -> None:
            if isinstance(toolset, MCPServer):
                toolset.sampling_model = sampling_model

        self._get_toolset().apply(_set_sampling_model)

# pydantic_evals/pydantic_evals/dataset.py:16-16
import traceback