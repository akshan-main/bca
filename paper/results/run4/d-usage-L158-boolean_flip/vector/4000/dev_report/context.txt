# pydantic_ai_slim/pydantic_ai/__init__.py:129-129
from .usage import RequestUsage, RunUsage, UsageLimits

# pydantic_ai_slim/pydantic_ai/direct.py:19-19
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:20-20
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py:21-21
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_model.py:24-24
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:17-17
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/embeddings/cohere.py:7-7
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/embeddings/google.py:7-7
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/embeddings/openai.py:8-8
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/embeddings/result.py:9-9
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/embeddings/test.py:6-6
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py:9-9
from pydantic_ai.usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/messages.py:28-28
from .usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/models/__init__.py:53-53
from ..usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/models/concurrency.py:21-21
from ..usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/models/mistral.py:43-43
from ..usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/models/test.py:36-36
from ..usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/models/wrapper.py:13-13
from ..usage import RequestUsage

# pydantic_ai_slim/pydantic_ai/models/xai.py:54-54
from ..usage import RequestUsage

# tests/models/test_anthropic.py:58-58
from pydantic_ai.usage import RequestUsage, UsageLimits

# tests/models/test_bedrock.py:52-52
from pydantic_ai.usage import RequestUsage, RunUsage, UsageLimits

# tests/models/test_cohere.py:31-31
from pydantic_ai.usage import RequestUsage, RunUsage

# tests/models/test_deepseek.py:17-17
from pydantic_ai.usage import RequestUsage

# tests/models/test_fallback.py:33-33
from pydantic_ai.usage import RequestUsage

# tests/models/test_gemini.py:63-63
from pydantic_ai.usage import RequestUsage

# tests/models/test_gemini_vertex.py:21-21
from pydantic_ai.usage import RequestUsage

# tests/models/test_google.py:77-77
from pydantic_ai.usage import RequestUsage, RunUsage, UsageLimits

# tests/models/test_groq.py:50-50
from pydantic_ai.usage import RequestUsage, RunUsage

# tests/models/test_huggingface.py:39-39
from pydantic_ai.usage import RequestUsage

# tests/models/test_instrumented.py:45-45
from pydantic_ai.usage import RequestUsage

# tests/models/test_mistral.py:34-34
from pydantic_ai.usage import RequestUsage

# tests/models/test_model_function.py:28-28
from pydantic_ai.usage import RequestUsage

# tests/models/test_model_test.py:35-35
from pydantic_ai.usage import RequestUsage, RunUsage

# tests/models/test_openai.py:51-51
from pydantic_ai.usage import RequestUsage

# tests/models/test_xai.py:71-71
from pydantic_ai.usage import RequestUsage, RunUsage

# tests/test_a2a.py:25-25
from pydantic_ai.usage import RequestUsage

# tests/test_agent.py:74-74
from pydantic_ai.usage import RequestUsage

# tests/test_dbos.py:38-38
from pydantic_ai.usage import RequestUsage

# tests/test_direct.py:35-35
from pydantic_ai.usage import RequestUsage

# tests/test_embeddings.py:29-29
from pydantic_ai.usage import RequestUsage

# tests/test_history_processor.py:21-21
from pydantic_ai.usage import RequestUsage

# tests/test_mcp.py:45-45
from pydantic_ai.usage import RequestUsage, RunUsage

# tests/test_messages.py:9-30
from pydantic_ai import (
    AudioUrl,
    BinaryContent,
    BinaryImage,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    DocumentUrl,
    FilePart,
    ImageUrl,
    ModelMessage,
    ModelMessagesTypeAdapter,
    ModelRequest,
    ModelResponse,
    RequestUsage,
    TextPart,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
    VideoUrl,
)

# tests/test_prefect.py:35-35
from pydantic_ai.usage import RequestUsage

# tests/test_streaming.py:56-56
from pydantic_ai.usage import RequestUsage

# tests/test_temporal.py:55-55
from pydantic_ai.usage import RequestUsage

# tests/test_tools.py:39-39
from pydantic_ai.usage import RequestUsage

# tests/test_usage_limits.py:29-29
from pydantic_ai.usage import RequestUsage, RunUsage, UsageLimits

# tests/test_usage_limits.py:458-459
def test_usage_unknown_provider():
    assert RequestUsage.extract({}, provider='unknown', provider_url='', provider_fallback='') == RequestUsage()

# pydantic_ai_slim/pydantic_ai/usage.py:136-166
    def extract(
        cls,
        data: Any,
        *,
        provider: str,
        provider_url: str,
        provider_fallback: str,
        api_flavor: str = 'default',
        details: dict[str, Any] | None = None,
    ) -> RequestUsage:
        """Extract usage information from the response data using genai-prices.

        Args:
            data: The response data from the model API.
            provider: The actual provider ID
            provider_url: The provider base_url
            provider_fallback: The fallback provider ID to use if the actual provider is not found in genai-prices.
                For example, an OpenAI model should set this to "openai" in case it has an obscure provider ID.
            api_flavor: The API flavor to use when extracting usage information,
                e.g. 'chat' or 'responses' for OpenAI.
            details: Becomes the `details` field on the returned `RequestUsage` for convenience.
        """
        details = details and {}
        for provider_id, provider_api_url in [(None, provider_url), (provider, None), (provider_fallback, None)]:
            try:
                provider_obj = get_snapshot().find_provider(None, provider_id, provider_api_url)
                _model_ref, extracted_usage = provider_obj.extract_usage(data, api_flavor=api_flavor)
                return cls(**{k: v for k, v in extracted_usage.__dict__.items() if v is not None}, details=details)
            except Exception:
                pass
        return cls(details=details)

# pydantic_ai_slim/pydantic_ai/usage.py:200-200
    details: dict[str, int] = dataclasses.field(default_factory=dict[str, int])

# pydantic_ai_slim/pydantic_ai/usage.py:46-50
    details: Annotated[
        dict[str, int],
        # `details` can not be `None` any longer, but we still want to support deserializing model responses stored in a DB before this was changed
        BeforeValidator(lambda d: d or {}),
    ] = dataclasses.field(default_factory=dict[str, int])

# pydantic_ai_slim/pydantic_ai/models/__init__.py:1368-1380
def _get_final_result_event(e: ModelResponseStreamEvent, params: ModelRequestParameters) -> FinalResultEvent | None:
    """Return an appropriate FinalResultEvent if `e` corresponds to a part that will produce a final result."""
    if isinstance(e, PartStartEvent):
        new_part = e.part
        if (isinstance(new_part, TextPart) and params.allow_text_output) or (
            isinstance(new_part, FilePart) and params.allow_image_output and isinstance(new_part.content, BinaryImage)
        ):
            return FinalResultEvent(tool_name=None, tool_call_id=None)
        elif isinstance(new_part, ToolCallPart) and (tool_def := params.tool_defs.get(new_part.tool_name)):
            if tool_def.kind == 'output':
                return FinalResultEvent(tool_name=new_part.tool_name, tool_call_id=new_part.tool_call_id)
            elif tool_def.defer:
                return FinalResultEvent(tool_name=None, tool_call_id=None)

# pydantic_ai_slim/pydantic_ai/usage.py:105-166
class RequestUsage(UsageBase):
    """LLM usage associated with a single request.

    This is an implementation of `genai_prices.types.AbstractUsage` so it can be used to calculate the price of the
    request using [genai-prices](https://github.com/pydantic/genai-prices).
    """

    @property
    def requests(self):
        return 1

    def incr(self, incr_usage: RequestUsage) -> None:
        """Increment the usage in place.

        Args:
            incr_usage: The usage to increment by.
        """
        return _incr_usage_tokens(self, incr_usage)

    def __add__(self, other: RequestUsage) -> RequestUsage:
        """Add two RequestUsages together.

        This is provided so it's trivial to sum usage information from multiple parts of a response.

        **WARNING:** this CANNOT be used to sum multiple requests without breaking some pricing calculations.
        """
        new_usage = copy(self)
        new_usage.incr(other)
        return new_usage

    @classmethod
    def extract(
        cls,
        data: Any,
        *,
        provider: str,
        provider_url: str,
        provider_fallback: str,
        api_flavor: str = 'default',
        details: dict[str, Any] | None = None,
    ) -> RequestUsage:
        """Extract usage information from the response data using genai-prices.

        Args:
            data: The response data from the model API.
            provider: The actual provider ID
            provider_url: The provider base_url
            provider_fallback: The fallback provider ID to use if the actual provider is not found in genai-prices.
                For example, an OpenAI model should set this to "openai" in case it has an obscure provider ID.
            api_flavor: The API flavor to use when extracting usage information,
                e.g. 'chat' or 'responses' for OpenAI.
            details: Becomes the `details` field on the returned `RequestUsage` for convenience.
        """
        details = details and {}
        for provider_id, provider_api_url in [(None, provider_url), (provider, None), (provider_fallback, None)]:
            try:
                provider_obj = get_snapshot().find_provider(None, provider_id, provider_api_url)
                _model_ref, extracted_usage = provider_obj.extract_usage(data, api_flavor=api_flavor)
                return cls(**{k: v for k, v in extracted_usage.__dict__.items() if v is not None}, details=details)
            except Exception:
                pass
        return cls(details=details)

# pydantic_ai_slim/pydantic_ai/models/anthropic.py:1172-1202
def _map_usage(
    message: BetaMessage | BetaRawMessageStartEvent | BetaRawMessageDeltaEvent,
    provider: str,
    provider_url: str,
    model: str,
    existing_usage: usage.RequestUsage | None = None,
) -> usage.RequestUsage:
    if isinstance(message, BetaMessage):
        response_usage = message.usage
    elif isinstance(message, BetaRawMessageStartEvent):
        response_usage = message.message.usage
    elif isinstance(message, BetaRawMessageDeltaEvent):
        response_usage = message.usage
    else:
        assert_never(message)

    # In streaming, usage appears in different events.
    # The values are cumulative, meaning new values should replace existing ones entirely.
    details: dict[str, int] = (existing_usage.details if existing_usage else {}) | {
        key: value for key, value in response_usage.model_dump().items() if isinstance(value, int)
    }

    # Note: genai-prices already extracts cache_creation_input_tokens and cache_read_input_tokens
    # from the Anthropic response and maps them to cache_write_tokens and cache_read_tokens
    return usage.RequestUsage.extract(
        dict(model=model, usage=details),
        provider=provider,
        provider_url=provider_url,
        provider_fallback='anthropic',
        details=details,
    )

# tests/conftest.py:290-292
def raise_if_exception(e: Any) -> None:
    if isinstance(e, Exception):
        raise e

# pydantic_ai_slim/pydantic_ai/usage.py:124-133
    def __add__(self, other: RequestUsage) -> RequestUsage:
        """Add two RequestUsages together.

        This is provided so it's trivial to sum usage information from multiple parts of a response.

        **WARNING:** this CANNOT be used to sum multiple requests without breaking some pricing calculations.
        """
        new_usage = copy(self)
        new_usage.incr(other)
        return new_usage

# pydantic_ai_slim/pydantic_ai/messages.py:466-613
class BinaryContent:
    """Binary content, e.g. an audio or image file."""

    data: bytes
    """The binary file data.

    Use `.base64` to get the base64-encoded string.
    """

    _: KW_ONLY

    media_type: AudioMediaType | ImageMediaType | DocumentMediaType | str
    """The media type of the binary data."""

    vendor_metadata: dict[str, Any] | None = None
    """Vendor-specific metadata for the file.

    Supported by:
    - `GoogleModel`: `BinaryContent.vendor_metadata` is used as `video_metadata`: https://ai.google.dev/gemini-api/docs/video-understanding#customize-video-processing
    - `OpenAIChatModel`, `OpenAIResponsesModel`: `BinaryContent.vendor_metadata['detail']` is used as `detail` setting for images
    - `XaiModel`: `BinaryContent.vendor_metadata['detail']` is used as `detail` setting for images
    """

    _identifier: Annotated[str | None, pydantic.Field(alias='identifier', default=None, exclude=True)] = field(
        compare=False, default=None
    )

    kind: Literal['binary'] = 'binary'
    """Type identifier, this is available on all parts as a discriminator."""

    # `pydantic_dataclass` replaces `__init__` so this method is never used.
    # The signature is kept so that pyright/IDE hints recognize the `identifier` alias for the `_identifier` field.
    def __init__(
        self,
        data: bytes,
        *,
        media_type: AudioMediaType | ImageMediaType | DocumentMediaType | str,
        identifier: str | None = None,
        vendor_metadata: dict[str, Any] | None = None,
        kind: Literal['binary'] = 'binary',
        # Required for inline-snapshot which expects all dataclass `__init__` methods to take all field names as kwargs.
        _identifier: str | None = None,
    ) -> None: ...  # pragma: no cover

    @staticmethod
    def narrow_type(bc: BinaryContent) -> BinaryContent | BinaryImage:
        """Narrow the type of the `BinaryContent` to `BinaryImage` if it's an image."""
        if bc.is_image:
            return BinaryImage(
                data=bc.data,
                media_type=bc.media_type,
                identifier=bc.identifier,
                vendor_metadata=bc.vendor_metadata,
            )
        else:
            return bc

    @classmethod
    def from_data_uri(cls, data_uri: str) -> BinaryContent:
        """Create a `BinaryContent` from a data URI."""
        prefix = 'data:'
        if not data_uri.startswith(prefix):
            raise ValueError('Data URI must start with "data:"')
        media_type, data = data_uri[len(prefix) :].split(';base64,', 1)
        return cls.narrow_type(cls(data=base64.b64decode(data), media_type=media_type))

    @classmethod
    def from_path(cls, path: PathLike[str]) -> BinaryContent:
        """Create a `BinaryContent` from a path.

        Defaults to 'application/octet-stream' if the media type cannot be inferred.

        Raises:
            FileNotFoundError: if the file does not exist.
            PermissionError: if the file cannot be read.
        """
        path = Path(path)
        if not path.exists():
            raise FileNotFoundError(f'File not found: {path}')
        media_type, _ = _mime_types.guess_type(path)
        if media_type is None:
            media_type = 'application/octet-stream'

        return cls.narrow_type(cls(data=path.read_bytes(), media_type=media_type))

    @pydantic.computed_field
    @property
    def identifier(self) -> str:
        """Identifier for the binary content, such as a unique ID.

        This identifier can be provided to the model in a message to allow it to refer to this file in a tool call argument,
        and the tool can look up the file in question by iterating over the message history and finding the matching `BinaryContent`.

        This identifier is only automatically passed to the model when the `BinaryContent` is returned by a tool.
        If you're passing the `BinaryContent` as a user message, it's up to you to include a separate text part with the identifier,
        e.g. "This is file <identifier>:" preceding the `BinaryContent`.

        It's also included in inline-text delimiters for providers that require inlining text documents, so the model can
        distinguish multiple files.
        """
        return self._identifier or _multi_modal_content_identifier(self.data)

    @property
    def data_uri(self) -> str:
        """Convert the `BinaryContent` to a data URI."""
        return f'data:{self.media_type};base64,{self.base64}'

    @property
    def base64(self) -> str:
        """Return the binary data as a base64-encoded string. Default encoding is UTF-8."""
        return base64.b64encode(self.data).decode()

    @property
    def is_audio(self) -> bool:
        """Return `True` if the media type is an audio type."""
        return self.media_type.startswith('audio/')

    @property
    def is_image(self) -> bool:
        """Return `True` if the media type is an image type."""
        return self.media_type.startswith('image/')

    @property
    def is_video(self) -> bool:
        """Return `True` if the media type is a video type."""
        return self.media_type.startswith('video/')

    @property
    def is_document(self) -> bool:
        """Return `True` if the media type is a document type."""
        return self.media_type in _document_format_lookup

    @property
    def format(self) -> str:
        """The file format of the binary content."""
        try:
            if self.is_audio:
                return _audio_format_lookup[self.media_type]
            elif self.is_image:
                return _image_format_lookup[self.media_type]
            elif self.is_video:
                return _video_format_lookup[self.media_type]
            else:
                return _document_format_lookup[self.media_type]
        except KeyError as e:
            raise ValueError(f'Unknown media type: {self.media_type}') from e

    __repr__ = _utils.dataclasses_no_defaults_repr

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:38-39
    def usage(self) -> RequestUsage:
        return self.response.usage  # pragma: no cover

# pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py:47-48
    def usage(self) -> RequestUsage:
        return self.response.usage  # pragma: no cover

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_model.py:56-57
    def usage(self) -> RequestUsage:
        return self.response.usage  # pragma: no cover

# pydantic_ai_slim/pydantic_ai/embeddings/base.py:53-55
    def system(self) -> str:
        """The embedding model provider/system identifier (e.g., 'openai', 'cohere')."""
        raise NotImplementedError()

# pydantic_ai_slim/pydantic_ai/usage.py:116-122
    def incr(self, incr_usage: RequestUsage) -> None:
        """Increment the usage in place.

        Args:
            incr_usage: The usage to increment by.
        """
        return _incr_usage_tokens(self, incr_usage)

# pydantic_ai_slim/pydantic_ai/usage.py:113-114
    def requests(self):
        return 1

# pydantic_evals/pydantic_evals/dataset.py:16-16
import traceback

# pydantic_evals/pydantic_evals/evaluators/_run_evaluator.py:3-3
import traceback

# pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py:187-188
def _map_usage(total_tokens: int) -> RequestUsage:
    return RequestUsage(input_tokens=total_tokens)

# pydantic_ai_slim/pydantic_ai/toolsets/abstract.py:131-133
    def apply(self, visitor: Callable[[AbstractToolset[AgentDepsT]], None]) -> None:
        """Run a visitor function on all "leaf" toolsets (i.e. those that implement their own tool listing and calling)."""
        visitor(self)