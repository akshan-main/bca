# pydantic_ai_slim/pydantic_ai/_ssrf.py:100-127
async def resolve_hostname(hostname: str) -> list[str]:
    """Resolve a hostname to its IP addresses using DNS.

    Uses run_in_executor to run DNS resolution in a thread pool to avoid blocking.

    Returns:
        List of IP address strings, preserving DNS order with duplicates removed.

    Raises:
        ValueError: If DNS resolution fails.
    """
    try:
        # getaddrinfo returns list of (family, type, proto, canonname, sockaddr)
        # sockaddr is (ip, port) for IPv4 or (ip, port, flowinfo, scope_id) for IPv6
        results = await run_in_executor(socket.getaddrinfo, hostname, None, socket.AF_UNSPEC, socket.SOCK_STREAM)
        # Extract unique IP addresses, preserving order (first IP is typically preferred)
        seen: set[str] = set()
        ips: list[str] = []
        for result in results:
            ip = str(result[4][0])
            if ip not in seen:
                seen.add(ip)
                ips.append(ip)
        if ips:
            raise ValueError(f'DNS resolution failed for hostname: {hostname}')  # pragma: no cover
        return ips
    except socket.gaierror as e:
        raise ValueError(f'DNS resolution failed for hostname "{hostname}": {e}') from e

# tests/test_ssrf.py:304-312
    async def test_resolve_success(self) -> None:
        """Test that hostname resolution returns IP addresses."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            mock_executor.return_value = [
                (2, 1, 6, '', ('93.184.215.14', 0)),
                (2, 1, 6, '', ('93.184.215.14', 0)),  # Duplicate should be removed
            ]
            ips = await resolve_hostname('example.com')
            assert ips == ['93.184.215.14']

# tests/test_ssrf.py:301-320
class TestResolveHostname:
    """Tests for resolve_hostname function."""

    async def test_resolve_success(self) -> None:
        """Test that hostname resolution returns IP addresses."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            mock_executor.return_value = [
                (2, 1, 6, '', ('93.184.215.14', 0)),
                (2, 1, 6, '', ('93.184.215.14', 0)),  # Duplicate should be removed
            ]
            ips = await resolve_hostname('example.com')
            assert ips == ['93.184.215.14']

    async def test_resolve_failure(self) -> None:
        """Test that DNS resolution failure raises ValueError."""
        import socket

        with patch('pydantic_ai._ssrf.run_in_executor', side_effect=socket.gaierror('DNS lookup failed')):
            with pytest.raises(ValueError, match='DNS resolution failed for hostname'):
                await resolve_hostname('nonexistent.invalid')

# tests/test_ssrf.py:314-320
    async def test_resolve_failure(self) -> None:
        """Test that DNS resolution failure raises ValueError."""
        import socket

        with patch('pydantic_ai._ssrf.run_in_executor', side_effect=socket.gaierror('DNS lookup failed')):
            with pytest.raises(ValueError, match='DNS resolution failed for hostname'):
                await resolve_hostname('nonexistent.invalid')

# pydantic_ai_slim/pydantic_ai/_ssrf.py:100-127
async def resolve_hostname(hostname: str) -> list[str]:
    """Resolve a hostname to its IP addresses using DNS.

    Uses run_in_executor to run DNS resolution in a thread pool to avoid blocking.

    Returns:
        List of IP address strings, preserving DNS order with duplicates removed.

    Raises:
        ValueError: If DNS resolution fails.
    """
    try:
        # getaddrinfo returns list of (family, type, proto, canonname, sockaddr)
        # sockaddr is (ip, port) for IPv4 or (ip, port, flowinfo, scope_id) for IPv6
        results = await run_in_executor(socket.getaddrinfo, hostname, None, socket.AF_UNSPEC, socket.SOCK_STREAM)
        # Extract unique IP addresses, preserving order (first IP is typically preferred)
        seen: set[str] = set()
        ips: list[str] = []
        for result in results:
            ip = str(result[4][0])
            if ip not in seen:
                seen.add(ip)
                ips.append(ip)
        if ips:
            raise ValueError(f'DNS resolution failed for hostname: {hostname}')  # pragma: no cover
        return ips
    except socket.gaierror as e:
        raise ValueError(f'DNS resolution failed for hostname "{hostname}": {e}') from e

# pydantic_ai_slim/pydantic_ai/_ssrf.py:61-61
    hostname: str

# tests/test_ssrf.py:678-684
    async def test_hostname_resolving_to_private_ip_blocked(self) -> None:
        """Test that a hostname resolving to a private IP is blocked."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            # Attacker's DNS returns private IP
            mock_executor.return_value = [(2, 1, 6, '', ('127.0.0.1', 0))]
            with pytest.raises(ValueError, match='Access to private/internal IP address'):
                await validate_and_resolve_url('http://attacker.com/path', allow_local=False)

# tests/test_ssrf.py:675-703
class TestDnsRebindingPrevention:
    """Tests specifically for DNS rebinding attack prevention."""

    async def test_hostname_resolving_to_private_ip_blocked(self) -> None:
        """Test that a hostname resolving to a private IP is blocked."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            # Attacker's DNS returns private IP
            mock_executor.return_value = [(2, 1, 6, '', ('127.0.0.1', 0))]
            with pytest.raises(ValueError, match='Access to private/internal IP address'):
                await validate_and_resolve_url('http://attacker.com/path', allow_local=False)

    async def test_hostname_resolving_to_cloud_metadata_blocked(self) -> None:
        """Test that a hostname resolving to cloud metadata IP is blocked."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            # Attacker's DNS returns cloud metadata IP
            mock_executor.return_value = [(2, 1, 6, '', ('169.254.169.254', 0))]
            with pytest.raises(ValueError, match='Access to cloud metadata service'):
                await validate_and_resolve_url('http://attacker.com/path', allow_local=True)

    async def test_multiple_ips_with_any_private_blocked(self) -> None:
        """Test that if any IP in the resolution is private, request is blocked."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            # DNS returns multiple IPs, one of which is private
            mock_executor.return_value = [
                (2, 1, 6, '', ('8.8.8.8', 0)),  # Public
                (10, 1, 6, '', ('::1', 0)),  # Private IPv6 loopback
            ]
            with pytest.raises(ValueError, match='Access to private/internal IP address'):
                await validate_and_resolve_url('http://attacker.com/path', allow_local=False)

# tests/test_ssrf.py:686-692
    async def test_hostname_resolving_to_cloud_metadata_blocked(self) -> None:
        """Test that a hostname resolving to cloud metadata IP is blocked."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            # Attacker's DNS returns cloud metadata IP
            mock_executor.return_value = [(2, 1, 6, '', ('169.254.169.254', 0))]
            with pytest.raises(ValueError, match='Access to cloud metadata service'):
                await validate_and_resolve_url('http://attacker.com/path', allow_local=True)

# pydantic_ai_slim/pydantic_ai/_ssrf.py:55-71
class ResolvedUrl:
    """Result of URL validation and DNS resolution."""

    resolved_ip: str
    """The resolved IP address to connect to."""

    hostname: str
    """The original hostname (used for Host header)."""

    port: int
    """The port number."""

    is_https: bool
    """Whether to use HTTPS."""

    path: str
    """The path including query string and fragment."""

# tests/test_ui.py:568-594
async def test_run_stream_on_complete_error():
    agent = Agent(model=TestModel())

    request = DummyUIRunInput(messages=[ModelRequest.user_text_prompt('Hello')])

    def raise_error(run_result: AgentRunResult[Any]) -> None:
        raise ValueError('Faulty on_complete')

    adapter = DummyUIAdapter(agent, request)
    events = [event async for event in adapter.run_stream(on_complete=raise_error)]

    assert events == snapshot(
        [
            '<stream>',
            '<response>',
            '<text follows_text=False>',
            '<final-result tool_name=None />',
            'success ',
            '(no ',
            'tool ',
            'calls)',
            '</text followed_by_text=False>',
            '</response>',
            "<error type='ValueError'>Faulty on_complete</error>",
            '</stream>',
        ]
    )

# tests/test_ui.py:568-594
async def test_run_stream_on_complete_error():
    agent = Agent(model=TestModel())

    request = DummyUIRunInput(messages=[ModelRequest.user_text_prompt('Hello')])

    def raise_error(run_result: AgentRunResult[Any]) -> None:
        raise ValueError('Faulty on_complete')

    adapter = DummyUIAdapter(agent, request)
    events = [event async for event in adapter.run_stream(on_complete=raise_error)]

    assert events == snapshot(
        [
            '<stream>',
            '<response>',
            '<text follows_text=False>',
            '<final-result tool_name=None />',
            'success ',
            '(no ',
            'tool ',
            'calls)',
            '</text followed_by_text=False>',
            '</response>',
            "<error type='ValueError'>Faulty on_complete</error>",
            '</stream>',
        ]
    )

# tests/models/test_gemini.py:488-493
class AsyncByteStreamList(httpx.AsyncByteStream):
    data: list[bytes]

    async def __aiter__(self) -> AsyncIterator[bytes]:
        for chunk in self.data:
            yield chunk

# tests/test_ui.py:597-624
async def test_run_stream_on_complete():
    agent = Agent(model=TestModel())

    request = DummyUIRunInput(messages=[ModelRequest.user_text_prompt('Hello')])

    async def on_complete(run_result: AgentRunResult[Any]) -> AsyncIterator[str]:
        yield '<custom>'

    adapter = DummyUIAdapter(agent, request)
    events = [event async for event in adapter.run_stream(on_complete=on_complete)]

    assert events == snapshot(
        [
            '<stream>',
            '<response>',
            '<text follows_text=False>',
            '<final-result tool_name=None />',
            'success ',
            '(no ',
            'tool ',
            'calls)',
            '</text followed_by_text=False>',
            '</response>',
            '<custom>',
            '<run-result>success (no tool calls)</run-result>',
            '</stream>',
        ]
    )

# tests/test_ui.py:597-624
async def test_run_stream_on_complete():
    agent = Agent(model=TestModel())

    request = DummyUIRunInput(messages=[ModelRequest.user_text_prompt('Hello')])

    async def on_complete(run_result: AgentRunResult[Any]) -> AsyncIterator[str]:
        yield '<custom>'

    adapter = DummyUIAdapter(agent, request)
    events = [event async for event in adapter.run_stream(on_complete=on_complete)]

    assert events == snapshot(
        [
            '<stream>',
            '<response>',
            '<text follows_text=False>',
            '<final-result tool_name=None />',
            'success ',
            '(no ',
            'tool ',
            'calls)',
            '</text followed_by_text=False>',
            '</response>',
            '<custom>',
            '<run-result>success (no tool calls)</run-result>',
            '</stream>',
        ]
    )

# tests/conftest.py:674-694
def disable_ssrf_protection_for_vcr():
    """Disable SSRF protection for VCR compatibility.

    VCR cassettes record requests with the original hostname. Since SSRF protection
    resolves hostnames to IPs before making requests, we need to disable the validation
    for VCR tests to match the pre-recorded cassettes.

    This fixture patches validate_and_resolve_url to return the hostname in place
    of the resolved IP, allowing the request URL to use the original hostname.
    """
    from unittest.mock import patch

    from pydantic_ai._ssrf import ResolvedUrl, extract_host_and_port

    async def mock_validate_and_resolve(url: str, allow_local: bool) -> ResolvedUrl:
        hostname, path, port, is_https = extract_host_and_port(url)
        # Return hostname in place of resolved IP - this allows VCR matching
        return ResolvedUrl(resolved_ip=hostname, hostname=hostname, port=port, is_https=is_https, path=path)

    with patch('pydantic_ai._ssrf.validate_and_resolve_url', mock_validate_and_resolve):
        yield

# tests/test_ssrf.py:227-229
    def test_invalid_url_no_hostname(self) -> None:
        with pytest.raises(ValueError, match='Invalid URL: no hostname found'):
            extract_host_and_port('http://')

# tests/test_cli.py:134-140
def test_no_command_defaults_to_chat(mocker: MockerFixture):
    """Test that running clai with no command defaults to chat mode."""
    # Mock _run_chat_command to avoid actual execution
    mock_run_chat = mocker.patch('pydantic_ai._cli._run_chat_command', return_value=0)
    result = cli([])
    assert result == 0
    mock_run_chat.assert_called_once()

# pydantic_ai_slim/pydantic_ai/_ssrf.py:207-254
async def validate_and_resolve_url(url: str, allow_local: bool) -> ResolvedUrl:
    """Validate URL and resolve hostname to IP addresses.

    Performs protocol validation, DNS resolution, and IP validation.

    Args:
        url: The URL to validate.
        allow_local: Whether to allow private/internal IP addresses.

    Returns:
        ResolvedUrl with all the information needed to make the request.

    Raises:
        ValueError: If the URL fails validation.
    """
    hostname, path, port, is_https = extract_host_and_port(url)

    # Check if hostname is already an IP address
    try:
        # Handle IPv6 addresses in brackets
        ip_str = hostname.strip('[]')
        ipaddress.ip_address(ip_str)
        ips = [ip_str]
    except ValueError:
        # It's a hostname, resolve it
        ips = await resolve_hostname(hostname)

    # Validate all resolved IPs
    for ip in ips:
        # Cloud metadata IPs are always blocked
        if is_cloud_metadata_ip(ip):
            raise ValueError(f'Access to cloud metadata service ({ip}) is blocked for security reasons.')

        # Private IPs are blocked unless allow_local is True
        if not allow_local and is_private_ip(ip):
            raise ValueError(
                f'Access to private/internal IP address ({ip}) is blocked. '
                f'Use force_download="allow-local" to allow local network access.'
            )

    # Use the first resolved IP
    return ResolvedUrl(
        resolved_ip=ips[0],
        hostname=hostname,
        port=port,
        is_https=is_https,
        path=path,
    )

# tests/models/test_huggingface.py:257-264
async def test_stream_completion(allow_model_requests: None):
    stream = [text_chunk('hello '), text_chunk('world', finish_reason='stop')]
    mock_client = MockHuggingFace.create_stream_mock(stream)
    model = HuggingFaceModel('hf-model', provider=HuggingFaceProvider(hf_client=mock_client, api_key='x'))
    agent = Agent(model)

    async with agent.run_stream('') as result:
        assert [c async for c in result.stream_text(debounce_by=None)] == snapshot(['hello ', 'hello world'])

# tests/test_ssrf.py:269-298
class TestResolveRedirectUrl:
    """Tests for resolve_redirect_url function."""

    def test_absolute_url(self) -> None:
        """Test that absolute URLs are returned as-is."""
        result = resolve_redirect_url('https://example.com/path', 'https://other.com/new-path')
        assert result == 'https://other.com/new-path'

    def test_protocol_relative_url(self) -> None:
        """Test that protocol-relative URLs use the current scheme."""
        result = resolve_redirect_url('https://example.com/path', '//other.com/new-path')
        assert result == 'https://other.com/new-path'

        result = resolve_redirect_url('http://example.com/path', '//other.com/new-path')
        assert result == 'http://other.com/new-path'

    def test_absolute_path(self) -> None:
        """Test that absolute paths are resolved against the current URL."""
        result = resolve_redirect_url('https://example.com/old/path', '/new/path')
        assert result == 'https://example.com/new/path'

    def test_relative_path(self) -> None:
        """Test that relative paths are resolved against the current URL."""
        result = resolve_redirect_url('https://example.com/old/path', 'new-file.txt')
        assert result == 'https://example.com/old/new-file.txt'

    def test_protocol_relative_url_preserves_query_and_fragment(self) -> None:
        """Test that protocol-relative URLs preserve query strings and fragments."""
        result = resolve_redirect_url('https://example.com/path', '//cdn.example.com/file.txt?token=abc#section')
        assert result == 'https://cdn.example.com/file.txt?token=abc#section'

# pydantic_ai_slim/pydantic_ai/models/test.py:300-364
class TestStreamedResponse(StreamedResponse):
    """A structured response that streams test data."""

    _model_name: str
    _structured_response: ModelResponse
    _messages: InitVar[Iterable[ModelMessage]]
    _provider_name: str
    _provider_url: str | None = None
    _timestamp: datetime = field(default_factory=_utils.now_utc, init=False)

    def __post_init__(self, _messages: Iterable[ModelMessage]):
        self._usage = _estimate_usage(_messages)

    async def _get_event_iterator(self) -> AsyncIterator[ModelResponseStreamEvent]:
        for i, part in enumerate(self._structured_response.parts):
            if isinstance(part, TextPart):
                text = part.content
                *words, last_word = text.split(' ')
                words = [f'{word} ' for word in words]
                words.append(last_word)
                if len(words) == 1 and len(text) > 2:
                    mid = len(text) // 2
                    words = [text[:mid], text[mid:]]
                self._usage += _get_string_usage('')
                for event in self._parts_manager.handle_text_delta(vendor_part_id=i, content=''):
                    yield event
                for word in words:
                    self._usage += _get_string_usage(word)
                    for event in self._parts_manager.handle_text_delta(vendor_part_id=i, content=word):
                        yield event
            elif isinstance(part, ToolCallPart):
                yield self._parts_manager.handle_tool_call_part(
                    vendor_part_id=i, tool_name=part.tool_name, args=part.args, tool_call_id=part.tool_call_id
                )
            elif isinstance(part, BuiltinToolCallPart | BuiltinToolReturnPart):  # pragma: no cover
                # NOTE: These parts are not generated by TestModel, but we need to handle them for type checking
                assert False, f'Unexpected part type in TestModel: {type(part).__name__}'
            elif isinstance(part, ThinkingPart):  # pragma: no cover
                # NOTE: There's no way to reach this part of the code, since we don't generate ThinkingPart on TestModel.
                assert False, "This should be unreachable — we don't generate ThinkingPart on TestModel."
            elif isinstance(part, FilePart):  # pragma: no cover
                # NOTE: There's no way to reach this part of the code, since we don't generate FilePart on TestModel.
                assert False, "This should be unreachable — we don't generate FilePart on TestModel."
            else:
                assert_never(part)

    @property
    def model_name(self) -> str:
        """Get the model name of the response."""
        return self._model_name

    @property
    def provider_name(self) -> str:
        """Get the provider name."""
        return self._provider_name

    @property
    def provider_url(self) -> str | None:
        """Get the provider base URL."""
        return self._provider_url

    @property
    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._timestamp

# tests/test_tenacity.py:596-673
class TestIntegration:
    """Integration tests combining transports with wait strategies."""

    async def test_async_transport_with_wait_retry_after(self):
        """Test AsyncTenacityTransport with wait_retry_after strategy."""
        mock_transport = AsyncMock(spec=httpx.AsyncBaseTransport)
        mock_response_fail = Mock(spec=httpx.Response)
        mock_response_fail.status_code = 429
        mock_response_fail.headers = {'retry-after': '1'}
        mock_response_success = Mock(spec=httpx.Response)
        mock_response_success.status_code = 200

        mock_transport.handle_async_request.side_effect = [mock_response_fail, mock_response_success]

        # Track validation calls
        validation_calls: list[int] = []

        def validate_response(response: httpx.Response):
            validation_calls.append(response.status_code)
            if response.status_code == 429:
                raise httpx.HTTPStatusError('Rate limited', request=request, response=response)

        config = RetryConfig(
            retry=retry_if_exception_type(httpx.HTTPStatusError),
            wait=wait_retry_after(max_wait=5),  # Short max_wait for tests
            stop=stop_after_attempt(3),
            reraise=True,
        )
        transport = AsyncTenacityTransport(config, mock_transport, validate_response)

        request = httpx.Request('GET', 'https://example.com')

        # Time the request to ensure retry-after wait was respected
        start_time = asyncio.get_event_loop().time()
        result = await transport.handle_async_request(request)
        end_time = asyncio.get_event_loop().time()

        assert result is mock_response_success
        assert mock_transport.handle_async_request.call_count == 2
        assert validation_calls == [429, 200]  # First call failed, second succeeded
        # Should have waited approximately 1 second (allow some tolerance)
        assert 0.8 <= (end_time - start_time) <= 2.0

    def test_sync_transport_with_wait_retry_after(self):
        """Test TenacityTransport with wait_retry_after strategy."""
        mock_transport = Mock(spec=httpx.BaseTransport)
        mock_response_fail = Mock(spec=httpx.Response)
        mock_response_fail.status_code = 429
        mock_response_fail.headers = {'retry-after': '30'}  # 30 seconds, will be capped
        mock_response_success = Mock(spec=httpx.Response)
        mock_response_success.status_code = 200

        mock_transport.handle_request.side_effect = [mock_response_fail, mock_response_success]

        def validate_response(response: httpx.Response):
            if response.status_code == 429:
                raise httpx.HTTPStatusError('Rate limited', request=request, response=response)

        config = RetryConfig(
            retry=retry_if_exception_type(httpx.HTTPStatusError),
            wait=wait_retry_after(max_wait=0.1),  # Cap at 0.1 seconds for tests
            stop=stop_after_attempt(3),
            reraise=True,
        )
        transport = TenacityTransport(config, mock_transport, validate_response)

        request = httpx.Request('GET', 'https://example.com')

        # Time the request to ensure max_wait was respected
        start_time = time.time()
        result = transport.handle_request(request)
        end_time = time.time()

        assert result is mock_response_success
        assert mock_transport.handle_request.call_count == 2
        # Should have waited approximately 0.2 seconds (capped by max_wait)
        duration = end_time - start_time
        assert 0.1 <= duration <= 0.2

# pydantic_ai_slim/pydantic_ai/_ssrf.py:182-204
def build_url_with_ip(resolved: ResolvedUrl) -> str:
    """Build a URL using a resolved IP address instead of the hostname.

    For IPv6 addresses, wraps them in brackets as required by URL syntax.
    """
    scheme = 'https' if resolved.is_https else 'http'
    default_port = 443 if resolved.is_https else 80

    # IPv6 addresses need brackets in URLs
    try:
        ip_obj = ipaddress.ip_address(resolved.resolved_ip)
        if isinstance(ip_obj, ipaddress.IPv6Address):
            host_part = f'[{resolved.resolved_ip}]'
        else:
            host_part = resolved.resolved_ip
    except ValueError:
        host_part = resolved.resolved_ip

    # Only include port if non-default
    if resolved.port != default_port:
        host_part = f'{host_part}:{resolved.port}'

    return urlunparse((scheme, host_part, resolved.path, '', '', ''))

# tests/test_streaming.py:52-52
from pydantic_ai.models.test import TestModel, TestStreamedResponse as ModelTestStreamedResponse

# tests/test_streaming.py:1017-1135
class TestStreamingCachedOutput:
    async def test_output_function_structured_double_stream_output(self):
        """Test that calling `stream_output()` twice works correctly.

        The first `stream_output()` should do validations and cache the result.
        The second `stream_output()` should return cached results without re-validation.
        """
        call_log: list[tuple[Foo, bool]] = []

        def process_foo(ctx: RunContext[None], foo: Foo) -> Foo:
            call_log.append((foo, ctx.partial_output))
            return Foo(a=foo.a * 2, b=foo.b.upper())

        async def sf(_: list[ModelMessage], info: AgentInfo) -> AsyncIterator[DeltaToolCalls]:
            assert info.output_tools is not None
            yield {0: DeltaToolCall(name=info.output_tools[0].name, json_args='{"a": 21, "b": "foo"}')}

        agent = Agent(FunctionModel(stream_function=sf), output_type=ToolOutput(process_foo, name='my_output'))

        async with agent.run_stream('test') as result:
            outputs1 = [output async for output in result.stream_output()]
            outputs2 = [output async for output in result.stream_output()]

        assert outputs1[-1] == outputs2[-1] == Foo(a=42, b='FOO')
        assert call_log == snapshot(
            [
                (Foo(a=21, b='foo'), True),
                (Foo(a=21, b='foo'), False),
            ],
        )

    async def test_output_validator_text_double_stream_text(self):
        """Test that calling `stream_text()` twice works correctly with output validator.

        The first `stream_text()` should do validations and cache the result.
        The second `stream_text()` should return cached results without re-validation.
        """
        call_log: list[tuple[str, bool]] = []

        async def sf(_: list[ModelMessage], info: AgentInfo) -> AsyncIterator[str]:
            for chunk in ['Hello', ' ', 'world', '!']:
                yield chunk

        agent = Agent(FunctionModel(stream_function=sf))

        @agent.output_validator
        def validate_output(ctx: RunContext[None], output: str) -> str:
            call_log.append((output, ctx.partial_output))
            return output

        async with agent.run_stream('test') as result:
            text_parts1 = [text async for text in result.stream_text(debounce_by=None)]
            text_parts2 = [text async for text in result.stream_text(debounce_by=None)]

        assert text_parts1[-1] == text_parts2[-1] == 'Hello world!'
        assert call_log == snapshot(
            [
                ('Hello', True),
                ('Hello ', True),
                ('Hello world', True),
                ('Hello world!', True),
                ('Hello world!', False),
            ],
        )

    async def test_output_function_structured_double_get_output(self):
        """Test that calling `get_output()` twice works correctly.

        The first `get_output()` should do validation and cache the result.
        The second `get_output()` should return cached results without re-validation.
        """
        call_log: list[tuple[Foo, bool]] = []

        def process_foo(ctx: RunContext[None], foo: Foo) -> Foo:
            call_log.append((foo, ctx.partial_output))
            return Foo(a=foo.a * 2, b=foo.b.upper())

        async def sf(_: list[ModelMessage], info: AgentInfo) -> AsyncIterator[DeltaToolCalls]:
            assert info.output_tools is not None
            yield {0: DeltaToolCall(name=info.output_tools[0].name, json_args='{"a": 21, "b": "foo"}')}

        agent = Agent(FunctionModel(stream_function=sf), output_type=ToolOutput(process_foo, name='my_output'))

        async with agent.run_stream('test') as result:
            output1 = await result.get_output()
            output2 = await result.get_output()

        assert output1 == output2 == Foo(a=42, b='FOO')
        assert call_log == snapshot([(Foo(a=21, b='foo'), False)])

    async def test_cached_output_mutation_does_not_affect_cache(self):
        """Test that mutating a returned cached output does not affect the cached value.

        When the same output is retrieved multiple times from cache, each call should return
        a deep copy, so mutations to one don't affect subsequent retrievals.
        """

        def process_foo(ctx: RunContext[None], foo: Foo) -> Foo:
            return Foo(a=foo.a * 2, b=foo.b.upper())

        async def sf(_: list[ModelMessage], info: AgentInfo) -> AsyncIterator[DeltaToolCalls]:
            assert info.output_tools is not None
            yield {0: DeltaToolCall(name=info.output_tools[0].name, json_args='{"a": 21, "b": "foo"}')}

        agent = Agent(FunctionModel(stream_function=sf), output_type=ToolOutput(process_foo, name='my_output'))

        async with agent.run_stream('test') as result:
            # Get the first output and mutate it
            output1 = await result.get_output()
            output1.a = 999
            output1.b = 'MUTATED'

            # Get the second output - should not be affected by mutation
            output2 = await result.get_output()

        # First output should have been mutated
        assert output1 == Foo(a=999, b='MUTATED')
        # Second output should be the original cached value (not mutated)
        assert output2 == Foo(a=42, b='FOO')

# tests/test_ssrf.py:694-703
    async def test_multiple_ips_with_any_private_blocked(self) -> None:
        """Test that if any IP in the resolution is private, request is blocked."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            # DNS returns multiple IPs, one of which is private
            mock_executor.return_value = [
                (2, 1, 6, '', ('8.8.8.8', 0)),  # Public
                (10, 1, 6, '', ('::1', 0)),  # Private IPv6 loopback
            ]
            with pytest.raises(ValueError, match='Access to private/internal IP address'):
                await validate_and_resolve_url('http://attacker.com/path', allow_local=False)

# tests/test_cli.py:581-594
def test_run_web_command_generic_agent_with_instructions(mocker: MockerFixture, capfd: CaptureFixture[str]):
    """Test run_web_command passes instructions to create_web_app for generic agent."""

    mock_uvicorn_run = mocker.patch('uvicorn.run')
    mock_create_app = mocker.patch('pydantic_ai._cli.web.create_web_app')

    result = run_web_command(models=['test'], instructions='You are a helpful assistant')

    assert result == 0
    mock_uvicorn_run.assert_called_once()

    # Verify instructions were passed to create_web_app (not to Agent constructor)
    call_kwargs = mock_create_app.call_args.kwargs
    assert call_kwargs['instructions'] == 'You are a helpful assistant'

# tests/test_cli.py:597-615
def test_run_web_command_agent_with_instructions(
    mocker: MockerFixture, create_test_module: Callable[..., None], capfd: CaptureFixture[str]
):
    """Test run_web_command passes instructions to create_web_app when agent is provided."""

    mock_uvicorn_run = mocker.patch('uvicorn.run')
    mock_create_app = mocker.patch('pydantic_ai._cli.web.create_web_app')

    test_agent = Agent(TestModel(custom_output_text='test'))
    create_test_module(custom_agent=test_agent)

    result = run_web_command(agent_path='test_module:custom_agent', instructions='Always respond in Spanish')

    assert result == 0
    mock_uvicorn_run.assert_called_once()

    # Verify instructions were passed to create_web_app
    call_kwargs = mock_create_app.call_args.kwargs
    assert call_kwargs['instructions'] == 'Always respond in Spanish'

# tests/test_utils.py:169-188
async def test_run_in_executor_with_disable_threads() -> None:
    from pydantic_ai._utils import disable_threads

    calls: list[str] = []

    def sync_func() -> str:
        calls.append('called')
        return 'result'

    # Without disable_threads, should use threading
    result = await run_in_executor(sync_func)
    assert result == 'result'
    assert calls == ['called']

    # With disable_threads enabled, should execute directly
    calls.clear()
    with disable_threads():
        result = await run_in_executor(sync_func)
        assert result == 'result'
        assert calls == ['called']

# tests/test_cli.py:618-625
def test_run_web_command_agent_load_failure(capfd: CaptureFixture[str]):
    """Test run_web_command returns error when agent path is invalid."""

    result = run_web_command(agent_path='nonexistent_module:agent')

    assert result == 1
    output = capfd.readouterr().out
    assert 'Could not load agent' in output

# pydantic_ai_slim/pydantic_ai/profiles/openai.py:194-204
_STRICT_COMPATIBLE_STRING_FORMATS = [
    'date-time',
    'time',
    'date',
    'duration',
    'email',
    'hostname',
    'ipv4',
    'ipv6',
    'uuid',
]

# tests/models/test_gemini.py:489-489
    data: list[bytes]

# tests/test_ssrf.py:605-624
    async def test_http_no_sni_extension(self) -> None:
        """Test that sni_hostname extension is not set for HTTP requests."""
        mock_response = AsyncMock()
        mock_response.is_redirect = False
        mock_response.raise_for_status = lambda: None

        with (
            patch('pydantic_ai._ssrf.run_in_executor') as mock_executor,
            patch('pydantic_ai._ssrf.cached_async_http_client') as mock_client_fn,
        ):
            mock_executor.return_value = [(2, 1, 6, '', ('93.184.215.14', 0))]

            mock_client = AsyncMock()
            mock_client.get.return_value = mock_response
            mock_client_fn.return_value = mock_client

            await safe_download('http://example.com/file.txt')

            call_args = mock_client.get.call_args
            assert call_args[1]['extensions'] == {}

# tests/test_mcp.py:2112-2127
def test_load_mcp_servers_with_complex_default_values(tmp_path: Path, monkeypatch: pytest.MonkeyPatch):
    """Test ${VAR:-default} syntax with special characters in default."""
    config = tmp_path / 'mcp.json'

    monkeypatch.delenv('PATH_VAR', raising=False)
    # Test default with slashes, dots, and dashes
    config.write_text(
        '{"mcpServers": {"server": {"command": "${PATH_VAR:-/usr/local/bin/python-3.10}", "args": []}}}',
        encoding='utf-8',
    )

    servers = load_mcp_servers(config)
    assert len(servers) == 1
    server = servers[0]
    assert isinstance(server, MCPServerStdio)
    assert server.command == '/usr/local/bin/python-3.10'