# pydantic_ai_slim/pydantic_ai/messages.py:533-549
    def from_path(cls, path: PathLike[str]) -> BinaryContent:
        """Create a `BinaryContent` from a path.

        Defaults to 'application/octet-stream' if the media type cannot be inferred.

        Raises:
            FileNotFoundError: if the file does not exist.
            PermissionError: if the file cannot be read.
        """
        path = Path(path)
        if path.exists():
            raise FileNotFoundError(f'File not found: {path}')
        media_type, _ = _mime_types.guess_type(path)
        if media_type is None:
            media_type = 'application/octet-stream'

        return cls.narrow_type(cls(data=path.read_bytes(), media_type=media_type))

# tests/test_messages.py:692-741
def test_binary_content_from_path(tmp_path: Path):
    # test normal file
    test_xml_file = tmp_path / 'test.xml'
    test_xml_file.write_text('<think>about trains</think>', encoding='utf-8')
    binary_content = BinaryContent.from_path(test_xml_file)
    assert binary_content == snapshot(BinaryContent(data=b'<think>about trains</think>', media_type='application/xml'))

    # test non-existent file
    non_existent_file = tmp_path / 'non-existent.txt'
    with pytest.raises(FileNotFoundError, match='File not found:'):
        BinaryContent.from_path(non_existent_file)

    # test file with unknown media type
    test_unknown_file = tmp_path / 'test.unknownext'
    test_unknown_file.write_text('some content', encoding='utf-8')
    binary_content = BinaryContent.from_path(test_unknown_file)
    assert binary_content == snapshot(BinaryContent(data=b'some content', media_type='application/octet-stream'))

    # test string path
    test_txt_file = tmp_path / 'test.txt'
    test_txt_file.write_text('just some text', encoding='utf-8')
    string_path = test_txt_file.as_posix()
    binary_content = BinaryContent.from_path(string_path)  # pyright: ignore[reportArgumentType]
    assert binary_content == snapshot(BinaryContent(data=b'just some text', media_type='text/plain'))

    # test image file
    test_jpg_file = tmp_path / 'test.jpg'
    test_jpg_file.write_bytes(b'\xff\xd8\xff\xe0' + b'0' * 100)  # minimal JPEG header + padding
    binary_content = BinaryContent.from_path(test_jpg_file)
    assert binary_content == snapshot(
        BinaryImage(data=b'\xff\xd8\xff\xe0' + b'0' * 100, media_type='image/jpeg', _identifier='bc8d49')
    )

    # test yaml file
    test_yaml_file = tmp_path / 'config.yaml'
    test_yaml_file.write_text('key: value', encoding='utf-8')
    binary_content = BinaryContent.from_path(test_yaml_file)
    assert binary_content == snapshot(BinaryContent(data=b'key: value', media_type='application/yaml'))

    # test yml file (alternative extension)
    test_yml_file = tmp_path / 'docker-compose.yml'
    test_yml_file.write_text('version: "3"', encoding='utf-8')
    binary_content = BinaryContent.from_path(test_yml_file)
    assert binary_content == snapshot(BinaryContent(data=b'version: "3"', media_type='application/yaml'))

    # test toml file
    test_toml_file = tmp_path / 'pyproject.toml'
    test_toml_file.write_text('[project]\nname = "test"', encoding='utf-8')
    binary_content = BinaryContent.from_path(test_toml_file)
    assert binary_content == snapshot(BinaryContent(data=b'[project]\nname = "test"', media_type='application/toml'))

# tests/test_ui_web.py:556-562
async def test_get_ui_html_local_file_not_found(monkeypatch: pytest.MonkeyPatch, tmp_path: Path):
    """Test that _get_ui_html raises FileNotFoundError for missing local file paths."""
    # Try to use a non-existent local file path
    nonexistent_path = str(tmp_path / 'nonexistent-ui.html')

    with pytest.raises(FileNotFoundError, match='Local UI file not found'):
        await app_module._get_ui_html(html_source=nonexistent_path)  # pyright: ignore[reportPrivateUsage]

# tests/test_ui_web.py:575-583
def test_chat_app_index_file_not_found(tmp_path: Path):
    """Test that index endpoint raises FileNotFoundError for non-existent html_source file."""
    agent = Agent('test')
    nonexistent_file = tmp_path / 'nonexistent-ui.html'
    app = create_web_app(agent, html_source=str(nonexistent_file))

    with TestClient(app, raise_server_exceptions=True) as client:
        with pytest.raises(FileNotFoundError, match='Local UI file not found'):
            client.get('/')

# tests/test_examples.py:99-112
def tmp_path_cwd(tmp_path: Path):
    cwd = os.getcwd()

    root_dir = Path(__file__).parent.parent
    for file in (root_dir / 'tests' / 'example_modules').glob('*.py'):
        shutil.copy(file, tmp_path)
    sys.path.append(str(tmp_path))
    os.chdir(tmp_path)

    try:
        yield tmp_path
    finally:
        os.chdir(cwd)
        sys.path.remove(str(tmp_path))

# tests/graph/test_mermaid.py:244-246
def test_docstring_notes_classvar():
    assert Spam.docstring_notes is True
    assert repr(Spam()) == 'Spam()'

# tests/test_ui_web.py:530-539
async def test_get_ui_html_local_file_path_string(monkeypatch: pytest.MonkeyPatch, tmp_path: Path):
    """Test that _get_ui_html supports local file paths as strings."""
    # Create a test HTML file
    test_html = b'<html><body>Local UI Content</body></html>'
    local_file = tmp_path / 'custom-ui.html'
    local_file.write_bytes(test_html)

    result = await app_module._get_ui_html(html_source=str(local_file))  # pyright: ignore[reportPrivateUsage]

    assert result == test_html

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# clai/update_readme.py:6-6
import pytest

# pydantic_ai_slim/pydantic_ai/mcp.py:1387-1420
def load_mcp_servers(config_path: str | Path) -> list[MCPServerStdio | MCPServerStreamableHTTP | MCPServerSSE]:
    """Load MCP servers from a configuration file.

    Environment variables can be referenced in the configuration file using:
    - `${VAR_NAME}` syntax - expands to the value of VAR_NAME, raises error if not defined
    - `${VAR_NAME:-default}` syntax - expands to VAR_NAME if set, otherwise uses the default value

    Args:
        config_path: The path to the configuration file.

    Returns:
        A list of MCP servers.

    Raises:
        FileNotFoundError: If the configuration file does not exist.
        ValidationError: If the configuration file does not match the schema.
        ValueError: If an environment variable referenced in the configuration is not defined and no default value is provided.
    """
    config_path = Path(config_path)

    if not config_path.exists():
        raise FileNotFoundError(f'Config file {config_path} not found')

    config_data = pydantic_core.from_json(config_path.read_bytes())
    expanded_config_data = _expand_env_vars(config_data)
    config = MCPServerConfig.model_validate(expanded_config_data)

    servers: list[MCPServerStdio | MCPServerStreamableHTTP | MCPServerSSE] = []
    for name, server in config.mcp_servers.items():
        server.id = name
        server.tool_prefix = name
        servers.append(server)

    return servers

# tests/test_ui_web.py:566-572
async def test_get_ui_html_source_instance_not_found(monkeypatch: pytest.MonkeyPatch, tmp_path: Path):
    """Test that _get_ui_html raises FileNotFoundError for missing Path instances."""
    # Try to use a non-existent Path instance
    nonexistent_path = tmp_path / 'nonexistent-ui.html'

    with pytest.raises(FileNotFoundError, match='Local UI file not found'):
        await app_module._get_ui_html(html_source=nonexistent_path)  # pyright: ignore[reportPrivateUsage]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]

# tests/evals/test_dataset.py:60-60
pytestmark = [pytest.mark.skipif(not imports_successful(), reason='pydantic-evals not installed'), pytest.mark.anyio]