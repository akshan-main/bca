l(
pydantic_ai_slim/pydantic_ai/_tool_manager.py:212: in _call_tool
    return await self.toolset.call_tool(name, args_dict, ctx, tool)
pydantic_ai_slim/pydantic_ai/toolsets/combined.py:90: in call_tool
    return await tool.source_toolset.call_tool(name, tool_args, ctx, tool.source_tool)
pydantic_ai_slim/pydantic_ai/toolsets/function.py:383: in call_tool
    return await tool.call_func(tool_args, ctx)
pydantic_ai_slim/pydantic_ai/_function_schema.py:53: in call
    return await function(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ctx = RunContext(deps=None, model=TestModel(call_tools='all', custom_output_text=None, custom_output_args=None, seed=0, last...gent1', tool_name='delegate_to_other_agent1', max_retries=1, run_step=1, run_id='96267ae0-f9ff-4500-8026-49d02ae966f0')
sentence = 'a'

    @controller_agent1.tool
    async def delegate_to_other_agent1(ctx: RunContext[None], sentence: str) -> int:
        delegate_result = await delegate_agent.run(sentence)
        delegate_usage = delegate_result.usage()
        run_1_usages.append(delegate_usage)
>       assert delegate_usage == snapshot(RunUsage(requests=1, input_tokens=51, output_tokens=4))
E       AssertionError: assert RunUsage(inpu...5, requests=1) == RunUsage(inpu...4, requests=1)
E         
E         Omitting 9 identical items, use -vv to show
E         Differing attributes:
E         ['output_tokens']
E         
E         Drill down into differing attribute output_tokens:
E           output_tokens: 5 != 4

tests/test_usage_limits.py:171: AssertionError
=========================== short test summary info ============================
FAILED tests/test_usage_limits.py::test_multi_agent_usage_no_incr - Assertion...
ERROR tests/test_usage_limits.py::test_multi_agent_usage_no_incr - Failed: so...
!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 2 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!
===================== 1 failed, 7 passed, 1 error in 1.06s =====================

/Users/akshankrithick/anaconda3/envs/vvenv/lib/python3.11/site-packages/pytest_asyncio/plugin.py:247: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))