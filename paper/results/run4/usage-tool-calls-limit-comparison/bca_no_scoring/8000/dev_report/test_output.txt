l_tools='all', custom_output_text=None, custom_output_args=None, seed=0, last_model_request_parameters=Mo...e, 'properties': {'x': {'type': 'string'}}, 'required': ['x'], 'type': 'object'})], builtin_tools=[], output_tools=[]))
messages = [ModelRequest(parts=[UserPromptPart(content='Hello', timestamp=datetime.datetime(2026, 2, 12, 19, 5, 40, 157665, tzinf...datetime(2026, 2, 12, 19, 5, 40, 157763, tzinfo=datetime.timezone.utc), run_id='d76f9f37-9a0f-4aa6-a05a-736b65c2c99b')]
model_settings = None
model_request_parameters = ModelRequestParameters(function_tools=[ToolDefinition(name='ret_a', parameters_json_schema={'additionalProperties': False, 'properties': {'x': {'type': 'string'}}, 'required': ['x'], 'type': 'object'})], builtin_tools=[], output_tools=[])

    def _request(
        self,
        messages: list[ModelMessage],
        model_settings: ModelSettings | None,
        model_request_parameters: ModelRequestParameters,
    ) -> ModelResponse:
        if model_request_parameters.builtin_tools:
            raise UserError('TestModel does not support built-in tools')
    
        tool_calls = self._get_tool_calls(model_request_parameters)
        output_wrapper = self._get_output(model_request_parameters)
        output_tools = model_request_parameters.output_tools
    
        # if there are tools, the first thing we want to do is call all of them
>       if tool_calls and not any(isinstance(m, ModelResponse) for m in messages) and model_request_parameters.tool_calls_limit is not None:
E       AttributeError: 'ModelRequestParameters' object has no attribute 'tool_calls_limit'

pydantic_ai_slim/pydantic_ai/models/test.py:215: AttributeError
=========================== short test summary info ============================
FAILED tests/test_usage_limits.py::test_tool_call_limit - AttributeError: 'Mo...
!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!
============================== 1 failed in 0.40s ===============================

/Users/akshankrithick/anaconda3/envs/vvenv/lib/python3.11/site-packages/pytest_asyncio/plugin.py:247: PytestDeprecationWarning: The configuration option "asyncio_default_fixture_loop_scope" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: "function", "class", "module", "package", "session"

  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))