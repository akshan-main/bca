FILE: httpx/_content.py
SEARCH:
    CHUNK_SIZE = 65_536
REPLACE:
    CHUNK_SIZE = 65_536

class AsyncIteratorByteStream(httpx.AsyncByteStream):
    CHUNK_SIZE = 65_536

    def __init__(self, stream: typing.AsyncIterable[bytes]) -> None:
        self._stream = stream
        self._is_stream_consumed = False
        self._is_generator = inspect.isasyncgen(stream)

    def __aiter__(self) -> typing.AsyncIterator[bytes]:
        if self._is_stream_consumed and self._is_generator:
            raise StreamConsumed()

        self._is_stream_consumed = True
        if hasattr(self._stream, "aread"):
            # Async file-like interfaces should use 'aread' directly.
            chunk = await self._stream.aread(self.CHUNK_SIZE)
            while chunk:
                yield chunk
                chunk = await self._stream.aread(self.CHUNK_SIZE)
        else:
            # Otherwise iterate.
            async for part in self._stream:
                yield part

FILE: httpx/_content.py
SEARCH:
        if hasattr(self._stream, "read"):
REPLACE:
        if hasattr(self._stream, "aread"):

FILE: httpx/_content.py
SEARCH:
        for part in self._stream:
REPLACE:
        async for part in self._stream:

FILE: httpx/_content.py
SEARCH:
    def __iter__(self) -> Iterator[bytes]:
REPLACE:
    def __aiter__(self) -> AsyncIterator[bytes]:

FILE: httpx/_content.py
SEARCH:
    def __init__(self, stream: Iterable[bytes]) -> None:
REPLACE:
    def __init__(self, stream: AsyncIterable[bytes]) -> None:

FILE: httpx/_content.py
SEARCH:
        if self._is_stream_consumed and self._is_generator:
REPLACE:
        if self._is_stream_consumed and self._is_generator:
