# pydantic_ai_slim/pydantic_ai/_otel_messages.py:20-20
    type: Literal['tool_call']

# pydantic_ai_slim/pydantic_ai/_otel_messages.py:15-15
    type: Literal['text']

# pydantic_ai_slim/pydantic_ai/_otel_messages.py:47-47
    type: Literal['thinking']

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:152-152
    type: Annotated[str, Field(pattern=r'^tool-')]

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:139-139
    type: Annotated[str, Field(pattern=r'^tool-')]

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:192-192
    type: Literal['dynamic-tool'] = 'dynamic-tool'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:90-90
    type: Literal['tool-input-start'] = 'tool-input-start'

# pydantic_evals/pydantic_evals/reporting/analyses.py:21-21
    type: Literal['confusion_matrix'] = 'confusion_matrix'

# pydantic_evals/pydantic_evals/reporting/analyses.py:52-52
    type: Literal['precision_recall'] = 'precision_recall'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:78-78
    type: Literal['file'] = 'file'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:128-128
    type: Annotated[str, Field(pattern=r'^tool-')]

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:205-205
    type: Literal['dynamic-tool'] = 'dynamic-tool'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:124-124
    type: Literal['tool-input-available'] = 'tool-input-available'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:136-136
    type: Literal['tool-input-error'] = 'tool-input-error'

# pydantic_evals/pydantic_evals/reporting/analyses.py:62-62
    type: Literal['scalar'] = 'scalar'

# pydantic_evals/pydantic_evals/reporting/analyses.py:73-73
    type: Literal['table'] = 'table'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:27-27
    type: Literal['text'] = 'text'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:67-67
    type: Literal['source-document'] = 'source-document'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:117-117
    type: Annotated[str, Field(pattern=r'^tool-')]

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:170-170
    type: Literal['dynamic-tool'] = 'dynamic-tool'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:181-181
    type: Literal['dynamic-tool'] = 'dynamic-tool'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:113-113
    type: Literal['tool-output-available'] = 'tool-output-available'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:42-42
    type: Literal['reasoning'] = 'reasoning'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:57-57
    type: Literal['source-url'] = 'source-url'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:149-149
    type: Literal['tool-output-error'] = 'tool-output-error'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:184-184
    type: Literal['source-document'] = 'source-document'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:203-203
    type: Annotated[str, Field(pattern=r'^data-')]

# pydantic_ai_slim/pydantic_ai/_otel_messages.py:28-28
    type: Literal['tool_call_response']

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:41-41
    type: Literal['text-delta'] = 'text-delta'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:66-66
    type: Literal['reasoning-delta'] = 'reasoning-delta'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:174-174
    type: Literal['source-url'] = 'source-url'

# pydantic_ai_slim/pydantic_ai/models/groq.py:665-665
    type: Literal['invalid_request_error']

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:258-258
    type: Literal['reasoning.text', 'reasoning.summary', 'reasoning.encrypted']

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:108-108
    type: Annotated[str, Field(pattern=r'^data-')]

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:33-33
    type: Literal['text-start'] = 'text-start'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:50-50
    type: Literal['text-end'] = 'text-end'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:58-58
    type: Literal['reasoning-start'] = 'reasoning-start'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:75-75
    type: Literal['reasoning-end'] = 'reasoning-end'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:105-105
    type: Literal['tool-input-delta'] = 'tool-input-delta'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:195-195
    type: Literal['file'] = 'file'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:224-224
    type: Literal['start'] = 'start'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:232-232
    type: Literal['finish'] = 'finish'

# pydantic_ai_slim/pydantic_ai/_otel_messages.py:41-41
    type: Literal['binary']

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:278-278
    type: Literal['reasoning.text']

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:83-83
    type: Literal['error'] = 'error'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:159-159
    type: Literal['tool-approval-request'] = 'tool-approval-request'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:254-254
    type: Literal['done'] = 'done'

# tests/models/test_model_names.py:121-121
    type: list[str]

# pydantic_ai_slim/pydantic_ai/_otel_messages.py:36-36
    type: Literal['image-url', 'audio-url', 'video-url', 'document-url']

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:264-264
    type: Literal['reasoning.summary']

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:271-271
    type: Literal['reasoning.encrypted']

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:356-356
    type: Literal['file']

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:102-102
    type: Literal['step-start'] = 'step-start'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:167-167
    type: Literal['tool-output-denied'] = 'tool-output-denied'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:212-212
    type: Literal['start-step'] = 'start-step'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:218-218
    type: Literal['finish-step'] = 'finish-step'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:240-240
    type: Literal['abort'] = 'abort'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:247-247
    type: Literal['message-metadata'] = 'message-metadata'

# pydantic_graph/pydantic_graph/beta/util.py:43-54
def unpack_type_expression(type_: TypeOrTypeExpression[T]) -> type[T]:
    """Extract the actual type from a TypeExpression wrapper or return the type directly.

    Args:
        type_: Either a direct type or a TypeExpression wrapper.

    Returns:
        The unwrapped type, ready for use in runtime type operations.
    """
    if get_origin(type_) is TypeExpression:
        return get_args(type_)[0]
    return cast(type[T], type_)

# pydantic_ai_slim/pydantic_ai/models/test.py:4-4
import string

# pydantic_evals/pydantic_evals/dataset.py:519-536
    def _params(cls) -> tuple[type[InputsT], type[OutputT], type[MetadataT]]:
        """Get the type parameters for the Dataset class.

        Returns:
            A tuple of (InputsT, OutputT, MetadataT) types.
        """
        for c in cls.__mro__:
            metadata = getattr(c, '__pydantic_generic_metadata__', {})
            if len(args := (metadata.get('args', ()) or getattr(c, '__args__', ()))) == 3:  # pragma: no branch
                return args
        else:  # pragma: no cover
            warnings.warn(
                f'Could not determine the generic parameters for {cls}; using `Any` for each.'
                f' You should explicitly set the generic parameters via `Dataset[MyInputs, MyOutput, MyMetadata]`'
                f' when serializing or deserializing.',
                UserWarning,
            )
            return Any, Any, Any  # type: ignore

# tests/test_utils.py:55-117
def test_check_object_json_schema():
    object_schema = {'type': 'object', 'properties': {'a': {'type': 'string'}}}
    assert check_object_json_schema(object_schema) == object_schema

    assert check_object_json_schema(
        {
            '$defs': {
                'JsonModel': {
                    'properties': {
                        'type': {'title': 'Type', 'type': 'string'},
                        'items': {'anyOf': [{'type': 'string'}, {'type': 'null'}]},
                    },
                    'required': ['type', 'items'],
                    'title': 'JsonModel',
                    'type': 'object',
                }
            },
            '$ref': '#/$defs/JsonModel',
        }
    ) == {
        'properties': {
            'items': {'anyOf': [{'type': 'string'}, {'type': 'null'}]},
            'type': {'title': 'Type', 'type': 'string'},
        },
        'required': ['type', 'items'],
        'title': 'JsonModel',
        'type': 'object',
    }

    # Can't remove the recursive ref here:
    assert check_object_json_schema(
        {
            '$defs': {
                'JsonModel': {
                    'properties': {
                        'type': {'title': 'Type', 'type': 'string'},
                        'items': {'anyOf': [{'$ref': '#/$defs/JsonModel'}, {'type': 'null'}]},
                    },
                    'required': ['type', 'items'],
                    'title': 'JsonModel',
                    'type': 'object',
                }
            },
            '$ref': '#/$defs/JsonModel',
        }
    ) == {
        '$defs': {
            'JsonModel': {
                'properties': {
                    'items': {'anyOf': [{'$ref': '#/$defs/JsonModel'}, {'type': 'null'}]},
                    'type': {'title': 'Type', 'type': 'string'},
                },
                'required': ['type', 'items'],
                'title': 'JsonModel',
                'type': 'object',
            }
        },
        '$ref': '#/$defs/JsonModel',
    }

    array_schema = {'type': 'array', 'items': {'type': 'string'}}
    with pytest.raises(UserError, match='^Schema must be an object$'):
        check_object_json_schema(array_schema)

# pydantic_graph/pydantic_graph/persistence/__init__.py:215-225
    def set_types(self, state_type: type[StateT], run_end_type: type[RunEndT]) -> None:
        """Set the types of the state and run end.

        This can be used to create [type adapters][pydantic.TypeAdapter] for serializing and deserializing snapshots,
        e.g. with [`build_snapshot_list_type_adapter`][pydantic_graph.persistence.build_snapshot_list_type_adapter].

        Args:
            state_type: The state type.
            run_end_type: The run end type.
        """
        pass

# pydantic_graph/pydantic_graph/beta/paths.py:295-421
class EdgePathBuilder(Generic[StateT, DepsT, OutputT]):
    """A builder for constructing complete edge paths with method chaining.

    EdgePathBuilder combines source nodes with path building capabilities
    to create complete edge definitions. It cannot use dataclass due to
    type variance issues.

    Type Parameters:
        StateT: The type of the graph state
        DepsT: The type of the dependencies
        OutputT: The type of the current data in the path
    """

    def __init__(
        self, sources: Sequence[SourceNode[StateT, DepsT, Any]], path_builder: PathBuilder[StateT, DepsT, OutputT]
    ):
        """Initialize an edge path builder.

        Args:
            sources: The source nodes for this edge path
            path_builder: The path builder for defining the data flow
        """
        self.sources = sources
        self._path_builder = path_builder

    def to(
        self,
        destination: DestinationNode[StateT, DepsT, OutputT] | type[BaseNode[StateT, DepsT, Any]],
        /,
        *extra_destinations: DestinationNode[StateT, DepsT, OutputT] | type[BaseNode[StateT, DepsT, Any]],
        fork_id: str | None = None,
    ) -> EdgePath[StateT, DepsT]:
        """Complete the edge path by routing to destination nodes.

        Args:
            destination: Either a destination node or a function that generates edge paths
            *extra_destinations: Additional destination nodes (creates a broadcast)
            fork_id: Optional ID for the fork created when multiple destinations are specified

        Returns:
            A complete EdgePath connecting sources to destinations
        """
        # `type[BaseNode[StateT, DepsT, Any]]` could actually be a `typing._GenericAlias` like `pydantic_ai._agent_graph.UserPromptNode[~DepsT, ~OutputT]`,
        # so we get the origin to get to the actual class
        destination = get_origin(destination) or destination
        extra_destinations = tuple(get_origin(d) or d for d in extra_destinations)
        destinations = [(NodeStep(d) if inspect.isclass(d) else d) for d in (destination, *extra_destinations)]
        return EdgePath(
            sources=self.sources,
            path=self._path_builder.to(destinations[0], *destinations[1:], fork_id=fork_id),
            destinations=destinations,
        )

    def broadcast(
        self, get_forks: Callable[[Self], Sequence[EdgePath[StateT, DepsT]]], /, *, fork_id: str | None = None
    ) -> EdgePath[StateT, DepsT]:
        """Broadcast this EdgePathBuilder into multiple destinations.

        Args:
            get_forks: The callback that will return a sequence of EdgePaths to broadcast to.
            fork_id: Optional node ID to use for the resulting broadcast fork.

        Returns:
            A completed EdgePath with the specified destinations.
        """
        new_edge_paths = get_forks(self)
        new_paths = [Path(x.path.items) for x in new_edge_paths]
        if not new_paths:
            raise GraphBuildingError(f'The call to {get_forks} returned no branches, but must return at least one.')
        path = self._path_builder.broadcast(new_paths, fork_id=fork_id)
        destinations = [d for ep in new_edge_paths for d in ep.destinations]
        return EdgePath(
            sources=self.sources,
            path=path,
            destinations=destinations,
        )

    def map(
        self: EdgePathBuilder[StateT, DepsT, Iterable[T]] | EdgePathBuilder[StateT, DepsT, AsyncIterable[T]],
        *,
        fork_id: str | None = None,
        downstream_join_id: JoinID | None = None,
    ) -> EdgePathBuilder[StateT, DepsT, T]:
        """Spread iterable data across parallel execution paths.

        Args:
            fork_id: Optional ID for the fork, defaults to a generated value
            downstream_join_id: Optional ID of a downstream join node which is involved when mapping empty iterables

        Returns:
            A new EdgePathBuilder that operates on individual items from the iterable
        """
        if len(self.sources) > 1:
            # The current implementation mishandles this because you get one copy of each edge
            # from the MapMarker to its destination for each source, resulting in unintentional multiple execution.
            # I suspect this is fixable without a major refactor, though it's not clear to me what the ideal behavior
            # would be. But for now, it's definitely easiest to just raise an error for this.
            raise NotImplementedError(
                'Map is not currently supported with multiple source nodes.'
                ' You can work around this by just creating a separate edge for each source.'
            )
        return EdgePathBuilder(
            sources=self.sources,
            path_builder=self._path_builder.map(fork_id=fork_id, downstream_join_id=downstream_join_id),
        )

    def transform(self, func: TransformFunction[StateT, DepsT, OutputT, T], /) -> EdgePathBuilder[StateT, DepsT, T]:
        """Add a transformation step to the edge path.

        Args:
            func: The step function that will transform the data

        Returns:
            A new EdgePathBuilder with the transformation added
        """
        return EdgePathBuilder(sources=self.sources, path_builder=self._path_builder.transform(func))

    def label(self, label: str) -> EdgePathBuilder[StateT, DepsT, OutputT]:
        """Add a human-readable label to this point in the edge path.

        Args:
            label: The label to add for documentation/debugging purposes

        Returns:
            A new EdgePathBuilder with the label added
        """
        return EdgePathBuilder(sources=self.sources, path_builder=self._path_builder.label(label))

# pydantic_graph/pydantic_graph/beta/step.py:66-87
class StepFunction(Protocol[StateT, DepsT, InputT, OutputT]):
    """Protocol for step functions that can be executed in the graph.

    Step functions are async callables that receive a step context and return a result.

    Type Parameters:
        StateT: The type of the graph state
        DepsT: The type of the dependencies
        InputT: The type of the input data
        OutputT: The type of the output data
    """

    def __call__(self, ctx: StepContext[StateT, DepsT, InputT]) -> Awaitable[OutputT]:
        """Execute the step function with the given context.

        Args:
            ctx: The step context containing state, dependencies, and inputs

        Returns:
            An awaitable that resolves to the step's output
        """
        raise NotImplementedError

# pydantic_graph/pydantic_graph/beta/util.py:16-31
class TypeExpression(Generic[T]):
    """A workaround for type checker limitations when using complex type expressions.

        This class serves as a wrapper for types that cannot normally be used in positions
    requiring `type[T]`, such as `Any`, `Union[...]`, or `Literal[...]`. It provides a
        way to pass these complex type expressions to functions expecting concrete types.

    Example:
            Instead of `output_type=Union[str, int]` (which may cause type errors),
            use `output_type=TypeExpression[Union[str, int]]`.

    Note:
            This is a workaround for the lack of TypeForm in the Python type system.
    """

    pass

# pydantic_graph/pydantic_graph/beta/step.py:90-112
class StreamFunction(Protocol[StateT, DepsT, InputT, OutputT]):
    """Protocol for stream functions that can be executed in the graph.

    Stream functions are async callables that receive a step context and return an async iterator.

    Type Parameters:
        StateT: The type of the graph state
        DepsT: The type of the dependencies
        InputT: The type of the input data
        OutputT: The type of the output data
    """

    def __call__(self, ctx: StepContext[StateT, DepsT, InputT]) -> AsyncIterator[OutputT]:
        """Execute the stream function with the given context.

        Args:
            ctx: The step context containing state, dependencies, and inputs

        Returns:
            An async iterator yielding the streamed output
        """
        raise NotImplementedError
        yield

# pydantic_graph/pydantic_graph/beta/graph.py:109-304
class Graph(Generic[StateT, DepsT, InputT, OutputT]):
    """A complete graph definition ready for execution.

    The Graph class represents a complete workflow graph with typed inputs,
    outputs, state, and dependencies. It contains all nodes, edges, and
    metadata needed for execution.

    Type Parameters:
        StateT: The type of the graph state
        DepsT: The type of the dependencies
        InputT: The type of the input data
        OutputT: The type of the output data
    """

    name: str | None
    """Optional name for the graph, if not provided the name will be inferred from the calling frame on the first call to a graph method."""

    state_type: type[StateT]
    """The type of the graph state."""

    deps_type: type[DepsT]
    """The type of the dependencies."""

    input_type: type[InputT]
    """The type of the input data."""

    output_type: type[OutputT]
    """The type of the output data."""

    auto_instrument: bool
    """Whether to automatically create instrumentation spans."""

    nodes: dict[NodeID, AnyNode]
    """All nodes in the graph indexed by their ID."""

    edges_by_source: dict[NodeID, list[Path]]
    """Outgoing paths from each source node."""

    parent_forks: dict[JoinID, ParentFork[NodeID]]
    """Parent fork information for each join node."""

    intermediate_join_nodes: dict[JoinID, set[JoinID]]
    """For each join, the set of other joins that appear between it and its parent fork.

    Used to determine which joins are "final" (have no other joins as intermediates) and
    which joins should preserve fork stacks when proceeding downstream."""

    def get_parent_fork(self, join_id: JoinID) -> ParentFork[NodeID]:
        """Get the parent fork information for a join node.

        Args:
            join_id: The ID of the join node

        Returns:
            The parent fork information for the join

        Raises:
            RuntimeError: If the join ID is not found or has no parent fork
        """
        result = self.parent_forks.get(join_id)
        if result is None:
            raise RuntimeError(f'Node {join_id} is not a join node or did not have a dominating fork (this is a bug)')
        return result

    def is_final_join(self, join_id: JoinID) -> bool:
        """Check if a join is 'final' (has no downstream joins with the same parent fork).

        A join is non-final if it appears as an intermediate node for another join
        with the same parent fork.

        Args:
            join_id: The ID of the join node

        Returns:
            True if the join is final, False if it's non-final
        """
        # Check if this join appears in any other join's intermediate_join_nodes
        for intermediate_joins in self.intermediate_join_nodes.values():
            if join_id in intermediate_joins:
                return False
        return True

    async def run(
        self,
        *,
        state: StateT = None,
        deps: DepsT = None,
        inputs: InputT = None,
        span: AbstractContextManager[AbstractSpan] | None = None,
        infer_name: bool = True,
    ) -> OutputT:
        """Execute the graph and return the final output.

        This is the main entry point for graph execution. It runs the graph
        to completion and returns the final output value.

        Args:
            state: The graph state instance
            deps: The dependencies instance
            inputs: The input data for the graph
            span: Optional span for tracing/instrumentation
            infer_name: Whether to infer the graph name from the calling frame.

        Returns:
            The final output from the graph execution
        """
        if infer_name and self.name is None:
            inferred_name = infer_obj_name(self, depth=2)
            if inferred_name is not None:  # pragma: no branch
                self.name = inferred_name

        async with self.iter(state=state, deps=deps, inputs=inputs, span=span, infer_name=False) as graph_run:
            # Note: This would probably be better using `async for _ in graph_run`, but this tests the `next` method,
            # which I'm less confident will be implemented correctly if not used on the critical path. We can change it
            # once we have tests, etc.
            event: Any = None
            while True:
                try:
                    event = await graph_run.next(event)
                except StopAsyncIteration:
                    assert isinstance(event, EndMarker), 'Graph run should end with an EndMarker.'
                    return cast(EndMarker[OutputT], event).value

    @asynccontextmanager
    async def iter(
        self,
        *,
        state: StateT = None,
        deps: DepsT = None,
        inputs: InputT = None,
        span: AbstractContextManager[AbstractSpan] | None = None,
        infer_name: bool = True,
    ) -> AsyncIterator[GraphRun[StateT, DepsT, OutputT]]:
        """Create an iterator for step-by-step graph execution.

        This method allows for more fine-grained control over graph execution,
        enabling inspection of intermediate states and results.

        Args:
            state: The graph state instance
            deps: The dependencies instance
            inputs: The input data for the graph
            span: Optional span for tracing/instrumentation
            infer_name: Whether to infer the graph name from the calling frame.

        Yields:
            A GraphRun instance that can be iterated for step-by-step execution
        """
        if infer_name and self.name is None:
            inferred_name = infer_obj_name(self, depth=3)  # depth=3 because asynccontextmanager adds one
            if inferred_name is not None:  # pragma: no branch
                self.name = inferred_name

        with ExitStack() as stack:
            entered_span: AbstractSpan | None = None
            if span is None:
                if self.auto_instrument:
                    entered_span = stack.enter_context(logfire_span('run graph {graph.name}', graph=self))
            else:
                entered_span = stack.enter_context(span)
            traceparent = None if entered_span is None else get_traceparent(entered_span)
            async with GraphRun[StateT, DepsT, OutputT](
                graph=self,
                state=state,
                deps=deps,
                inputs=inputs,
                traceparent=traceparent,
            ) as graph_run:
                yield graph_run

    def render(self, *, title: str | None = None, direction: StateDiagramDirection | None = None) -> str:
        """Render the graph as a Mermaid diagram string.

        Args:
            title: Optional title for the diagram
            direction: Optional direction for the diagram layout

        Returns:
            A string containing the Mermaid diagram representation
        """
        from pydantic_graph.beta.mermaid import build_mermaid_graph

        return build_mermaid_graph(self.nodes, self.edges_by_source).render(title=title, direction=direction)

    def __repr__(self) -> str:
        super_repr = super().__repr__()  # include class and memory address
        # Insert the result of calling `__str__` before the final '>' in the repr
        return f'{super_repr[:-1]}\n{self}\n{super_repr[-1]}'

    def __str__(self) -> str:
        """Return a Mermaid diagram representation of the graph.

        Returns:
            A string containing the Mermaid diagram of the graph
        """
        return self.render()

# pydantic_graph/pydantic_graph/beta/step.py:120-165
class Step(Generic[StateT, DepsT, InputT, OutputT]):
    """A step in the graph execution that wraps a step function.

    Steps represent individual units of execution in the graph, encapsulating
    a step function along with metadata like ID and label.

    Type Parameters:
        StateT: The type of the graph state
        DepsT: The type of the dependencies
        InputT: The type of the input data
        OutputT: The type of the output data
    """

    id: NodeID
    """Unique identifier for this step."""
    _call: StepFunction[StateT, DepsT, InputT, OutputT]
    """The step function to execute."""
    label: str | None
    """Optional human-readable label for this step."""

    def __init__(self, *, id: NodeID, call: StepFunction[StateT, DepsT, InputT, OutputT], label: str | None = None):
        self.id = id
        self._call = call
        self.label = label

    @property
    def call(self) -> StepFunction[StateT, DepsT, InputT, OutputT]:
        """The step function to execute. This needs to be a property for proper variance inference."""
        return self._call

    @overload
    def as_node(self, inputs: None = None) -> StepNode[StateT, DepsT]: ...

    @overload
    def as_node(self, inputs: InputT) -> StepNode[StateT, DepsT]: ...

    def as_node(self, inputs: InputT | None = None) -> StepNode[StateT, DepsT]:
        """Create a step node with bound inputs.

        Args:
            inputs: The input data to bind to this step, or None

        Returns:
            A [`StepNode`][pydantic_graph.beta.step.StepNode] with this step and the bound inputs
        """
        return StepNode(self, inputs)

# pydantic_graph/pydantic_graph/beta/step.py:26-63
class StepContext(Generic[StateT, DepsT, InputT]):
    """Context information passed to step functions during graph execution.

    The step context provides access to the current graph state, dependencies, and input data for a step.

    Type Parameters:
        StateT: The type of the graph state
        DepsT: The type of the dependencies
        InputT: The type of the input data
    """

    _state: StateT
    """The current graph state."""
    _deps: DepsT
    """The graph run dependencies."""
    _inputs: InputT
    """The input data for this step."""

    def __init__(self, *, state: StateT, deps: DepsT, inputs: InputT):
        self._state = state
        self._deps = deps
        self._inputs = inputs

    @property
    def state(self) -> StateT:
        return self._state

    @property
    def deps(self) -> DepsT:
        return self._deps

    @property
    def inputs(self) -> InputT:
        """The input data for this step.

        This must be a property to ensure correct variance behavior
        """
        return self._inputs

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:107-109
    def deps_type(self) -> type:
        """The type of dependencies used by the agent."""
        raise NotImplementedError

# pydantic_ai_slim/pydantic_ai/output.py:296-360
def StructuredDict(
    json_schema: JsonSchemaValue, name: str | None = None, description: str | None = None
) -> type[JsonSchemaValue]:
    """Returns a `dict[str, Any]` subclass with a JSON schema attached that will be used for structured output.

    Args:
        json_schema: A JSON schema of type `object` defining the structure of the dictionary content.
        name: Optional name of the structured output. If not provided, the `title` field of the JSON schema will be used if it's present.
        description: Optional description of the structured output. If not provided, the `description` field of the JSON schema will be used if it's present.

    Example:
    ```python {title="structured_dict.py"}
    from pydantic_ai import Agent, StructuredDict

    schema = {
        'type': 'object',
        'properties': {
            'name': {'type': 'string'},
            'age': {'type': 'integer'}
        },
        'required': ['name', 'age']
    }

    agent = Agent('openai:gpt-5.2', output_type=StructuredDict(schema))
    result = agent.run_sync('Create a person')
    print(result.output)
    #> {'name': 'John Doe', 'age': 30}
    ```
    """
    json_schema = _utils.check_object_json_schema(json_schema)

    # Pydantic `TypeAdapter` fails when `object.__get_pydantic_json_schema__` has `$defs`, so we inline them
    # See https://github.com/pydantic/pydantic/issues/12145
    if '$defs' in json_schema:
        json_schema = InlineDefsJsonSchemaTransformer(json_schema).walk()
        if '$defs' in json_schema:
            raise exceptions.UserError(
                '`StructuredDict` does not currently support recursive `$ref`s and `$defs`. See https://github.com/pydantic/pydantic/issues/12145 for more information.'
            )

    if name:
        json_schema['title'] = name

    if description:
        json_schema['description'] = description

    class _StructuredDict(JsonSchemaValue):
        __is_model_like__ = True

        @classmethod
        def __get_pydantic_core_schema__(
            cls, source_type: Any, handler: GetCoreSchemaHandler
        ) -> core_schema.CoreSchema:
            return core_schema.dict_schema(
                keys_schema=core_schema.str_schema(),
                values_schema=core_schema.any_schema(),
            )

        @classmethod
        def __get_pydantic_json_schema__(
            cls, core_schema: core_schema.CoreSchema, handler: GetJsonSchemaHandler
        ) -> JsonSchemaValue:
            return json_schema

    return _StructuredDict

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:453-455
    def deps_type(self) -> type:
        """The type of dependencies used by the agent."""
        return self._deps_type

# pydantic_graph/pydantic_graph/beta/paths.py:32-57
class TransformFunction(Protocol[StateT, DepsT, InputT, OutputT]):
    """Protocol for step functions that can be executed in the graph.

    Transform functions are sync callables that receive a step context and return
    a result. This protocol enables serialization and deserialization of step
    calls similar to how evaluators work.

    This is very similar to a StepFunction, but must be sync instead of async.

    Type Parameters:
        StateT: The type of the graph state
        DepsT: The type of the dependencies
        InputT: The type of the input data
        OutputT: The type of the output data
    """

    def __call__(self, ctx: StepContext[StateT, DepsT, InputT]) -> OutputT:
        """Execute the step function with the given context.

        Args:
            ctx: The step context containing state, dependencies, and inputs

        Returns:
            An awaitable that resolves to the step's output
        """
        raise NotImplementedError

# pydantic_ai_slim/pydantic_ai/models/openai.py:885-890
    def _streamed_response_cls(self) -> type[OpenAIStreamedResponse]:
        """Returns the `StreamedResponse` type that will be used for streamed responses.

        This method may be overridden by subclasses of `OpenAIChatModel` to provide their own `StreamedResponse` type.
        """
        return OpenAIStreamedResponse

# pydantic_graph/pydantic_graph/beta/join.py:151-216
class Join(Generic[StateT, DepsT, InputT, OutputT]):
    """A join operation that synchronizes and aggregates parallel execution paths.

    A join defines how to combine outputs from multiple parallel execution paths
    using a [`ReducerFunction`][pydantic_graph.beta.join.ReducerFunction]. It specifies which fork
    it joins (if any) and manages the initialization of reducers.

    Type Parameters:
        StateT: The type of the graph state
        DepsT: The type of the dependencies
        InputT: The type of input data to join
        OutputT: The type of the final joined output
    """

    id: JoinID
    _reducer: ReducerFunction[StateT, DepsT, InputT, OutputT]
    _initial_factory: Callable[[], OutputT]
    parent_fork_id: ForkID | None
    preferred_parent_fork: Literal['closest', 'farthest']

    def __init__(
        self,
        *,
        id: JoinID,
        reducer: ReducerFunction[StateT, DepsT, InputT, OutputT],
        initial_factory: Callable[[], OutputT],
        parent_fork_id: ForkID | None = None,
        preferred_parent_fork: Literal['farthest', 'closest'] = 'farthest',
    ):
        self.id = id
        self._reducer = reducer
        self._initial_factory = initial_factory
        self.parent_fork_id = parent_fork_id
        self.preferred_parent_fork = preferred_parent_fork

    @property
    def reducer(self):
        return self._reducer

    @property
    def initial_factory(self):
        return self._initial_factory

    def reduce(self, ctx: ReducerContext[StateT, DepsT], current: OutputT, inputs: InputT) -> OutputT:
        n_parameters = len(inspect.signature(self.reducer).parameters)
        if n_parameters == 2:
            return cast(PlainReducerFunction[InputT, OutputT], self.reducer)(current, inputs)
        else:
            return cast(ContextReducerFunction[StateT, DepsT, InputT, OutputT], self.reducer)(ctx, current, inputs)

    @overload
    def as_node(self, inputs: None = None) -> JoinNode[StateT, DepsT]: ...

    @overload
    def as_node(self, inputs: InputT) -> JoinNode[StateT, DepsT]: ...

    def as_node(self, inputs: InputT | None = None) -> JoinNode[StateT, DepsT]:
        """Create a step node with bound inputs.

        Args:
            inputs: The input data to bind to this step, or None

        Returns:
            A [`StepNode`][pydantic_graph.beta.step.StepNode] with this step and the bound inputs
        """
        return JoinNode(self, inputs)