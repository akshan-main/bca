# pydantic_ai_slim/pydantic_ai/_otel_messages.py:16-16
    content: NotRequired[str]

# pydantic_ai_slim/pydantic_ai/_otel_messages.py:16-16
    content: NotRequired[str]

# pydantic_ai_slim/pydantic_ai/messages.py:1562-1562
    content_delta: str

# pydantic_ai_slim/pydantic_ai/messages.py:1091-1093
    def has_content(self) -> bool:
        """Return `True` if the text content is non-empty."""
        return bool(self.content)

# tests/test_parts_manager.py:27-43
def test_handle_text_deltas(vendor_part_id: str | None):
    manager = ModelResponsePartsManager()
    assert manager.get_parts() == []

    event = next(manager.handle_text_delta(vendor_part_id=vendor_part_id, content='hello '))
    assert event == snapshot(
        PartStartEvent(index=0, part=TextPart(content='hello ', part_kind='text'), event_kind='part_start')
    )
    assert manager.get_parts() == snapshot([TextPart(content='hello ', part_kind='text')])

    event = next(manager.handle_text_delta(vendor_part_id=vendor_part_id, content='world'))
    assert event == snapshot(
        PartDeltaEvent(
            index=0, delta=TextPartDelta(content_delta='world', part_delta_kind='text'), event_kind='part_delta'
        )
    )
    assert manager.get_parts() == snapshot([TextPart(content='hello world', part_kind='text')])

# tests/mcp_server.py:7-17
from mcp.types import (
    Annotations,
    BlobResourceContents,
    CreateMessageResult,
    EmbeddedResource,
    ResourceLink,
    SamplingMessage,
    TextContent,
    TextResourceContents,
    ToolAnnotations,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:50-102
from .messages import (
    AgentStreamEvent,
    AudioFormat,
    AudioMediaType,
    AudioUrl,
    BaseToolCallPart,
    BaseToolReturnPart,
    BinaryContent,
    BinaryImage,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentFormat,
    DocumentMediaType,
    DocumentUrl,
    FilePart,
    FileUrl,
    FinalResultEvent,
    FinishReason,
    FunctionToolCallEvent,
    FunctionToolResultEvent,
    HandleResponseEvent,
    ImageFormat,
    ImageMediaType,
    ImageUrl,
    ModelMessage,
    ModelMessagesTypeAdapter,
    ModelRequest,
    ModelRequestPart,
    ModelResponse,
    ModelResponsePart,
    ModelResponsePartDelta,
    ModelResponseStreamEvent,
    MultiModalContent,
    PartDeltaEvent,
    PartEndEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolCallPartDelta,
    ToolReturn,
    ToolReturnPart,
    UserContent,
    UserPromptPart,
    VideoFormat,
    VideoMediaType,
    VideoUrl,
)

# pydantic_ai_slim/pydantic_ai/ui/ag_ui/_event_stream.py:84-85
    def content_type(self) -> str:
        return self._event_encoder.get_content_type()

# pydantic_ai_slim/pydantic_ai/models/gemini.py:812-814
class _GeminiTextContent(TypedDict):
    role: Literal['user', 'model']
    parts: list[_GeminiTextPart]

# tests/mcp_server.py:7-17
from mcp.types import (
    Annotations,
    BlobResourceContents,
    CreateMessageResult,
    EmbeddedResource,
    ResourceLink,
    SamplingMessage,
    TextContent,
    TextResourceContents,
    ToolAnnotations,
)

# tests/conftest.py:403-406
def text_document_content(assets_path: Path) -> BinaryContent:
    content = assets_path.joinpath('dummy.txt').read_text(encoding='utf-8')
    bin_content = BinaryContent(data=content.encode(), media_type='text/plain')
    return bin_content

# pydantic_ai_slim/pydantic_ai/messages.py:2010-2010
    content: str | Sequence[UserContent] | None = None

# tests/test_parts_manager.py:84-162
def test_handle_text_deltas_with_think_tags():
    manager = ModelResponsePartsManager()
    thinking_tags = ('<think>', '</think>')

    event = next(manager.handle_text_delta(vendor_part_id='content', content='pre-', thinking_tags=thinking_tags))
    assert event == snapshot(
        PartStartEvent(index=0, part=TextPart(content='pre-', part_kind='text'), event_kind='part_start')
    )
    assert manager.get_parts() == snapshot([TextPart(content='pre-', part_kind='text')])

    event = next(manager.handle_text_delta(vendor_part_id='content', content='thinking', thinking_tags=thinking_tags))
    assert event == snapshot(
        PartDeltaEvent(
            index=0, delta=TextPartDelta(content_delta='thinking', part_delta_kind='text'), event_kind='part_delta'
        )
    )
    assert manager.get_parts() == snapshot([TextPart(content='pre-thinking', part_kind='text')])

    event = next(manager.handle_text_delta(vendor_part_id='content', content='<think>', thinking_tags=thinking_tags))
    assert event == snapshot(
        PartStartEvent(index=1, part=ThinkingPart(content='', part_kind='thinking'), event_kind='part_start')
    )
    assert manager.get_parts() == snapshot(
        [TextPart(content='pre-thinking', part_kind='text'), ThinkingPart(content='', part_kind='thinking')]
    )

    event = next(manager.handle_text_delta(vendor_part_id='content', content='thinking', thinking_tags=thinking_tags))
    assert event == snapshot(
        PartDeltaEvent(
            index=1,
            delta=ThinkingPartDelta(content_delta='thinking', part_delta_kind='thinking'),
            event_kind='part_delta',
        )
    )
    assert manager.get_parts() == snapshot(
        [TextPart(content='pre-thinking', part_kind='text'), ThinkingPart(content='thinking', part_kind='thinking')]
    )

    event = next(manager.handle_text_delta(vendor_part_id='content', content=' more', thinking_tags=thinking_tags))
    assert event == snapshot(
        PartDeltaEvent(
            index=1, delta=ThinkingPartDelta(content_delta=' more', part_delta_kind='thinking'), event_kind='part_delta'
        )
    )
    assert manager.get_parts() == snapshot(
        [
            TextPart(content='pre-thinking', part_kind='text'),
            ThinkingPart(content='thinking more', part_kind='thinking'),
        ]
    )

    events = list(manager.handle_text_delta(vendor_part_id='content', content='</think>', thinking_tags=thinking_tags))
    assert events == []

    event = next(manager.handle_text_delta(vendor_part_id='content', content='post-', thinking_tags=thinking_tags))
    assert event == snapshot(
        PartStartEvent(index=2, part=TextPart(content='post-', part_kind='text'), event_kind='part_start')
    )
    assert manager.get_parts() == snapshot(
        [
            TextPart(content='pre-thinking', part_kind='text'),
            ThinkingPart(content='thinking more', part_kind='thinking'),
            TextPart(content='post-', part_kind='text'),
        ]
    )

    event = next(manager.handle_text_delta(vendor_part_id='content', content='thinking', thinking_tags=thinking_tags))
    assert event == snapshot(
        PartDeltaEvent(
            index=2, delta=TextPartDelta(content_delta='thinking', part_delta_kind='text'), event_kind='part_delta'
        )
    )
    assert manager.get_parts() == snapshot(
        [
            TextPart(content='pre-thinking', part_kind='text'),
            ThinkingPart(content='thinking more', part_kind='thinking'),
            TextPart(content='post-thinking', part_kind='text'),
        ]
    )

# pydantic_ai_slim/pydantic_ai/_parts_manager.py:465-480
    def _handle_embedded_thinking_content(
        self,
        existing_part: ThinkingPart,
        part_index: int,
        content: str,
        provider_name: str | None,
        provider_details: dict[str, Any] | None,
    ) -> Iterator[ModelResponseStreamEvent]:
        """Handle content inside <think>...</think>."""
        part_delta = ThinkingPartDelta(
            content_delta=content,
            provider_name=self._resolve_provider_name(existing_part, provider_name),
            provider_details=provider_details,
        )
        self._parts[part_index] = part_delta.apply(existing_part)
        yield PartDeltaEvent(index=part_index, delta=part_delta)

# pydantic_ai_slim/pydantic_ai/models/function.py:263-263
    content: str | None = None

# tests/models/test_bedrock.py:929-947
async def test_text_as_binary_content_input(allow_model_requests: None, bedrock_provider: BedrockProvider):
    m = BedrockConverseModel('us.amazon.nova-pro-v1:0', provider=bedrock_provider)
    agent = Agent(m, instructions='You are a helpful chatbot.')

    text_content = BinaryContent(data=b'This is a test document.', media_type='text/plain')

    result = await agent.run(['What is the main content on this document?', text_content])
    assert result.output == snapshot(
        """\
The document you're referring to appears to be a test document, which means its primary purpose is likely to serve as an example or a placeholder rather than containing substantive content. Test documents are commonly used for various purposes such as:

1. **Software Testing**: To verify that a system can correctly handle, display, or process documents.
2. **Design Mockups**: To illustrate how a document might look in a particular format or style.
3. **Training Materials**: To provide examples for instructional purposes.
4. **Placeholders**: To fill space in a system or application where real content will eventually be placed.

Since this is a test document, it probably doesn't contain any meaningful or specific information beyond what is necessary to serve its testing purpose. If you have specific questions about the format, structure, or any particular element within the document, feel free to ask!\
"""
    )

# pydantic_ai_slim/pydantic_ai/messages.py:1154-1154
    content: Annotated[BinaryContent, pydantic.AfterValidator(BinaryImage.narrow_type)]

# pydantic_ai_slim/pydantic_ai/messages.py:1612-1612
    content_delta: str | None = None

# pydantic_ai_slim/pydantic_ai/ui/_event_stream.py:444-451
    async def handle_text_delta(self, delta: TextPartDelta) -> AsyncIterator[EventT]:
        """Handle a `TextPartDelta`.

        Args:
            delta: The text part delta.
        """
        return  # pragma: no cover
        yield  # Make this an async generator

# pydantic_ai_slim/pydantic_ai/models/gemini.py:814-814
    parts: list[_GeminiTextPart]

# pydantic_ai_slim/pydantic_ai/models/xai.py:1085-1099
def _get_tool_result_content(content: str) -> dict[str, Any] | str | None:
    """Extract tool result content from a content string.

    Args:
        content: The content string (may be JSON or plain text)

    Returns:
        Tool result content as dict (if JSON), string, or None if no content
    """
    if content:
        try:
            return json.loads(content)
        except (json.JSONDecodeError, TypeError):
            return content
    return None

# pydantic_ai_slim/pydantic_ai/common_tools/exa.py:76-76
    text: str

# pydantic_ai_slim/pydantic_ai/models/mistral.py:629-629
    _delta_content: str = field(default='', init=False)

# pydantic_ai_slim/pydantic_ai/models/mistral.py:779-807
def _map_content(content: MistralOptionalNullable[MistralContent]) -> tuple[str | None, list[str]]:
    """Maps the delta content from a Mistral Completion Chunk to a string or None."""
    text: str | None = None
    thinking: list[str] = []

    if isinstance(content, MistralUnset) or not content:
        return None, []
    elif isinstance(content, list):
        for chunk in content:
            if isinstance(chunk, MistralTextChunk):
                text = (text or '') + chunk.text
            elif isinstance(chunk, MistralThinkChunk):
                for thought in chunk.thinking:
                    if thought.type == 'text':  # pragma: no branch
                        thinking.append(thought.text)
            elif isinstance(chunk, MistralReferenceChunk):
                pass  # Reference chunks are not yet supported, skip silently
            else:
                assert False, (  # pragma: no cover
                    f'Other data types like (Image) are not yet supported, got {type(chunk)}'
                )
    elif isinstance(content, str):
        text = content

    # Note: Check len to handle potential mismatch between function calls and responses from the API. (`msg: not the same number of function class and responses`)
    if text and len(text) == 0:  # pragma: no cover
        text = None

    return text, thinking

# pydantic_ai_slim/pydantic_ai/_otel_messages.py:48-48
    content: NotRequired[str]

# pydantic_ai_slim/pydantic_ai/_otel_messages.py:48-48
    content: NotRequired[str]

# pydantic_ai_slim/pydantic_ai/ui/ag_ui/_event_stream.py:137-139
    async def handle_text_delta(self, delta: TextPartDelta) -> AsyncIterator[BaseEvent]:
        if delta.content_delta:  # pragma: no branch
            yield TextMessageContentEvent(message_id=self.message_id, delta=delta.content_delta)

# pydantic_ai_slim/pydantic_ai/_otel_messages.py:43-43
    content: NotRequired[str]

# pydantic_ai_slim/pydantic_ai/messages.py:751-751
    content: str | Sequence[UserContent]

# pydantic_ai_slim/pydantic_ai/messages.py:946-946
    content: list[pydantic_core.ErrorDetails] | str

# pydantic_ai_slim/pydantic_ai/_run_context.py:47-47
    trace_include_content: bool = False

# tests/test_ui.py:145-146
    async def handle_text_delta(self, delta: TextPartDelta) -> AsyncIterator[str]:
        yield delta.content_delta

# pydantic_ai_slim/pydantic_ai/ui/_event_stream.py:92-98
    def content_type(self) -> str:
        """Get the content type for the event stream, compatible with the `Accept` header value.

        By default, this returns the Server-Sent Events content type (`text/event-stream`).
        If a subclass supports other types as well, it should consider `self.accept` in [`encode_event()`][pydantic_ai.ui.UIEventStream.encode_event] and return the resulting content type.
        """
        return SSE_CONTENT_TYPE

# pydantic_ai_slim/pydantic_ai/messages.py:134-134
    content: str

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/_event_stream.py:133-138
    async def handle_text_delta(self, delta: TextPartDelta) -> AsyncIterator[BaseChunk]:
        if delta.content_delta:  # pragma: no branch
            provider_metadata = dump_provider_metadata(
                provider_name=delta.provider_name, provider_details=delta.provider_details
            )
            yield TextDeltaChunk(id=self.message_id, delta=delta.content_delta, provider_metadata=provider_metadata)

# pydantic_ai_slim/pydantic_ai/exceptions.py:163-164
class ContentFilterError(UnexpectedModelBehavior):
    """Raised when content filtering is triggered by the model provider resulting in an empty response."""

# pydantic_ai_slim/pydantic_ai/exceptions.py:163-164
class ContentFilterError(UnexpectedModelBehavior):
    """Raised when content filtering is triggered by the model provider resulting in an empty response."""

# pydantic_ai_slim/pydantic_ai/exceptions.py:163-164
class ContentFilterError(UnexpectedModelBehavior):
    """Raised when content filtering is triggered by the model provider resulting in an empty response."""

# pydantic_ai_slim/pydantic_ai/messages.py:827-827
    content: ToolReturnContent

# tests/test_fastmcp.py:360-382
    async def test_call_tool_with_text_content(
        self,
        fastmcp_toolset: FastMCPToolset[None],
        run_context: RunContext[None],
    ):
        """Test tool call that returns text content."""
        async with fastmcp_toolset:
            tools = await fastmcp_toolset.get_tools(run_context)
            text_tool = tools['text_tool']

            result = await fastmcp_toolset.call_tool(
                name='text_tool', tool_args={'message': 'Hello World'}, ctx=run_context, tool=text_tool
            )

            assert result == snapshot({'result': 'Echo: Hello World'})

            text_list_tool = tools['text_list_tool']

            result = await fastmcp_toolset.call_tool(
                name='text_list_tool', tool_args={'message': 'Hello World'}, ctx=run_context, tool=text_list_tool
            )

            assert result == snapshot(['Echo: Hello World', 'Echo: Hello World again'])

# pydantic_ai_slim/pydantic_ai/_thinking_part.py:6-31
def split_content_into_text_and_thinking(content: str, thinking_tags: tuple[str, str]) -> list[ThinkingPart | TextPart]:
    """Split a string into text and thinking parts.

    Some models don't return the thinking part as a separate part, but rather as a tag in the content.
    This function splits the content into text and thinking parts.
    """
    start_tag, end_tag = thinking_tags
    parts: list[ThinkingPart | TextPart] = []

    start_index = content.find(start_tag)
    while start_index >= 0:
        before_think, content = content[:start_index], content[start_index + len(start_tag) :]
        if before_think:
            parts.append(TextPart(content=before_think))
        end_index = content.find(end_tag)
        if end_index >= 0:
            think_content, content = content[:end_index], content[end_index + len(end_tag) :]
            parts.append(ThinkingPart(content=think_content))
        else:
            # We lose the `<think>` tag, but it shouldn't matter.
            parts.append(TextPart(content=content))
            content = ''
        start_index = content.find(start_tag)
    if content:
        parts.append(TextPart(content=content))
    return parts

# pydantic_ai_slim/pydantic_ai/_thinking_part.py:6-31
def split_content_into_text_and_thinking(content: str, thinking_tags: tuple[str, str]) -> list[ThinkingPart | TextPart]:
    """Split a string into text and thinking parts.

    Some models don't return the thinking part as a separate part, but rather as a tag in the content.
    This function splits the content into text and thinking parts.
    """
    start_tag, end_tag = thinking_tags
    parts: list[ThinkingPart | TextPart] = []

    start_index = content.find(start_tag)
    while start_index >= 0:
        before_think, content = content[:start_index], content[start_index + len(start_tag) :]
        if before_think:
            parts.append(TextPart(content=before_think))
        end_index = content.find(end_tag)
        if end_index >= 0:
            think_content, content = content[:end_index], content[end_index + len(end_tag) :]
            parts.append(ThinkingPart(content=think_content))
        else:
            # We lose the `<think>` tag, but it shouldn't matter.
            parts.append(TextPart(content=content))
            content = ''
        start_index = content.find(start_tag)
    if content:
        parts.append(TextPart(content=content))
    return parts

# pydantic_ai_slim/pydantic_ai/_thinking_part.py:6-31
def split_content_into_text_and_thinking(content: str, thinking_tags: tuple[str, str]) -> list[ThinkingPart | TextPart]:
    """Split a string into text and thinking parts.

    Some models don't return the thinking part as a separate part, but rather as a tag in the content.
    This function splits the content into text and thinking parts.
    """
    start_tag, end_tag = thinking_tags
    parts: list[ThinkingPart | TextPart] = []

    start_index = content.find(start_tag)
    while start_index >= 0:
        before_think, content = content[:start_index], content[start_index + len(start_tag) :]
        if before_think:
            parts.append(TextPart(content=before_think))
        end_index = content.find(end_tag)
        if end_index >= 0:
            think_content, content = content[:end_index], content[end_index + len(end_tag) :]
            parts.append(ThinkingPart(content=think_content))
        else:
            # We lose the `<think>` tag, but it shouldn't matter.
            parts.append(TextPart(content=content))
            content = ''
        start_index = content.find(start_tag)
    if content:
        parts.append(TextPart(content=content))
    return parts

# pydantic_ai_slim/pydantic_ai/_thinking_part.py:6-31
def split_content_into_text_and_thinking(content: str, thinking_tags: tuple[str, str]) -> list[ThinkingPart | TextPart]:
    """Split a string into text and thinking parts.

    Some models don't return the thinking part as a separate part, but rather as a tag in the content.
    This function splits the content into text and thinking parts.
    """
    start_tag, end_tag = thinking_tags
    parts: list[ThinkingPart | TextPart] = []

    start_index = content.find(start_tag)
    while start_index >= 0:
        before_think, content = content[:start_index], content[start_index + len(start_tag) :]
        if before_think:
            parts.append(TextPart(content=before_think))
        end_index = content.find(end_tag)
        if end_index >= 0:
            think_content, content = content[:end_index], content[end_index + len(end_tag) :]
            parts.append(ThinkingPart(content=think_content))
        else:
            # We lose the `<think>` tag, but it shouldn't matter.
            parts.append(TextPart(content=content))
            content = ''
        start_index = content.find(start_tag)
    if content:
        parts.append(TextPart(content=content))
    return parts

# pydantic_ai_slim/pydantic_ai/_thinking_part.py:6-31
def split_content_into_text_and_thinking(content: str, thinking_tags: tuple[str, str]) -> list[ThinkingPart | TextPart]:
    """Split a string into text and thinking parts.

    Some models don't return the thinking part as a separate part, but rather as a tag in the content.
    This function splits the content into text and thinking parts.
    """
    start_tag, end_tag = thinking_tags
    parts: list[ThinkingPart | TextPart] = []

    start_index = content.find(start_tag)
    while start_index >= 0:
        before_think, content = content[:start_index], content[start_index + len(start_tag) :]
        if before_think:
            parts.append(TextPart(content=before_think))
        end_index = content.find(end_tag)
        if end_index >= 0:
            think_content, content = content[:end_index], content[end_index + len(end_tag) :]
            parts.append(ThinkingPart(content=think_content))
        else:
            # We lose the `<think>` tag, but it shouldn't matter.
            parts.append(TextPart(content=content))
            content = ''
        start_index = content.find(start_tag)
    if content:
        parts.append(TextPart(content=content))
    return parts

# pydantic_ai_slim/pydantic_ai/__init__.py:50-102
from .messages import (
    AgentStreamEvent,
    AudioFormat,
    AudioMediaType,
    AudioUrl,
    BaseToolCallPart,
    BaseToolReturnPart,
    BinaryContent,
    BinaryImage,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentFormat,
    DocumentMediaType,
    DocumentUrl,
    FilePart,
    FileUrl,
    FinalResultEvent,
    FinishReason,
    FunctionToolCallEvent,
    FunctionToolResultEvent,
    HandleResponseEvent,
    ImageFormat,
    ImageMediaType,
    ImageUrl,
    ModelMessage,
    ModelMessagesTypeAdapter,
    ModelRequest,
    ModelRequestPart,
    ModelResponse,
    ModelResponsePart,
    ModelResponsePartDelta,
    ModelResponseStreamEvent,
    MultiModalContent,
    PartDeltaEvent,
    PartEndEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolCallPartDelta,
    ToolReturn,
    ToolReturnPart,
    UserContent,
    UserPromptPart,
    VideoFormat,
    VideoMediaType,
    VideoUrl,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:50-102
from .messages import (
    AgentStreamEvent,
    AudioFormat,
    AudioMediaType,
    AudioUrl,
    BaseToolCallPart,
    BaseToolReturnPart,
    BinaryContent,
    BinaryImage,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentFormat,
    DocumentMediaType,
    DocumentUrl,
    FilePart,
    FileUrl,
    FinalResultEvent,
    FinishReason,
    FunctionToolCallEvent,
    FunctionToolResultEvent,
    HandleResponseEvent,
    ImageFormat,
    ImageMediaType,
    ImageUrl,
    ModelMessage,
    ModelMessagesTypeAdapter,
    ModelRequest,
    ModelRequestPart,
    ModelResponse,
    ModelResponsePart,
    ModelResponsePartDelta,
    ModelResponseStreamEvent,
    MultiModalContent,
    PartDeltaEvent,
    PartEndEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolCallPartDelta,
    ToolReturn,
    ToolReturnPart,
    UserContent,
    UserPromptPart,
    VideoFormat,
    VideoMediaType,
    VideoUrl,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:50-102
from .messages import (
    AgentStreamEvent,
    AudioFormat,
    AudioMediaType,
    AudioUrl,
    BaseToolCallPart,
    BaseToolReturnPart,
    BinaryContent,
    BinaryImage,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentFormat,
    DocumentMediaType,
    DocumentUrl,
    FilePart,
    FileUrl,
    FinalResultEvent,
    FinishReason,
    FunctionToolCallEvent,
    FunctionToolResultEvent,
    HandleResponseEvent,
    ImageFormat,
    ImageMediaType,
    ImageUrl,
    ModelMessage,
    ModelMessagesTypeAdapter,
    ModelRequest,
    ModelRequestPart,
    ModelResponse,
    ModelResponsePart,
    ModelResponsePartDelta,
    ModelResponseStreamEvent,
    MultiModalContent,
    PartDeltaEvent,
    PartEndEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolCallPartDelta,
    ToolReturn,
    ToolReturnPart,
    UserContent,
    UserPromptPart,
    VideoFormat,
    VideoMediaType,
    VideoUrl,
)

# tests/models/test_anthropic.py:1944-1951
async def test_text_document_as_binary_content_input(
    allow_model_requests: None, anthropic_api_key: str, text_document_content: BinaryContent
):
    m = AnthropicModel('claude-sonnet-4-5', provider=AnthropicProvider(api_key=anthropic_api_key))
    agent = Agent(m)

    result = await agent.run(['What does this text file say?', text_document_content])
    assert result.output == snapshot('The text file says "Dummy TXT file".')