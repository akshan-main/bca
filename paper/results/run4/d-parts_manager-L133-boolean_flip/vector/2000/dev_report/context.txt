# pydantic_ai_slim/pydantic_ai/messages.py:1067-1067
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:1300-1300
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:475-475
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:1270-1270
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:1033-1033
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:1105-1105
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:754-754
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:1280-1280
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:909-909
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:953-953
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:370-370
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:899-899
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:416-416
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:137-137
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/embeddings/result.py:59-59
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:1157-1157
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:264-264
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:1565-1565
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:323-323
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/_event_stream.py:79-79
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/run.py:450-450
    _: dataclasses.KW_ONLY

# pydantic_ai_slim/pydantic_ai/toolsets/fastmcp.py:69-69
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:185-185
    _: dataclasses.KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:2008-2008
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/ui/_adapter.py:123-123
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:177-177
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:1982-1982
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:693-693
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:836-836
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/_adapter.py:78-78
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:1207-1207
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/models/function.py:250-250
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:2034-2034
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/messages.py:2050-2050
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/models/mcp_sampling.py:39-39
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/tools.py:184-184
    _: KW_ONLY

# pydantic_ai_slim/pydantic_ai/common_tools/duckduckgo.py:45-45
    _: KW_ONLY

# tests/conftest.py:136-138
def _(value: datetime):  # pragma: no cover
    """Use IsDatetime() for datetime values in snapshots."""
    return 'IsDatetime()'

# tests/models/test_model_function.py:327-328
async def foo(_: RunContext[None], x: int) -> str:
    return str(x + 1)

# tests/models/test_bedrock.py:91-92
    def count_tokens(self, **_: Any) -> None:
        raise self._error

# tests/models/test_bedrock.py:85-86
    def converse(self, **_: Any) -> None:
        raise self._error

# tests/models/test_bedrock.py:88-89
    def converse_stream(self, **_: Any) -> None:
        raise self._error

# pydantic_ai_slim/pydantic_ai/mcp.py:937-950
    def __get_pydantic_core_schema__(cls, _: Any, __: Any) -> CoreSchema:
        return core_schema.no_info_after_validator_function(
            lambda dct: MCPServerStdio(**dct),
            core_schema.typed_dict_schema(
                {
                    'command': core_schema.typed_dict_field(core_schema.str_schema()),
                    'args': core_schema.typed_dict_field(core_schema.list_schema(core_schema.str_schema())),
                    'env': core_schema.typed_dict_field(
                        core_schema.dict_schema(core_schema.str_schema(), core_schema.str_schema()),
                        required=False,
                    ),
                }
            ),
        )

# tests/models/test_model_function.py:158-163
async def get_weather(_: RunContext[None], lat: int, lng: int):
    if (lat, lng) == (51, 0):
        # it always rains in London
        return 'Raining'
    else:
        return 'Sunny'

# pydantic_ai_slim/pydantic_ai/mcp.py:1247-1258
    def __get_pydantic_core_schema__(cls, _: Any, __: Any) -> CoreSchema:
        return core_schema.no_info_after_validator_function(
            lambda dct: MCPServerStreamableHTTP(**dct),
            core_schema.typed_dict_schema(
                {
                    'url': core_schema.typed_dict_field(core_schema.str_schema()),
                    'headers': core_schema.typed_dict_field(
                        core_schema.dict_schema(core_schema.str_schema(), core_schema.str_schema()), required=False
                    ),
                }
            ),
        )

# pydantic_ai_slim/pydantic_ai/mcp.py:1145-1156
    def __get_pydantic_core_schema__(cls, _: Any, __: Any) -> CoreSchema:
        return core_schema.no_info_after_validator_function(
            lambda dct: MCPServerSSE(**dct),
            core_schema.typed_dict_schema(
                {
                    'url': core_schema.typed_dict_field(core_schema.str_schema()),
                    'headers': core_schema.typed_dict_field(
                        core_schema.dict_schema(core_schema.str_schema(), core_schema.str_schema()), required=False
                    ),
                }
            ),
        )

# tests/models/test_model_function.py:55-60
async def return_last(messages: list[ModelMessage], _: AgentInfo) -> ModelResponse:
    last = messages[-1].parts[-1]
    response = asdict(last)
    response.pop('timestamp', None)
    response['message_count'] = len(messages)
    return ModelResponse(parts=[TextPart(' '.join(f'{k}={v!r}' for k, v in response.items()))])

# tests/test_a2a.py:42-45
def return_string(_: list[ModelMessage], info: AgentInfo) -> ModelResponse:
    assert info.output_tools is not None
    args_json = '{"response": ["foo", "bar"]}'
    return ModelResponse(parts=[ToolCallPart(info.output_tools[0].name, args_json)])

# tests/test_a2a.py:58-61
def return_pydantic_model(_: list[ModelMessage], info: AgentInfo) -> ModelResponse:
    assert info.output_tools is not None
    args_json = '{"name": "John Doe", "age": 30, "email": "john@example.com"}'
    return ModelResponse(parts=[ToolCallPart(info.output_tools[0].name, args_json)])

# tests/models/test_model_function.py:475-477
async def stream_text_function(_messages: list[ModelMessage], _: AgentInfo) -> AsyncIterator[str]:
    yield 'hello '
    yield 'world'

# tests/models/test_model_function.py:540-542
async def stream_text_function_empty(_messages: list[ModelMessage], _: AgentInfo) -> AsyncIterator[str]:
    if False:
        yield 'hello '

# tests/models/test_model_function.py:232-241
async def call_function_model(messages: list[ModelMessage], _: AgentInfo) -> ModelResponse:  # pragma: lax no cover
    last = messages[-1].parts[-1]
    if isinstance(last, UserPromptPart):
        if isinstance(last.content, str) and last.content.startswith('{'):
            details = json.loads(last.content)
            return ModelResponse(parts=[ToolCallPart(details['function'], json.dumps(details['arguments']))])
    elif isinstance(last, ToolReturnPart):
        return ModelResponse(parts=[TextPart(pydantic_core.to_json(last).decode())])

    raise ValueError(f'Unexpected message: {last}')

# pydantic_ai_slim/pydantic_ai/exceptions.py:56-71
    def __get_pydantic_core_schema__(cls, _: Any, __: Any) -> core_schema.CoreSchema:
        """Pydantic core schema to allow `ModelRetry` to be (de)serialized."""
        schema = core_schema.typed_dict_schema(
            {
                'message': core_schema.typed_dict_field(core_schema.str_schema()),
                'kind': core_schema.typed_dict_field(core_schema.literal_schema(['model-retry'])),
            }
        )
        return core_schema.no_info_after_validator_function(
            lambda dct: ModelRetry(dct['message']),
            schema,
            serialization=core_schema.plain_serializer_function_ser_schema(
                lambda x: {'message': x.message, 'kind': 'model-retry'},
                return_schema=schema,
            ),
        )

# pydantic_ai_slim/pydantic_ai/_otel_messages.py:16-16
    content: NotRequired[str]

# pydantic_ai_slim/pydantic_ai/messages.py:1064-1064
    content: str

# pydantic_ai_slim/pydantic_ai/profiles/__init__.py:59-59
    thinking_tags: tuple[str, str] = ('<think>', '</think>')

# pydantic_ai_slim/pydantic_ai/_otel_messages.py:48-48
    content: NotRequired[str]

# pydantic_ai_slim/pydantic_ai/messages.py:1102-1102
    content: str

# pydantic_ai_slim/pydantic_ai/messages.py:751-751
    content: str | Sequence[UserContent]

# pydantic_ai_slim/pydantic_ai/messages.py:946-946
    content: list[pydantic_core.ErrorDetails] | str

# pydantic_ai_slim/pydantic_ai/messages.py:134-134
    content: str

# pydantic_ai_slim/pydantic_ai/messages.py:1154-1154
    content: Annotated[BinaryContent, pydantic.AfterValidator(BinaryImage.narrow_type)]

# pydantic_ai_slim/pydantic_ai/_parts_manager.py:465-480
    def _handle_embedded_thinking_content(
        self,
        existing_part: ThinkingPart,
        part_index: int,
        content: str,
        provider_name: str | None,
        provider_details: dict[str, Any] | None,
    ) -> Iterator[ModelResponseStreamEvent]:
        """Handle content inside <think>...</think>."""
        part_delta = ThinkingPartDelta(
            content_delta=content,
            provider_name=self._resolve_provider_name(existing_part, provider_name),
            provider_details=provider_details,
        )
        self._parts[part_index] = part_delta.apply(existing_part)
        yield PartDeltaEvent(index=part_index, delta=part_delta)

# pydantic_ai_slim/pydantic_ai/messages.py:2010-2010
    content: str | Sequence[UserContent] | None = None

# pydantic_ai_slim/pydantic_ai/_thinking_part.py:6-31
def split_content_into_text_and_thinking(content: str, thinking_tags: tuple[str, str]) -> list[ThinkingPart | TextPart]:
    """Split a string into text and thinking parts.

    Some models don't return the thinking part as a separate part, but rather as a tag in the content.
    This function splits the content into text and thinking parts.
    """
    start_tag, end_tag = thinking_tags
    parts: list[ThinkingPart | TextPart] = []

    start_index = content.find(start_tag)
    while start_index >= 0:
        before_think, content = content[:start_index], content[start_index + len(start_tag) :]
        if before_think:
            parts.append(TextPart(content=before_think))
        end_index = content.find(end_tag)
        if end_index >= 0:
            think_content, content = content[:end_index], content[end_index + len(end_tag) :]
            parts.append(ThinkingPart(content=think_content))
        else:
            # We lose the `<think>` tag, but it shouldn't matter.
            parts.append(TextPart(content=content))
            content = ''
        start_index = content.find(start_tag)
    if content:
        parts.append(TextPart(content=content))
    return parts

# pydantic_ai_slim/pydantic_ai/messages.py:695-695
    content: str | Sequence[UserContent] | None = None

# pydantic_ai_slim/pydantic_ai/messages.py:827-827
    content: ToolReturnContent

# tests/test_dbos.py:199-199
    content: str

# tests/test_prefect.py:186-186
    content: str

# tests/test_temporal.py:324-324
    content: str

# examples/pydantic_ai_examples/rag.py:174-174
    content: str

# examples/pydantic_ai_examples/chat_app.py:86-86
    content: str

# docs/.hooks/algolia.py:19-19
    content: str

# pydantic_ai_slim/pydantic_ai/models/gemini.py:867-867
    content: NotRequired[_GeminiContent]

# docs/.hooks/snippets.py:56-56
    content: str