# examples/pydantic_ai_examples/slack_lead_qualifier/modal.py:6-12
image = modal.Image.debian_slim(python_version='3.13').pip_install(
    'pydantic',
    'pydantic_ai_slim[openai,duckduckgo]',
    'logfire[httpx,fastapi]',
    'fastapi[standard]',
    'httpx',
)

# tests/mcp_server.py:5-5
from mcp.server.fastmcp import Context, FastMCP, Image

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:53-53
    image: int

# pydantic_ai_slim/pydantic_ai/messages.py:364-406
class ImageUrl(FileUrl):
    """A URL to an image."""

    url: str
    """The URL of the image."""

    _: KW_ONLY

    kind: Literal['image-url'] = 'image-url'
    """Type identifier, this is available on all parts as a discriminator."""

    # `pydantic_dataclass` replaces `__init__` so this method is never used.
    # The signature is kept so that pyright/IDE hints recognize the aliases for the `_media_type` and `_identifier` fields.
    def __init__(
        self,
        url: str,
        *,
        media_type: str | None = None,
        identifier: str | None = None,
        force_download: ForceDownloadMode = False,
        vendor_metadata: dict[str, Any] | None = None,
        kind: Literal['image-url'] = 'image-url',
        # Required for inline-snapshot which expects all dataclass `__init__` methods to take all field names as kwargs.
        _media_type: str | None = None,
        _identifier: str | None = None,
    ) -> None: ...  # pragma: no cover

    def _infer_media_type(self) -> str:
        """Return the media type of the image, based on the url."""
        mime_type, _ = _mime_types.guess_type(self.url)
        if mime_type is None:
            raise ValueError(
                f'Could not infer media type from image URL: {self.url}. Explicitly provide a `media_type` instead.'
            )
        return mime_type

    @property
    def format(self) -> ImageFormat:
        """The file format of the image.

        The choice of supported formats were based on the Bedrock Converse API. Other APIs don't require to use a format.
        """
        return _image_format_lookup[self.media_type]

# tests/test_messages.py:624-656
def test_image_url_validation_with_optional_identifier():
    image_url_ta = TypeAdapter(ImageUrl)
    image = image_url_ta.validate_python({'url': 'https://example.com/image.jpg'})
    assert image.url == snapshot('https://example.com/image.jpg')
    assert image.identifier == snapshot('39cfc4')
    assert image.media_type == snapshot('image/jpeg')
    assert image_url_ta.dump_python(image) == snapshot(
        {
            'url': 'https://example.com/image.jpg',
            'force_download': False,
            'vendor_metadata': None,
            'kind': 'image-url',
            'media_type': 'image/jpeg',
            'identifier': '39cfc4',
        }
    )

    image = image_url_ta.validate_python(
        {'url': 'https://example.com/image.jpg', 'identifier': 'foo', 'media_type': 'image/png'}
    )
    assert image.url == snapshot('https://example.com/image.jpg')
    assert image.identifier == snapshot('foo')
    assert image.media_type == snapshot('image/png')
    assert image_url_ta.dump_python(image) == snapshot(
        {
            'url': 'https://example.com/image.jpg',
            'force_download': False,
            'vendor_metadata': None,
            'kind': 'image-url',
            'media_type': 'image/png',
            'identifier': 'foo',
        }
    )

# pydantic_ai_slim/pydantic_ai/messages.py:367-367
    url: str

# docs/.hooks/test_snippets.py:9-9
from inline_snapshot import snapshot

# pydantic_graph/pydantic_graph/__init__.py:4-4
from .persistence import EndSnapshot, NodeSnapshot, Snapshot

# pydantic_graph/pydantic_graph/persistence/__init__.py:98-98
Snapshot = NodeSnapshot[StateT, RunEndT] | EndSnapshot[StateT, RunEndT]

# pydantic_graph/pydantic_graph/persistence/file.py:16-26
from . import (
    BaseStatePersistence,
    EndSnapshot,
    NodeSnapshot,
    RunEndT,
    Snapshot,
    SnapshotStatus,
    StateT,
    _utils,
    build_snapshot_list_type_adapter,
)

# pydantic_graph/pydantic_graph/persistence/in_mem.py:19-28
from . import (
    BaseStatePersistence,
    EndSnapshot,
    NodeSnapshot,
    RunEndT,
    Snapshot,
    StateT,
    _utils,
    build_snapshot_list_type_adapter,
)

# tests/evals/test_dataset.py:12-12
from inline_snapshot import snapshot

# tests/evals/test_evaluator_base.py:9-9
from inline_snapshot import snapshot

# tests/evals/test_evaluator_common.py:7-7
from inline_snapshot import snapshot

# tests/evals/test_evaluators.py:7-7
from inline_snapshot import snapshot

# tests/evals/test_llm_as_a_judge.py:4-4
from inline_snapshot import snapshot

# tests/evals/test_multi_run.py:8-8
from inline_snapshot import snapshot

# tests/evals/test_otel.py:6-6
from inline_snapshot import snapshot

# tests/evals/test_render_numbers.py:4-4
from inline_snapshot import snapshot

# tests/evals/test_reporting.py:6-6
from inline_snapshot import snapshot

# tests/evals/test_reports.py:6-6
from inline_snapshot import snapshot

# tests/ext/test_langchain.py:5-5
from inline_snapshot import snapshot

# tests/graph/beta/test_graph_edge_cases.py:10-10
from inline_snapshot import snapshot

# tests/graph/beta/test_parent_forks.py:4-4
from inline_snapshot import snapshot

# tests/graph/beta/test_v1_v2_integration.py:9-9
from inline_snapshot import snapshot

# tests/graph/test_file_persistence.py:9-9
from inline_snapshot import snapshot

# tests/graph/test_graph.py:11-11
from inline_snapshot import snapshot

# tests/graph/test_mermaid.py:12-12
from inline_snapshot import snapshot

# tests/graph/test_persistence.py:11-11
from inline_snapshot import snapshot

# tests/graph/test_state.py:7-7
from inline_snapshot import snapshot

# tests/models/anthropic/test_output.py:19-19
from inline_snapshot import snapshot

# tests/models/test_anthropic.py:15-15
from inline_snapshot import snapshot

# tests/models/test_bedrock.py:8-8
from inline_snapshot import snapshot

# tests/models/test_cohere.py:10-10
from inline_snapshot import snapshot

# tests/models/test_deepseek.py:6-6
from inline_snapshot import snapshot

# tests/models/test_fallback.py:11-11
from inline_snapshot import snapshot

# tests/models/test_gemini.py:16-16
from inline_snapshot import snapshot

# tests/models/test_gemini_vertex.py:6-6
from inline_snapshot import Is, snapshot

# tests/models/test_google.py:16-16
from inline_snapshot import Is, snapshot

# tests/models/test_groq.py:14-14
from inline_snapshot import snapshot

# tests/models/test_huggingface.py:12-12
from inline_snapshot import snapshot

# tests/models/test_instrumented.py:9-9
from inline_snapshot import snapshot

# tests/models/test_mcp_sampling.py:7-7
from inline_snapshot import snapshot

# tests/models/test_mistral.py:12-12
from inline_snapshot import snapshot

# tests/models/test_model_function.py:9-9
from inline_snapshot import snapshot

# tests/models/test_model_request_parameters.py:1-1
from inline_snapshot import snapshot

# tests/models/test_model_test.py:14-14
from inline_snapshot import snapshot

# tests/models/test_openai.py:15-15
from inline_snapshot import snapshot

# tests/models/test_openrouter.py:7-7
from inline_snapshot import snapshot

# tests/models/test_outlines.py:15-15
from inline_snapshot import snapshot

# tests/models/test_xai.py:25-25
from inline_snapshot import snapshot

# tests/profiles/test_anthropic.py:22-22
from inline_snapshot import snapshot

# tests/profiles/test_google.py:13-13
from inline_snapshot import snapshot

# tests/providers/test_azure.py:4-4
from inline_snapshot import snapshot

# tests/providers/test_gateway.py:9-9
from inline_snapshot import snapshot

# tests/providers/test_google_vertex.py:12-12
from inline_snapshot import snapshot

# tests/providers/test_heroku.py:5-5
from inline_snapshot import snapshot

# tests/providers/test_openrouter.py:5-5
from inline_snapshot import snapshot

# tests/test_a2a.py:9-9
from inline_snapshot import snapshot

# tests/test_ag_ui.py:16-16
from inline_snapshot import snapshot

# tests/test_agent.py:13-13
from inline_snapshot import snapshot

# tests/test_agent_output_schemas.py:2-2
from inline_snapshot import snapshot

# tests/test_cli.py:9-9
from inline_snapshot import snapshot

# tests/test_dbos.py:72-72
from inline_snapshot import snapshot

# tests/test_direct.py:8-8
from inline_snapshot import snapshot

# tests/test_embeddings.py:11-11
from inline_snapshot import snapshot

# tests/test_fastmcp.py:11-11
from inline_snapshot import snapshot

# tests/test_format_as_xml.py:11-11
from inline_snapshot import snapshot

# tests/test_history_processor.py:5-5
from inline_snapshot import snapshot

# tests/test_logfire.py:9-9
from inline_snapshot import snapshot

# tests/test_mcp.py:13-13
from inline_snapshot import snapshot

# tests/test_messages.py:6-6
from inline_snapshot import snapshot

# tests/test_parts_manager.py:7-7
from inline_snapshot import snapshot

# tests/test_prefect.py:69-69
from inline_snapshot import snapshot

# tests/test_streaming.py:14-14
from inline_snapshot import snapshot

# tests/test_temporal.py:13-13
from inline_snapshot import snapshot

# tests/test_thinking_part.py:4-4
from inline_snapshot import snapshot

# tests/test_tools.py:9-9
from inline_snapshot import snapshot

# tests/test_toolsets.py:10-10
from inline_snapshot import snapshot

# tests/test_ui.py:9-9
from inline_snapshot import snapshot

# tests/test_ui_web.py:12-12
from inline_snapshot import snapshot

# tests/test_usage_limits.py:10-10
from inline_snapshot import snapshot

# tests/test_utils.py:11-11
from inline_snapshot import snapshot

# tests/test_validation_context.py:4-4
from inline_snapshot import snapshot

# tests/test_vercel_ai.py:8-8
from inline_snapshot import snapshot

# tests/test_ag_ui.py:1576-1795
async def test_messages(image_content: BinaryContent, document_content: BinaryContent) -> None:
    messages = [
        SystemMessage(
            id='msg_1',
            content='System message',
        ),
        DeveloperMessage(
            id='msg_2',
            content='Developer message',
        ),
        UserMessage(
            id='msg_3',
            content='User message',
        ),
        UserMessage(
            id='msg_4',
            content='User message',
        ),
        UserMessage(
            id='msg_1',
            content=[
                TextInputContent(text='this is an image:'),
                BinaryInputContent(url=image_content.data_uri, mime_type=image_content.media_type),
            ],
        ),
        UserMessage(
            id='msg2',
            content=[BinaryInputContent(url='http://example.com/image.png', mime_type='image/png')],
        ),
        UserMessage(
            id='msg3',
            content=[BinaryInputContent(url='http://example.com/video.mp4', mime_type='video/mp4')],
        ),
        UserMessage(
            id='msg4',
            content=[BinaryInputContent(url='http://example.com/audio.mp3', mime_type='audio/mpeg')],
        ),
        UserMessage(
            id='msg5',
            content=[BinaryInputContent(url='http://example.com/doc.pdf', mime_type='application/pdf')],
        ),
        UserMessage(
            id='msg6', content=[BinaryInputContent(data=document_content.base64, mime_type=document_content.media_type)]
        ),
        AssistantMessage(
            id='msg_5',
            tool_calls=[
                ToolCall(
                    id='pyd_ai_builtin|function|search_1',
                    function=FunctionCall(
                        name='web_search',
                        arguments='{"query": "Hello, world!"}',
                    ),
                ),
            ],
        ),
        ToolMessage(
            id='msg_6',
            content='{"results": [{"title": "Hello, world!", "url": "https://en.wikipedia.org/wiki/Hello,_world!"}]}',
            tool_call_id='pyd_ai_builtin|function|search_1',
        ),
        AssistantMessage(
            id='msg_7',
            content='Assistant message',
        ),
        AssistantMessage(
            id='msg_8',
            tool_calls=[
                ToolCall(
                    id='tool_call_1',
                    function=FunctionCall(
                        name='tool_call_1',
                        arguments='{}',
                    ),
                ),
            ],
        ),
        AssistantMessage(
            id='msg_9',
            tool_calls=[
                ToolCall(
                    id='tool_call_2',
                    function=FunctionCall(
                        name='tool_call_2',
                        arguments='{}',
                    ),
                ),
            ],
        ),
        ToolMessage(
            id='msg_10',
            content='Tool message',
            tool_call_id='tool_call_1',
        ),
        ToolMessage(
            id='msg_11',
            content='Tool message',
            tool_call_id='tool_call_2',
        ),
        UserMessage(
            id='msg_12',
            content='User message',
        ),
        AssistantMessage(
            id='msg_13',
            content='Assistant message',
        ),
    ]

    assert AGUIAdapter.load_messages(messages) == snapshot(
        [
            ModelRequest(
                parts=[
                    SystemPromptPart(
                        content='System message',
                        timestamp=IsDatetime(),
                    ),
                    SystemPromptPart(
                        content='Developer message',
                        timestamp=IsDatetime(),
                    ),
                    UserPromptPart(
                        content='User message',
                        timestamp=IsDatetime(),
                    ),
                    UserPromptPart(
                        content='User message',
                        timestamp=IsDatetime(),
                    ),
                    UserPromptPart(
                        content=['this is an image:', image_content],
                        timestamp=IsDatetime(),
                    ),
                    UserPromptPart(
                        content=[
                            ImageUrl(
                                url='http://example.com/image.png', _media_type='image/png', media_type='image/png'
                            )
                        ],
                        timestamp=IsDatetime(),
                    ),
                    UserPromptPart(
                        content=[
                            VideoUrl(
                                url='http://example.com/video.mp4', _media_type='video/mp4', media_type='video/mp4'
                            )
                        ],
                        timestamp=IsDatetime(),
                    ),
                    UserPromptPart(
                        content=[
                            AudioUrl(
                                url='http://example.com/audio.mp3', _media_type='audio/mpeg', media_type='audio/mpeg'
                            )
                        ],
                        timestamp=IsDatetime(),
                    ),
                    UserPromptPart(
                        content=[
                            DocumentUrl(
                                url='http://example.com/doc.pdf',
                                _media_type='application/pdf',
                                media_type='application/pdf',
                            )
                        ],
                        timestamp=IsDatetime(),
                    ),
                    UserPromptPart(
                        content=[document_content],
                        timestamp=IsDatetime(),
                    ),
                ]
            ),
            ModelResponse(
                parts=[
                    BuiltinToolCallPart(
                        tool_name='web_search',
                        args='{"query": "Hello, world!"}',
                        tool_call_id='search_1',
                        provider_name='function',
                    ),
                    BuiltinToolReturnPart(
                        tool_name='web_search',
                        content='{"results": [{"title": "Hello, world!", "url": "https://en.wikipedia.org/wiki/Hello,_world!"}]}',
                        tool_call_id='search_1',
                        timestamp=IsDatetime(),
                        provider_name='function',
                    ),
                    TextPart(content='Assistant message'),
                    ToolCallPart(tool_name='tool_call_1', args='{}', tool_call_id='tool_call_1'),
                    ToolCallPart(tool_name='tool_call_2', args='{}', tool_call_id='tool_call_2'),
                ],
                timestamp=IsDatetime(),
            ),
            ModelRequest(
                parts=[
                    ToolReturnPart(
                        tool_name='tool_call_1',
                        content='Tool message',
                        tool_call_id='tool_call_1',
                        timestamp=IsDatetime(),
                    ),
                    ToolReturnPart(
                        tool_name='tool_call_2',
                        content='Tool message',
                        tool_call_id='tool_call_2',
                        timestamp=IsDatetime(),
                    ),
                    UserPromptPart(
                        content='User message',
                        timestamp=IsDatetime(),
                    ),
                ]
            ),
            ModelResponse(
                parts=[TextPart(content='Assistant message')],
                timestamp=IsDatetime(),
            ),
        ]
    )

# pydantic_ai_slim/pydantic_ai/messages.py:466-613
class BinaryContent:
    """Binary content, e.g. an audio or image file."""

    data: bytes
    """The binary file data.

    Use `.base64` to get the base64-encoded string.
    """

    _: KW_ONLY

    media_type: AudioMediaType | ImageMediaType | DocumentMediaType | str
    """The media type of the binary data."""

    vendor_metadata: dict[str, Any] | None = None
    """Vendor-specific metadata for the file.

    Supported by:
    - `GoogleModel`: `BinaryContent.vendor_metadata` is used as `video_metadata`: https://ai.google.dev/gemini-api/docs/video-understanding#customize-video-processing
    - `OpenAIChatModel`, `OpenAIResponsesModel`: `BinaryContent.vendor_metadata['detail']` is used as `detail` setting for images
    - `XaiModel`: `BinaryContent.vendor_metadata['detail']` is used as `detail` setting for images
    """

    _identifier: Annotated[str | None, pydantic.Field(alias='identifier', default=None, exclude=True)] = field(
        compare=False, default=None
    )

    kind: Literal['binary'] = 'binary'
    """Type identifier, this is available on all parts as a discriminator."""

    # `pydantic_dataclass` replaces `__init__` so this method is never used.
    # The signature is kept so that pyright/IDE hints recognize the `identifier` alias for the `_identifier` field.
    def __init__(
        self,
        data: bytes,
        *,
        media_type: AudioMediaType | ImageMediaType | DocumentMediaType | str,
        identifier: str | None = None,
        vendor_metadata: dict[str, Any] | None = None,
        kind: Literal['binary'] = 'binary',
        # Required for inline-snapshot which expects all dataclass `__init__` methods to take all field names as kwargs.
        _identifier: str | None = None,
    ) -> None: ...  # pragma: no cover

    @staticmethod
    def narrow_type(bc: BinaryContent) -> BinaryContent | BinaryImage:
        """Narrow the type of the `BinaryContent` to `BinaryImage` if it's an image."""
        if bc.is_image:
            return BinaryImage(
                data=bc.data,
                media_type=bc.media_type,
                identifier=bc.identifier,
                vendor_metadata=bc.vendor_metadata,
            )
        else:
            return bc

    @classmethod
    def from_data_uri(cls, data_uri: str) -> BinaryContent:
        """Create a `BinaryContent` from a data URI."""
        prefix = 'data:'
        if not data_uri.startswith(prefix):
            raise ValueError('Data URI must start with "data:"')
        media_type, data = data_uri[len(prefix) :].split(';base64,', 1)
        return cls.narrow_type(cls(data=base64.b64decode(data), media_type=media_type))

    @classmethod
    def from_path(cls, path: PathLike[str]) -> BinaryContent:
        """Create a `BinaryContent` from a path.

        Defaults to 'application/octet-stream' if the media type cannot be inferred.

        Raises:
            FileNotFoundError: if the file does not exist.
            PermissionError: if the file cannot be read.
        """
        path = Path(path)
        if not path.exists():
            raise FileNotFoundError(f'File not found: {path}')
        media_type, _ = _mime_types.guess_type(path)
        if media_type is None:
            media_type = 'application/octet-stream'

        return cls.narrow_type(cls(data=path.read_bytes(), media_type=media_type))

    @pydantic.computed_field
    @property
    def identifier(self) -> str:
        """Identifier for the binary content, such as a unique ID.

        This identifier can be provided to the model in a message to allow it to refer to this file in a tool call argument,
        and the tool can look up the file in question by iterating over the message history and finding the matching `BinaryContent`.

        This identifier is only automatically passed to the model when the `BinaryContent` is returned by a tool.
        If you're passing the `BinaryContent` as a user message, it's up to you to include a separate text part with the identifier,
        e.g. "This is file <identifier>:" preceding the `BinaryContent`.

        It's also included in inline-text delimiters for providers that require inlining text documents, so the model can
        distinguish multiple files.
        """
        return self._identifier or _multi_modal_content_identifier(self.data)

    @property
    def data_uri(self) -> str:
        """Convert the `BinaryContent` to a data URI."""
        return f'data:{self.media_type};base64,{self.base64}'

    @property
    def base64(self) -> str:
        """Return the binary data as a base64-encoded string. Default encoding is UTF-8."""
        return base64.b64encode(self.data).decode()

    @property
    def is_audio(self) -> bool:
        """Return `True` if the media type is an audio type."""
        return self.media_type.startswith('audio/')

    @property
    def is_image(self) -> bool:
        """Return `True` if the media type is an image type."""
        return self.media_type.startswith('image/')

    @property
    def is_video(self) -> bool:
        """Return `True` if the media type is a video type."""
        return self.media_type.startswith('video/')

    @property
    def is_document(self) -> bool:
        """Return `True` if the media type is a document type."""
        return self.media_type in _document_format_lookup

    @property
    def format(self) -> str:
        """The file format of the binary content."""
        try:
            if self.is_audio:
                return _audio_format_lookup[self.media_type]
            elif self.is_image:
                return _image_format_lookup[self.media_type]
            elif self.is_video:
                return _video_format_lookup[self.media_type]
            else:
                return _document_format_lookup[self.media_type]
        except KeyError as e:
            raise ValueError(f'Unknown media type: {self.media_type}') from e

    __repr__ = _utils.dataclasses_no_defaults_repr

# pydantic_graph/pydantic_graph/mermaid.py:133-195
def request_image(
    graph: Graph[Any, Any, Any],
    /,
    **kwargs: Unpack[MermaidConfig],
) -> bytes:
    """Generate an image of a Mermaid diagram using [mermaid.ink](https://mermaid.ink).

    Args:
        graph: The graph to generate the image for.
        **kwargs: Additional parameters to configure mermaid chart generation.

    Returns:
        The image data.
    """
    code = generate_code(
        graph,
        start_node=kwargs.get('start_node'),
        highlighted_nodes=kwargs.get('highlighted_nodes'),
        highlight_css=kwargs.get('highlight_css', DEFAULT_HIGHLIGHT_CSS),
        title=kwargs.get('title'),
        edge_labels=kwargs.get('edge_labels', True),
        notes=kwargs.get('notes', True),
        direction=kwargs.get('direction'),
    )
    code_base64 = base64.b64encode(code.encode()).decode()

    params: dict[str, str | float] = {}
    if kwargs.get('image_type') == 'pdf':
        url = f'https://mermaid.ink/pdf/{code_base64}'
        if kwargs.get('pdf_fit'):
            params['fit'] = ''
        if kwargs.get('pdf_landscape'):
            params['landscape'] = ''
        if pdf_paper := kwargs.get('pdf_paper'):
            params['paper'] = pdf_paper
    elif kwargs.get('image_type') == 'svg':
        url = f'https://mermaid.ink/svg/{code_base64}'
    else:
        url = f'https://mermaid.ink/img/{code_base64}'

        if image_type := kwargs.get('image_type'):
            params['type'] = image_type

    if background_color := kwargs.get('background_color'):
        params['bgColor'] = background_color
    if theme := kwargs.get('theme'):
        params['theme'] = theme
    if width := kwargs.get('width'):
        params['width'] = width
    if height := kwargs.get('height'):
        params['height'] = height
    if scale := kwargs.get('scale'):
        params['scale'] = scale

    httpx_client = kwargs.get('httpx_client') or httpx.Client()
    response = httpx_client.get(url, params=params)
    if not response.is_success:
        raise httpx.HTTPStatusError(
            f'{response.status_code} error generating image:\n{response.text}',
            request=response.request,
            response=response,
        )
    return response.content

# examples/pydantic_ai_examples/rag.py:176-180
    def url(self) -> str:
        url_path = re.sub(r'\.md$', '', self.path)
        return (
            f'https://logfire.pydantic.dev/docs/{url_path}/#{slugify(self.title, "-")}'
        )

# pydantic_ai_slim/pydantic_ai/messages.py:413-413
    url: str

# pydantic_ai_slim/pydantic_ai/messages.py:261-261
    url: str

# pydantic_ai_slim/pydantic_ai/messages.py:320-320
    url: str

# pydantic_ai_slim/pydantic_ai/messages.py:391-398
    def _infer_media_type(self) -> str:
        """Return the media type of the image, based on the url."""
        mime_type, _ = _mime_types.guess_type(self.url)
        if mime_type is None:
            raise ValueError(
                f'Could not infer media type from image URL: {self.url}. Explicitly provide a `media_type` instead.'
            )
        return mime_type

# pydantic_ai_slim/pydantic_ai/models/outlines.py:497-501
    def _create_PIL_image(self, data: bytes, data_type: str) -> PILImage.Image:
        """Create a PIL Image from the data and data type."""
        image = PILImage.open(io.BytesIO(data))
        image.format = data_type.split('/')[-1]
        return image

# pydantic_ai_slim/pydantic_ai/builtin_tools.py:387-387
    url: str

# pydantic_ai_slim/pydantic_ai/messages.py:174-174
    url: str

# pydantic_ai_slim/pydantic_ai/mcp.py:986-986
    url: str

# pydantic_graph/pydantic_graph/mermaid.py:198-221
def save_image(
    path: Path | str,
    graph: Graph[Any, Any, Any],
    /,
    **kwargs: Unpack[MermaidConfig],
) -> None:
    """Generate an image of a Mermaid diagram using [mermaid.ink](https://mermaid.ink) and save it to a local file.

    Args:
        path: The path to save the image to.
        graph: The graph to generate the image for.
        **kwargs: Additional parameters to configure mermaid chart generation.
    """
    if isinstance(path, str):
        path = Path(path)

    if 'image_type' not in kwargs:
        ext = path.suffix.lower()[1:]
        # no need to check for .jpeg/.jpg, as it is the default
        if ext in ('png', 'webp', 'svg', 'pdf'):
            kwargs['image_type'] = ext

    image_data = request_image(graph, **kwargs)
    path.write_bytes(image_data)

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:89-89
    url: str

# pydantic_ai_slim/pydantic_ai/common_tools/exa.py:42-42
    url: str

# pydantic_ai_slim/pydantic_ai/common_tools/exa.py:72-72
    url: str

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:59-59
    url: str

# pydantic_ai_slim/pydantic_ai/common_tools/tavily.py:29-29
    url: str

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:176-176
    url: str

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:196-196
    url: str

# pydantic_ai_slim/pydantic_ai/_otel_messages.py:37-37
    url: NotRequired[str]

# pydantic_ai_slim/pydantic_ai/__init__.py:50-102
from .messages import (
    AgentStreamEvent,
    AudioFormat,
    AudioMediaType,
    AudioUrl,
    BaseToolCallPart,
    BaseToolReturnPart,
    BinaryContent,
    BinaryImage,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentFormat,
    DocumentMediaType,
    DocumentUrl,
    FilePart,
    FileUrl,
    FinalResultEvent,
    FinishReason,
    FunctionToolCallEvent,
    FunctionToolResultEvent,
    HandleResponseEvent,
    ImageFormat,
    ImageMediaType,
    ImageUrl,
    ModelMessage,
    ModelMessagesTypeAdapter,
    ModelRequest,
    ModelRequestPart,
    ModelResponse,
    ModelResponsePart,
    ModelResponsePartDelta,
    ModelResponseStreamEvent,
    MultiModalContent,
    PartDeltaEvent,
    PartEndEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolCallPartDelta,
    ToolReturn,
    ToolReturnPart,
    UserContent,
    UserPromptPart,
    VideoFormat,
    VideoMediaType,
    VideoUrl,
)

# pydantic_ai_slim/pydantic_ai/_a2a.py:14-29
from pydantic_ai import (
    AudioUrl,
    BinaryContent,
    DocumentUrl,
    ImageUrl,
    ModelMessage,
    ModelRequest,
    ModelRequestPart,
    ModelResponse,
    ModelResponsePart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    UserPromptPart,
    VideoUrl,
)

# pydantic_ai_slim/pydantic_ai/models/anthropic.py:25-46
from ..messages import (
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentUrl,
    FilePart,
    FinishReason,
    ImageUrl,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    ModelResponsePart,
    ModelResponseStreamEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
)

# pydantic_ai_slim/pydantic_ai/models/bedrock.py:17-42
from pydantic_ai import (
    AudioUrl,
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentUrl,
    FinishReason,
    ImageUrl,
    ModelMessage,
    ModelProfileSpec,
    ModelRequest,
    ModelResponse,
    ModelResponsePart,
    ModelResponseStreamEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
    VideoUrl,
    _utils,
    usage,
)

# pydantic_ai_slim/pydantic_ai/models/groq.py:20-40
from ..messages import (
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    DocumentUrl,
    FilePart,
    FinishReason,
    ImageUrl,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    ModelResponsePart,
    ModelResponseStreamEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
)

# pydantic_ai_slim/pydantic_ai/models/huggingface.py:15-38
from ..messages import (
    AudioUrl,
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentUrl,
    FilePart,
    FinishReason,
    ImageUrl,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    ModelResponsePart,
    ModelResponseStreamEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
    VideoUrl,
)

# pydantic_ai_slim/pydantic_ai/models/mistral.py:17-38
from ..messages import (
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    DocumentUrl,
    FilePart,
    FinishReason,
    ImageUrl,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    ModelResponsePart,
    ModelResponseStreamEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
    VideoUrl,
)

# pydantic_ai_slim/pydantic_ai/models/openai.py:33-58
from ..messages import (
    AudioUrl,
    BinaryContent,
    BinaryImage,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentUrl,
    FilePart,
    FinishReason,
    ImageUrl,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    ModelResponsePart,
    ModelResponseStreamEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
    VideoUrl,
)

# pydantic_ai_slim/pydantic_ai/models/outlines.py:21-39
from ..messages import (
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    FilePart,
    ImageUrl,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    ModelResponsePart,
    ModelResponseStreamEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
)

# pydantic_ai_slim/pydantic_ai/models/xai.py:18-42
from ..messages import (
    AudioUrl,
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentUrl,
    FilePart,
    FinishReason,
    ImageUrl,
    ModelMessage,
    ModelRequest,
    ModelRequestPart,
    ModelResponse,
    ModelResponsePart,
    ModelResponseStreamEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
    VideoUrl,
)

# pydantic_ai_slim/pydantic_ai/ui/ag_ui/_adapter.py:15-29
from ...messages import (
    AudioUrl,
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    DocumentUrl,
    ImageUrl,
    ModelMessage,
    SystemPromptPart,
    TextPart,
    ToolCallPart,
    ToolReturnPart,
    UserPromptPart,
    VideoUrl,
)

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/_adapter.py:15-36
from ...messages import (
    AudioUrl,
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentUrl,
    FilePart,
    ImageUrl,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    ThinkingPart,
    ToolCallPart,
    ToolReturnPart,
    UserContent,
    UserPromptPart,
    VideoUrl,
)

# tests/models/test_anthropic.py:18-47
from pydantic_ai import (
    Agent,
    BinaryContent,
    BuiltinToolCallPart,
    BuiltinToolReturnPart,
    CachePoint,
    DocumentUrl,
    FinalResultEvent,
    ImageUrl,
    ModelAPIError,
    ModelHTTPError,
    ModelMessage,
    ModelRequest,
    ModelResponse,
    ModelRetry,
    PartDeltaEvent,
    PartEndEvent,
    PartStartEvent,
    RetryPromptPart,
    SystemPromptPart,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolCallPartDelta,
    ToolReturnPart,
    UsageLimitExceeded,
    UserPromptPart,
)

# tests/models/test_download_item.py:3-3
from pydantic_ai import AudioUrl, DocumentUrl, ImageUrl, VideoUrl

# tests/mcp_server.py:140-142
async def get_image() -> Image:
    data = Path(__file__).parent.joinpath('assets/kiwi.jpg').read_bytes()
    return Image(data=data, format='jpg')

# pydantic_ai_slim/pydantic_ai/messages.py:584-586
    def is_image(self) -> bool:
        """Return `True` if the media type is an image type."""
        return self.media_type.startswith('image/')

# pydantic_evals/pydantic_evals/dataset.py:16-16
import traceback