# src/cegraph/tools/definitions.py:104-117
    def impact_of(self, symbol_name: str) -> str:
        """Analyze the impact of changing a symbol."""
        result = self.query.impact_of(symbol_name)
        if not result.get("found"):
            return f"Symbol '{symbol_name}' not found in the knowledge graph"

        output = [f"Impact analysis for `{symbol_name}`:"]
        output.append(f"Risk score: {result['risk_score']:.1%}")
        output.append(f"Direct callers: {len(result['direct_callers'])}")
        output.append(f"Transitive callers: {len(result['transitive_callers'])}")
        output.append(f"Affected files ({len(result['affected_files'])}):")
        for f in result["affected_files"]:
            output.append(f"  - {f}")
        return "\n".join(output)

# src/cegraph/graph/query.py:56-64
    def find_symbol(self, name: str) -> list[str]:
        """Find symbol node IDs matching a name (exact or qualified)."""
        results = self._name_index.get(name, [])
        if not results:
            # Try partial match
            for key, ids in self._name_index.items():
                if name.lower() in key.lower():
                    results.extend(ids)
        return list(set(results))

# src/cegraph/graph/query.py:185-229
    def impact_of(self, name: str, max_depth: int = 3) -> dict:
        """Analyze the impact of changing a symbol.

        Returns a dict with:
        - direct_callers: immediate callers
        - transitive_callers: all callers up to max_depth
        - affected_files: set of files that could be affected
        - risk_score: rough risk assessment (0-1)
        """
        symbol_ids = self.find_symbol(name)
        if not symbol_ids:
            return {
                "symbol": name,
                "found": False,
                "direct_callers": [],
                "transitive_callers": [],
                "affected_files": [],
                "risk_score": 0.0,
            }

        direct = self.who_calls(name, max_depth=1)
        transitive = self.who_calls(name, max_depth=max_depth)

        affected_files = set()
        for item in transitive:
            if item.get("file_path"):
                affected_files.add(item["file_path"])
        # Also include the symbol's own file
        for sid in symbol_ids:
            data = self.graph.nodes.get(sid, {})
            if data.get("file_path"):
                affected_files.add(data["file_path"])

        # Risk score based on impact breadth
        total_files = sum(1 for _, d in self.graph.nodes(data=True) if d.get("type") == "file")
        risk_score = min(len(affected_files) / max(total_files, 1), 1.0)

        return {
            "symbol": name,
            "found": False,
            "direct_callers": direct,
            "transitive_callers": transitive,
            "affected_files": sorted(affected_files),
            "risk_score": round(risk_score, 3),
        }

# src/cegraph/tools/definitions.py:19-318
class CeGraphTools:
    """Collection of built-in tools for the CeGraph agent.

    Each tool interacts with the knowledge graph, search engine,
    and/or the filesystem to provide the agent with accurate information.
    """

    def __init__(
        self,
        root: Path,
        graph: nx.DiGraph,
        query: GraphQuery,
        search: HybridSearch,
    ) -> None:
        self.root = root
        self.graph = graph
        self.query = query
        self.search = search

    def search_code(self, query: str, file_pattern: str = "", max_results: int = 10) -> str:
        """Search for code in the repository matching a query."""
        results = self.search.search(query, file_pattern, max_results=max_results)
        if not results:
            return f"No results found for '{query}'"

        output = []
        for r in results:
            header = f"**{r.file_path}:{r.line_number}**"
            if r.symbol_name:
                header += f" (in `{r.symbol_name}`)"
            output.append(header)

            if r.context_before:
                for line in r.context_before:
                    output.append(f"  {line}")
            output.append(f"→ {r.line_content}")
            if r.context_after:
                for line in r.context_after:
                    output.append(f"  {line}")
            output.append("")

        return "\n".join(output)

    def search_symbols(self, query: str, kind: str = "", max_results: int = 10) -> str:
        """Search for symbol definitions (functions, classes, etc.)."""
        results = self.search.search_symbols(query, kind, max_results)
        if not results:
            return f"No symbols found matching '{query}'"

        output = []
        for r in results:
            output.append(
                f"- **{r['qualified_name']}** ({r['kind']}) at {r['file_path']}:{r['line']}"
            )
            if r.get("signature"):
                output.append(f"  `{r['signature']}`")
        return "\n".join(output)

    def who_calls(self, symbol_name: str, max_depth: int = 2) -> str:
        """Find all callers of a function/method."""
        results = self.query.who_calls(symbol_name, max_depth=max_depth)
        if not results:
            return f"No callers found for '{symbol_name}'"

        output = [f"Callers of `{symbol_name}`:"]
        for r in results:
            indent = "  " * r["depth"]
            output.append(
                f"{indent}← **{r['name']}** ({r['kind']}) at {r['file_path']}:{r['line']}"
            )
        return "\n".join(output)

    def what_calls(self, symbol_name: str) -> str:
        """Find all symbols called by a function/method."""
        results = self.query.what_calls(symbol_name)
        if not results:
            return f"No callees found for '{symbol_name}'"

        output = [f"`{symbol_name}` calls:"]
        for r in results:
            output.append(
                f"→ **{r['name']}** ({r['kind']}) at {r['file_path']}:{r['line']}"
            )
        return "\n".join(output)

    def impact_of(self, symbol_name: str) -> str:
        """Analyze the impact of changing a symbol."""
        result = self.query.impact_of(symbol_name)
        if not result.get("found"):
            return f"Symbol '{symbol_name}' not found in the knowledge graph"

        output = [f"Impact analysis for `{symbol_name}`:"]
        output.append(f"Risk score: {result['risk_score']:.1%}")
        output.append(f"Direct callers: {len(result['direct_callers'])}")
        output.append(f"Transitive callers: {len(result['transitive_callers'])}")
        output.append(f"Affected files ({len(result['affected_files'])}):")
        for f in result["affected_files"]:
            output.append(f"  - {f}")
        return "\n".join(output)

    def read_file(self, file_path: str, start_line: int = 0, end_line: int = 0) -> str:
        """Read a file from the repository."""
        full_path = self.root / file_path
        if not full_path.exists():
            return f"File not found: {file_path}"
        if not full_path.is_file():
            return f"Not a file: {file_path}"

        # Security: ensure we're within the project root
        try:
            full_path.resolve().relative_to(self.root.resolve())
        except ValueError:
            return f"Access denied: {file_path} is outside the project root"

        try:
            content = full_path.read_text(encoding="utf-8", errors="replace")
        except OSError as e:
            return f"Error reading file: {e}"

        lines = content.splitlines()
        if start_line or end_line:
            start = max(0, start_line - 1)
            end = end_line if end_line else len(lines)
            lines = lines[start:end]
            # Add line numbers
            numbered = [
                f"{i + start + 1:4d} | {line}" for i, line in enumerate(lines)
            ]
            return "\n".join(numbered)

        # If file is too long, truncate with message
        if len(lines) > 200:
            numbered = [f"{i + 1:4d} | {line}" for i, line in enumerate(lines[:200])]
            numbered.append(f"\n... ({len(lines) - 200} more lines)")
            return "\n".join(numbered)

        numbered = [f"{i + 1:4d} | {line}" for i, line in enumerate(lines)]
        return "\n".join(numbered)

    def write_file(self, file_path: str, content: str) -> str:
        """Write content to a file (creates or overwrites)."""
        full_path = self.root / file_path
        try:
            full_path.resolve().relative_to(self.root.resolve())
        except ValueError:
            return f"Access denied: {file_path} is outside the project root"

        full_path.parent.mkdir(parents=True, exist_ok=True)
        full_path.write_text(content, encoding="utf-8")
        return f"Successfully wrote {len(content)} bytes to {file_path}"

    def edit_file(
        self, file_path: str, old_text: str, new_text: str
    ) -> str:
        """Replace specific text in a file (targeted edit, not full rewrite)."""
        full_path = self.root / file_path
        if not full_path.exists():
            return f"File not found: {file_path}"

        try:
            full_path.resolve().relative_to(self.root.resolve())
        except ValueError:
            return f"Access denied: {file_path} is outside the project root"

        content = full_path.read_text(encoding="utf-8", errors="replace")
        if old_text not in content:
            return f"Text to replace not found in {file_path}"

        count = content.count(old_text)
        if count > 1:
            return f"Text to replace found {count} times. Please provide more context to make it unique."

        new_content = content.replace(old_text, new_text, 1)
        full_path.write_text(new_content, encoding="utf-8")
        return f"Successfully edited {file_path}"

    def list_files(self, path: str = "", pattern: str = "") -> str:
        """List files in the repository."""
        target = self.root / path if path else self.root
        if not target.exists():
            return f"Path not found: {path}"

        try:
            target.resolve().relative_to(self.root.resolve())
        except ValueError:
            return f"Access denied: {path} is outside the project root"

        files = []
        if pattern:
            import fnmatch

            for p in sorted(target.rglob("*")):
                if p.is_file() and fnmatch.fnmatch(p.name, pattern):
                    files.append(str(p.relative_to(self.root)))
        else:
            for p in sorted(target.iterdir()):
                prefix = "d " if p.is_dir() else "f "
                files.append(prefix + str(p.relative_to(self.root)))

        return "\n".join(files) if files else "No files found"

    def get_structure(self, path: str = "") -> str:
        """Get the project structure with symbol counts."""
        structure = self.query.get_structure(path)
        return json.dumps(structure, indent=2) if structure else "No structure data"

    def get_context(self, symbol_name: str) -> str:
        """Get full context for a symbol including its source code and relationships."""
        symbol_ids = self.query.find_symbol(symbol_name)
        if not symbol_ids:
            return f"Symbol '{symbol_name}' not found"

        output = []
        for sid in symbol_ids[:3]:  # Limit to 3 matches
            info = self.query.get_symbol_info(sid)
            if not info:
                continue

            output.append(f"## {info.qualified_name} ({info.kind})")
            output.append(f"**File:** {info.file_path}:{info.line_start}-{info.line_end}")
            if info.signature:
                output.append(f"**Signature:** `{info.signature}`")
            if info.docstring:
                output.append(f"**Docstring:** {info.docstring[:200]}")

            # Show source code
            file_content = self.read_file(
                info.file_path,
                start_line=info.line_start,
                end_line=info.line_end,
            )
            output.append(f"\n```\n{file_content}\n```")

            # Show relationships
            if info.callers:
                output.append(f"\n**Called by:** {', '.join(c.split('::')[-1] for c in info.callers[:5])}")
            if info.callees:
                output.append(f"**Calls:** {', '.join(c.split('::')[-1] for c in info.callees[:5])}")
            if info.children:
                output.append(f"**Contains:** {', '.join(c.split('::')[-1] for c in info.children[:5])}")

            output.append("")

        return "\n".join(output)

    def run_command(self, command: str) -> str:
        """Run a shell command in the project root (for tests, lint, etc.)."""
        import shlex

        # Parse into argv — this prevents injection via shell metacharacters
        try:
            argv = shlex.split(command)
        except ValueError as e:
            return f"Invalid command syntax: {e}"

        if not argv:
            return "Empty command"

        # Security: only allow specific executables (check first token only)
        allowed_executables = {
            "python", "python3", "pytest", "pip", "pip3",
            "npm", "node", "npx", "yarn", "pnpm",
            "go", "cargo", "make", "gradle", "mvn",
            "ruff", "black", "mypy", "flake8", "eslint", "prettier",
            "git", "ls", "cat", "head", "tail", "wc", "find", "grep",
        }
        # For git, only allow safe read-only subcommands
        _git_safe_subcommands = {"status", "diff", "log", "show", "branch", "tag"}

        exe = argv[0].lower()
        if exe not in allowed_executables:
            return f"Command not allowed for safety. Allowed executables: {', '.join(sorted(allowed_executables))}"

        if exe == "git":
            subcommand = argv[1].lower() if len(argv) > 1 else ""
            if subcommand not in _git_safe_subcommands:
                return f"Only read-only git subcommands are allowed: {', '.join(sorted(_git_safe_subcommands))}"

        try:
            result = subprocess.run(
                argv,
                shell=False,
                cwd=str(self.root),
                capture_output=True,
                text=True,
                timeout=60,
            )
            output = result.stdout
            if result.stderr:
                output += "\n[stderr]\n" + result.stderr
            if result.returncode != 0:
                output += f"\n[exit code: {result.returncode}]"
            # Truncate very long output
            if len(output) > 5000:
                output = output[:5000] + "\n... (truncated)"
            return output or "(no output)"
        except subprocess.TimeoutExpired:
            return "Command timed out after 60 seconds"
        except Exception as e:
            return f"Error running command: {e}"

# src/cegraph/context/engine.py:567-630
    def _expand_context_pagerank(
        self, seeds: list[dict], config: dict
    ) -> list[dict]:
        """Expand context via personalized PageRank from seeds.

        Instead of BFS, compute PPR with the seed set as the personalization
        vector.  This gives a global relevance score that accounts for the
        full graph structure, not just local neighborhoods.
        """
        min_score = config["min_score"]

        # Build personalization vector (seed nodes get their scores)
        personalization: dict[str, float] = {}
        for s in seeds:
            personalization[s["symbol_id"]] = s["score"]

        # Ensure all seed nodes exist in graph
        personalization = {
            k: v for k, v in personalization.items()
            if self.graph.has_node(k)
        }
        if not personalization:
            return []

        # Normalize
        total = sum(personalization.values())
        personalization = {k: v / total for k, v in personalization.items()}

        try:
            ppr = nx.pagerank(
                self.graph,
                alpha=0.85,
                personalization=personalization,
                max_iter=100,
                tol=1e-6,
            )
        except nx.NetworkXError:
            return self._expand_context(seeds, config)

        seed_reason = {s["symbol_id"]: s["reason"] for s in seeds}
        candidates: list[dict] = []

        for node_id, score in ppr.items():
            if score < min_score * 0.01:
                continue
            data = self.graph.nodes.get(node_id, {})
            if data.get("type") != "symbol":
                continue

            # Scale PPR scores to be comparable with BFS scores
            scaled_score = score * 100

            reason = seed_reason.get(node_id, "pagerank expansion")
            depth = 0 if node_id in personalization else 1
            candidates.append({
                "symbol_id": node_id,
                "score": scaled_score,
                "depth": depth,
                "reason": reason,
                "via": [],
            })

        candidates.sort(key=lambda x: x["score"], reverse=True)
        return candidates

# src/cegraph/graph/builder.py:12-12
from cegraph.parser.models import FileSymbols, RelKind, Relationship, Symbol, SymbolKind

# src/cegraph/parser/__init__.py:3-3
from cegraph.parser.models import FileSymbols, Relationship, RelKind, Symbol, SymbolKind

# src/cegraph/parser/python_parser.py:8-14
from cegraph.parser.models import (
    FileSymbols,
    RelKind,
    Relationship,
    Symbol,
    SymbolKind,
)

# src/cegraph/parser/tree_sitter_parser.py:7-13
from cegraph.parser.models import (
    FileSymbols,
    RelKind,
    Relationship,
    Symbol,
    SymbolKind,
)

# examples/demo.py:10-10
from cegraph.graph.query import GraphQuery

# paper/experiments/ablation.py:23-23
from cegraph.graph.query import GraphQuery

# paper/experiments/baselines.py:30-30
from cegraph.graph.query import GraphQuery

# paper/experiments/benchmark.py:57-57
from cegraph.graph.query import GraphQuery

# src/cegraph/context/engine.py:49-49
from cegraph.graph.query import GraphQuery

# src/cegraph/graph/__init__.py:5-5
from cegraph.graph.query import GraphQuery

# src/cegraph/tools/definitions.py:13-13
from cegraph.graph.query import GraphQuery

# tests/test_context.py:17-17
from cegraph.graph.query import GraphQuery

# tests/test_graph.py:11-11
from cegraph.graph.query import GraphQuery

# tests/test_mcp.py:11-11
from cegraph.graph.query import GraphQuery

# tests/test_tools.py:10-10
from cegraph.graph.query import GraphQuery

# src/cegraph/context/engine.py:906-938
    def _marginal_utility(
        self, symbol_id: str, covered_edges: set[tuple[str, str]]
    ) -> float:
        """Compute marginal coverage gain of adding symbol_id.

        This makes the utility submodular: each new symbol covers some edges
        in the graph. As more symbols are selected, each new symbol covers
        fewer NEW edges → diminishing returns.

        Returns a value in [0, 1] representing the fraction of new edges.
        """
        new_edges = 0
        total_edges = 0

        for succ in self.graph.successors(symbol_id):
            succ_data = self.graph.nodes.get(succ, {})
            if succ_data.get("type") == "symbol":
                total_edges += 1
                edge_key = (symbol_id, succ)
                if edge_key not in covered_edges:
                    new_edges += 1

        for pred in self.graph.predecessors(symbol_id):
            pred_data = self.graph.nodes.get(pred, {})
            if pred_data.get("type") == "symbol":
                total_edges += 1
                edge_key = (pred, symbol_id)
                if edge_key not in covered_edges:
                    new_edges += 1

        if total_edges == 0:
            return 1.0
        return new_edges / total_edges

# src/cegraph/context/models.py:54-102
    def render(self, include_line_numbers: bool = True, include_metadata: bool = True) -> str:
        """Render the context package as a string for LLM consumption.

        This is the key output - a carefully structured text that gives the LLM
        exactly what it needs to understand the relevant code.
        """
        sections: list[str] = []

        if include_metadata:
            sections.append(f"# Codebase Context for: {self.task}")
            sections.append(
                f"# {self.symbols_included} symbols from {self.files_included} files "
                f"(~{self.total_tokens:,} tokens, {self.budget_used_pct:.0f}% of budget)"
            )
            sections.append("")

        # Group items by file
        by_file: dict[str, list[ContextItem]] = {}
        for item in self.items:
            by_file.setdefault(item.file_path, []).append(item)

        for file_path, items in sorted(by_file.items()):
            sections.append(f"## {file_path}")
            if include_metadata:
                reasons = set(i.reason for i in items if i.reason)
                if reasons:
                    sections.append(f"# Included because: {'; '.join(reasons)}")
            sections.append("")

            # Sort items by line number
            items.sort(key=lambda x: x.line_start)

            for item in items:
                if include_metadata:
                    sections.append(
                        f"# [{item.kind}] {item.qualified_name} "
                        f"(relevance: {item.relevance_score:.2f}, depth: {item.depth})"
                    )

                if include_line_numbers:
                    lines = item.source_code.splitlines()
                    for i, line in enumerate(lines):
                        sections.append(f"{item.line_start + i:4d} | {line}")
                else:
                    sections.append(item.source_code)

                sections.append("")

        return "\n".join(sections)

# src/cegraph/search/lexical.py:105-155
    def search_symbols(
        self, query: str, kind: str = "", max_results: int = 20
    ) -> list[dict]:
        """Search through symbol definitions in the knowledge graph."""
        if not self.graph:
            return []

        results = []
        query_lower = query.lower()

        for node_id, data in self.graph.nodes(data=True):
            if data.get("type") != "symbol":
                continue

            name = data.get("name", "")
            qname = data.get("qualified_name", "")
            sig = data.get("signature", "")
            doc = data.get("docstring", "")
            sym_kind = data.get("kind", "")

            if kind and sym_kind != kind:
                continue

            # Score based on match quality
            score = 0.0
            if query_lower == name.lower():
                score = 1.0
            elif query_lower in name.lower():
                score = 0.8
            elif query_lower in qname.lower():
                score = 0.6
            elif query_lower in sig.lower():
                score = 0.4
            elif query_lower in doc.lower():
                score = 0.3
            else:
                continue

            results.append({
                "id": node_id,
                "name": name,
                "qualified_name": qname,
                "kind": sym_kind,
                "file_path": data.get("file_path", ""),
                "line": data.get("line_start", 0),
                "signature": sig,
                "score": score,
            })

        results.sort(key=lambda r: r["score"], reverse=True)
        return results[:max_results]

# src/cegraph/parser/models.py:39-60
class Symbol(BaseModel):
    """A code symbol (function, class, method, variable, etc.)."""

    id: str = ""  # auto-generated: "file_path::name"
    name: str
    qualified_name: str = ""  # e.g., "MyClass.my_method"
    kind: SymbolKind
    file_path: str
    line_start: int
    line_end: int
    column_start: int = 0
    column_end: int = 0
    signature: str = ""  # e.g., "def my_method(self, x: int) -> str"
    docstring: str = ""
    decorators: list[str] = Field(default_factory=list)
    parent: str = ""  # parent symbol ID (e.g., class for a method)

    def model_post_init(self, __context: object) -> None:
        if not self.id:
            self.id = f"{self.file_path}::{self.qualified_name or self.name}"
        if not self.qualified_name:
            self.qualified_name = self.name

# src/cegraph/mcp/server.py:466-481
    def _rpc_tools_call(self, params: dict) -> dict:
        """Call a tool and return the result."""
        name = params.get("name", "")
        arguments = params.get("arguments", {})

        try:
            result = self._handle_tool_call(name, arguments)
            return {
                "content": [{"type": "text", "text": result}],
                "isError": False,
            }
        except Exception as e:
            return {
                "content": [{"type": "text", "text": f"Error: {e}"}],
                "isError": True,
            }

# src/cegraph/github/diff_parser.py:116-177
def get_changed_symbols(
    root: Path, graph, file_diffs: list[FileDiff]
) -> list[ChangedSymbol]:
    """Map diff hunks to symbols using the knowledge graph.

    For each changed line range, find which symbols in the graph
    overlap with those lines.
    """
    changed: list[ChangedSymbol] = []
    seen = set()

    for fd in file_diffs:
        if fd.status == "deleted":
            # All symbols in deleted file are affected
            for node_id, data in graph.nodes(data=True):
                if data.get("type") == "symbol" and data.get("file_path") == fd.path:
                    key = (data.get("name"), fd.path)
                    if key not in seen:
                        changed.append(ChangedSymbol(
                            name=data.get("name", ""),
                            qualified_name=data.get("qualified_name", ""),
                            kind=data.get("kind", ""),
                            file_path=fd.path,
                            line_start=data.get("line_start", 0),
                            line_end=data.get("line_end", 0),
                            change_type="deleted",
                        ))
                        seen.add(key)
            continue

        # For modified/added files, find overlapping symbols
        ranges = fd.changed_line_ranges
        for node_id, data in graph.nodes(data=True):
            if data.get("type") != "symbol":
                continue
            if data.get("file_path") != fd.path:
                continue

            sym_start = data.get("line_start", 0)
            sym_end = data.get("line_end", 0)

            # Check if any hunk overlaps with this symbol
            for r_start, r_end in ranges:
                if sym_start <= r_end and sym_end >= r_start:
                    key = (data.get("name"), fd.path)
                    if key not in seen:
                        overlap = min(sym_end, r_end) - max(sym_start, r_start)
                        change_type = "added" if fd.status == "added" else "modified"
                        changed.append(ChangedSymbol(
                            name=data.get("name", ""),
                            qualified_name=data.get("qualified_name", ""),
                            kind=data.get("kind", ""),
                            file_path=fd.path,
                            line_start=sym_start,
                            line_end=sym_end,
                            change_type=change_type,
                            lines_changed=max(0, overlap),
                        ))
                        seen.add(key)
                    break

    return changed

# src/cegraph/graph/query.py:248-268
    def get_structure(self, path_prefix: str = "") -> dict:
        """Get the directory/file structure with symbol counts."""
        structure: dict = {}

        for node_id, data in self.graph.nodes(data=True):
            if data.get("type") != "file":
                continue
            file_path = data.get("path", "")
            if path_prefix and not file_path.startswith(path_prefix):
                continue

            parts = file_path.split("/")
            current = structure
            for part in parts[:-1]:
                current = current.setdefault(part, {})
            current[parts[-1]] = {
                "_language": data.get("language", ""),
                "_symbols": data.get("symbol_count", 0),
            }

        return structure

# src/cegraph/graph/query.py:162-183
    def what_calls(self, name: str) -> list[dict]:
        """Find all symbols called by the given symbol."""
        symbol_ids = self.find_symbol(name)
        results = []

        for sid in symbol_ids:
            for succ in self.graph.successors(sid):
                edge_data = self.graph.edges[sid, succ]
                if edge_data.get("kind") != "calls":
                    continue
                succ_data = self.graph.nodes.get(succ, {})
                if succ_data.get("type") != "symbol":
                    continue
                results.append({
                    "symbol_id": succ,
                    "name": succ_data.get("qualified_name", succ_data.get("name", "")),
                    "kind": succ_data.get("kind", ""),
                    "file_path": succ_data.get("file_path", ""),
                    "line": succ_data.get("line_start", 0),
                })

        return results

# tests/test_mcp.py:111-119
    def test_impact_of(self, mcp_server: MCPServer):
        """Test the impact_of tool."""
        result = mcp_server._dispatch("tools/call", {
            "name": "impact_of",
            "arguments": {"symbol": "calculate_total"},
        })
        assert not result.get("isError")
        content = result["content"][0]["text"]
        assert "Impact" in content or "calculate_total" in content

# src/cegraph/cli.py:224-235
def impact(symbol_name: str, path: str | None):
    """Analyze the blast radius of changing a symbol."""
    root = _get_project_root(path)
    graph, store = _load_graph(root)

    from cegraph.graph.query import GraphQuery

    query = GraphQuery(graph, store)
    result = query.impact_of(symbol_name)
    console.show_impact(result)

    store.close()

# src/cegraph/cli.py:369-407
def serve(path: str | None, transport: str, generate_config: str | None):
    """Start the MCP server for AI tool integration.

    Exposes CeGraph's knowledge graph as MCP tools, allowing Claude Code,
    Cursor, and other MCP clients to query your codebase intelligently.

    Setup for Claude Code:

        cegraph serve --generate-config claude >> ~/.claude/mcp_servers.json

    Setup for Cursor:

        cegraph serve --generate-config cursor >> .cursor/mcp.json

    Then restart your AI tool. It will now have access to:
      - cag_assemble: Get budgeted context for any task
      - search_code: Search symbols in the graph
      - who_calls: Find callers of a function
      - impact_of: Analyze blast radius
      - get_structure: See codebase overview
    """
    if generate_config:
        from cegraph.mcp.server import MCPServer

        root_path = str(Path(path or ".").resolve())
        if generate_config == "claude":
            config = MCPServer.generate_claude_config(root_path)
        else:
            config = MCPServer.generate_cursor_config(root_path)
        click.echo(json.dumps(config, indent=2))
        return

    root = _get_project_root(path)
    from cegraph.mcp.server import MCPServer

    server = MCPServer(root)

    if transport == "stdio":
        asyncio.run(server.run_stdio())

# src/cegraph/github/diff_parser.py:205-209
def get_pr_diff(root: Path) -> str:
    """Get the diff for the current PR (GitHub Actions context)."""
    import os
    base_ref = os.environ.get("GITHUB_BASE_REF", "main")
    return get_git_diff(root, base=f"origin/{base_ref}")