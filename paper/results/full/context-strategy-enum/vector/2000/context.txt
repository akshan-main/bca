# src/cegraph/context/models.py:15-15
    SMART = "balanced"  # Graph-expanded with relevance scoring (default)

# src/cegraph/context/models.py:11-16
class ContextStrategy(str, Enum):
    """Strategy for assembling context."""

    PRECISE = "precise"  # Only directly relevant symbols
    SMART = "balanced"  # Graph-expanded with relevance scoring (default)
    THOROUGH = "thorough"  # Deep expansion, all related code

# paper/experiments/ablation.py:21-21
from cegraph.context.models import ContextStrategy

# paper/experiments/baselines.py:28-28
from cegraph.context.models import ContextStrategy, TokenEstimator

# paper/experiments/benchmark.py:55-55
from cegraph.context.models import ContextStrategy, TokenEstimator

# src/cegraph/context/__init__.py:15-15
from cegraph.context.models import ContextPackage, ContextItem, ContextStrategy

# src/cegraph/context/engine.py:43-48
from cegraph.context.models import (
    ContextItem,
    ContextPackage,
    ContextStrategy,
    TokenEstimator,
)

# tests/test_context.py:10-15
from cegraph.context.models import (
    ContextItem,
    ContextPackage,
    ContextStrategy,
    TokenEstimator,
)

# src/cegraph/context/engine.py:204-272
    def assemble(
        self,
        task: str,
        token_budget: int = 8000,
        strategy: ContextStrategy = ContextStrategy.SMART,
        focus_files: list[str] | None = None,
    ) -> ContextPackage:
        """Assemble a budgeted context package for a given task.

        Args:
            task: Natural language description of the task.
            token_budget: Maximum tokens to include (budget B).
            strategy: How aggressively to expand context.
            focus_files: Optional list of files to prioritize.

        Returns:
            A ContextPackage with the selected symbols and their source code,
            ordered by dependency (definitions before usage).
        """
        start_time = time.time()
        config = _STRATEGY_CONFIG[strategy]

        # Phase 1: Extract entities from the task
        entities = self._extract_entities(task)

        # Phase 2: Find seed symbols in the graph
        seeds = self._find_seeds(entities, focus_files)

        # Phase 3: Expand context via graph traversal
        if self.ablation.use_pagerank and seeds:
            candidates = self._expand_context_pagerank(seeds, config)
        elif self._native_graph and seeds:
            candidates = self._expand_context_native(seeds, config)
        else:
            candidates = self._expand_context(seeds, config)

        # Phase 4: Score candidates
        scored = self._score_candidates(candidates, entities, seeds)

        # Phase 5: Compute dependency closures
        closures = self._compute_closures(scored)

        # Phase 6: Budgeted selection with closure constraints
        selected = self._budget_select(scored, closures, token_budget)

        # Phase 7: Load source code
        items = self._load_source(selected)

        # Phase 8: Dependency-safe ordering
        if self.ablation.dependency_ordering:
            items = self._dependency_order(items)

        elapsed_ms = (time.time() - start_time) * 1000
        total_tokens = sum(item.token_estimate for item in items)
        files = set(item.file_path for item in items)

        return ContextPackage(
            task=task,
            strategy=strategy,
            items=items,
            seed_symbols=[s["symbol_id"] for s in seeds],
            total_tokens=total_tokens,
            token_budget=token_budget,
            files_included=len(files),
            symbols_included=len(items),
            symbols_available=len(scored),
            budget_used_pct=round(total_tokens / max(token_budget, 1) * 100, 1),
            assembly_time_ms=round(elapsed_ms, 1),
        )

# src/cegraph/ui/console.py:49-51
    def code(self, text: str, language: str = "python") -> None:
        """Render syntax-highlighted code."""
        self.console.print(Syntax(text, language, theme="monokai", line_numbers=True))

# src/cegraph/context/models.py:54-102
    def render(self, include_line_numbers: bool = True, include_metadata: bool = True) -> str:
        """Render the context package as a string for LLM consumption.

        This is the key output - a carefully structured text that gives the LLM
        exactly what it needs to understand the relevant code.
        """
        sections: list[str] = []

        if include_metadata:
            sections.append(f"# Codebase Context for: {self.task}")
            sections.append(
                f"# {self.symbols_included} symbols from {self.files_included} files "
                f"(~{self.total_tokens:,} tokens, {self.budget_used_pct:.0f}% of budget)"
            )
            sections.append("")

        # Group items by file
        by_file: dict[str, list[ContextItem]] = {}
        for item in self.items:
            by_file.setdefault(item.file_path, []).append(item)

        for file_path, items in sorted(by_file.items()):
            sections.append(f"## {file_path}")
            if include_metadata:
                reasons = set(i.reason for i in items if i.reason)
                if reasons:
                    sections.append(f"# Included because: {'; '.join(reasons)}")
            sections.append("")

            # Sort items by line number
            items.sort(key=lambda x: x.line_start)

            for item in items:
                if include_metadata:
                    sections.append(
                        f"# [{item.kind}] {item.qualified_name} "
                        f"(relevance: {item.relevance_score:.2f}, depth: {item.depth})"
                    )

                if include_line_numbers:
                    lines = item.source_code.splitlines()
                    for i, line in enumerate(lines):
                        sections.append(f"{item.line_start + i:4d} | {line}")
                else:
                    sections.append(item.source_code)

                sections.append("")

        return "\n".join(sections)

# tests/test_cli.py:19-24
def indexed_project(tmp_project: Path) -> Path:
    """Create a tmp_project that has been indexed."""
    runner = CliRunner()
    result = runner.invoke(main, ["init", "--path", str(tmp_project)])
    assert result.exit_code == 0, f"Init failed: {result.output}"
    return tmp_project

# src/cegraph/config.py:125-137
def set_config_value(config: ProjectConfig, key: str, value: Any) -> ProjectConfig:
    """Set a nested config value using dot notation (e.g., 'llm.provider')."""
    parts = key.split(".")
    data = config.model_dump()
    target = data
    for part in parts[:-1]:
        if part not in target or not isinstance(target[part], dict):
            raise KeyError(f"Invalid config key: {key}")
        target = target[part]
    if parts[-1] not in target:
        raise KeyError(f"Invalid config key: {key}")
    target[parts[-1]] = value
    return ProjectConfig(**data)

# src/cegraph/context/models.py:16-16
    THOROUGH = "thorough"  # Deep expansion, all related code

# src/cegraph/context/models.py:14-14
    PRECISE = "precise"  # Only directly relevant symbols

# src/cegraph/agent/loop.py:185-191
    async def ask(self, question: str) -> str:
        """Simple Q&A mode - ask a question about the codebase.

        Returns just the answer string.
        """
        result = await self.run(question)
        return result.answer

# src/cegraph/tools/registry.py:42-58
    async def execute(self, name: str, arguments: dict[str, Any]) -> str:
        """Execute a tool by name with the given arguments.

        Returns the result as a string.
        """
        func = self._tools.get(name)
        if func is None:
            return f"Error: Unknown tool '{name}'"

        try:
            if inspect.iscoroutinefunction(func):
                result = await func(**arguments)
            else:
                result = func(**arguments)
            return str(result) if result is not None else "Done."
        except Exception as e:
            return f"Error executing tool '{name}': {e}"

# src/cegraph/github/diff_parser.py:47-56
class ChangedSymbol:
    """A symbol that was affected by the diff."""
    name: str
    qualified_name: str
    kind: str
    file_path: str
    line_start: int
    line_end: int
    change_type: str  # 'modified', 'added', 'deleted'
    lines_changed: int = 0