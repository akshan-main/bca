# src/cegraph/context/models.py:15-15
    SMART = "balanced"  # Graph-expanded with relevance scoring (default)

# paper/experiments/ablation.py:21-21
from cegraph.context.models import ContextStrategy

# paper/experiments/ablation.py:21-21
from cegraph.context.models import ContextStrategy

# paper/experiments/ablation.py:21-21
from cegraph.context.models import ContextStrategy

# paper/experiments/ablation.py:21-21
from cegraph.context.models import ContextStrategy

# paper/experiments/ablation.py:21-21
from cegraph.context.models import ContextStrategy

# paper/experiments/ablation.py:21-21
from cegraph.context.models import ContextStrategy

# tests/test_context.py:48-52
class TestContextStrategy:
    def test_strategies_exist(self):
        assert ContextStrategy.PRECISE.value == "precise"
        assert ContextStrategy.SMART.value == "smart"
        assert ContextStrategy.THOROUGH.value == "thorough"

# paper/experiments/ablation.py:21-21
from cegraph.context.models import ContextStrategy

# src/cegraph/context/models.py:14-14
    PRECISE = "precise"  # Only directly relevant symbols

# src/cegraph/context/models.py:16-16
    THOROUGH = "thorough"  # Deep expansion, all related code

# src/cegraph/graph/builder.py:5-5
import hashlib

# tests/test_context.py:49-52
    def test_strategies_exist(self):
        assert ContextStrategy.PRECISE.value == "precise"
        assert ContextStrategy.SMART.value == "smart"
        assert ContextStrategy.THOROUGH.value == "thorough"

# src/cegraph/context/engine.py:90-109
_STRATEGY_CONFIG = {
    ContextStrategy.PRECISE: {
        "max_depth": 1,
        "min_score": 0.3,
        "include_callers": True,
        "include_callees": True,
    },
    ContextStrategy.SMART: {
        "max_depth": 3,
        "min_score": 0.1,
        "include_callers": True,
        "include_callees": True,
    },
    ContextStrategy.THOROUGH: {
        "max_depth": 5,
        "min_score": 0.05,
        "include_callers": True,
        "include_callees": True,
    },
}

# src/cegraph/cli.py:14-22
from cegraph.config import (
    GRAPH_DB_FILE,
    ProjectConfig,
    find_project_root,
    get_cegraph_dir,
    load_config,
    save_config,
    set_config_value,
)

# src/cegraph/cli.py:14-22
from cegraph.config import (
    GRAPH_DB_FILE,
    ProjectConfig,
    find_project_root,
    get_cegraph_dir,
    load_config,
    save_config,
    set_config_value,
)

# src/cegraph/llm/base.py:55-56
    def has_tool_calls(self) -> bool:
        return len(self.tool_calls) > 0

# src/cegraph/agent/loop.py:185-191
    async def ask(self, question: str) -> str:
        """Simple Q&A mode - ask a question about the codebase.

        Returns just the answer string.
        """
        result = await self.run(question)
        return result.answer

# src/cegraph/parser/python_parser.py:35-45
def _get_docstring(node: ast.AST) -> str:
    """Extract docstring from a node if present."""
    if (
        isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef, ast.Module))
        and node.body
        and isinstance(node.body[0], ast.Expr)
        and isinstance(node.body[0].value, (ast.Constant,))
        and isinstance(node.body[0].value.value, str)
    ):
        return node.body[0].value.value.strip()
    return ""

# tests/test_cli.py:19-24
def indexed_project(tmp_project: Path) -> Path:
    """Create a tmp_project that has been indexed."""
    runner = CliRunner()
    result = runner.invoke(main, ["init", "--path", str(tmp_project)])
    assert result.exit_code == 0, f"Init failed: {result.output}"
    return tmp_project

# tests/test_config.py:50-53
    def test_set_config_value(self):
        config = ProjectConfig()
        updated = set_config_value(config, "llm.provider", "openai")
        assert updated.llm.provider == "openai"

# src/cegraph/context/models.py:54-102
    def render(self, include_line_numbers: bool = True, include_metadata: bool = True) -> str:
        """Render the context package as a string for LLM consumption.

        This is the key output - a carefully structured text that gives the LLM
        exactly what it needs to understand the relevant code.
        """
        sections: list[str] = []

        if include_metadata:
            sections.append(f"# Codebase Context for: {self.task}")
            sections.append(
                f"# {self.symbols_included} symbols from {self.files_included} files "
                f"(~{self.total_tokens:,} tokens, {self.budget_used_pct:.0f}% of budget)"
            )
            sections.append("")

        # Group items by file
        by_file: dict[str, list[ContextItem]] = {}
        for item in self.items:
            by_file.setdefault(item.file_path, []).append(item)

        for file_path, items in sorted(by_file.items()):
            sections.append(f"## {file_path}")
            if include_metadata:
                reasons = set(i.reason for i in items if i.reason)
                if reasons:
                    sections.append(f"# Included because: {'; '.join(reasons)}")
            sections.append("")

            # Sort items by line number
            items.sort(key=lambda x: x.line_start)

            for item in items:
                if include_metadata:
                    sections.append(
                        f"# [{item.kind}] {item.qualified_name} "
                        f"(relevance: {item.relevance_score:.2f}, depth: {item.depth})"
                    )

                if include_line_numbers:
                    lines = item.source_code.splitlines()
                    for i, line in enumerate(lines):
                        sections.append(f"{item.line_start + i:4d} | {line}")
                else:
                    sections.append(item.source_code)

                sections.append("")

        return "\n".join(sections)

# src/cegraph/cli.py:14-22
from cegraph.config import (
    GRAPH_DB_FILE,
    ProjectConfig,
    find_project_root,
    get_cegraph_dir,
    load_config,
    save_config,
    set_config_value,
)

# tests/test_mcp.py:93-101
    def test_search_code(self, mcp_server: MCPServer):
        """Test the search_code tool."""
        result = mcp_server._dispatch("tools/call", {
            "name": "search_code",
            "arguments": {"query": "main"},
        })
        assert not result.get("isError")
        content = result["content"][0]["text"]
        assert "main" in content

# tests/test_parser.py:100-104
    def test_parse_docstrings(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        funcs = {s.name: s for s in result.symbols if s.kind in (SymbolKind.FUNCTION, SymbolKind.METHOD)}
        assert "Factory function" in funcs["create_processor"].docstring
        assert "Transform a single item" in funcs["_transform"].docstring

# src/cegraph/tools/definitions.py:38-60
    def search_code(self, query: str, file_pattern: str = "", max_results: int = 10) -> str:
        """Search for code in the repository matching a query."""
        results = self.search.search(query, file_pattern, max_results=max_results)
        if not results:
            return f"No results found for '{query}'"

        output = []
        for r in results:
            header = f"**{r.file_path}:{r.line_number}**"
            if r.symbol_name:
                header += f" (in `{r.symbol_name}`)"
            output.append(header)

            if r.context_before:
                for line in r.context_before:
                    output.append(f"  {line}")
            output.append(f"â†’ {r.line_content}")
            if r.context_after:
                for line in r.context_after:
                    output.append(f"  {line}")
            output.append("")

        return "\n".join(output)