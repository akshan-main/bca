# Codebase Context for: ContextStrategy.SMART has the wrong string value — code that checks strategy == "smart" fails silently.
# 38 symbols from 8 files (~7,507 tokens, 94% of budget)

## src/cegraph/config.py
# Included because: matches 'value'

# [function] set_config_value (relevance: 0.40, depth: 0)
 125 | def set_config_value(config: ProjectConfig, key: str, value: Any) -> ProjectConfig:
 126 |     """Set a nested config value using dot notation (e.g., 'llm.provider')."""
 127 |     parts = key.split(".")
 128 |     data = config.model_dump()
 129 |     target = data
 130 |     for part in parts[:-1]:
 131 |         if part not in target or not isinstance(target[part], dict):
 132 |             raise KeyError(f"Invalid config key: {key}")
 133 |         target = target[part]
 134 |     if parts[-1] not in target:
 135 |         raise KeyError(f"Invalid config key: {key}")
 136 |     target[parts[-1]] = value
 137 |     return ProjectConfig(**data)

## src/cegraph/context/models.py
# Included because: graph expansion (depth 2); matches 'ContextStrategy'

# [class] ContextStrategy (relevance: 1.21, depth: 0)
  11 | class ContextStrategy(str, Enum):
  12 |     """Strategy for assembling context."""
  13 | 
  14 |     PRECISE = "precise"  # Only directly relevant symbols
  15 |     SMART = "balanced"  # Graph-expanded with relevance scoring (default)
  16 |     THOROUGH = "thorough"  # Deep expansion, all related code

# [class] ContextItem (relevance: 0.24, depth: 2)
  19 | class ContextItem(BaseModel):
  20 |     """A single item in the assembled context."""
  21 | 
  22 |     symbol_id: str
  23 |     name: str
  24 |     qualified_name: str
  25 |     kind: str
  26 |     file_path: str
  27 |     line_start: int
  28 |     line_end: int
  29 |     source_code: str
  30 |     signature: str = ""
  31 |     docstring: str = ""
  32 |     relevance_score: float = 0.0
  33 |     reason: str = ""  # Why this was included
  34 |     token_estimate: int = 0
  35 |     depth: int = 0  # Distance from seed symbols
  36 |     is_dependency: bool = False  # Included via dependency closure

# [class] ContextPackage (relevance: 0.24, depth: 2)
  39 | class ContextPackage(BaseModel):
  40 |     """The complete assembled context package ready for LLM consumption."""
  41 | 
  42 |     task: str
  43 |     strategy: ContextStrategy
  44 |     items: list[ContextItem] = Field(default_factory=list)
  45 |     seed_symbols: list[str] = Field(default_factory=list)
  46 |     total_tokens: int = 0
  47 |     token_budget: int = 0
  48 |     files_included: int = 0
  49 |     symbols_included: int = 0
  50 |     symbols_available: int = 0  # Total candidates before budget cut
  51 |     budget_used_pct: float = 0.0
  52 |     assembly_time_ms: float = 0.0
  53 | 
  54 |     def render(self, include_line_numbers: bool = True, include_metadata: bool = True) -> str:
  55 |         """Render the context package as a string for LLM consumption.
  56 | 
  57 |         This is the key output - a carefully structured text that gives the LLM
  58 |         exactly what it needs to understand the relevant code.
  59 |         """
  60 |         sections: list[str] = []
  61 | 
  62 |         if include_metadata:
  63 |             sections.append(f"# Codebase Context for: {self.task}")
  64 |             sections.append(
  65 |                 f"# {self.symbols_included} symbols from {self.files_included} files "
  66 |                 f"(~{self.total_tokens:,} tokens, {self.budget_used_pct:.0f}% of budget)"
  67 |             )
  68 |             sections.append("")
  69 | 
  70 |         # Group items by file
  71 |         by_file: dict[str, list[ContextItem]] = {}
  72 |         for item in self.items:
  73 |             by_file.setdefault(item.file_path, []).append(item)
  74 | 
  75 |         for file_path, items in sorted(by_file.items()):
  76 |             sections.append(f"## {file_path}")
  77 |             if include_metadata:
  78 |                 reasons = set(i.reason for i in items if i.reason)
  79 |                 if reasons:
  80 |                     sections.append(f"# Included because: {'; '.join(reasons)}")
  81 |             sections.append("")
  82 | 
  83 |             # Sort items by line number
  84 |             items.sort(key=lambda x: x.line_start)
  85 | 
  86 |             for item in items:
  87 |                 if include_metadata:
  88 |                     sections.append(
  89 |                         f"# [{item.kind}] {item.qualified_name} "
  90 |                         f"(relevance: {item.relevance_score:.2f}, depth: {item.depth})"
  91 |                     )
  92 | 
  93 |                 if include_line_numbers:
  94 |                     lines = item.source_code.splitlines()
  95 |                     for i, line in enumerate(lines):
  96 |                         sections.append(f"{item.line_start + i:4d} | {line}")
  97 |                 else:
  98 |                     sections.append(item.source_code)
  99 | 
 100 |                 sections.append("")
 101 | 
 102 |         return "\n".join(sections)
 103 | 
 104 |     def render_compact(self) -> str:
 105 |         """Render a compact version - signatures + docstrings only for secondary symbols."""
 106 |         sections: list[str] = []
 107 |         sections.append(f"# Context for: {self.task}")
 108 |         sections.append("")
 109 | 
 110 |         by_file: dict[str, list[ContextItem]] = {}
 111 |         for item in self.items:
 112 |             by_file.setdefault(item.file_path, []).append(item)
 113 | 
 114 |         for file_path, items in sorted(by_file.items()):
 115 |             sections.append(f"## {file_path}")
 116 |             items.sort(key=lambda x: x.line_start)
 117 | 
 118 |             for item in items:
 119 |                 if item.depth == 0:
 120 |                     # Primary symbols: full source
 121 |                     sections.append(item.source_code)
 122 |                 else:
 123 |                     # Secondary: signature + docstring only
 124 |                     sections.append(item.signature)
 125 |                     if item.docstring:
 126 |                         doc_preview = item.docstring[:150]
 127 |                         if len(item.docstring) > 150:
 128 |                             doc_preview += "..."
 129 |                         sections.append(f'    """{doc_preview}"""')
 130 |                 sections.append("")
 131 | 
 132 |         return "\n".join(sections)
 133 | 
 134 |     def summary(self) -> str:
 135 |         """Human-readable summary of what's in the context."""
 136 |         lines = [
 137 |             f"CAG Context Package for: {self.task}",
 138 |             f"Strategy: {self.strategy.value}",
 139 |             f"Tokens: {self.total_tokens:,} / {self.token_budget:,} ({self.budget_used_pct:.0f}%)",
 140 |             f"Symbols: {self.symbols_included} included, {self.symbols_available} candidates",
 141 |             f"Files: {self.files_included}",
 142 |             f"Assembly time: {self.assembly_time_ms:.1f}ms",
 143 |             "",
 144 |             "Included symbols:",
 145 |         ]
 146 |         for item in self.items:
 147 |             marker = ">" if item.depth == 0 else " " * item.depth + "·"
 148 |             lines.append(
 149 |                 f"  {marker} {item.qualified_name} ({item.kind}) "
 150 |                 f"[{item.file_path}:{item.line_start}] "
 151 |                 f"score={item.relevance_score:.2f} ~{item.token_estimate}tok"
 152 |             )
 153 |             if item.reason:
 154 |                 lines.append(f"    reason: {item.reason}")
 155 | 
 156 |         return "\n".join(lines)

# [method] ContextPackage.render (relevance: 0.36, depth: 2)
  54 |     def render(self, include_line_numbers: bool = True, include_metadata: bool = True) -> str:
  55 |         """Render the context package as a string for LLM consumption.
  56 | 
  57 |         This is the key output - a carefully structured text that gives the LLM
  58 |         exactly what it needs to understand the relevant code.
  59 |         """
  60 |         sections: list[str] = []
  61 | 
  62 |         if include_metadata:
  63 |             sections.append(f"# Codebase Context for: {self.task}")
  64 |             sections.append(
  65 |                 f"# {self.symbols_included} symbols from {self.files_included} files "
  66 |                 f"(~{self.total_tokens:,} tokens, {self.budget_used_pct:.0f}% of budget)"
  67 |             )
  68 |             sections.append("")
  69 | 
  70 |         # Group items by file
  71 |         by_file: dict[str, list[ContextItem]] = {}
  72 |         for item in self.items:
  73 |             by_file.setdefault(item.file_path, []).append(item)
  74 | 
  75 |         for file_path, items in sorted(by_file.items()):
  76 |             sections.append(f"## {file_path}")
  77 |             if include_metadata:
  78 |                 reasons = set(i.reason for i in items if i.reason)
  79 |                 if reasons:
  80 |                     sections.append(f"# Included because: {'; '.join(reasons)}")
  81 |             sections.append("")
  82 | 
  83 |             # Sort items by line number
  84 |             items.sort(key=lambda x: x.line_start)
  85 | 
  86 |             for item in items:
  87 |                 if include_metadata:
  88 |                     sections.append(
  89 |                         f"# [{item.kind}] {item.qualified_name} "
  90 |                         f"(relevance: {item.relevance_score:.2f}, depth: {item.depth})"
  91 |                     )
  92 | 
  93 |                 if include_line_numbers:
  94 |                     lines = item.source_code.splitlines()
  95 |                     for i, line in enumerate(lines):
  96 |                         sections.append(f"{item.line_start + i:4d} | {line}")
  97 |                 else:
  98 |                     sections.append(item.source_code)
  99 | 
 100 |                 sections.append("")
 101 | 
 102 |         return "\n".join(sections)

# [method] ContextPackage.render_compact (relevance: 0.26, depth: 2)
 104 |     def render_compact(self) -> str:
 105 |         """Render a compact version - signatures + docstrings only for secondary symbols."""
 106 |         sections: list[str] = []
 107 |         sections.append(f"# Context for: {self.task}")
 108 |         sections.append("")
 109 | 
 110 |         by_file: dict[str, list[ContextItem]] = {}
 111 |         for item in self.items:
 112 |             by_file.setdefault(item.file_path, []).append(item)
 113 | 
 114 |         for file_path, items in sorted(by_file.items()):
 115 |             sections.append(f"## {file_path}")
 116 |             items.sort(key=lambda x: x.line_start)
 117 | 
 118 |             for item in items:
 119 |                 if item.depth == 0:
 120 |                     # Primary symbols: full source
 121 |                     sections.append(item.source_code)
 122 |                 else:
 123 |                     # Secondary: signature + docstring only
 124 |                     sections.append(item.signature)
 125 |                     if item.docstring:
 126 |                         doc_preview = item.docstring[:150]
 127 |                         if len(item.docstring) > 150:
 128 |                             doc_preview += "..."
 129 |                         sections.append(f'    """{doc_preview}"""')
 130 |                 sections.append("")
 131 | 
 132 |         return "\n".join(sections)

# [method] ContextPackage.summary (relevance: 0.26, depth: 2)
 134 |     def summary(self) -> str:
 135 |         """Human-readable summary of what's in the context."""
 136 |         lines = [
 137 |             f"CAG Context Package for: {self.task}",
 138 |             f"Strategy: {self.strategy.value}",
 139 |             f"Tokens: {self.total_tokens:,} / {self.token_budget:,} ({self.budget_used_pct:.0f}%)",
 140 |             f"Symbols: {self.symbols_included} included, {self.symbols_available} candidates",
 141 |             f"Files: {self.files_included}",
 142 |             f"Assembly time: {self.assembly_time_ms:.1f}ms",
 143 |             "",
 144 |             "Included symbols:",
 145 |         ]
 146 |         for item in self.items:
 147 |             marker = ">" if item.depth == 0 else " " * item.depth + "·"
 148 |             lines.append(
 149 |                 f"  {marker} {item.qualified_name} ({item.kind}) "
 150 |                 f"[{item.file_path}:{item.line_start}] "
 151 |                 f"score={item.relevance_score:.2f} ~{item.token_estimate}tok"
 152 |             )
 153 |             if item.reason:
 154 |                 lines.append(f"    reason: {item.reason}")
 155 | 
 156 |         return "\n".join(lines)

# [method] TokenEstimator.estimate (relevance: 0.40, depth: 2)
 166 |     def estimate(cls, text: str) -> int:
 167 |         """Estimate token count for a string."""
 168 |         return max(1, int(len(text) / cls.CHARS_PER_TOKEN))

# [method] TokenEstimator.estimate_lines (relevance: 0.32, depth: 2)
 171 |     def estimate_lines(cls, line_count: int, avg_line_length: int = 40) -> int:
 172 |         """Estimate tokens for a given number of lines."""
 173 |         return max(1, int(line_count * avg_line_length / cls.CHARS_PER_TOKEN))

## src/cegraph/llm/base.py
# Included because: matches 'has'; graph expansion (depth 1)

# [class] LLMResponse (relevance: 0.22, depth: 1)
  46 | class LLMResponse(BaseModel):
  47 |     """Response from the LLM."""
  48 | 
  49 |     content: str = ""
  50 |     tool_calls: list[ToolCall] = Field(default_factory=list)
  51 |     finish_reason: str = ""
  52 |     usage: dict[str, int] = Field(default_factory=dict)
  53 | 
  54 |     @property
  55 |     def has_tool_calls(self) -> bool:
  56 |         return len(self.tool_calls) > 0

# [method] LLMResponse.has_tool_calls (relevance: 0.37, depth: 0)
  55 |     def has_tool_calls(self) -> bool:
  56 |         return len(self.tool_calls) > 0

## src/cegraph/parser/core.py
# Included because: graph expansion (depth 2)

# [function] parse_file (relevance: 0.23, depth: 2)
  13 | def parse_file(file_path: str, source: str | None = None) -> FileSymbols | None:
  14 |     """Parse a single file, auto-detecting language and selecting the best parser.
  15 | 
  16 |     Returns None if the file's language is not supported.
  17 | 
  18 |     - Python: uses stdlib ast (zero deps, high accuracy)
  19 |     - JS/TS, Go, Rust, Java: uses tree-sitter (required dep, full AST)
  20 |     """
  21 |     language = detect_language(file_path)
  22 |     if not language:
  23 |         return None
  24 | 
  25 |     # Python uses stdlib AST — better than tree-sitter for Python
  26 |     if language == "python":
  27 |         from cegraph.parser.python_parser import parse_python_file
  28 | 
  29 |         return parse_python_file(file_path, source)
  30 | 
  31 |     # Everything else uses tree-sitter
  32 |     from cegraph.parser.tree_sitter_parser import is_available, parse_tree_sitter_file
  33 | 
  34 |     if is_available(language):
  35 |         return parse_tree_sitter_file(file_path, language, source)
  36 | 
  37 |     # Language detected but no tree-sitter grammar installed
  38 |     return None

## src/cegraph/parser/python_parser.py
# Included because: graph expansion (depth 1); matches 'string'; graph expansion (depth 3); graph expansion (depth 2)

# [function] parse_python_file (relevance: 0.58, depth: 1)
  17 | def parse_python_file(file_path: str, source: str | None = None) -> FileSymbols:
  18 |     """Parse a Python file and extract symbols and relationships."""
  19 |     if source is None:
  20 |         source = Path(file_path).read_text(encoding="utf-8", errors="replace")
  21 | 
  22 |     result = FileSymbols(file_path=file_path, language="python")
  23 | 
  24 |     try:
  25 |         tree = ast.parse(source, filename=file_path)
  26 |     except SyntaxError as e:
  27 |         result.errors.append(f"SyntaxError: {e}")
  28 |         return result
  29 | 
  30 |     lines = source.splitlines()
  31 |     _extract_from_module(tree, file_path, lines, result)
  32 |     return result

# [function] _get_docstring (relevance: 0.42, depth: 0)
  35 | def _get_docstring(node: ast.AST) -> str:
  36 |     """Extract docstring from a node if present."""
  37 |     if (
  38 |         isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef, ast.Module))
  39 |         and node.body
  40 |         and isinstance(node.body[0], ast.Expr)
  41 |         and isinstance(node.body[0].value, (ast.Constant,))
  42 |         and isinstance(node.body[0].value.value, str)
  43 |     ):
  44 |         return node.body[0].value.value.strip()
  45 |     return ""

# [function] _get_decorators (relevance: 0.24, depth: 2)
  48 | def _get_decorators(node: ast.FunctionDef | ast.AsyncFunctionDef | ast.ClassDef) -> list[str]:
  49 |     """Extract decorator names."""
  50 |     decorators = []
  51 |     for dec in node.decorator_list:
  52 |         if isinstance(dec, ast.Name):
  53 |             decorators.append(dec.id)
  54 |         elif isinstance(dec, ast.Attribute):
  55 |             decorators.append(ast.dump(dec))
  56 |         elif isinstance(dec, ast.Call):
  57 |             if isinstance(dec.func, ast.Name):
  58 |                 decorators.append(dec.func.id)
  59 |             elif isinstance(dec.func, ast.Attribute):
  60 |                 decorators.append(ast.dump(dec.func))
  61 |     return decorators

# [function] _get_function_signature (relevance: 0.22, depth: 2)
  64 | def _get_function_signature(
  65 |     node: ast.FunctionDef | ast.AsyncFunctionDef, lines: list[str]
  66 | ) -> str:
  67 |     """Extract the function signature from source lines."""
  68 |     start = node.lineno - 1
  69 |     sig_lines = []
  70 |     for i in range(start, min(start + 10, len(lines))):
  71 |         line = lines[i]
  72 |         sig_lines.append(line.strip())
  73 |         if ":" in line:
  74 |             # Check if we've reached the colon that ends the signature
  75 |             text = "".join(sig_lines)
  76 |             if text.count("(") <= text.count(")"):
  77 |                 break
  78 |     sig = " ".join(sig_lines)
  79 |     # Trim to just the def ... : part
  80 |     if ":" in sig:
  81 |         sig = sig[: sig.rindex(":") + 1]
  82 |     return sig

# [function] _extract_from_module (relevance: 0.38, depth: 2)
  85 | def _extract_from_module(
  86 |     tree: ast.Module,
  87 |     file_path: str,
  88 |     lines: list[str],
  89 |     result: FileSymbols,
  90 |     parent_name: str = "",
  91 |     parent_id: str = "",
  92 | ) -> None:
  93 |     """Recursively extract symbols from an AST module/class body."""
  94 | 
  95 |     for node in ast.iter_child_nodes(tree):
  96 |         if isinstance(node, (ast.Import, ast.ImportFrom)):
  97 |             _extract_import(node, file_path, result)
  98 | 
  99 |         elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
 100 |             _extract_function(node, file_path, lines, result, parent_name, parent_id)
 101 | 
 102 |         elif isinstance(node, ast.ClassDef):
 103 |             _extract_class(node, file_path, lines, result, parent_name, parent_id)
 104 | 
 105 |         elif isinstance(node, ast.Assign):
 106 |             _extract_assignment(node, file_path, result, parent_name, parent_id)

# [function] _extract_import (relevance: 0.28, depth: 3)
 109 | def _extract_import(
 110 |     node: ast.Import | ast.ImportFrom, file_path: str, result: FileSymbols
 111 | ) -> None:
 112 |     """Extract import statements."""
 113 |     if isinstance(node, ast.Import):
 114 |         for alias in node.names:
 115 |             name = alias.asname or alias.name
 116 |             result.imports.append(alias.name)
 117 |             result.symbols.append(
 118 |                 Symbol(
 119 |                     name=name,
 120 |                     kind=SymbolKind.IMPORT,
 121 |                     file_path=file_path,
 122 |                     line_start=node.lineno,
 123 |                     line_end=node.end_lineno or node.lineno,
 124 |                 )
 125 |             )
 126 |             result.relationships.append(
 127 |                 Relationship(
 128 |                     source=f"{file_path}::{name}",
 129 |                     target=alias.name,
 130 |                     kind=RelKind.IMPORTS,
 131 |                     file_path=file_path,
 132 |                     line=node.lineno,
 133 |                 )
 134 |             )
 135 |     elif isinstance(node, ast.ImportFrom):
 136 |         module = node.module or ""
 137 |         for alias in node.names:
 138 |             name = alias.asname or alias.name
 139 |             full_import = f"{module}.{alias.name}" if module else alias.name
 140 |             result.imports.append(full_import)
 141 |             result.symbols.append(
 142 |                 Symbol(
 143 |                     name=name,
 144 |                     kind=SymbolKind.IMPORT,
 145 |                     file_path=file_path,
 146 |                     line_start=node.lineno,
 147 |                     line_end=node.end_lineno or node.lineno,
 148 |                 )
 149 |             )
 150 |             result.relationships.append(
 151 |                 Relationship(
 152 |                     source=f"{file_path}::{name}",
 153 |                     target=full_import,
 154 |                     kind=RelKind.IMPORTS,
 155 |                     file_path=file_path,
 156 |                     line=node.lineno,
 157 |                 )
 158 |             )

# [function] _extract_function (relevance: 0.38, depth: 1)
 161 | def _extract_function(
 162 |     node: ast.FunctionDef | ast.AsyncFunctionDef,
 163 |     file_path: str,
 164 |     lines: list[str],
 165 |     result: FileSymbols,
 166 |     parent_name: str,
 167 |     parent_id: str,
 168 | ) -> None:
 169 |     """Extract function/method definition."""
 170 |     qualified = f"{parent_name}.{node.name}" if parent_name else node.name
 171 |     kind = SymbolKind.METHOD if parent_name else SymbolKind.FUNCTION
 172 |     sig = _get_function_signature(node, lines)
 173 | 
 174 |     symbol = Symbol(
 175 |         name=node.name,
 176 |         qualified_name=qualified,
 177 |         kind=kind,
 178 |         file_path=file_path,
 179 |         line_start=node.lineno,
 180 |         line_end=node.end_lineno or node.lineno,
 181 |         signature=sig,
 182 |         docstring=_get_docstring(node),
 183 |         decorators=_get_decorators(node),
 184 |         parent=parent_id,
 185 |     )
 186 |     result.symbols.append(symbol)
 187 | 
 188 |     # Add contains relationship
 189 |     if parent_id:
 190 |         result.relationships.append(
 191 |             Relationship(
 192 |                 source=parent_id,
 193 |                 target=symbol.id,
 194 |                 kind=RelKind.CONTAINS,
 195 |                 file_path=file_path,
 196 |                 line=node.lineno,
 197 |             )
 198 |         )
 199 | 
 200 |     # Extract calls within the function body
 201 |     _extract_calls(node, file_path, symbol.id, result)

# [function] _extract_class (relevance: 0.38, depth: 1)
 204 | def _extract_class(
 205 |     node: ast.ClassDef,
 206 |     file_path: str,
 207 |     lines: list[str],
 208 |     result: FileSymbols,
 209 |     parent_name: str,
 210 |     parent_id: str,
 211 | ) -> None:
 212 |     """Extract class definition and its members."""
 213 |     qualified = f"{parent_name}.{node.name}" if parent_name else node.name
 214 | 
 215 |     symbol = Symbol(
 216 |         name=node.name,
 217 |         qualified_name=qualified,
 218 |         kind=SymbolKind.CLASS,
 219 |         file_path=file_path,
 220 |         line_start=node.lineno,
 221 |         line_end=node.end_lineno or node.lineno,
 222 |         signature=f"class {node.name}",
 223 |         docstring=_get_docstring(node),
 224 |         decorators=_get_decorators(node),
 225 |         parent=parent_id,
 226 |     )
 227 |     result.symbols.append(symbol)
 228 | 
 229 |     # Add contains relationship
 230 |     if parent_id:
 231 |         result.relationships.append(
 232 |             Relationship(
 233 |                 source=parent_id,
 234 |                 target=symbol.id,
 235 |                 kind=RelKind.CONTAINS,
 236 |                 file_path=file_path,
 237 |                 line=node.lineno,
 238 |             )
 239 |         )
 240 | 
 241 |     # Extract inheritance
 242 |     for base in node.bases:
 243 |         base_name = _node_to_name(base)
 244 |         if base_name:
 245 |             result.relationships.append(
 246 |                 Relationship(
 247 |                     source=symbol.id,
 248 |                     target=base_name,
 249 |                     kind=RelKind.INHERITS,
 250 |                     file_path=file_path,
 251 |                     line=node.lineno,
 252 |                 )
 253 |             )
 254 | 
 255 |     # Recurse into class body
 256 |     _extract_from_module(node, file_path, lines, result, qualified, symbol.id)

# [function] _extract_assignment (relevance: 0.28, depth: 3)
 259 | def _extract_assignment(
 260 |     node: ast.Assign,
 261 |     file_path: str,
 262 |     result: FileSymbols,
 263 |     parent_name: str,
 264 |     parent_id: str,
 265 | ) -> None:
 266 |     """Extract variable/constant assignments at module or class level."""
 267 |     for target in node.targets:
 268 |         name = _node_to_name(target)
 269 |         if not name:
 270 |             continue
 271 |         qualified = f"{parent_name}.{name}" if parent_name else name
 272 |         kind = SymbolKind.CONSTANT if name.isupper() else SymbolKind.VARIABLE
 273 | 
 274 |         symbol = Symbol(
 275 |             name=name,
 276 |             qualified_name=qualified,
 277 |             kind=kind,
 278 |             file_path=file_path,
 279 |             line_start=node.lineno,
 280 |             line_end=node.end_lineno or node.lineno,
 281 |             parent=parent_id,
 282 |         )
 283 |         result.symbols.append(symbol)

# [function] _extract_calls (relevance: 0.26, depth: 2)
 286 | def _extract_calls(
 287 |     node: ast.AST, file_path: str, caller_id: str, result: FileSymbols
 288 | ) -> None:
 289 |     """Walk a function body and extract all function calls."""
 290 |     for child in ast.walk(node):
 291 |         if isinstance(child, ast.Call):
 292 |             callee = _node_to_name(child.func)
 293 |             if callee:
 294 |                 result.relationships.append(
 295 |                     Relationship(
 296 |                         source=caller_id,
 297 |                         target=callee,
 298 |                         kind=RelKind.CALLS,
 299 |                         file_path=file_path,
 300 |                         line=child.lineno if hasattr(child, "lineno") else 0,
 301 |                     )
 302 |                 )

# [function] _node_to_name (relevance: 0.30, depth: 2)
 305 | def _node_to_name(node: ast.AST) -> str:
 306 |     """Convert an AST node to a dotted name string."""
 307 |     if isinstance(node, ast.Name):
 308 |         return node.id
 309 |     elif isinstance(node, ast.Attribute):
 310 |         parent = _node_to_name(node.value)
 311 |         if parent:
 312 |             return f"{parent}.{node.attr}"
 313 |         return node.attr
 314 |     elif isinstance(node, ast.Subscript):
 315 |         return _node_to_name(node.value)
 316 |     return ""

## src/cegraph/parser/tree_sitter_parser.py
# Included because: graph expansion (depth 3)

# [function] parse_tree_sitter_file (relevance: 0.23, depth: 3)
 106 | def parse_tree_sitter_file(
 107 |     file_path: str, language: str, source: str | None = None
 108 | ) -> FileSymbols:
 109 |     """Parse a file using tree-sitter for accurate AST extraction."""
 110 |     from tree_sitter import Parser
 111 | 
 112 |     if source is None:
 113 |         source = Path(file_path).read_text(encoding="utf-8", errors="replace")
 114 | 
 115 |     result = FileSymbols(file_path=file_path, language=language)
 116 |     source_bytes = source.encode("utf-8")
 117 | 
 118 |     try:
 119 |         ts_language = _get_language(language)
 120 |         parser = Parser(ts_language)
 121 |         tree = parser.parse(source_bytes)
 122 |     except Exception as e:
 123 |         result.errors.append(f"tree-sitter parse error: {e}")
 124 |         return result
 125 | 
 126 |     _walk_tree(tree.root_node, file_path, language, source_bytes, result)
 127 |     return result

## tests/test_context.py
# Included because: matches 'strategy'; graph expansion (depth 1)

# [class] TestContextStrategy (relevance: 0.40, depth: 0)
  48 | class TestContextStrategy:
  49 |     def test_strategies_exist(self):
  50 |         assert ContextStrategy.PRECISE.value == "precise"
  51 |         assert ContextStrategy.SMART.value == "smart"
  52 |         assert ContextStrategy.THOROUGH.value == "thorough"

# [method] TestContextStrategy.test_strategies_exist (relevance: 0.27, depth: 1)
  49 |     def test_strategies_exist(self):
  50 |         assert ContextStrategy.PRECISE.value == "precise"
  51 |         assert ContextStrategy.SMART.value == "smart"
  52 |         assert ContextStrategy.THOROUGH.value == "thorough"

## tests/test_parser.py
# Included because: matches 'string'; graph expansion (depth 1); graph expansion (depth 2)

# [class] TestPythonParser (relevance: 0.40, depth: 1)
  39 | class TestPythonParser:
  40 |     def test_parse_functions(self, sample_python_source: str):
  41 |         result = parse_python_file("sample.py", sample_python_source)
  42 |         assert result.language == "python"
  43 |         assert len(result.errors) == 0
  44 | 
  45 |         # Check functions are found
  46 |         func_names = [
  47 |             s.name for s in result.symbols if s.kind == SymbolKind.FUNCTION
  48 |         ]
  49 |         assert "create_processor" in func_names
  50 |         assert "run_pipeline" in func_names
  51 | 
  52 |     def test_parse_classes(self, sample_python_source: str):
  53 |         result = parse_python_file("sample.py", sample_python_source)
  54 | 
  55 |         class_names = [
  56 |             s.name for s in result.symbols if s.kind == SymbolKind.CLASS
  57 |         ]
  58 |         assert "BaseProcessor" in class_names
  59 |         assert "AdvancedProcessor" in class_names
  60 | 
  61 |     def test_parse_methods(self, sample_python_source: str):
  62 |         result = parse_python_file("sample.py", sample_python_source)
  63 | 
  64 |         methods = [s for s in result.symbols if s.kind == SymbolKind.METHOD]
  65 |         method_names = [m.name for m in methods]
  66 |         assert "__init__" in method_names
  67 |         assert "process" in method_names
  68 |         assert "_transform" in method_names
  69 |         assert "batch_process" in method_names
  70 | 
  71 |     def test_parse_imports(self, sample_python_source: str):
  72 |         result = parse_python_file("sample.py", sample_python_source)
  73 |         assert "os" in result.imports
  74 |         assert "typing.List" in result.imports
  75 |         assert "pathlib.Path" in result.imports
  76 | 
  77 |     def test_parse_constants(self, sample_python_source: str):
  78 |         result = parse_python_file("sample.py", sample_python_source)
  79 |         constants = [
  80 |             s for s in result.symbols if s.kind == SymbolKind.CONSTANT
  81 |         ]
  82 |         assert any(c.name == "CONSTANT_VALUE" for c in constants)
  83 | 
  84 |     def test_parse_inheritance(self, sample_python_source: str):
  85 |         result = parse_python_file("sample.py", sample_python_source)
  86 |         inherits = [
  87 |             r for r in result.relationships if r.kind == RelKind.INHERITS
  88 |         ]
  89 |         assert any("AdvancedProcessor" in r.source and "BaseProcessor" in r.target for r in inherits)
  90 | 
  91 |     def test_parse_calls(self, sample_python_source: str):
  92 |         result = parse_python_file("sample.py", sample_python_source)
  93 |         calls = [r for r in result.relationships if r.kind == RelKind.CALLS]
  94 |         # run_pipeline calls create_processor
  95 |         assert any(
  96 |             "run_pipeline" in r.source and "create_processor" in r.target
  97 |             for r in calls
  98 |         )
  99 | 
 100 |     def test_parse_docstrings(self, sample_python_source: str):
 101 |         result = parse_python_file("sample.py", sample_python_source)
 102 |         funcs = {s.name: s for s in result.symbols if s.kind in (SymbolKind.FUNCTION, SymbolKind.METHOD)}
 103 |         assert "Factory function" in funcs["create_processor"].docstring
 104 |         assert "Transform a single item" in funcs["_transform"].docstring
 105 | 
 106 |     def test_parse_contains_relationships(self, sample_python_source: str):
 107 |         result = parse_python_file("sample.py", sample_python_source)
 108 |         contains = [r for r in result.relationships if r.kind == RelKind.CONTAINS]
 109 |         # BaseProcessor should contain process, _transform, __init__
 110 |         assert any("BaseProcessor" in r.source and "process" in r.target for r in contains)
 111 | 
 112 |     def test_syntax_error_handling(self):
 113 |         result = parse_python_file("bad.py", "def broken(:\n  pass")
 114 |         assert len(result.errors) > 0
 115 | 
 116 |     def test_empty_file(self):
 117 |         result = parse_python_file("empty.py", "")
 118 |         assert result.language == "python"
 119 |         assert len(result.symbols) == 0

# [method] TestPythonParser.test_parse_functions (relevance: 0.21, depth: 2)
  40 |     def test_parse_functions(self, sample_python_source: str):
  41 |         result = parse_python_file("sample.py", sample_python_source)
  42 |         assert result.language == "python"
  43 |         assert len(result.errors) == 0
  44 | 
  45 |         # Check functions are found
  46 |         func_names = [
  47 |             s.name for s in result.symbols if s.kind == SymbolKind.FUNCTION
  48 |         ]
  49 |         assert "create_processor" in func_names
  50 |         assert "run_pipeline" in func_names

# [method] TestPythonParser.test_parse_classes (relevance: 0.21, depth: 2)
  52 |     def test_parse_classes(self, sample_python_source: str):
  53 |         result = parse_python_file("sample.py", sample_python_source)
  54 | 
  55 |         class_names = [
  56 |             s.name for s in result.symbols if s.kind == SymbolKind.CLASS
  57 |         ]
  58 |         assert "BaseProcessor" in class_names
  59 |         assert "AdvancedProcessor" in class_names

# [method] TestPythonParser.test_parse_methods (relevance: 0.21, depth: 2)
  61 |     def test_parse_methods(self, sample_python_source: str):
  62 |         result = parse_python_file("sample.py", sample_python_source)
  63 | 
  64 |         methods = [s for s in result.symbols if s.kind == SymbolKind.METHOD]
  65 |         method_names = [m.name for m in methods]
  66 |         assert "__init__" in method_names
  67 |         assert "process" in method_names
  68 |         assert "_transform" in method_names
  69 |         assert "batch_process" in method_names

# [method] TestPythonParser.test_parse_imports (relevance: 0.21, depth: 2)
  71 |     def test_parse_imports(self, sample_python_source: str):
  72 |         result = parse_python_file("sample.py", sample_python_source)
  73 |         assert "os" in result.imports
  74 |         assert "typing.List" in result.imports
  75 |         assert "pathlib.Path" in result.imports

# [method] TestPythonParser.test_parse_constants (relevance: 0.21, depth: 2)
  77 |     def test_parse_constants(self, sample_python_source: str):
  78 |         result = parse_python_file("sample.py", sample_python_source)
  79 |         constants = [
  80 |             s for s in result.symbols if s.kind == SymbolKind.CONSTANT
  81 |         ]
  82 |         assert any(c.name == "CONSTANT_VALUE" for c in constants)

# [method] TestPythonParser.test_parse_inheritance (relevance: 0.21, depth: 2)
  84 |     def test_parse_inheritance(self, sample_python_source: str):
  85 |         result = parse_python_file("sample.py", sample_python_source)
  86 |         inherits = [
  87 |             r for r in result.relationships if r.kind == RelKind.INHERITS
  88 |         ]
  89 |         assert any("AdvancedProcessor" in r.source and "BaseProcessor" in r.target for r in inherits)

# [method] TestPythonParser.test_parse_calls (relevance: 0.21, depth: 2)
  91 |     def test_parse_calls(self, sample_python_source: str):
  92 |         result = parse_python_file("sample.py", sample_python_source)
  93 |         calls = [r for r in result.relationships if r.kind == RelKind.CALLS]
  94 |         # run_pipeline calls create_processor
  95 |         assert any(
  96 |             "run_pipeline" in r.source and "create_processor" in r.target
  97 |             for r in calls
  98 |         )

# [method] TestPythonParser.test_parse_docstrings (relevance: 0.39, depth: 0)
 100 |     def test_parse_docstrings(self, sample_python_source: str):
 101 |         result = parse_python_file("sample.py", sample_python_source)
 102 |         funcs = {s.name: s for s in result.symbols if s.kind in (SymbolKind.FUNCTION, SymbolKind.METHOD)}
 103 |         assert "Factory function" in funcs["create_processor"].docstring
 104 |         assert "Transform a single item" in funcs["_transform"].docstring

# [method] TestPythonParser.test_parse_contains_relationships (relevance: 0.21, depth: 2)
 106 |     def test_parse_contains_relationships(self, sample_python_source: str):
 107 |         result = parse_python_file("sample.py", sample_python_source)
 108 |         contains = [r for r in result.relationships if r.kind == RelKind.CONTAINS]
 109 |         # BaseProcessor should contain process, _transform, __init__
 110 |         assert any("BaseProcessor" in r.source and "process" in r.target for r in contains)

# [method] TestPythonParser.test_syntax_error_handling (relevance: 0.21, depth: 2)
 112 |     def test_syntax_error_handling(self):
 113 |         result = parse_python_file("bad.py", "def broken(:\n  pass")
 114 |         assert len(result.errors) > 0

# [method] TestPythonParser.test_empty_file (relevance: 0.21, depth: 2)
 116 |     def test_empty_file(self):
 117 |         result = parse_python_file("empty.py", "")
 118 |         assert result.language == "python"
 119 |         assert len(result.symbols) == 0
