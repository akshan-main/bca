examples/demo.py
  def main():
paper/experiments/ablation.py
  class AblationResult
  def run_ablation( repo_path: Path, task: str, budgets: list[int], ground_truth_symbols: list[str] | None = None, ) -> list[AblationResult]:
  def format_results_table(results: list[AblationResult]) -> str:
  def main():
paper/experiments/baselines.py
  class BaselineResult
  def baseline_grep( repo_path: Path, task: str, budget: int, graph, ) -> BaselineResult:
  def baseline_bm25( repo_path: Path, task: str, budget: int, graph, ) -> BaselineResult:
  def baseline_unweighted_bfs( repo_path: Path, task: str, budget: int, graph, query_engine: GraphQuery, ) -> BaselineResult:
  def baseline_repo_map( repo_path: Path, task: str, budget: int, graph, ) -> BaselineResult:
  def run_bca( repo_path: Path, task: str, budget: int, graph, query_engine: GraphQuery, ) -> BaselineResult:
  def run_comparison( repo_path: Path, task: str, budgets: list[int], ground_truth_symbols: list[str] | None = None, ) -> list[BaselineResult]:
  def format_comparison_table(results: list[BaselineResult]) -> str:
  def main():
paper/experiments/benchmark.py
  class EvalTask
  class EvalResult
  def assemble_bca( repo_path: Path, task: str, budget: int, graph, query: GraphQuery, ) -> tuple[str, int, int, int, float]:
  def assemble_bca_no_closure( repo_path: Path, task: str, budget: int, graph, query: GraphQuery, ) -> tuple[str, int, int, int, float]:
  def assemble_bm25( repo_path: Path, task: str, budget: int, graph, query: GraphQuery, ) -> tuple[str, int, int, int, float]:
  def assemble_grep( repo_path: Path, task: str, budget: int, graph, query: GraphQuery, ) -> tuple[str, int, int, int, float]:
  def assemble_repo_map( repo_path: Path, task: str, budget: int, graph, query: GraphQuery, ) -> tuple[str, int, int, int, float]:
  def assemble_vector( repo_path: Path, task: str, budget: int, graph, query: GraphQuery, ) -> tuple[str, int, int, int, float]:
  def _vector_score_tfidf(query: str, symbols: list[dict]) -> list[float]:
  def _vector_score_dense(query: str, symbols: list[dict]) -> list[float]:
  def assemble_embedding( repo_path: Path, task: str, budget: int, graph, query: GraphQuery, ) -> tuple[str, int, int, int, float]:
  def _embedding_score_openai(query_text: str, symbols: list[dict]) -> list[float]:
  def build_prompt(context: str, task: str) -> str:
  async def call_llm( provider, context: str, task: str, ) -> tuple[str, float, int, int]:
  class SearchReplaceEdit
  def _strip_line_prefixes(text: str) -> str:
  def extract_edits(llm_output: str) -> list[SearchReplaceEdit]:
  def extract_patch(llm_output: str) -> str:
  def apply_and_test( repo_path: Path, llm_output: str, test_cmd: str, timeout: int = 60, ) -> tuple[bool, str]:
  def _apply_mutation(repo_path: Path, mutation: dict) -> str | None:
  def _restore_mutation(repo_path: Path, mutation: dict, original: str) -> None:
  async def run_benchmark( tasks: list[EvalTask], budgets: list[int], methods: list[str], llm_config: LLMConfig, output_dir: Path, ) -> list[EvalResult]:
  def format_results(results: list[EvalResult], budgets: list[int]) -> str:
  def main():
paper/experiments/make_tasks.py
  def verify_mutations(repo_path: Path) -> list[dict]:
  def write_eval_tasks( repo_path: Path, mutations: list[dict], output_file: Path, ) -> None:
  def main():
paper/experiments/run_all.py
  def aggregate_baselines(results: list[BaselineResult]) -> str:
  def aggregate_ablation(results: list[AblationResult]) -> str:
  def generate_latex_baseline_table(results: list[BaselineResult]) -> str:
  def generate_latex_ablation_table(results: list[AblationResult]) -> str:
  def main():
src/cegraph/__init__.py
src/cegraph/__main__.py
src/cegraph/agent/__init__.py
src/cegraph/agent/loop.py
  class AgentStep
  class AgentResult
  class AgentLoop
    def __init__( self, llm: LLMProvider, tools: ToolRegistry, project_name: str = "", max_iterations: int = 15, on_step: Callable[[AgentStep], None] | None = None, on_approval_needed: Callable[[str], bool] | None = None, ) -> None:
    async def run(self, task: str, context: str = "") -> AgentResult:
    async def ask(self, question: str) -> str:
src/cegraph/agent/prompts.py
  def get_system_prompt(project_name: str = "") -> str:
  def get_question_prompt(project_name: str = "") -> str:
src/cegraph/cli.py
  def _get_project_root(path: str | None = None) -> Path:
  def _load_graph(root: Path):
  def main():
  def init(path: str | None, provider: str | None, model: str | None):
  def reindex(path: str | None):
  def _do_index(root: Path, config: ProjectConfig):
  def status(path: str | None):
  def search(query: str, path: str | None, kind: str):
  def who_calls(symbol_name: str, path: str | None, depth: int):
  def impact(symbol_name: str, path: str | None):
  def context( task: str, path: str | None, budget: int, strategy: str, compact: bool, savings: bool, focus: tuple[str, ...] ):
  def serve(path: str | None, transport: str, generate_config: str | None):
  def impact_pr(path: str | None, base: str, output_format: str):
  def code_map(path: str | None):
  def ask(question: str, path: str | None):
  def agent(task: str, path: str | None, auto: bool):
  def _run_agent( root: Path, config: ProjectConfig, graph, store, task: str, agent_mode: bool = True, auto_approve: bool = False, ):
  def benchmark(path: str | None):
  def config_cmd(action: str, key: str | None, value: str | None, path: str | None):
src/cegraph/config.py
  class LLMConfig
    def api_key(self) -> str | None:
  class AgentConfig
  class IndexerConfig
  class ProjectConfig
  def find_project_root(start: Path | None = None) -> Path | None:
  def get_cegraph_dir(root: Path) -> Path:
  def load_config(root: Path) -> ProjectConfig:
  def save_config(root: Path, config: ProjectConfig) -> None:
  def set_config_value(config: ProjectConfig, key: str, value: Any) -> ProjectConfig:
src/cegraph/context/__init__.py
src/cegraph/context/_native.py
  def _find_library() -> str | None:
  def _load_library():
  def _setup_signatures(lib):
  class NativeCAG
    def is_available() -> bool:
    def version() -> str:
    def create_graph(num_nodes: int) -> NativeGraph:
    def estimate_tokens(text: str) -> int:
    def extract_entities(text: str, max_entities: int = 200) -> list[dict]:
  class NativeGraph
    def __init__(self, lib, handle, num_nodes: int):
    def add_edge(self, src: int, dst: int, weight: float) -> None:
    def set_node_weight(self, node: int, weight: float) -> None:
    def set_lines(self, node: int, start: int, end: int) -> None:
    def weighted_bfs( self, seed_nodes: list[int], seed_scores: list[float], max_depth: int = 3, min_score: float = 0.1, backward_decay: float = 0.7, max_results: int = 5000, ) -> list[dict]:
    def topological_sort(self, nodes: list[int]) -> list[int]:
    def destroy(self) -> None:
    def __del__(self):
src/cegraph/context/engine.py
  class AblationConfig
  class ContextAssembler
    def __init__( self, root: Path, graph: nx.DiGraph, query: GraphQuery, ablation: AblationConfig | None = None, ) -> None:
    def _build_native_graph(self) -> None:
    def is_accelerated(self) -> bool:
    def assemble( self, task: str, token_budget: int = 8000, strategy: ContextStrategy = ContextStrategy.SMART, focus_files: list[str] | None = None, ) -> ContextPackage:
    def _extract_entities(self, task: str) -> list[dict]:
    def _find_seeds( self, entities: list[dict], focus_files: list[str] | None = None ) -> list[dict]:
    def _expand_context_native( self, seeds: list[dict], config: dict ) -> list[dict]:
    def _expand_context( self, seeds: list[dict], config: dict ) -> list[dict]:
    def _expand_context_pagerank( self, seeds: list[dict], config: dict ) -> list[dict]:
    def _score_candidates( self, candidates: list[dict], entities: list[dict], seeds: list[dict], ) -> list[dict]:
    def _compute_closures(self, candidates: list[dict]) -> dict[str, set[str]]:
    def _closure_of(self, symbol_id: str, candidate_ids: set[str]) -> set[str]:
    def _budget_select( self, candidates: list[dict], closures: dict[str, set[str]], token_budget: int, ) -> list[dict]:
    def _token_cost(self, symbol_id: str, cand: dict | None = None) -> int:
    def _marginal_utility( self, symbol_id: str, covered_edges: set[tuple[str, str]] ) -> float:
    def _update_coverage( self, symbol_id: str, covered_edges: set[tuple[str, str]] ) -> None:
    def _load_source(self, candidates: list[dict]) -> list[ContextItem]:
    def _dependency_order(self, items: list[ContextItem]) -> list[ContextItem]:
    def _scc_topo_sort( self, dep_graph: nx.DiGraph, items: list[ContextItem] ) -> list[str]:
    def estimate_savings(self, task: str, token_budget: int = 8000) -> dict:
src/cegraph/context/learned_weights.py
  def learn_edge_weights( root: Path, graph: nx.DiGraph, max_commits: int = 500, min_samples: int = 5, ) -> dict[str, float]:
  def _get_commit_file_changes( root: Path, max_commits: int ) -> list[set[str]]:
src/cegraph/context/models.py
  class ContextStrategy
  class ContextItem
  class ContextPackage
    def render(self, include_line_numbers: bool = True, include_metadata: bool = True) -> str:
    def render_compact(self) -> str:
    def summary(self) -> str:
  class TokenEstimator
    def estimate(cls, text: str) -> int:
    def estimate_lines(cls, line_count: int, avg_line_length: int = 40) -> int:
src/cegraph/exceptions.py
  class CeGraphError
  class ConfigError
  class ParserError
  class GraphError
  class LLMError
  class ToolError
  class IndexError
  class ProviderNotAvailable
    def __init__(self, provider: str, package: str):
src/cegraph/github/diff_parser.py
  class DiffHunk
  class FileDiff
    def changed_line_ranges(self) -> list[tuple[int, int]]:
  class ChangedSymbol
  def parse_diff(diff_text: str) -> list[FileDiff]:
  def get_changed_symbols( root: Path, graph, file_diffs: list[FileDiff] ) -> list[ChangedSymbol]:
  def get_git_diff(root: Path, base: str = "main") -> str:
  def get_pr_diff(root: Path) -> str:
src/cegraph/github/impact_bot.py
  def run_impact_analysis( root: Path, base: str = "main", is_pr: bool = False, ) -> dict:
  def post_github_comment(comment: str) -> bool:
src/cegraph/github/renderer.py
  def render_impact_comment( changed_symbols: list[ChangedSymbol], impact_results: list[dict], pr_title: str = "", stats: dict | None = None, ) -> str:
  def _risk_badge(risk: float) -> tuple[str, str, str]:
  def _render_file_tree(files: list[str]) -> list[str]:
  def _render_tree_recursive( node: dict, prefix: str, lines: list[str], is_last: bool = True, is_root: bool = False ) -> None:
  def _footer() -> str:
src/cegraph/graph/__init__.py
src/cegraph/graph/builder.py
  class GraphBuilder
    def __init__(self) -> None:
    def build_from_directory( self, root: str | Path, config: ProjectConfig | None = None, progress_callback: callable | None = None, ) -> nx.DiGraph:
    def _add_file(self, fs: FileSymbols, root: Path) -> None:
    def _try_resolve(self, rel: Relationship) -> bool:
    def _resolve_references(self) -> None:
    def get_stats(self) -> dict:
src/cegraph/graph/query.py
  class SymbolInfo
  class GraphQuery
    def __init__(self, graph: nx.DiGraph, store: GraphStore | None = None) -> None:
    def _build_index(self) -> None:
    def find_symbol(self, name: str) -> list[str]:
    def get_symbol_info(self, symbol_id: str) -> SymbolInfo | None:
    def who_calls(self, name: str, max_depth: int = 1) -> list[dict]:
    def what_calls(self, name: str) -> list[dict]:
    def impact_of(self, name: str, max_depth: int = 3) -> dict:
    def get_file_symbols(self, file_path: str) -> list[dict]:
    def get_structure(self, path_prefix: str = "") -> dict:
    def find_related(self, name: str, max_hops: int = 2) -> list[dict]:
src/cegraph/graph/store.py
  class GraphStore
    def __init__(self, db_path: str | Path) -> None:
    def _get_conn(self) -> sqlite3.Connection:
    def _create_tables(self) -> None:
    def _make_text_id(node_type: str, path: str, qualified_name: str = "") -> str:
    def _resolve_text_id(self, conn: sqlite3.Connection, text_id: str) -> int | None:
    def save(self, graph: nx.DiGraph, metadata: dict | None = None) -> None:
    def load(self) -> nx.DiGraph | None:
    def _load_legacy(self) -> nx.DiGraph | None:
    def _load_v1_normalized(self) -> nx.DiGraph | None:
    def _load_text_tables(self) -> nx.DiGraph | None:
    def search_symbols( self, query: str = "", kind: str = "", file_path: str = "", limit: int = 50, ) -> list[dict]:
    def get_callers(self, symbol_id: str) -> list[dict]:
    def get_callees(self, symbol_id: str) -> list[dict]:
    def get_metadata(self, key: str) -> str | None:
    def close(self) -> None:
src/cegraph/llm/__init__.py
src/cegraph/llm/anthropic_provider.py
  class AnthropicProvider
    def __init__( self, model: str = "claude-sonnet-4-5-20250929", api_key: str | None = None, base_url: str | None = None, ) -> None:
    def _get_client(self):
    def _format_messages(self, messages: list[Message]) -> tuple[str, list[dict]]:
    def _format_tools(self, tools: list[ToolDefinition]) -> list[dict]:
    async def complete( self, messages: list[Message], tools: list[ToolDefinition] | None = None, temperature: float = 0.0, max_tokens: int = 4096, ) -> LLMResponse:
    async def stream( self, messages: list[Message], tools: list[ToolDefinition] | None = None, temperature: float = 0.0, max_tokens: int = 4096, ) -> AsyncIterator[str]:
src/cegraph/llm/base.py
  class Message
  class ToolCall
  class ToolResult
  class ToolDefinition
  class LLMResponse
    def has_tool_calls(self) -> bool:
  class LLMProvider
    def __init__(self, model: str, api_key: str | None = None, base_url: str | None = None) -> None:
    async def complete( self, messages: list[Message], tools: list[ToolDefinition] | None = None, temperature: float = 0.0, max_tokens: int = 4096, ) -> LLMResponse:
    async def stream( self, messages: list[Message], tools: list[ToolDefinition] | None = None, temperature: float = 0.0, max_tokens: int = 4096, ) -> AsyncIterator[str]:
src/cegraph/llm/factory.py
  def create_provider(config: LLMConfig) -> LLMProvider:
src/cegraph/llm/openai_provider.py
  class OpenAIProvider
    def __init__( self, model: str = "gpt-4o", api_key: str | None = None, base_url: str | None = None ) -> None:
    def _get_client(self):
    def _format_messages(self, messages: list[Message]) -> list[dict]:
    def _format_tools(self, tools: list[ToolDefinition]) -> list[dict]:
    async def complete( self, messages: list[Message], tools: list[ToolDefinition] | None = None, temperature: float = 0.0, max_tokens: int = 4096, ) -> LLMResponse:
    async def stream( self, messages: list[Message], tools: list[ToolDefinition] | None = None, temperature: float = 0.0, max_tokens: int = 4096, ) -> AsyncIterator[str]:
src/cegraph/map/app.py
  def check_textual():
  def launch_map(root: Path, graph, query) -> None:
src/cegraph/mcp/__init__.py
src/cegraph/mcp/server.py
  class MCPServer
    def __init__(self, root: Path | None = None) -> None:
    def _ensure_graph(self):
    def _ensure_cag(self):
    def _define_tools(self) -> list[dict]:
    def _handle_tool_call(self, name: str, arguments: dict) -> Any:
    def _tool_cag_assemble(self, args: dict) -> str:
    def _tool_search_code(self, args: dict) -> str:
    def _tool_who_calls(self, args: dict) -> str:
    def _tool_impact_of(self, args: dict) -> str:
    def _tool_get_structure(self, _args: dict) -> str:
    def _render_structure(self, node: dict, lines: list[str], indent: int) -> None:
    def _tool_find_related(self, args: dict) -> str:
    async def run_stdio(self) -> None:
    async def _read_message(self, reader: asyncio.StreamReader) -> dict | None:
    async def _write_message(self, writer: asyncio.StreamWriter, message: dict) -> None:
    def _handle_message(self, message: dict) -> dict | None:
    def _handle_notification(self, method: str, params: dict) -> None:
    def _dispatch(