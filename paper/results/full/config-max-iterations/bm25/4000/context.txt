# src/cegraph/agent/__init__.py:3-3
from cegraph.agent.loop import AgentLoop

# src/cegraph/agent/loop.py:22-30
class AgentStep:
    """A single step in the agent loop."""

    iteration: int
    thought: str = ""
    tool_calls: list[ToolCall] = field(default_factory=list)
    tool_results: list[ToolResult] = field(default_factory=list)
    response: str = ""
    usage: dict[str, int] = field(default_factory=dict)

# src/cegraph/cli.py:526-594
def _run_agent(
    root: Path,
    config: ProjectConfig,
    graph,
    store,
    task: str,
    agent_mode: bool = True,
    auto_approve: bool = False,
):
    """Run the agent loop."""
    from cegraph.agent.loop import AgentLoop, AgentStep
    from cegraph.graph.query import GraphQuery
    from cegraph.llm.factory import create_provider
    from cegraph.search.hybrid import HybridSearch
    from cegraph.tools.definitions import get_all_tools

    # Check for API key (skip for local providers that don't need one)
    llm_config = config.llm
    if not llm_config.api_key and llm_config.provider not in ("local",):
        provider = llm_config.provider
        env_var = {"openai": "OPENAI_API_KEY", "anthropic": "ANTHROPIC_API_KEY"}.get(
            provider, f"{provider.upper()}_API_KEY"
        )
        console.error(
            f"No API key found for {provider}. "
            f"Set the {env_var} environment variable or configure it with:\n"
            f"  cegraph config set llm.api_key_env {env_var}"
        )
        store.close()
        sys.exit(1)

    try:
        llm = create_provider(llm_config)
    except Exception as e:
        console.error(str(e))
        store.close()
        sys.exit(1)

    query = GraphQuery(graph, store)
    search_engine = HybridSearch(root, graph)
    tools = get_all_tools(root, graph, query, search_engine)

    def on_step(step: AgentStep):
        console.show_agent_step(step)

    agent_loop = AgentLoop(
        llm=llm,
        tools=tools,
        project_name=config.name,
        max_iterations=config.agent.max_iterations,
        on_step=on_step,
    )

    console.info(f"Running {'agent' if agent_mode else 'Q&A'} for: {task}")
    console.console.print()

    result = asyncio.run(agent_loop.run(task))

    if not result.success:
        if result.error:
            console.error(result.error)

    console.console.print()
    console.info(
        f"Completed in {result.total_iterations} step(s), "
        f"~{result.total_tokens:,} tokens used"
    )

    store.close()

# src/cegraph/agent/loop.py:22-30
class AgentStep:
    """A single step in the agent loop."""

    iteration: int
    thought: str = ""
    tool_calls: list[ToolCall] = field(default_factory=list)
    tool_results: list[ToolResult] = field(default_factory=list)
    response: str = ""
    usage: dict[str, int] = field(default_factory=dict)

# src/cegraph/config.py:41-46
class AgentConfig(BaseModel):
    """Agent behavior configuration."""

    max_iterations: int = 150
    auto_verify: bool = True
    require_approval: bool = True

# src/cegraph/agent/loop.py:34-42
class AgentResult:
    """Final result from the agent loop."""

    answer: str
    steps: list[AgentStep]
    total_iterations: int
    total_tokens: int
    success: bool = True
    error: str = ""

# src/cegraph/cli.py:517-523
def agent(task: str, path: str | None, auto: bool):
    """Run an agentic task (coding, debugging, refactoring)."""
    root = _get_project_root(path)
    config = load_config(root)
    graph, store = _load_graph(root)

    _run_agent(root, config, graph, store, task, agent_mode=True, auto_approve=auto)

# src/cegraph/ui/console.py:86-118
    def show_agent_step(self, step: AgentStep) -> None:
        """Display an agent step with tool calls and results."""
        if step.thought:
            self.console.print(
                Panel(
                    Markdown(step.thought),
                    title=f"[bold]Step {step.iteration}[/bold] - Thinking",
                    border_style="blue",
                )
            )

        for tc in step.tool_calls:
            args_str = ", ".join(f"{k}={repr(v)}" for k, v in tc.arguments.items())
            self.console.print(
                f"  [yellow]â†’[/yellow] [bold]{tc.name}[/bold]({args_str})"
            )

        for tr in step.tool_results:
            # Truncate long results
            content = tr.content
            if len(content) > 500:
                content = content[:500] + "\n... (truncated)"
            style = "red" if tr.is_error else "dim"
            self.console.print(f"  [{style}]{content}[/{style}]")

        if step.response:
            self.console.print(
                Panel(
                    Markdown(step.response),
                    title="[bold green]Answer[/bold green]",
                    border_style="green",
                )
            )

# src/cegraph/agent/loop.py:18-18
from cegraph.tools.registry import ToolRegistry

# src/cegraph/agent/loop.py:57-71
    def __init__(
        self,
        llm: LLMProvider,
        tools: ToolRegistry,
        project_name: str = "",
        max_iterations: int = 15,
        on_step: Callable[[AgentStep], None] | None = None,
        on_approval_needed: Callable[[str], bool] | None = None,
    ) -> None:
        self.llm = llm
        self.tools = tools
        self.project_name = project_name
        self.max_iterations = max_iterations
        self.on_step = on_step
        self.on_approval_needed = on_approval_needed

# paper/experiments/run_all.py:12-12
from collections import defaultdict

# paper/experiments/run_all.py:12-12
from collections import defaultdict

# src/cegraph/config.py:29-38
    def api_key(self) -> str | None:
        if self.api_key_env:
            return os.environ.get(self.api_key_env)
        # Try common env vars
        env_map = {
            "openai": "OPENAI_API_KEY",
            "anthropic": "ANTHROPIC_API_KEY",
        }
        env_var = env_map.get(self.provider, "")
        return os.environ.get(env_var)

# src/cegraph/exceptions.py:24-25
class ToolError(CeGraphError):
    """Agent tool execution errors."""

# tests/test_config.py:19-23
    def test_default_config(self):
        config = ProjectConfig()
        assert config.llm.provider == "anthropic"
        assert config.agent.max_iterations == 15
        assert len(config.indexer.exclude_patterns) > 0

# src/cegraph/context/_native.py:235-236
    def set_lines(self, node: int, start: int, end: int) -> None:
        self._lib.cag_graph_set_lines(self._handle, node, start, end)

# src/cegraph/cli.py:14-22
from cegraph.config import (
    GRAPH_DB_FILE,
    ProjectConfig,
    find_project_root,
    get_cegraph_dir,
    load_config,
    save_config,
    set_config_value,
)

# src/cegraph/cli.py:14-22
from cegraph.config import (
    GRAPH_DB_FILE,
    ProjectConfig,
    find_project_root,
    get_cegraph_dir,
    load_config,
    save_config,
    set_config_value,
)

# src/cegraph/agent/__init__.py:3-3
from cegraph.agent.loop import AgentLoop

# src/cegraph/context/_native.py:232-233
    def set_node_weight(self, node: int, weight: float) -> None:
        self._lib.cag_graph_set_node_weight(self._handle, node, weight)

# tests/test_cli.py:107-113
    def test_config_set(self, runner: CliRunner, indexed_project: Path):
        result = runner.invoke(
            main,
            ["config", "set", "llm.provider", "openai", "--path", str(indexed_project)],
        )
        assert result.exit_code == 0
        assert "Set" in result.output

# tests/test_config.py:50-53
    def test_set_config_value(self):
        config = ProjectConfig()
        updated = set_config_value(config, "llm.provider", "openai")
        assert updated.llm.provider == "openai"

# tests/test_config.py:55-58
    def test_set_config_nested(self):
        config = ProjectConfig()
        updated = set_config_value(config, "agent.max_iterations", 20)
        assert updated.agent.max_iterations == 20