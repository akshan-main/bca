# Codebase Context for: detect_language returns "python3" instead of "python" for .py files, causing the parser to fail to select the correct Python parser.
# 100 symbols from 21 files (~8,438 tokens, 106% of budget)

## src/cegraph/cli.py
# Included because: graph expansion (depth 3)

# [function] _get_project_root (relevance: 0.61, depth: 3)
  28 | def _get_project_root(path: str | None = None) -> Path:
  29 |     """Find the project root or error."""
  30 |     if path:
  31 |         root = Path(path).resolve()
  32 |         if not root.exists():
  33 |             console.error(f"Path does not exist: {path}")
  34 |             sys.exit(1)
  35 |         return root
  36 | 
  37 |     root = find_project_root()
  38 |     if root is None:
  39 |         console.error(
  40 |             "No CeGraph project found. Run 'cegraph init' first, "
  41 |             "or specify a path with --path."
  42 |         )
  43 |         sys.exit(1)
  44 |     return root

# [function] _load_graph (relevance: 0.59, depth: 3)
  47 | def _load_graph(root: Path):
  48 |     """Load the knowledge graph and related objects."""
  49 |     from cegraph.graph.store import GraphStore
  50 | 
  51 |     db_path = get_cegraph_dir(root) / GRAPH_DB_FILE
  52 |     store = GraphStore(db_path)
  53 |     graph = store.load()
  54 |     if graph is None:
  55 |         console.error("No index found. Run 'cegraph init' or 'cegraph reindex' first.")
  56 |         sys.exit(1)
  57 |     return graph, store

# [function] reindex (relevance: 0.30, depth: 3)
 100 | def reindex(path: str | None):
 101 |     """Rebuild the knowledge graph from scratch."""
 102 |     root = _get_project_root(path)
 103 |     config = load_config(root)
 104 |     _do_index(root, config)

# [function] ask (relevance: 0.32, depth: 3)
 504 | def ask(question: str, path: str | None):
 505 |     """Ask a question about the codebase (uses LLM + knowledge graph)."""
 506 |     root = _get_project_root(path)
 507 |     config = load_config(root)
 508 |     graph, store = _load_graph(root)
 509 | 
 510 |     _run_agent(root, config, graph, store, question, agent_mode=False)

# [function] agent (relevance: 0.32, depth: 3)
 517 | def agent(task: str, path: str | None, auto: bool):
 518 |     """Run an agentic task (coding, debugging, refactoring)."""
 519 |     root = _get_project_root(path)
 520 |     config = load_config(root)
 521 |     graph, store = _load_graph(root)
 522 | 
 523 |     _run_agent(root, config, graph, store, task, agent_mode=True, auto_approve=auto)

## src/cegraph/config.py
# Included because: graph expansion (depth 2)

# [method] LLMConfig.api_key (relevance: 0.39, depth: 2)
  29 |     def api_key(self) -> str | None:
  30 |         if self.api_key_env:
  31 |             return os.environ.get(self.api_key_env)
  32 |         # Try common env vars
  33 |         env_map = {
  34 |             "openai": "OPENAI_API_KEY",
  35 |             "anthropic": "ANTHROPIC_API_KEY",
  36 |         }
  37 |         env_var = env_map.get(self.provider, "")
  38 |         return os.environ.get(env_var)

## src/cegraph/context/_native.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [method] NativeCAG.is_available (relevance: 0.37, depth: 2)
 160 |     def is_available() -> bool:
 161 |         """Check if the native C++ library is available."""
 162 |         return _load_library() is not None

# [method] NativeCAG.create_graph (relevance: 0.35, depth: 3)
 173 |     def create_graph(num_nodes: int) -> NativeGraph:
 174 |         """Create a new native graph."""
 175 |         lib = _load_library()
 176 |         if lib is None:
 177 |             raise RuntimeError("Native CAG library not available")
 178 |         handle = lib.cag_graph_create(num_nodes)
 179 |         return NativeGraph(lib, handle, num_nodes)

# [method] NativeGraph.add_edge (relevance: 0.45, depth: 3)
 229 |     def add_edge(self, src: int, dst: int, weight: float) -> None:
 230 |         self._lib.cag_graph_add_edge(self._handle, src, dst, weight)

# [method] NativeGraph.set_node_weight (relevance: 0.31, depth: 3)
 232 |     def set_node_weight(self, node: int, weight: float) -> None:
 233 |         self._lib.cag_graph_set_node_weight(self._handle, node, weight)

# [method] NativeGraph.set_lines (relevance: 0.31, depth: 3)
 235 |     def set_lines(self, node: int, start: int, end: int) -> None:
 236 |         self._lib.cag_graph_set_lines(self._handle, node, start, end)

# [method] NativeGraph.topological_sort (relevance: 0.33, depth: 3)
 269 |     def topological_sort(self, nodes: list[int]) -> list[int]:
 270 |         """Topological sort a subset of nodes."""
 271 |         n = len(nodes)
 272 |         c_nodes = (ctypes.c_int32 * n)(*nodes)
 273 |         out_order = (ctypes.c_int32 * n)()
 274 | 
 275 |         count = self._lib.cag_topological_sort(self._handle, c_nodes, n, out_order)
 276 |         return [out_order[i] for i in range(count)]

## src/cegraph/context/engine.py
# Included because: graph expansion (depth 2)

# [method] ContextAssembler._token_cost (relevance: 0.43, depth: 2)
 898 |     def _token_cost(self, symbol_id: str, cand: dict | None = None) -> int:
 899 |         """Compute token cost c(v) for a symbol."""
 900 |         data = self.graph.nodes.get(symbol_id, {})
 901 |         line_start = data.get("line_start", 0)
 902 |         line_end = data.get("line_end", 0)
 903 |         line_count = max(1, line_end - line_start + 1)
 904 |         return TokenEstimator.estimate_lines(line_count)

# [method] ContextAssembler._update_coverage (relevance: 0.41, depth: 2)
 940 |     def _update_coverage(
 941 |         self, symbol_id: str, covered_edges: set[tuple[str, str]]
 942 |     ) -> None:
 943 |         """Mark edges incident to symbol_id as covered."""
 944 |         for succ in self.graph.successors(symbol_id):
 945 |             if self.graph.nodes.get(succ, {}).get("type") == "symbol":
 946 |                 covered_edges.add((symbol_id, succ))
 947 | 
 948 |         for pred in self.graph.predecessors(symbol_id):
 949 |             if self.graph.nodes.get(pred, {}).get("type") == "symbol":
 950 |                 covered_edges.add((pred, symbol_id))

## src/cegraph/context/models.py
# Included because: graph expansion (depth 3)

# [method] TokenEstimator.estimate (relevance: 0.50, depth: 3)
 166 |     def estimate(cls, text: str) -> int:
 167 |         """Estimate token count for a string."""
 168 |         return max(1, int(len(text) / cls.CHARS_PER_TOKEN))

# [method] TokenEstimator.estimate_lines (relevance: 0.42, depth: 3)
 171 |     def estimate_lines(cls, line_count: int, avg_line_length: int = 40) -> int:
 172 |         """Estimate tokens for a given number of lines."""
 173 |         return max(1, int(line_count * avg_line_length / cls.CHARS_PER_TOKEN))

## src/cegraph/github/diff_parser.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [class] ChangedSymbol (relevance: 0.37, depth: 3)
  47 | class ChangedSymbol:
  48 |     """A symbol that was affected by the diff."""
  49 |     name: str
  50 |     qualified_name: str
  51 |     kind: str
  52 |     file_path: str
  53 |     line_start: int
  54 |     line_end: int
  55 |     change_type: str  # 'modified', 'added', 'deleted'
  56 |     lines_changed: int = 0

# [function] get_pr_diff (relevance: 0.44, depth: 2)
 205 | def get_pr_diff(root: Path) -> str:
 206 |     """Get the diff for the current PR (GitHub Actions context)."""
 207 |     import os
 208 |     base_ref = os.environ.get("GITHUB_BASE_REF", "main")
 209 |     return get_git_diff(root, base=f"origin/{base_ref}")

## src/cegraph/github/renderer.py
# Included because: graph expansion (depth 3)

# [function] _footer (relevance: 0.35, depth: 3)
 192 | def _footer() -> str:
 193 |     return (
 194 |         "---\n"
 195 |         "*Powered by [CeGraph](https://github.com/cegraph-ai/cegraph) "
 196 |         "— CAG-driven code intelligence*"
 197 |     )

## src/cegraph/graph/query.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [method] GraphQuery.__init__ (relevance: 0.23, depth: 3)
  38 |     def __init__(self, graph: nx.DiGraph, store: GraphStore | None = None) -> None:
  39 |         self.graph = graph
  40 |         self.store = store
  41 |         self._name_index: dict[str, list[str]] = {}
  42 |         self._build_index()

# [method] GraphQuery._build_index (relevance: 0.41, depth: 2)
  44 |     def _build_index(self) -> None:
  45 |         """Build a name->node_id lookup index."""
  46 |         for node_id, data in self.graph.nodes(data=True):
  47 |             if data.get("type") != "symbol":
  48 |                 continue
  49 |             name = data.get("name", "")
  50 |             qname = data.get("qualified_name", "")
  51 |             if name:
  52 |                 self._name_index.setdefault(name, []).append(node_id)
  53 |             if qname and qname != name:
  54 |                 self._name_index.setdefault(qname, []).append(node_id)

# [method] GraphQuery.find_symbol (relevance: 0.61, depth: 2)
  56 |     def find_symbol(self, name: str) -> list[str]:
  57 |         """Find symbol node IDs matching a name (exact or qualified)."""
  58 |         results = self._name_index.get(name, [])
  59 |         if not results:
  60 |             # Try partial match
  61 |             for key, ids in self._name_index.items():
  62 |                 if name.lower() in key.lower():
  63 |                     results.extend(ids)
  64 |         return list(set(results))

## src/cegraph/graph/store.py
# Included because: graph expansion (depth 3)

# [method] GraphStore._get_conn (relevance: 0.53, depth: 3)
  28 |     def _get_conn(self) -> sqlite3.Connection:
  29 |         if self._conn is None:
  30 |             self.db_path.parent.mkdir(parents=True, exist_ok=True)
  31 |             self._conn = sqlite3.connect(str(self.db_path))
  32 |             self._conn.row_factory = sqlite3.Row
  33 |             self._conn.execute("PRAGMA journal_mode=WAL")
  34 |             self._create_tables()
  35 |         return self._conn

# [method] GraphStore.get_metadata (relevance: 0.44, depth: 3)
 491 |     def get_metadata(self, key: str) -> str | None:
 492 |         """Get a metadata value."""
 493 |         conn = self._get_conn()
 494 |         row = conn.execute("SELECT value FROM metadata WHERE key = ?", (key,)).fetchone()
 495 |         if row:
 496 |             return json.loads(row["value"])
 497 |         return None

# [method] GraphStore.close (relevance: 0.58, depth: 3)
 499 |     def close(self) -> None:
 500 |         """Close the database connection."""
 501 |         if self._conn:
 502 |             self._conn.close()
 503 |             self._conn = None

## src/cegraph/mcp/server.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [method] MCPServer._ensure_cag (relevance: 0.35, depth: 3)
  69 |     def _ensure_cag(self):
  70 |         """Lazy-load the context assembler."""
  71 |         if self._assembler is not None:
  72 |             return
  73 | 
  74 |         self._ensure_graph()
  75 |         from cegraph.context.engine import ContextAssembler
  76 |         self._assembler = ContextAssembler(self.root, self._graph, self._query)

# [method] MCPServer._tool_get_structure (relevance: 0.29, depth: 3)
 308 |     def _tool_get_structure(self, _args: dict) -> str:
 309 |         self._ensure_graph()
 310 |         structure = self._query.get_structure()
 311 | 
 312 |         lines = ["Codebase structure:"]
 313 |         self._render_structure(structure, lines, indent=1)
 314 |         return "\n".join(lines)

# [method] MCPServer._tool_find_related (relevance: 0.45, depth: 2)
 333 |     def _tool_find_related(self, args: dict) -> str:
 334 |         self._ensure_graph()
 335 |         related = self._query.find_related(args["symbol"])
 336 |         if not related:
 337 |             return f"No related symbols found for '{args['symbol']}'"
 338 | 
 339 |         lines = [f"Related to '{args['symbol']}':"]
 340 |         for r in related:
 341 |             lines.append(f"  {r['name']} ({r['kind']}) — {r.get('relation', 'related')}")
 342 |         return "\n".join(lines)

# [method] MCPServer._handle_notification (relevance: 0.43, depth: 2)
 424 |     def _handle_notification(self, method: str, params: dict) -> None:
 425 |         """Handle a notification (no response needed)."""
 426 |         if method == "notifications/initialized":
 427 |             logger.info("Client initialized")
 428 |         elif method == "notifications/cancelled":
 429 |             logger.info(f"Request cancelled: {params.get('requestId')}")

## src/cegraph/parser/models.py
# Included because: matches 'detect_language'; graph expansion (depth 2)

# [method] Symbol.model_post_init (relevance: 0.20, depth: 2)
  56 |     def model_post_init(self, __context: object) -> None:
  57 |         if not self.id:
  58 |             self.id = f"{self.file_path}::{self.qualified_name or self.name}"
  59 |         if not self.qualified_name:
  60 |             self.qualified_name = self.name

# [function] detect_language (relevance: 1.10, depth: 0)
 100 | def detect_language(file_path: str) -> str | None:
 101 |     """Detect programming language from file extension."""
 102 |     from pathlib import Path
 103 | 
 104 |     ext = Path(file_path).suffix.lower()
 105 |     return EXTENSION_LANGUAGE_MAP.get(ext)

## src/cegraph/parser/python_parser.py
# Included because: graph expansion (depth 1); graph expansion (depth 3); matches 'python'

# [function] parse_python_file (relevance: 1.12, depth: 0)
  17 | def parse_python_file(file_path: str, source: str | None = None) -> FileSymbols:
  18 |     """Parse a Python file and extract symbols and relationships."""
  19 |     if source is None:
  20 |         source = Path(file_path).read_text(encoding="utf-8", errors="replace")
  21 | 
  22 |     result = FileSymbols(file_path=file_path, language="python")
  23 | 
  24 |     try:
  25 |         tree = ast.parse(source, filename=file_path)
  26 |     except SyntaxError as e:
  27 |         result.errors.append(f"SyntaxError: {e}")
  28 |         return result
  29 | 
  30 |     lines = source.splitlines()
  31 |     _extract_from_module(tree, file_path, lines, result)
  32 |     return result

# [function] _get_docstring (relevance: 0.56, depth: 3)
  35 | def _get_docstring(node: ast.AST) -> str:
  36 |     """Extract docstring from a node if present."""
  37 |     if (
  38 |         isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef, ast.Module))
  39 |         and node.body
  40 |         and isinstance(node.body[0], ast.Expr)
  41 |         and isinstance(node.body[0].value, (ast.Constant,))
  42 |         and isinstance(node.body[0].value.value, str)
  43 |     ):
  44 |         return node.body[0].value.value.strip()
  45 |     return ""

# [function] _get_decorators (relevance: 0.56, depth: 3)
  48 | def _get_decorators(node: ast.FunctionDef | ast.AsyncFunctionDef | ast.ClassDef) -> list[str]:
  49 |     """Extract decorator names."""
  50 |     decorators = []
  51 |     for dec in node.decorator_list:
  52 |         if isinstance(dec, ast.Name):
  53 |             decorators.append(dec.id)
  54 |         elif isinstance(dec, ast.Attribute):
  55 |             decorators.append(ast.dump(dec))
  56 |         elif isinstance(dec, ast.Call):
  57 |             if isinstance(dec.func, ast.Name):
  58 |                 decorators.append(dec.func.id)
  59 |             elif isinstance(dec.func, ast.Attribute):
  60 |                 decorators.append(ast.dump(dec.func))
  61 |     return decorators

# [function] _extract_from_module (relevance: 0.84, depth: 1)
  85 | def _extract_from_module(
  86 |     tree: ast.Module,
  87 |     file_path: str,
  88 |     lines: list[str],
  89 |     result: FileSymbols,
  90 |     parent_name: str = "",
  91 |     parent_id: str = "",
  92 | ) -> None:
  93 |     """Recursively extract symbols from an AST module/class body."""
  94 | 
  95 |     for node in ast.iter_child_nodes(tree):
  96 |         if isinstance(node, (ast.Import, ast.ImportFrom)):
  97 |             _extract_import(node, file_path, result)
  98 | 
  99 |         elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
 100 |             _extract_function(node, file_path, lines, result, parent_name, parent_id)
 101 | 
 102 |         elif isinstance(node, ast.ClassDef):
 103 |             _extract_class(node, file_path, lines, result, parent_name, parent_id)
 104 | 
 105 |         elif isinstance(node, ast.Assign):
 106 |             _extract_assignment(node, file_path, result, parent_name, parent_id)

# [function] _node_to_name (relevance: 0.62, depth: 3)
 305 | def _node_to_name(node: ast.AST) -> str:
 306 |     """Convert an AST node to a dotted name string."""
 307 |     if isinstance(node, ast.Name):
 308 |         return node.id
 309 |     elif isinstance(node, ast.Attribute):
 310 |         parent = _node_to_name(node.value)
 311 |         if parent:
 312 |             return f"{parent}.{node.attr}"
 313 |         return node.attr
 314 |     elif isinstance(node, ast.Subscript):
 315 |         return _node_to_name(node.value)
 316 |     return ""

## src/cegraph/parser/tree_sitter_parser.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [function] _get_language (relevance: 0.42, depth: 2)
  94 | def _get_language(lang: str):
  95 |     """Get a tree-sitter Language object for the given language."""
  96 |     from tree_sitter import Language
  97 | 
  98 |     module_name = _TS_LANGUAGE_MODULES.get(lang)
  99 |     if not module_name:
 100 |         raise ValueError(f"No tree-sitter grammar for language: {lang}")
 101 | 
 102 |     module = __import__(module_name)
 103 |     return Language(module.language())

# [function] _extract_ts_import (relevance: 0.35, depth: 3)
 250 | def _extract_ts_import(node, file_path: str, source: bytes, result: FileSymbols) -> None:
 251 |     """Extract import information from a tree-sitter node."""
 252 |     text = node.text.decode("utf-8")
 253 |     result.imports.append(text)

## src/cegraph/search/hybrid.py
# Included because: graph expansion (depth 3)

# [function] _tokenize (relevance: 0.34, depth: 3)
 170 | def _tokenize(text: str) -> list[str]:
 171 |     """Simple tokenizer that splits on non-alphanumeric and camelCase."""
 172 |     import re
 173 | 
 174 |     # Split camelCase and snake_case
 175 |     text = re.sub(r"([a-z])([A-Z])", r"\1 \2", text)
 176 |     text = text.replace("_", " ").replace(".", " ")
 177 |     tokens = re.findall(r"[a-zA-Z]{2,}", text.lower())
 178 |     return tokens

## src/cegraph/tools/registry.py
# Included because: graph expansion (depth 2); graph expansion (depth 1); graph expansion (depth 3)

# [method] ToolRegistry.__init__ (relevance: 0.23, depth: 3)
  17 |     def __init__(self) -> None:
  18 |         self._tools: dict[str, Callable] = {}
  19 |         self._definitions: dict[str, ToolDefinition] = {}

# [method] ToolRegistry.register (relevance: 0.34, depth: 3)
  21 |     def register(self, func: Callable, definition: ToolDefinition) -> None:
  22 |         """Register a tool function with its definition."""
  23 |         self._tools[definition.name] = func
  24 |         self._definitions[definition.name] = definition

# [method] ToolRegistry.get (relevance: 0.91, depth: 1)
  26 |     def get(self, name: str) -> Callable | None:
  27 |         """Get a tool function by name."""
  28 |         return self._tools.get(name)

# [method] ToolRegistry.get_definition (relevance: 0.39, depth: 2)
  30 |     def get_definition(self, name: str) -> ToolDefinition | None:
  31 |         """Get a tool definition by name."""
  32 |         return self._definitions.get(name)

# [method] ToolRegistry.list_tools (relevance: 0.31, depth: 3)
  34 |     def list_tools(self) -> list[str]:
  35 |         """List all registered tool names."""
  36 |         return list(self._tools.keys())

# [method] ToolRegistry.get_definitions (relevance: 0.25, depth: 3)
  38 |     def get_definitions(self) -> list[ToolDefinition]:
  39 |         """Get all tool definitions (for passing to LLM)."""
  40 |         return list(self._definitions.values())

# [method] ToolRegistry.execute (relevance: 0.63, depth: 2)
  42 |     async def execute(self, name: str, arguments: dict[str, Any]) -> str:
  43 |         """Execute a tool by name with the given arguments.
  44 | 
  45 |         Returns the result as a string.
  46 |         """
  47 |         func = self._tools.get(name)
  48 |         if func is None:
  49 |             return f"Error: Unknown tool '{name}'"
  50 | 
  51 |         try:
  52 |             if inspect.iscoroutinefunction(func):
  53 |                 result = await func(**arguments)
  54 |             else:
  55 |                 result = func(**arguments)
  56 |             return str(result) if result is not None else "Done."
  57 |         except Exception as e:
  58 |             return f"Error executing tool '{name}': {e}"

## src/cegraph/ui/console.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [method] Console.success (relevance: 0.40, depth: 3)
  33 |     def success(self, message: str) -> None:
  34 |         self.console.print(f"[green]✓[/green] {message}")

# [method] Console.error (relevance: 0.54, depth: 3)
  36 |     def error(self, message: str) -> None:
  37 |         self.console.print(f"[red]✗[/red] {message}")

# [method] Console.warning (relevance: 0.42, depth: 3)
  39 |     def warning(self, message: str) -> None:
  40 |         self.console.print(f"[yellow]![/yellow] {message}")

# [method] Console.info (relevance: 0.50, depth: 3)
  42 |     def info(self, message: str) -> None:
  43 |         self.console.print(f"[blue]i[/blue] {message}")

# [method] Console.indexing_progress (relevance: 0.44, depth: 3)
  53 |     def indexing_progress(self) -> Progress:
  54 |         """Create a progress bar for indexing."""
  55 |         return Progress(
  56 |             SpinnerColumn(),
  57 |             TextColumn("[progress.description]{task.description}"),
  58 |             BarColumn(),
  59 |             TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
  60 |             TimeElapsedColumn(),
  61 |             console=self.console,
  62 |         )

# [method] Console.show_search_results (relevance: 0.41, depth: 2)
 120 |     def show_search_results(self, results: list[dict]) -> None:
 121 |         """Display search results."""
 122 |         for r in results:
 123 |             self.console.print(
 124 |                 f"  [bold]{r.get('qualified_name', r.get('name', 'unknown'))}[/bold] "
 125 |                 f"[dim]({r.get('kind', '')})[/dim] "
 126 |                 f"at [cyan]{r.get('file_path', '')}:{r.get('line', '')}[/cyan]"
 127 |             )
 128 |             if r.get("signature"):
 129 |                 self.console.print(f"    [dim]{r['signature']}[/dim]")

## tests/conftest.py
# Included because: matches 'python'

# [function] sample_python_source (relevance: 0.84, depth: 0)
 143 | def sample_python_source() -> str:
 144 |     """Sample Python source code for parser testing."""
 145 |     return '''"""Sample module."""
 146 | 
 147 | import os
 148 | from typing import List, Optional
 149 | from pathlib import Path
 150 | 
 151 | 
 152 | CONSTANT_VALUE = 42
 153 | 
 154 | 
 155 | class BaseProcessor:
 156 |     """Base class for processors."""
 157 | 
 158 |     def __init__(self, name: str):
 159 |         self.name = name
 160 | 
 161 |     def process(self, data: List[str]) -> List[str]:
 162 |         """Process the data."""
 163 |         return [self._transform(item) for item in data]
 164 | 
 165 |     def _transform(self, item: str) -> str:
 166 |         """Transform a single item."""
 167 |         return item.strip()
 168 | 
 169 | 
 170 | class AdvancedProcessor(BaseProcessor):
 171 |     """Advanced processor with extra features."""
 172 | 
 173 |     def __init__(self, name: str, verbose: bool = False):
 174 |         super().__init__(name)
 175 |         self.verbose = verbose
 176 | 
 177 |     def process(self, data: List[str]) -> List[str]:
 178 |         """Process with logging."""
 179 |         if self.verbose:
 180 |             print(f"Processing {len(data)} items")
 181 |         return super().process(data)
 182 | 
 183 |     def batch_process(self, batches: List[List[str]]) -> List[List[str]]:
 184 |         """Process multiple batches."""
 185 |         return [self.process(batch) for batch in batches]
 186 | 
 187 | 
 188 | def create_processor(name: str, advanced: bool = False) -> BaseProcessor:
 189 |     """Factory function for creating processors."""
 190 |     if advanced:
 191 |         return AdvancedProcessor(name, verbose=True)
 192 |     return BaseProcessor(name)
 193 | 
 194 | 
 195 | def run_pipeline(items: List[str], processor_name: str = "default") -> List[str]:
 196 |     """Run the processing pipeline."""
 197 |     processor = create_processor(processor_name)
 198 |     result = processor.process(items)
 199 |     return result
 200 | '''

## tests/test_graph.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [method] TestGraphBuilder.test_file_nodes_present (relevance: 0.43, depth: 2)
  34 |     def test_file_nodes_present(self, tmp_project: Path):
  35 |         builder = GraphBuilder()
  36 |         graph = builder.build_from_directory(tmp_project)
  37 | 
  38 |         file_nodes = [
  39 |             n for n, d in graph.nodes(data=True) if d.get("type") == "file"
  40 |         ]
  41 |         file_paths = [graph.nodes[n].get("path") for n in file_nodes]
  42 |         assert "main.py" in file_paths
  43 |         assert "utils.py" in file_paths
  44 |         assert "models.py" in file_paths

# [method] TestGraphBuilder.test_symbol_nodes_have_attributes (relevance: 0.43, depth: 2)
  46 |     def test_symbol_nodes_have_attributes(self, tmp_project: Path):
  47 |         builder = GraphBuilder()
  48 |         graph = builder.build_from_directory(tmp_project)
  49 | 
  50 |         for node_id, data in graph.nodes(data=True):
  51 |             if data.get("type") == "symbol":
  52 |                 assert "name" in data
  53 |                 assert "kind" in data
  54 |                 assert "file_path" in data
  55 |                 assert "line_start" in data

# [method] TestGraphBuilder.test_call_edges_exist (relevance: 0.43, depth: 2)
  57 |     def test_call_edges_exist(self, tmp_project: Path):
  58 |         builder = GraphBuilder()
  59 |         graph = builder.build_from_directory(tmp_project)
  60 | 
  61 |         call_edges = [
  62 |             (u, v) for u, v, d in graph.edges(data=True) if d.get("kind") == "calls"
  63 |         ]
  64 |         assert len(call_edges) > 0

# [method] TestGraphBuilder.test_contains_edges_exist (relevance: 0.43, depth: 2)
  66 |     def test_contains_edges_exist(self, tmp_project: Path):
  67 |         builder = GraphBuilder()
  68 |         graph = builder.build_from_directory(tmp_project)
  69 | 
  70 |         contains_edges = [
  71 |             (u, v) for u, v, d in graph.edges(data=True) if d.get("kind") == "contains"
  72 |         ]
  73 |         assert len(contains_edges) > 0

# [method] TestGraphQuery.test_find_symbol (relevance: 0.26, depth: 3)
 160 |     def test_find_symbol(self, tmp_project: Path):
 161 |         query = self._build_query(tmp_project)
 162 |         results = query.find_symbol("main")
 163 |         assert len(results) > 0

# [method] TestGraphQuery.test_find_symbol_partial (relevance: 0.26, depth: 3)
 165 |     def test_find_symbol_partial(self, tmp_project: Path):
 166 |         query = self._build_query(tmp_project)
 167 |         results = query.find_symbol("helper")
 168 |         assert len(results) > 0

# [method] TestGraphQuery.test_what_calls (relevance: 0.26, depth: 3)
 177 |     def test_what_calls(self, tmp_project: Path):
 178 |         query = self._build_query(tmp_project)
 179 |         callees = query.what_calls("main")
 180 |         callee_names = [c["name"] for c in callees]
 181 |         # main() should call several functions
 182 |         assert len(callees) > 0

# [method] TestGraphQuery.test_impact_of (relevance: 0.26, depth: 3)
 184 |     def test_impact_of(self, tmp_project: Path):
 185 |         query = self._build_query(tmp_project)
 186 |         impact = query.impact_of("calculate_total")
 187 |         assert impact["found"] is True
 188 |         assert len(impact["affected_files"]) > 0
 189 |         assert impact["risk_score"] >= 0

# [method] TestGraphQuery.test_impact_not_found (relevance: 0.26, depth: 3)
 191 |     def test_impact_not_found(self, tmp_project: Path):
 192 |         query = self._build_query(tmp_project)
 193 |         impact = query.impact_of("nonexistent_function")
 194 |         assert impact["found"] is False

# [method] TestGraphQuery.test_get_file_symbols (relevance: 0.26, depth: 3)
 196 |     def test_get_file_symbols(self, tmp_project: Path):
 197 |         query = self._build_query(tmp_project)
 198 |         symbols = query.get_file_symbols("main.py")
 199 |         assert len(symbols) > 0
 200 |         names = [s["name"] for s in symbols]
 201 |         assert "main" in names

# [method] TestGraphQuery.test_get_structure (relevance: 0.26, depth: 3)
 203 |     def test_get_structure(self, tmp_project: Path):
 204 |         query = self._build_query(tmp_project)
 205 |         structure = query.get_structure()
 206 |         assert "main.py" in structure or len(structure) > 0

# [method] TestGraphQuery.test_find_related (relevance: 0.26, depth: 3)
 208 |     def test_find_related(self, tmp_project: Path):
 209 |         query = self._build_query(tmp_project)
 210 |         related = query.find_related("calculate_total")
 211 |         assert len(related) > 0

## tests/test_mcp.py
# Included because: graph expansion (depth 2)

# [method] TestMCPTools.test_search_code (relevance: 0.41, depth: 2)
  93 |     def test_search_code(self, mcp_server: MCPServer):
  94 |         """Test the search_code tool."""
  95 |         result = mcp_server._dispatch("tools/call", {
  96 |             "name": "search_code",
  97 |             "arguments": {"query": "main"},
  98 |         })
  99 |         assert not result.get("isError")
 100 |         content = result["content"][0]["text"]
 101 |         assert "main" in content

# [method] TestMCPTools.test_who_calls (relevance: 0.41, depth: 2)
 103 |     def test_who_calls(self, mcp_server: MCPServer):
 104 |         """Test the who_calls tool."""
 105 |         result = mcp_server._dispatch("tools/call", {
 106 |             "name": "who_calls",
 107 |             "arguments": {"symbol": "helper_function"},
 108 |         })
 109 |         assert not result.get("isError")

# [method] TestMCPTools.test_impact_of (relevance: 0.41, depth: 2)
 111 |     def test_impact_of(self, mcp_server: MCPServer):
 112 |         """Test the impact_of tool."""
 113 |         result = mcp_server._dispatch("tools/call", {
 114 |             "name": "impact_of",
 115 |             "arguments": {"symbol": "calculate_total"},
 116 |         })
 117 |         assert not result.get("isError")
 118 |         content = result["content"][0]["text"]
 119 |         assert "Impact" in content or "calculate_total" in content

# [method] TestMCPTools.test_get_structure (relevance: 0.41, depth: 2)
 121 |     def test_get_structure(self, mcp_server: MCPServer):
 122 |         """Test the get_structure tool."""
 123 |         result = mcp_server._dispatch("tools/call", {
 124 |             "name": "get_structure",
 125 |             "arguments": {},
 126 |         })
 127 |         assert not result.get("isError")
 128 |         content = result["content"][0]["text"]
 129 |         assert "main.py" in content or "structure" in content.lower()

# [method] TestMCPTools.test_find_related (relevance: 0.41, depth: 2)
 131 |     def test_find_related(self, mcp_server: MCPServer):
 132 |         """Test the find_related tool."""
 133 |         result = mcp_server._dispatch("tools/call", {
 134 |             "name": "find_related",
 135 |             "arguments": {"symbol": "main"},
 136 |         })
 137 |         assert not result.get("isError")

# [method] TestMCPTools.test_unknown_tool (relevance: 0.41, depth: 2)
 139 |     def test_unknown_tool(self, mcp_server: MCPServer):
 140 |         """Test calling an unknown tool."""
 141 |         result = mcp_server._dispatch("tools/call", {
 142 |             "name": "nonexistent_tool",
 143 |             "arguments": {},
 144 |         })
 145 |         assert result.get("isError")

# [method] TestMCPTools.test_search_no_results (relevance: 0.41, depth: 2)
 147 |     def test_search_no_results(self, mcp_server: MCPServer):
 148 |         """Test search with no results."""
 149 |         result = mcp_server._dispatch("tools/call", {
 150 |             "name": "search_code",
 151 |             "arguments": {"query": "zzz_nonexistent_symbol_zzz"},
 152 |         })
 153 |         assert not result.get("isError")
 154 |         content = result["content"][0]["text"]
 155 |         assert "No symbols found" in content

# [method] TestMCPSecurity.test_resources_read_path_traversal (relevance: 0.41, depth: 2)
 171 |     def test_resources_read_path_traversal(self, mcp_server: MCPServer):
 172 |         """Regression: reading files outside the project root must be denied."""
 173 |         result = mcp_server._dispatch("resources/read", {
 174 |             "uri": "file://../../../../etc/hosts",
 175 |         })
 176 |         text = result["contents"][0].get("text", "")
 177 |         assert "Access denied" in text
 178 |         assert "localhost" not in text

# [method] TestMCPSecurity.test_resources_read_valid_file (relevance: 0.41, depth: 2)
 180 |     def test_resources_read_valid_file(self, mcp_server: MCPServer):
 181 |         """Reading a file inside the project root should work."""
 182 |         result = mcp_server._dispatch("resources/read", {
 183 |             "uri": "file://main.py",
 184 |         })
 185 |         text = result["contents"][0].get("text", "")
 186 |         assert "Access denied" not in text

## tests/test_parser.py
# Included because: graph expansion (depth 1); graph expansion (depth 2); matches 'python'

# [method] TestLanguageDetection.test_python (relevance: 0.80, depth: 0)
  13 |     def test_python(self):
  14 |         assert detect_language("main.py") == "python"
  15 |         assert detect_language("types.pyi") == "python"

# [method] TestLanguageDetection.test_javascript (relevance: 0.29, depth: 2)
  17 |     def test_javascript(self):
  18 |         assert detect_language("app.js") == "javascript"
  19 |         assert detect_language("component.jsx") == "javascript"

# [method] TestLanguageDetection.test_typescript (relevance: 0.29, depth: 2)
  21 |     def test_typescript(self):
  22 |         assert detect_language("app.ts") == "typescript"
  23 |         assert detect_language("component.tsx") == "typescript"

# [method] TestLanguageDetection.test_go (relevance: 0.29, depth: 2)
  25 |     def test_go(self):
  26 |         assert detect_language("main.go") == "go"

# [method] TestLanguageDetection.test_rust (relevance: 0.29, depth: 2)
  28 |     def test_rust(self):
  29 |         assert detect_language("main.rs") == "rust"

# [method] TestLanguageDetection.test_unknown (relevance: 0.29, depth: 2)
  31 |     def test_unknown(self):
  32 |         assert detect_language("readme.md") is None
  33 |         assert detect_language("data.json") is None
  34 |         # Languages without tree-sitter grammars are not supported
  35 |         assert detect_language("main.rb") is None
  36 |         assert detect_language("main.php") is None

# [class] TestPythonParser (relevance: 1.06, depth: 0)
  39 | class TestPythonParser:
  40 |     def test_parse_functions(self, sample_python_source: str):
  41 |         result = parse_python_file("sample.py", sample_python_source)
  42 |         assert result.language == "python"
  43 |         assert len(result.errors) == 0
  44 | 
  45 |         # Check functions are found
  46 |         func_names = [
  47 |             s.name for s in result.symbols if s.kind == SymbolKind.FUNCTION
  48 |         ]
  49 |         assert "create_processor" in func_names
  50 |         assert "run_pipeline" in func_names
  51 | 
  52 |     def test_parse_classes(self, sample_python_source: str):
  53 |         result = parse_python_file("sample.py", sample_python_source)
  54 | 
  55 |         class_names = [
  56 |             s.name for s in result.symbols if s.kind == SymbolKind.CLASS
  57 |         ]
  58 |         assert "BaseProcessor" in class_names
  59 |         assert "AdvancedProcessor" in class_names
  60 | 
  61 |     def test_parse_methods(self, sample_python_source: str):
  62 |         result = parse_python_file("sample.py", sample_python_source)
  63 | 
  64 |         methods = [s for s in result.symbols if s.kind == SymbolKind.METHOD]
  65 |         method_names = [m.name for m in methods]
  66 |         assert "__init__" in method_names
  67 |         assert "process" in method_names
  68 |         assert "_transform" in method_names
  69 |         assert "batch_process" in method_names
  70 | 
  71 |     def test_parse_imports(self, sample_python_source: str):
  72 |         result = parse_python_file("sample.py", sample_python_source)
  73 |         assert "os" in result.imports
  74 |         assert "typing.List" in result.imports
  75 |         assert "pathlib.Path" in result.imports
  76 | 
  77 |     def test_parse_constants(self, sample_python_source: str):
  78 |         result = parse_python_file("sample.py", sample_python_source)
  79 |         constants = [
  80 |             s for s in result.symbols if s.kind == SymbolKind.CONSTANT
  81 |         ]
  82 |         assert any(c.name == "CONSTANT_VALUE" for c in constants)
  83 | 
  84 |     def test_parse_inheritance(self, sample_python_source: str):
  85 |         result = parse_python_file("sample.py", sample_python_source)
  86 |         inherits = [
  87 |             r for r in result.relationships if r.kind == RelKind.INHERITS
  88 |         ]
  89 |         assert any("AdvancedProcessor" in r.source and "BaseProcessor" in r.target for r in inherits)
  90 | 
  91 |     def test_parse_calls(self, sample_python_source: str):
  92 |         result = parse_python_file("sample.py", sample_python_source)
  93 |         calls = [r for r in result.relationships if r.kind == RelKind.CALLS]
  94 |         # run_pipeline calls create_processor
  95 |         assert any(
  96 |             "run_pipeline" in r.source and "create_processor" in r.target
  97 |             for r in calls
  98 |         )
  99 | 
 100 |     def test_parse_docstrings(self, sample_python_source: str):
 101 |         result = parse_python_file("sample.py", sample_python_source)
 102 |         funcs = {s.name: s for s in result.symbols if s.kind in (SymbolKind.FUNCTION, SymbolKind.METHOD)}
 103 |         assert "Factory function" in funcs["create_processor"].docstring
 104 |         assert "Transform a single item" in funcs["_transform"].docstring
 105 | 
 106 |     def test_parse_contains_relationships(self, sample_python_source: str):
 107 |         result = parse_python_file("sample.py", sample_python_source)
 108 |         contains = [r for r in result.relationships if r.kind == RelKind.CONTAINS]
 109 |         # BaseProcessor should contain process, _transform, __init__
 110 |         assert any("BaseProcessor" in r.source and "process" in r.target for r in contains)
 111 | 
 112 |     def test_syntax_error_handling(self):
 113 |         result = parse_python_file("bad.py", "def broken(:\n  pass")
 114 |         assert len(result.errors) > 0
 115 | 
 116 |     def test_empty_file(self):
 117 |         result = parse_python_file("empty.py", "")
 118 |         assert result.language == "python"
 119 |         assert len(result.symbols) == 0

# [method] TestPythonParser.test_parse_functions (relevance: 0.58, depth: 1)
  40 |     def test_parse_functions(self, sample_python_source: str):
  41 |         result = parse_python_file("sample.py", sample_python_source)
  42 |         assert result.language == "python"
  43 |         assert len(result.errors) == 0
  44 | 
  45 |         # Check functions are found
  46 |         func_names = [
  47 |             s.name for s in result.symbols if s.kind == SymbolKind.FUNCTION
  48 |         ]
  49 |         assert "create_processor" in func_names
  50 |         assert "run_pipeline" in func_names

# [method] TestPythonParser.test_parse_classes (relevance: 0.58, depth: 1)
  52 |     def test_parse_classes(self, sample_python_source: str):
  53 |         result = parse_python_file("sample.py", sample_python_source)
  54 | 
  55 |         class_names = [
  56 |             s.name for s in result.symbols if s.kind == SymbolKind.CLASS
  57 |         ]
  58 |         assert "BaseProcessor" in class_names
  59 |         assert "AdvancedProcessor" in class_names

# [method] TestPythonParser.test_parse_methods (relevance: 0.58, depth: 1)
  61 |     def test_parse_methods(self, sample_python_source: str):
  62 |         result = parse_python_file("sample.py", sample_python_source)
  63 | 
  64 |         methods = [s for s in result.symbols if s.kind == SymbolKind.METHOD]
  65 |         method_names = [m.name for m in methods]
  66 |         assert "__init__" in method_names
  67 |         assert "process" in method_names
  68 |         assert "_transform" in method_names
  69 |         assert "batch_process" in method_names

# [method] TestPythonParser.test_parse_imports (relevance: 0.58, depth: 1)
  71 |     def test_parse_imports(self, sample_python_source: str):
  72 |         result = parse_python_file("sample.py", sample_python_source)
  73 |         assert "os" in result.imports
  74 |         assert "typing.List" in result.imports
  75 |         assert "pathlib.Path" in result.imports

# [method] TestPythonParser.test_parse_constants (relevance: 0.58, depth: 1)
  77 |     def test_parse_constants(self, sample_python_source: str):
  78 |         result = parse_python_file("sample.py", sample_python_source)
  79 |         constants = [
  80 |             s for s in result.symbols if s.kind == SymbolKind.CONSTANT
  81 |         ]
  82 |         assert any(c.name == "CONSTANT_VALUE" for c in constants)

# [method] TestPythonParser.test_parse_inheritance (relevance: 0.58, depth: 1)
  84 |     def test_parse_inheritance(self, sample_python_source: str):
  85 |         result = parse_python_file("sample.py", sample_python_source)
  86 |         inherits = [
  87 |             r for r in result.relationships if r.kind == RelKind.INHERITS
  88 |         ]
  89 |         assert any("AdvancedProcessor" in r.source and "BaseProcessor" in r.target for r in inherits)

# [method] TestPythonParser.test_parse_calls (relevance: 0.58, depth: 1)
  91 |     def test_parse_calls(self, sample_python_source: str):
  92 |         result = parse_python_file("sample.py", sample_python_source)
  93 |         calls = [r for r in result.relationships if r.kind == RelKind.CALLS]
  94 |         # run_pipeline calls create_processor
  95 |         assert any(
  96 |             "run_pipeline" in r.source and "create_processor" in r.target
  97 |             for r in calls
  98 |         )

# [method] TestPythonParser.test_parse_docstrings (relevance: 0.58, depth: 1)
 100 |     def test_parse_docstrings(self, sample_python_source: str):
 101 |         result = parse_python_file("sample.py", sample_python_source)
 102 |         funcs = {s.name: s for s in result.symbols if s.kind in (SymbolKind.FUNCTION, SymbolKind.METHOD)}
 103 |         assert "Factory function" in funcs["create_processor"].docstring
 104 |         assert "Transform a single item" in funcs["_transform"].docstring

# [method] TestPythonParser.test_parse_contains_relationships (relevance: 0.58, depth: 1)
 106 |     def test_parse_contains_relationships(self, sample_python_source: str):
 107 |         result = parse_python_file("sample.py", sample_python_source)
 108 |         contains = [r for r in result.relationships if r.kind == RelKind.CONTAINS]
 109 |         # BaseProcessor should contain process, _transform, __init__
 110 |         assert any("BaseProcessor" in r.source and "process" in r.target for r in contains)

# [method] TestPythonParser.test_syntax_error_handling (relevance: 0.58, depth: 1)
 112 |     def test_syntax_error_handling(self):
 113 |         result = parse_python_file("bad.py", "def broken(:\n  pass")
 114 |         assert len(result.errors) > 0

# [method] TestPythonParser.test_empty_file (relevance: 0.58, depth: 1)
 116 |     def test_empty_file(self):
 117 |         result = parse_python_file("empty.py", "")
 118 |         assert result.language == "python"
 119 |         assert len(result.symbols) == 0

# [method] TestCoreParser.test_auto_detect_python (relevance: 0.80, depth: 0)
 155 |     def test_auto_detect_python(self, sample_python_source: str):
 156 |         result = parse_file("sample.py", sample_python_source)
 157 |         assert result is not None
 158 |         assert result.language == "python"

# [method] TestCoreParser.test_auto_detect_javascript (relevance: 0.29, depth: 2)
 160 |     def test_auto_detect_javascript(self, sample_js_source: str):
 161 |         result = parse_file("app.js", sample_js_source)
 162 |         assert result is not None
 163 |         assert result.language == "javascript"

# [method] TestCoreParser.test_unsupported_file (relevance: 0.29, depth: 2)
 165 |     def test_unsupported_file(self):
 166 |         result = parse_file("readme.md", "# Hello")
 167 |         assert result is None

## tests/test_tools.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [method] TestCeGraphTools.test_what_calls (relevance: 0.26, depth: 3)
  40 |     def test_what_calls(self, tmp_project: Path):
  41 |         tools = self._build_tools(tmp_project)
  42 |         result = tools.what_calls("main")
  43 |         assert len(result) > 0

# [method] TestCeGraphTools.test_impact_of (relevance: 0.26, depth: 3)
  45 |     def test_impact_of(self, tmp_project: Path):
  46 |         tools = self._build_tools(tmp_project)
  47 |         result = tools.impact_of("calculate_total")
  48 |         assert "Risk score" in result or "Impact" in result

# [method] TestToolRegistry.test_get_all_tools_creates_registry (relevance: 0.51, depth: 2)
 175 |     def test_get_all_tools_creates_registry(self, tmp_project: Path):
 176 |         builder = GraphBuilder()
 177 |         graph = builder.build_from_directory(tmp_project)
 178 |         query = GraphQuery(graph)
 179 |         search = HybridSearch(tmp_project, graph)
 180 |         registry = get_all_tools(tmp_project, graph, query, search)
 181 | 
 182 |         assert len(registry.list_tools()) > 0
 183 |         assert registry.get("search_code") is not None
 184 |         assert registry.get("nonexistent") is None

# [method] TestToolRegistry.test_registry_execute (relevance: 0.34, depth: 3)
 187 |     async def test_registry_execute(self, tmp_project: Path):
 188 |         builder = GraphBuilder()
 189 |         graph = builder.build_from_directory(tmp_project)
 190 |         query = GraphQuery(graph)
 191 |         search = HybridSearch(tmp_project, graph)
 192 |         registry = get_all_tools(tmp_project, graph, query, search)
 193 | 
 194 |         result = await registry.execute("search_code", {"query": "main"})
 195 |         assert "main" in result

# [method] TestToolRegistry.test_registry_execute_unknown_tool (relevance: 0.34, depth: 3)
 198 |     async def test_registry_execute_unknown_tool(self, tmp_project: Path):
 199 |         builder = GraphBuilder()
 200 |         graph = builder.build_from_directory(tmp_project)
 201 |         query = GraphQuery(graph)
 202 |         search = HybridSearch(tmp_project, graph)
 203 |         registry = get_all_tools(tmp_project, graph, query, search)
 204 | 
 205 |         result = await registry.execute("nonexistent_tool", {})
 206 |         assert "Unknown tool" in result
