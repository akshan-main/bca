# Codebase Context for: detect_language returns "python3" instead of "python" for .py files, causing the parser to fail to select the correct Python parser.
# 33 symbols from 9 files (~3,981 tokens, 100% of budget)

## src/cegraph/cli.py
# Included because: graph expansion (depth 3)

# [function] _get_project_root (relevance: 0.61, depth: 3)
  28 | def _get_project_root(path: str | None = None) -> Path:
  29 |     """Find the project root or error."""
  30 |     if path:
  31 |         root = Path(path).resolve()
  32 |         if not root.exists():
  33 |             console.error(f"Path does not exist: {path}")
  34 |             sys.exit(1)
  35 |         return root
  36 | 
  37 |     root = find_project_root()
  38 |     if root is None:
  39 |         console.error(
  40 |             "No CeGraph project found. Run 'cegraph init' first, "
  41 |             "or specify a path with --path."
  42 |         )
  43 |         sys.exit(1)
  44 |     return root

# [function] _load_graph (relevance: 0.59, depth: 3)
  47 | def _load_graph(root: Path):
  48 |     """Load the knowledge graph and related objects."""
  49 |     from cegraph.graph.store import GraphStore
  50 | 
  51 |     db_path = get_cegraph_dir(root) / GRAPH_DB_FILE
  52 |     store = GraphStore(db_path)
  53 |     graph = store.load()
  54 |     if graph is None:
  55 |         console.error("No index found. Run 'cegraph init' or 'cegraph reindex' first.")
  56 |         sys.exit(1)
  57 |     return graph, store

# [function] reindex (relevance: 0.30, depth: 3)
 100 | def reindex(path: str | None):
 101 |     """Rebuild the knowledge graph from scratch."""
 102 |     root = _get_project_root(path)
 103 |     config = load_config(root)
 104 |     _do_index(root, config)

# [function] ask (relevance: 0.32, depth: 3)
 504 | def ask(question: str, path: str | None):
 505 |     """Ask a question about the codebase (uses LLM + knowledge graph)."""
 506 |     root = _get_project_root(path)
 507 |     config = load_config(root)
 508 |     graph, store = _load_graph(root)
 509 | 
 510 |     _run_agent(root, config, graph, store, question, agent_mode=False)

# [function] agent (relevance: 0.32, depth: 3)
 517 | def agent(task: str, path: str | None, auto: bool):
 518 |     """Run an agentic task (coding, debugging, refactoring)."""
 519 |     root = _get_project_root(path)
 520 |     config = load_config(root)
 521 |     graph, store = _load_graph(root)
 522 | 
 523 |     _run_agent(root, config, graph, store, task, agent_mode=True, auto_approve=auto)

## src/cegraph/github/diff_parser.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [class] ChangedSymbol (relevance: 0.37, depth: 3)
  47 | class ChangedSymbol:
  48 |     """A symbol that was affected by the diff."""
  49 |     name: str
  50 |     qualified_name: str
  51 |     kind: str
  52 |     file_path: str
  53 |     line_start: int
  54 |     line_end: int
  55 |     change_type: str  # 'modified', 'added', 'deleted'
  56 |     lines_changed: int = 0

# [function] get_pr_diff (relevance: 0.44, depth: 2)
 205 | def get_pr_diff(root: Path) -> str:
 206 |     """Get the diff for the current PR (GitHub Actions context)."""
 207 |     import os
 208 |     base_ref = os.environ.get("GITHUB_BASE_REF", "main")
 209 |     return get_git_diff(root, base=f"origin/{base_ref}")

## src/cegraph/github/renderer.py
# Included because: graph expansion (depth 3)

# [function] _risk_badge (relevance: 0.43, depth: 3)
 137 | def _risk_badge(risk: float) -> tuple[str, str, str]:
 138 |     """Return (emoji, label, color) for a risk score."""
 139 |     if risk < 0.1:
 140 |         return ("ðŸŸ¢", "LOW", "green")
 141 |     elif risk < 0.2:
 142 |         return ("ðŸŸ¡", "LOW", "yellow")
 143 |     elif risk < 0.4:
 144 |         return ("ðŸŸ ", "MEDIUM", "orange")
 145 |     elif risk < 0.6:
 146 |         return ("ðŸ”´", "HIGH", "red")
 147 |     else:
 148 |         return ("â›”", "CRITICAL", "red")

# [function] _footer (relevance: 0.35, depth: 3)
 192 | def _footer() -> str:
 193 |     return (
 194 |         "---\n"
 195 |         "*Powered by [CeGraph](https://github.com/cegraph-ai/cegraph) "
 196 |         "â€” CAG-driven code intelligence*"
 197 |     )

## src/cegraph/parser/models.py
# Included because: matches 'detect_language'

# [function] detect_language (relevance: 1.10, depth: 0)
 100 | def detect_language(file_path: str) -> str | None:
 101 |     """Detect programming language from file extension."""
 102 |     from pathlib import Path
 103 | 
 104 |     ext = Path(file_path).suffix.lower()
 105 |     return EXTENSION_LANGUAGE_MAP.get(ext)

## src/cegraph/parser/python_parser.py
# Included because: graph expansion (depth 1); graph expansion (depth 3); matches 'python'

# [function] parse_python_file (relevance: 1.12, depth: 0)
  17 | def parse_python_file(file_path: str, source: str | None = None) -> FileSymbols:
  18 |     """Parse a Python file and extract symbols and relationships."""
  19 |     if source is None:
  20 |         source = Path(file_path).read_text(encoding="utf-8", errors="replace")
  21 | 
  22 |     result = FileSymbols(file_path=file_path, language="python")
  23 | 
  24 |     try:
  25 |         tree = ast.parse(source, filename=file_path)
  26 |     except SyntaxError as e:
  27 |         result.errors.append(f"SyntaxError: {e}")
  28 |         return result
  29 | 
  30 |     lines = source.splitlines()
  31 |     _extract_from_module(tree, file_path, lines, result)
  32 |     return result

# [function] _get_docstring (relevance: 0.56, depth: 3)
  35 | def _get_docstring(node: ast.AST) -> str:
  36 |     """Extract docstring from a node if present."""
  37 |     if (
  38 |         isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef, ast.Module))
  39 |         and node.body
  40 |         and isinstance(node.body[0], ast.Expr)
  41 |         and isinstance(node.body[0].value, (ast.Constant,))
  42 |         and isinstance(node.body[0].value.value, str)
  43 |     ):
  44 |         return node.body[0].value.value.strip()
  45 |     return ""

# [function] _get_decorators (relevance: 0.56, depth: 3)
  48 | def _get_decorators(node: ast.FunctionDef | ast.AsyncFunctionDef | ast.ClassDef) -> list[str]:
  49 |     """Extract decorator names."""
  50 |     decorators = []
  51 |     for dec in node.decorator_list:
  52 |         if isinstance(dec, ast.Name):
  53 |             decorators.append(dec.id)
  54 |         elif isinstance(dec, ast.Attribute):
  55 |             decorators.append(ast.dump(dec))
  56 |         elif isinstance(dec, ast.Call):
  57 |             if isinstance(dec.func, ast.Name):
  58 |                 decorators.append(dec.func.id)
  59 |             elif isinstance(dec.func, ast.Attribute):
  60 |                 decorators.append(ast.dump(dec.func))
  61 |     return decorators

# [function] _extract_from_module (relevance: 0.84, depth: 1)
  85 | def _extract_from_module(
  86 |     tree: ast.Module,
  87 |     file_path: str,
  88 |     lines: list[str],
  89 |     result: FileSymbols,
  90 |     parent_name: str = "",
  91 |     parent_id: str = "",
  92 | ) -> None:
  93 |     """Recursively extract symbols from an AST module/class body."""
  94 | 
  95 |     for node in ast.iter_child_nodes(tree):
  96 |         if isinstance(node, (ast.Import, ast.ImportFrom)):
  97 |             _extract_import(node, file_path, result)
  98 | 
  99 |         elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
 100 |             _extract_function(node, file_path, lines, result, parent_name, parent_id)
 101 | 
 102 |         elif isinstance(node, ast.ClassDef):
 103 |             _extract_class(node, file_path, lines, result, parent_name, parent_id)
 104 | 
 105 |         elif isinstance(node, ast.Assign):
 106 |             _extract_assignment(node, file_path, result, parent_name, parent_id)

# [function] _node_to_name (relevance: 0.62, depth: 3)
 305 | def _node_to_name(node: ast.AST) -> str:
 306 |     """Convert an AST node to a dotted name string."""
 307 |     if isinstance(node, ast.Name):
 308 |         return node.id
 309 |     elif isinstance(node, ast.Attribute):
 310 |         parent = _node_to_name(node.value)
 311 |         if parent:
 312 |             return f"{parent}.{node.attr}"
 313 |         return node.attr
 314 |     elif isinstance(node, ast.Subscript):
 315 |         return _node_to_name(node.value)
 316 |     return ""

## src/cegraph/parser/tree_sitter_parser.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [function] _get_language (relevance: 0.42, depth: 2)
  94 | def _get_language(lang: str):
  95 |     """Get a tree-sitter Language object for the given language."""
  96 |     from tree_sitter import Language
  97 | 
  98 |     module_name = _TS_LANGUAGE_MODULES.get(lang)
  99 |     if not module_name:
 100 |         raise ValueError(f"No tree-sitter grammar for language: {lang}")
 101 | 
 102 |     module = __import__(module_name)
 103 |     return Language(module.language())

# [function] _extract_ts_import (relevance: 0.35, depth: 3)
 250 | def _extract_ts_import(node, file_path: str, source: bytes, result: FileSymbols) -> None:
 251 |     """Extract import information from a tree-sitter node."""
 252 |     text = node.text.decode("utf-8")
 253 |     result.imports.append(text)

## src/cegraph/search/hybrid.py
# Included because: graph expansion (depth 3)

# [function] _tokenize (relevance: 0.34, depth: 3)
 170 | def _tokenize(text: str) -> list[str]:
 171 |     """Simple tokenizer that splits on non-alphanumeric and camelCase."""
 172 |     import re
 173 | 
 174 |     # Split camelCase and snake_case
 175 |     text = re.sub(r"([a-z])([A-Z])", r"\1 \2", text)
 176 |     text = text.replace("_", " ").replace(".", " ")
 177 |     tokens = re.findall(r"[a-zA-Z]{2,}", text.lower())
 178 |     return tokens

## tests/conftest.py
# Included because: matches 'python'

# [function] sample_python_source (relevance: 0.84, depth: 0)
 143 | def sample_python_source() -> str:
 144 |     """Sample Python source code for parser testing."""
 145 |     return '''"""Sample module."""
 146 | 
 147 | import os
 148 | from typing import List, Optional
 149 | from pathlib import Path
 150 | 
 151 | 
 152 | CONSTANT_VALUE = 42
 153 | 
 154 | 
 155 | class BaseProcessor:
 156 |     """Base class for processors."""
 157 | 
 158 |     def __init__(self, name: str):
 159 |         self.name = name
 160 | 
 161 |     def process(self, data: List[str]) -> List[str]:
 162 |         """Process the data."""
 163 |         return [self._transform(item) for item in data]
 164 | 
 165 |     def _transform(self, item: str) -> str:
 166 |         """Transform a single item."""
 167 |         return item.strip()
 168 | 
 169 | 
 170 | class AdvancedProcessor(BaseProcessor):
 171 |     """Advanced processor with extra features."""
 172 | 
 173 |     def __init__(self, name: str, verbose: bool = False):
 174 |         super().__init__(name)
 175 |         self.verbose = verbose
 176 | 
 177 |     def process(self, data: List[str]) -> List[str]:
 178 |         """Process with logging."""
 179 |         if self.verbose:
 180 |             print(f"Processing {len(data)} items")
 181 |         return super().process(data)
 182 | 
 183 |     def batch_process(self, batches: List[List[str]]) -> List[List[str]]:
 184 |         """Process multiple batches."""
 185 |         return [self.process(batch) for batch in batches]
 186 | 
 187 | 
 188 | def create_processor(name: str, advanced: bool = False) -> BaseProcessor:
 189 |     """Factory function for creating processors."""
 190 |     if advanced:
 191 |         return AdvancedProcessor(name, verbose=True)
 192 |     return BaseProcessor(name)
 193 | 
 194 | 
 195 | def run_pipeline(items: List[str], processor_name: str = "default") -> List[str]:
 196 |     """Run the processing pipeline."""
 197 |     processor = create_processor(processor_name)
 198 |     result = processor.process(items)
 199 |     return result
 200 | '''

## tests/test_parser.py
# Included because: graph expansion (depth 1); matches 'python'

# [method] TestLanguageDetection.test_python (relevance: 0.80, depth: 0)
  13 |     def test_python(self):
  14 |         assert detect_language("main.py") == "python"
  15 |         assert detect_language("types.pyi") == "python"

# [class] TestPythonParser (relevance: 1.06, depth: 0)
  39 | class TestPythonParser:
  40 |     def test_parse_functions(self, sample_python_source: str):
  41 |         result = parse_python_file("sample.py", sample_python_source)
  42 |         assert result.language == "python"
  43 |         assert len(result.errors) == 0
  44 | 
  45 |         # Check functions are found
  46 |         func_names = [
  47 |             s.name for s in result.symbols if s.kind == SymbolKind.FUNCTION
  48 |         ]
  49 |         assert "create_processor" in func_names
  50 |         assert "run_pipeline" in func_names
  51 | 
  52 |     def test_parse_classes(self, sample_python_source: str):
  53 |         result = parse_python_file("sample.py", sample_python_source)
  54 | 
  55 |         class_names = [
  56 |             s.name for s in result.symbols if s.kind == SymbolKind.CLASS
  57 |         ]
  58 |         assert "BaseProcessor" in class_names
  59 |         assert "AdvancedProcessor" in class_names
  60 | 
  61 |     def test_parse_methods(self, sample_python_source: str):
  62 |         result = parse_python_file("sample.py", sample_python_source)
  63 | 
  64 |         methods = [s for s in result.symbols if s.kind == SymbolKind.METHOD]
  65 |         method_names = [m.name for m in methods]
  66 |         assert "__init__" in method_names
  67 |         assert "process" in method_names
  68 |         assert "_transform" in method_names
  69 |         assert "batch_process" in method_names
  70 | 
  71 |     def test_parse_imports(self, sample_python_source: str):
  72 |         result = parse_python_file("sample.py", sample_python_source)
  73 |         assert "os" in result.imports
  74 |         assert "typing.List" in result.imports
  75 |         assert "pathlib.Path" in result.imports
  76 | 
  77 |     def test_parse_constants(self, sample_python_source: str):
  78 |         result = parse_python_file("sample.py", sample_python_source)
  79 |         constants = [
  80 |             s for s in result.symbols if s.kind == SymbolKind.CONSTANT
  81 |         ]
  82 |         assert any(c.name == "CONSTANT_VALUE" for c in constants)
  83 | 
  84 |     def test_parse_inheritance(self, sample_python_source: str):
  85 |         result = parse_python_file("sample.py", sample_python_source)
  86 |         inherits = [
  87 |             r for r in result.relationships if r.kind == RelKind.INHERITS
  88 |         ]
  89 |         assert any("AdvancedProcessor" in r.source and "BaseProcessor" in r.target for r in inherits)
  90 | 
  91 |     def test_parse_calls(self, sample_python_source: str):
  92 |         result = parse_python_file("sample.py", sample_python_source)
  93 |         calls = [r for r in result.relationships if r.kind == RelKind.CALLS]
  94 |         # run_pipeline calls create_processor
  95 |         assert any(
  96 |             "run_pipeline" in r.source and "create_processor" in r.target
  97 |             for r in calls
  98 |         )
  99 | 
 100 |     def test_parse_docstrings(self, sample_python_source: str):
 101 |         result = parse_python_file("sample.py", sample_python_source)
 102 |         funcs = {s.name: s for s in result.symbols if s.kind in (SymbolKind.FUNCTION, SymbolKind.METHOD)}
 103 |         assert "Factory function" in funcs["create_processor"].docstring
 104 |         assert "Transform a single item" in funcs["_transform"].docstring
 105 | 
 106 |     def test_parse_contains_relationships(self, sample_python_source: str):
 107 |         result = parse_python_file("sample.py", sample_python_source)
 108 |         contains = [r for r in result.relationships if r.kind == RelKind.CONTAINS]
 109 |         # BaseProcessor should contain process, _transform, __init__
 110 |         assert any("BaseProcessor" in r.source and "process" in r.target for r in contains)
 111 | 
 112 |     def test_syntax_error_handling(self):
 113 |         result = parse_python_file("bad.py", "def broken(:\n  pass")
 114 |         assert len(result.errors) > 0
 115 | 
 116 |     def test_empty_file(self):
 117 |         result = parse_python_file("empty.py", "")
 118 |         assert result.language == "python"
 119 |         assert len(result.symbols) == 0

# [method] TestPythonParser.test_parse_functions (relevance: 0.58, depth: 1)
  40 |     def test_parse_functions(self, sample_python_source: str):
  41 |         result = parse_python_file("sample.py", sample_python_source)
  42 |         assert result.language == "python"
  43 |         assert len(result.errors) == 0
  44 | 
  45 |         # Check functions are found
  46 |         func_names = [
  47 |             s.name for s in result.symbols if s.kind == SymbolKind.FUNCTION
  48 |         ]
  49 |         assert "create_processor" in func_names
  50 |         assert "run_pipeline" in func_names

# [method] TestPythonParser.test_parse_classes (relevance: 0.58, depth: 1)
  52 |     def test_parse_classes(self, sample_python_source: str):
  53 |         result = parse_python_file("sample.py", sample_python_source)
  54 | 
  55 |         class_names = [
  56 |             s.name for s in result.symbols if s.kind == SymbolKind.CLASS
  57 |         ]
  58 |         assert "BaseProcessor" in class_names
  59 |         assert "AdvancedProcessor" in class_names

# [method] TestPythonParser.test_parse_methods (relevance: 0.58, depth: 1)
  61 |     def test_parse_methods(self, sample_python_source: str):
  62 |         result = parse_python_file("sample.py", sample_python_source)
  63 | 
  64 |         methods = [s for s in result.symbols if s.kind == SymbolKind.METHOD]
  65 |         method_names = [m.name for m in methods]
  66 |         assert "__init__" in method_names
  67 |         assert "process" in method_names
  68 |         assert "_transform" in method_names
  69 |         assert "batch_process" in method_names

# [method] TestPythonParser.test_parse_imports (relevance: 0.58, depth: 1)
  71 |     def test_parse_imports(self, sample_python_source: str):
  72 |         result = parse_python_file("sample.py", sample_python_source)
  73 |         assert "os" in result.imports
  74 |         assert "typing.List" in result.imports
  75 |         assert "pathlib.Path" in result.imports

# [method] TestPythonParser.test_parse_constants (relevance: 0.58, depth: 1)
  77 |     def test_parse_constants(self, sample_python_source: str):
  78 |         result = parse_python_file("sample.py", sample_python_source)
  79 |         constants = [
  80 |             s for s in result.symbols if s.kind == SymbolKind.CONSTANT
  81 |         ]
  82 |         assert any(c.name == "CONSTANT_VALUE" for c in constants)

# [method] TestPythonParser.test_parse_inheritance (relevance: 0.58, depth: 1)
  84 |     def test_parse_inheritance(self, sample_python_source: str):
  85 |         result = parse_python_file("sample.py", sample_python_source)
  86 |         inherits = [
  87 |             r for r in result.relationships if r.kind == RelKind.INHERITS
  88 |         ]
  89 |         assert any("AdvancedProcessor" in r.source and "BaseProcessor" in r.target for r in inherits)

# [method] TestPythonParser.test_parse_calls (relevance: 0.58, depth: 1)
  91 |     def test_parse_calls(self, sample_python_source: str):
  92 |         result = parse_python_file("sample.py", sample_python_source)
  93 |         calls = [r for r in result.relationships if r.kind == RelKind.CALLS]
  94 |         # run_pipeline calls create_processor
  95 |         assert any(
  96 |             "run_pipeline" in r.source and "create_processor" in r.target
  97 |             for r in calls
  98 |         )

# [method] TestPythonParser.test_parse_docstrings (relevance: 0.58, depth: 1)
 100 |     def test_parse_docstrings(self, sample_python_source: str):
 101 |         result = parse_python_file("sample.py", sample_python_source)
 102 |         funcs = {s.name: s for s in result.symbols if s.kind in (SymbolKind.FUNCTION, SymbolKind.METHOD)}
 103 |         assert "Factory function" in funcs["create_processor"].docstring
 104 |         assert "Transform a single item" in funcs["_transform"].docstring

# [method] TestPythonParser.test_parse_contains_relationships (relevance: 0.58, depth: 1)
 106 |     def test_parse_contains_relationships(self, sample_python_source: str):
 107 |         result = parse_python_file("sample.py", sample_python_source)
 108 |         contains = [r for r in result.relationships if r.kind == RelKind.CONTAINS]
 109 |         # BaseProcessor should contain process, _transform, __init__
 110 |         assert any("BaseProcessor" in r.source and "process" in r.target for r in contains)

# [method] TestPythonParser.test_syntax_error_handling (relevance: 0.58, depth: 1)
 112 |     def test_syntax_error_handling(self):
 113 |         result = parse_python_file("bad.py", "def broken(:\n  pass")
 114 |         assert len(result.errors) > 0

# [method] TestPythonParser.test_empty_file (relevance: 0.58, depth: 1)
 116 |     def test_empty_file(self):
 117 |         result = parse_python_file("empty.py", "")
 118 |         assert result.language == "python"
 119 |         assert len(result.symbols) == 0

# [method] TestCoreParser.test_auto_detect_python (relevance: 0.80, depth: 0)
 155 |     def test_auto_detect_python(self, sample_python_source: str):
 156 |         result = parse_file("sample.py", sample_python_source)
 157 |         assert result is not None
 158 |         assert result.language == "python"
