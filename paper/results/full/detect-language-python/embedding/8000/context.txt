# src/cegraph/parser/models.py:100-105
def detect_language(file_path: str) -> str | None:
    """Detect programming language from file extension."""
    from pathlib import Path

    ext = Path(file_path).suffix.lower()
    return EXTENSION_LANGUAGE_MAP.get(ext)

# tests/test_parser.py:7-7
from cegraph.parser.models import SymbolKind, RelKind, detect_language

# src/cegraph/parser/core.py:10-10
from cegraph.parser.models import FileSymbols, detect_language

# tests/test_parser.py:13-15
    def test_python(self):
        assert detect_language("main.py") == "python"
        assert detect_language("types.pyi") == "python"

# tests/test_parser.py:8-8
from cegraph.parser.python_parser import parse_python_file

# tests/test_parser.py:155-158
    def test_auto_detect_python(self, sample_python_source: str):
        result = parse_file("sample.py", sample_python_source)
        assert result is not None
        assert result.language == "python"

# tests/test_parser.py:148-151
    def test_typescript_detection(self):
        result = parse_file("app.ts", "const x: number = 1;")
        assert result is not None
        assert result.language == "typescript"

# tests/test_parser.py:112-114
    def test_syntax_error_handling(self):
        result = parse_python_file("bad.py", "def broken(:\n  pass")
        assert len(result.errors) > 0

# tests/test_parser.py:39-119
class TestPythonParser:
    def test_parse_functions(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        assert result.language == "python"
        assert len(result.errors) == 0

        # Check functions are found
        func_names = [
            s.name for s in result.symbols if s.kind == SymbolKind.FUNCTION
        ]
        assert "create_processor" in func_names
        assert "run_pipeline" in func_names

    def test_parse_classes(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)

        class_names = [
            s.name for s in result.symbols if s.kind == SymbolKind.CLASS
        ]
        assert "BaseProcessor" in class_names
        assert "AdvancedProcessor" in class_names

    def test_parse_methods(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)

        methods = [s for s in result.symbols if s.kind == SymbolKind.METHOD]
        method_names = [m.name for m in methods]
        assert "__init__" in method_names
        assert "process" in method_names
        assert "_transform" in method_names
        assert "batch_process" in method_names

    def test_parse_imports(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        assert "os" in result.imports
        assert "typing.List" in result.imports
        assert "pathlib.Path" in result.imports

    def test_parse_constants(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        constants = [
            s for s in result.symbols if s.kind == SymbolKind.CONSTANT
        ]
        assert any(c.name == "CONSTANT_VALUE" for c in constants)

    def test_parse_inheritance(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        inherits = [
            r for r in result.relationships if r.kind == RelKind.INHERITS
        ]
        assert any("AdvancedProcessor" in r.source and "BaseProcessor" in r.target for r in inherits)

    def test_parse_calls(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        calls = [r for r in result.relationships if r.kind == RelKind.CALLS]
        # run_pipeline calls create_processor
        assert any(
            "run_pipeline" in r.source and "create_processor" in r.target
            for r in calls
        )

    def test_parse_docstrings(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        funcs = {s.name: s for s in result.symbols if s.kind in (SymbolKind.FUNCTION, SymbolKind.METHOD)}
        assert "Factory function" in funcs["create_processor"].docstring
        assert "Transform a single item" in funcs["_transform"].docstring

    def test_parse_contains_relationships(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        contains = [r for r in result.relationships if r.kind == RelKind.CONTAINS]
        # BaseProcessor should contain process, _transform, __init__
        assert any("BaseProcessor" in r.source and "process" in r.target for r in contains)

    def test_syntax_error_handling(self):
        result = parse_python_file("bad.py", "def broken(:\n  pass")
        assert len(result.errors) > 0

    def test_empty_file(self):
        result = parse_python_file("empty.py", "")
        assert result.language == "python"
        assert len(result.symbols) == 0

# tests/test_parser.py:116-119
    def test_empty_file(self):
        result = parse_python_file("empty.py", "")
        assert result.language == "python"
        assert len(result.symbols) == 0

# src/cegraph/parser/core.py:13-38
def parse_file(file_path: str, source: str | None = None) -> FileSymbols | None:
    """Parse a single file, auto-detecting language and selecting the best parser.

    Returns None if the file's language is not supported.

    - Python: uses stdlib ast (zero deps, high accuracy)
    - JS/TS, Go, Rust, Java: uses tree-sitter (required dep, full AST)
    """
    language = detect_language(file_path)
    if not language:
        return None

    # Python uses stdlib AST â€” better than tree-sitter for Python
    if language == "python":
        from cegraph.parser.python_parser import parse_python_file

        return parse_python_file(file_path, source)

    # Everything else uses tree-sitter
    from cegraph.parser.tree_sitter_parser import is_available, parse_tree_sitter_file

    if is_available(language):
        return parse_tree_sitter_file(file_path, language, source)

    # Language detected but no tree-sitter grammar installed
    return None

# tests/test_parser.py:100-104
    def test_parse_docstrings(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        funcs = {s.name: s for s in result.symbols if s.kind in (SymbolKind.FUNCTION, SymbolKind.METHOD)}
        assert "Factory function" in funcs["create_processor"].docstring
        assert "Transform a single item" in funcs["_transform"].docstring

# tests/test_parser.py:165-167
    def test_unsupported_file(self):
        result = parse_file("readme.md", "# Hello")
        assert result is None

# tests/conftest.py:143-200
def sample_python_source() -> str:
    """Sample Python source code for parser testing."""
    return '''"""Sample module."""

import os
from typing import List, Optional
from pathlib import Path


CONSTANT_VALUE = 42


class BaseProcessor:
    """Base class for processors."""

    def __init__(self, name: str):
        self.name = name

    def process(self, data: List[str]) -> List[str]:
        """Process the data."""
        return [self._transform(item) for item in data]

    def _transform(self, item: str) -> str:
        """Transform a single item."""
        return item.strip()


class AdvancedProcessor(BaseProcessor):
    """Advanced processor with extra features."""

    def __init__(self, name: str, verbose: bool = False):
        super().__init__(name)
        self.verbose = verbose

    def process(self, data: List[str]) -> List[str]:
        """Process with logging."""
        if self.verbose:
            print(f"Processing {len(data)} items")
        return super().process(data)

    def batch_process(self, batches: List[List[str]]) -> List[List[str]]:
        """Process multiple batches."""
        return [self.process(batch) for batch in batches]


def create_processor(name: str, advanced: bool = False) -> BaseProcessor:
    """Factory function for creating processors."""
    if advanced:
        return AdvancedProcessor(name, verbose=True)
    return BaseProcessor(name)


def run_pipeline(items: List[str], processor_name: str = "default") -> List[str]:
    """Run the processing pipeline."""
    processor = create_processor(processor_name)
    result = processor.process(items)
    return result
'''

# tests/test_parser.py:52-59
    def test_parse_classes(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)

        class_names = [
            s.name for s in result.symbols if s.kind == SymbolKind.CLASS
        ]
        assert "BaseProcessor" in class_names
        assert "AdvancedProcessor" in class_names

# tests/test_parser.py:31-36
    def test_unknown(self):
        assert detect_language("readme.md") is None
        assert detect_language("data.json") is None
        # Languages without tree-sitter grammars are not supported
        assert detect_language("main.rb") is None
        assert detect_language("main.php") is None

# tests/test_impact_bot.py:95-98
    def test_parse_multiple_files(self):
        combined = SAMPLE_DIFF + SAMPLE_DIFF_NEW_FILE
        diffs = parse_diff(combined)
        assert len(diffs) == 2

# tests/test_impact_bot.py:90-93
    def test_parse_deleted_file(self):
        diffs = parse_diff(SAMPLE_DIFF_DELETED)
        assert len(diffs) == 1
        assert diffs[0].status == "deleted"

# tests/test_impact_bot.py:85-88
    def test_parse_new_file(self):
        diffs = parse_diff(SAMPLE_DIFF_NEW_FILE)
        assert len(diffs) == 1
        assert diffs[0].status == "added"

# tests/test_parser.py:71-75
    def test_parse_imports(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        assert "os" in result.imports
        assert "typing.List" in result.imports
        assert "pathlib.Path" in result.imports

# tests/test_parser.py:17-19
    def test_javascript(self):
        assert detect_language("app.js") == "javascript"
        assert detect_language("component.jsx") == "javascript"

# tests/test_parser.py:21-23
    def test_typescript(self):
        assert detect_language("app.ts") == "typescript"
        assert detect_language("component.tsx") == "typescript"

# tests/test_parser.py:91-98
    def test_parse_calls(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        calls = [r for r in result.relationships if r.kind == RelKind.CALLS]
        # run_pipeline calls create_processor
        assert any(
            "run_pipeline" in r.source and "create_processor" in r.target
            for r in calls
        )

# tests/test_parser.py:77-82
    def test_parse_constants(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        constants = [
            s for s in result.symbols if s.kind == SymbolKind.CONSTANT
        ]
        assert any(c.name == "CONSTANT_VALUE" for c in constants)

# tests/test_parser.py:28-29
    def test_rust(self):
        assert detect_language("main.rs") == "rust"

# tests/test_impact_bot.py:70-75
    def test_parse_modified_file(self):
        diffs = parse_diff(SAMPLE_DIFF)
        assert len(diffs) == 1
        assert diffs[0].path == "utils.py"
        assert diffs[0].status == "modified"
        assert len(diffs[0].hunks) == 2

# src/cegraph/parser/python_parser.py:17-32
def parse_python_file(file_path: str, source: str | None = None) -> FileSymbols:
    """Parse a Python file and extract symbols and relationships."""
    if source is None:
        source = Path(file_path).read_text(encoding="utf-8", errors="replace")

    result = FileSymbols(file_path=file_path, language="python")

    try:
        tree = ast.parse(source, filename=file_path)
    except SyntaxError as e:
        result.errors.append(f"SyntaxError: {e}")
        return result

    lines = source.splitlines()
    _extract_from_module(tree, file_path, lines, result)
    return result

# tests/test_parser.py:25-26
    def test_go(self):
        assert detect_language("main.go") == "go"

# src/cegraph/parser/tree_sitter_parser.py:106-127
def parse_tree_sitter_file(
    file_path: str, language: str, source: str | None = None
) -> FileSymbols:
    """Parse a file using tree-sitter for accurate AST extraction."""
    from tree_sitter import Parser

    if source is None:
        source = Path(file_path).read_text(encoding="utf-8", errors="replace")

    result = FileSymbols(file_path=file_path, language=language)
    source_bytes = source.encode("utf-8")

    try:
        ts_language = _get_language(language)
        parser = Parser(ts_language)
        tree = parser.parse(source_bytes)
    except Exception as e:
        result.errors.append(f"tree-sitter parse error: {e}")
        return result

    _walk_tree(tree.root_node, file_path, language, source_bytes, result)
    return result

# tests/test_parser.py:40-50
    def test_parse_functions(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        assert result.language == "python"
        assert len(result.errors) == 0

        # Check functions are found
        func_names = [
            s.name for s in result.symbols if s.kind == SymbolKind.FUNCTION
        ]
        assert "create_processor" in func_names
        assert "run_pipeline" in func_names

# src/cegraph/exceptions.py:12-13
class ParserError(CeGraphError):
    """Code parsing errors."""

# paper/experiments/ablation.py:13-13
import argparse

# paper/experiments/benchmark.py:32-32
import argparse

# paper/experiments/run_all.py:9-9
import argparse

# paper/experiments/baselines.py:18-18
import argparse

# paper/experiments/make_tasks.py:17-17
import argparse

# tests/test_parser.py:106-110
    def test_parse_contains_relationships(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        contains = [r for r in result.relationships if r.kind == RelKind.CONTAINS]
        # BaseProcessor should contain process, _transform, __init__
        assert any("BaseProcessor" in r.source and "process" in r.target for r in contains)

# src/cegraph/exceptions.py:24-25
class ToolError(CeGraphError):
    """Agent tool execution errors."""

# tests/test_parser.py:160-163
    def test_auto_detect_javascript(self, sample_js_source: str):
        result = parse_file("app.js", sample_js_source)
        assert result is not None
        assert result.language == "javascript"

# tests/test_tools.py:62-65
    def test_read_file_not_found(self, tmp_project: Path):
        tools = self._build_tools(tmp_project)
        result = tools.read_file("nonexistent.py")
        assert "not found" in result.lower()

# tests/test_parser.py:12-36
class TestLanguageDetection:
    def test_python(self):
        assert detect_language("main.py") == "python"
        assert detect_language("types.pyi") == "python"

    def test_javascript(self):
        assert detect_language("app.js") == "javascript"
        assert detect_language("component.jsx") == "javascript"

    def test_typescript(self):
        assert detect_language("app.ts") == "typescript"
        assert detect_language("component.tsx") == "typescript"

    def test_go(self):
        assert detect_language("main.go") == "go"

    def test_rust(self):
        assert detect_language("main.rs") == "rust"

    def test_unknown(self):
        assert detect_language("readme.md") is None
        assert detect_language("data.json") is None
        # Languages without tree-sitter grammars are not supported
        assert detect_language("main.rb") is None
        assert detect_language("main.php") is None

# tests/test_impact_bot.py:81-83
    def test_parse_deleted_lines(self):
        diffs = parse_diff(SAMPLE_DIFF)
        assert diffs[0].deleted_lines > 0

# tests/test_parser.py:61-69
    def test_parse_methods(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)

        methods = [s for s in result.symbols if s.kind == SymbolKind.METHOD]
        method_names = [m.name for m in methods]
        assert "__init__" in method_names
        assert "process" in method_names
        assert "_transform" in method_names
        assert "batch_process" in method_names

# src/cegraph/parser/__init__.py:4-4
from cegraph.parser.core import parse_file, parse_directory

# src/cegraph/graph/builder.py:11-11
from cegraph.parser.core import parse_directory

# tests/test_impact_bot.py:194-197
    def test_render_file_tree(self):
        files = ["src/main.py", "src/utils.py", "tests/test_main.py"]
        tree = _render_file_tree(files)
        assert len(tree) > 0

# tests/test_impact_bot.py:108-110
    def test_parse_empty(self):
        diffs = parse_diff("")
        assert diffs == []

# tests/test_tools.py:105-108
    def test_list_files_pattern(self, tmp_project: Path):
        tools = self._build_tools(tmp_project)
        result = tools.list_files(pattern="*.py")
        assert "main.py" in result

# tests/test_tools.py:87-90
    def test_edit_file_text_not_found(self, tmp_project: Path):
        tools = self._build_tools(tmp_project)
        result = tools.edit_file("utils.py", "NONEXISTENT_TEXT", "replacement")
        assert "not found" in result.lower()

# tests/test_impact_bot.py:77-79
    def test_parse_added_lines(self):
        diffs = parse_diff(SAMPLE_DIFF)
        assert diffs[0].added_lines > 0

# src/cegraph/parser/__init__.py:4-4
from cegraph.parser.core import parse_file, parse_directory

# tests/test_parser.py:9-9
from cegraph.parser.core import parse_file

# tests/test_tools.py:100-103
    def test_list_files(self, tmp_project: Path):
        tools = self._build_tools(tmp_project)
        result = tools.list_files()
        assert "main.py" in result

# src/cegraph/ui/console.py:49-51
    def code(self, text: str, language: str = "python") -> None:
        """Render syntax-highlighted code."""
        self.console.print(Syntax(text, language, theme="monokai", line_numbers=True))

# tests/test_parser.py:84-89
    def test_parse_inheritance(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        inherits = [
            r for r in result.relationships if r.kind == RelKind.INHERITS
        ]
        assert any("AdvancedProcessor" in r.source and "BaseProcessor" in r.target for r in inherits)

# tests/test_tools.py:67-70
    def test_read_file_outside_root(self, tmp_project: Path):
        tools = self._build_tools(tmp_project)
        result = tools.read_file("../../etc/passwd")
        assert "denied" in result.lower() or "not found" in result.lower()

# tests/test_search.py:26-30
    def test_search_with_file_pattern(self, tmp_project: Path):
        search = self._build_search(tmp_project)
        results = search.search("def ", file_pattern="*.py")
        assert len(results) > 0
        assert all(r.file_path.endswith(".py") for r in results)

# src/cegraph/parser/tree_sitter_parser.py:220-247
def _extract_ts_calls(
    node, file_path: str, language: str, source: bytes,
    caller_id: str, call_types: list[str], result: FileSymbols
) -> None:
    """Extract function calls from a tree-sitter node."""
    if node.type in call_types:
        # Get the function being called
        func_node = node.child_by_field_name("function")
        if func_node is None and node.children:
            func_node = node.children[0]
        if func_node:
            callee = func_node.text.decode("utf-8")
            # Clean up multiline callees
            callee = callee.split("(")[0].strip()
            if callee and len(callee) < 100:
                result.relationships.append(
                    Relationship(
                        source=caller_id,
                        target=callee,
                        kind=RelKind.CALLS,
                        file_path=file_path,
                        line=node.start_point[0] + 1,
                    )
                )
        return

    for child in node.children:
        _extract_ts_calls(child, file_path, language, source, caller_id, call_types, result)

# tests/test_parser.py:123-127
    def test_parse_classes(self, sample_js_source: str):
        result = parse_file("app.js", sample_js_source)
        assert result is not None
        class_names = [s.name for s in result.symbols if s.kind == SymbolKind.CLASS]
        assert "UserService" in class_names

# tests/test_tools.py:158-168
    def test_get_tool_definitions(self):
        defs = get_tool_definitions()
        assert len(defs) > 0

        names = [d.name for d in defs]
        assert "search_code" in names
        assert "who_calls" in names
        assert "impact_of" in names
        assert "read_file" in names
        assert "edit_file" in names
        assert "run_command" in names

# tests/test_tools.py:50-53
    def test_read_file(self, tmp_project: Path):
        tools = self._build_tools(tmp_project)
        result = tools.read_file("main.py")
        assert "def main" in result

# tests/test_search.py:44-47
    def test_search_no_results(self, tmp_project: Path):
        search = self._build_search(tmp_project)
        results = search.search("xyznonexistent123")
        assert len(results) == 0

# src/cegraph/parser/tree_sitter_parser.py:94-103
def _get_language(lang: str):
    """Get a tree-sitter Language object for the given language."""
    from tree_sitter import Language

    module_name = _TS_LANGUAGE_MODULES.get(lang)
    if not module_name:
        raise ValueError(f"No tree-sitter grammar for language: {lang}")

    module = __import__(module_name)
    return Language(module.language())

# tests/test_context.py:223-232
    def test_focus_files(self, cag_engine: ContextAssembler):
        """Test that focus files are prioritized."""
        package = cag_engine.assemble(
            task="review code",
            token_budget=8000,
            focus_files=["utils.py"],
        )
        # Should include symbols from utils.py
        files = set(item.file_path for item in package.items)
        assert "utils.py" in files or len(package.items) > 0

# tests/test_impact_bot.py:9-15
from cegraph.github.diff_parser import (
    DiffHunk,
    FileDiff,
    ChangedSymbol,
    get_changed_symbols,
    parse_diff,
)

# src/cegraph/github/impact_bot.py:26-33
from cegraph.github.diff_parser import (
    ChangedSymbol,
    FileDiff,
    get_changed_symbols,
    get_git_diff,
    get_pr_diff,
    parse_diff,
)

# tests/test_impact_bot.py:199-201
    def test_footer_present(self):
        comment = render_impact_comment([], [])
        assert "CeGraph" in comment

# src/cegraph/context/_native.py:55-81
def _load_library():
    """Load the native library, or return None."""
    global _lib, _lib_path

    if _lib is not None:
        return _lib

    path = _find_library()
    if path is None:
        return None

    try:
        lib = ctypes.CDLL(path)

        # Verify it's the right library
        lib.cag_is_available.restype = ctypes.c_int32
        if lib.cag_is_available() != 1:
            return None

        # Set up function signatures
        _setup_signatures(lib)

        _lib = lib
        _lib_path = path
        return lib
    except (OSError, AttributeError):
        return None

# tests/test_parser.py:142-146
    def test_parse_imports(self, sample_js_source: str):
        result = parse_file("app.js", sample_js_source)
        assert result is not None
        # tree-sitter captures import statements as raw text
        assert any("react" in imp for imp in result.imports)

# tests/test_graph.py:196-201
    def test_get_file_symbols(self, tmp_project: Path):
        query = self._build_query(tmp_project)
        symbols = query.get_file_symbols("main.py")
        assert len(symbols) > 0
        names = [s["name"] for s in symbols]
        assert "main" in names

# tests/test_cli.py:77-82
    def test_who_calls_not_found(self, runner: CliRunner, indexed_project: Path):
        result = runner.invoke(
            main, ["who-calls", "nonexistent_func", "--path", str(indexed_project)]
        )
        assert result.exit_code == 0
        assert "No callers" in result.output

# tests/test_search.py:70-76
    def test_search_delegates_to_lexical(self, tmp_project: Path):
        builder = GraphBuilder()
        graph = builder.build_from_directory(tmp_project)
        search = HybridSearch(tmp_project, graph)

        results = search.search("calculate_total")
        assert len(results) > 0

# tests/test_graph.py:34-44
    def test_file_nodes_present(self, tmp_project: Path):
        builder = GraphBuilder()
        graph = builder.build_from_directory(tmp_project)

        file_nodes = [
            n for n, d in graph.nodes(data=True) if d.get("type") == "file"
        ]
        file_paths = [graph.nodes[n].get("path") for n in file_nodes]
        assert "main.py" in file_paths
        assert "utils.py" in file_paths
        assert "models.py" in file_paths

# src/cegraph/context/engine.py:956-1010
    def _load_source(self, candidates: list[dict]) -> list[ContextItem]:
        """Load actual source code for selected symbols."""
        items = []

        for cand in candidates:
            sid = cand["symbol_id"]
            data = self.graph.nodes.get(sid, {})
            file_path = data.get("file_path", "")
            line_start = data.get("line_start", 0)
            line_end = data.get("line_end", 0)

            source = ""
            full_path = self.root / file_path
            if full_path.exists():
                try:
                    all_lines = full_path.read_text(
                        encoding="utf-8", errors="replace"
                    ).splitlines()
                    source = "\n".join(all_lines[max(0, line_start - 1):line_end])
                except OSError:
                    source = f"# Could not read {file_path}"

            token_est = (
                TokenEstimator.estimate(source)
                if source
                else cand.get("token_estimate", 0)
            )

            reason = cand.get("reason", "")
            if cand.get("is_dependency"):
                closure_sym = cand.get("closure_of", "")
                closure_name = self.graph.nodes.get(closure_sym, {}).get("name", "")
                reason = f"required dependency of {closure_name}"

            items.append(
                ContextItem(
                    symbol_id=sid,
                    name=data.get("name", ""),
                    qualified_name=data.get("qualified_name", ""),
                    kind=data.get("kind", ""),
                    file_path=file_path,
                    line_start=line_start,
                    line_end=line_end,
                    source_code=source,
                    signature=data.get("signature", ""),
                    docstring=data.get("docstring", ""),
                    relevance_score=round(cand["score"], 3),
                    reason=reason,
                    token_estimate=token_est,
                    depth=cand.get("depth", 0),
                    is_dependency=cand.get("is_dependency", False),
                )
            )

        return items

# tests/test_impact_bot.py:133-142
    def test_deleted_file_symbols(self, tmp_project: Path):
        builder = GraphBuilder()
        graph = builder.build_from_directory(tmp_project)

        file_diff = FileDiff(path="utils.py", status="deleted")
        changed = get_changed_symbols(tmp_project, graph, [file_diff])
        # All symbols in utils.py should be marked as deleted
        for s in changed:
            assert s.change_type == "deleted"
            assert s.file_path == "utils.py"

# src/cegraph/parser/core.py:82-130
def _collect_files(root: Path, config: IndexerConfig) -> list[Path]:
    """Collect all parseable files, respecting exclusion patterns."""
    files = []
    max_size = config.max_file_size_kb * 1024

    # Read .gitignore if available
    gitignore_patterns = _read_gitignore(root)
    all_exclude = config.exclude_patterns + gitignore_patterns

    for dirpath, dirnames, filenames in os.walk(root):
        rel_dir = os.path.relpath(dirpath, root)

        # Filter out excluded directories
        dirnames[:] = [
            d
            for d in dirnames
            if not _should_exclude(os.path.join(rel_dir, d) if rel_dir != "." else d, all_exclude)
        ]

        for filename in filenames:
            rel_path = (
                os.path.join(rel_dir, filename) if rel_dir != "." else filename
            )

            # Check exclusion patterns
            if _should_exclude(rel_path, all_exclude):
                continue

            # Check language support
            lang = detect_language(filename)
            if lang is None:
                continue

            # Filter by configured languages (empty list = all)
            if config.languages and lang not in config.languages:
                continue

            full_path = Path(dirpath) / filename

            # Check file size
            try:
                if full_path.stat().st_size > max_size:
                    continue
            except OSError:
                continue

            files.append(full_path)

    return sorted(files)

# src/cegraph/llm/base.py:55-56
    def has_tool_calls(self) -> bool:
        return len(self.tool_calls) > 0

# src/cegraph/parser/tree_sitter_parser.py:73-91
def is_available(language: str | None = None) -> bool:
    """Check if tree-sitter and the required language grammar are available."""
    try:
        import tree_sitter  # noqa: F401
    except ImportError:
        return False

    if language is None:
        return True

    module_name = _TS_LANGUAGE_MODULES.get(language)
    if not module_name:
        return False

    try:
        __import__(module_name)
        return True
    except ImportError:
        return False

# tests/test_mcp.py:171-178
    def test_resources_read_path_traversal(self, mcp_server: MCPServer):
        """Regression: reading files outside the project root must be denied."""
        result = mcp_server._dispatch("resources/read", {
            "uri": "file://../../../../etc/hosts",
        })
        text = result["contents"][0].get("text", "")
        assert "Access denied" in text
        assert "localhost" not in text

# tests/test_impact_bot.py:69-110
class TestDiffParser:
    def test_parse_modified_file(self):
        diffs = parse_diff(SAMPLE_DIFF)
        assert len(diffs) == 1
        assert diffs[0].path == "utils.py"
        assert diffs[0].status == "modified"
        assert len(diffs[0].hunks) == 2

    def test_parse_added_lines(self):
        diffs = parse_diff(SAMPLE_DIFF)
        assert diffs[0].added_lines > 0

    def test_parse_deleted_lines(self):
        diffs = parse_diff(SAMPLE_DIFF)
        assert diffs[0].deleted_lines > 0

    def test_parse_new_file(self):
        diffs = parse_diff(SAMPLE_DIFF_NEW_FILE)
        assert len(diffs) == 1
        assert diffs[0].status == "added"

    def test_parse_deleted_file(self):
        diffs = parse_diff(SAMPLE_DIFF_DELETED)
        assert len(diffs) == 1
        assert diffs[0].status == "deleted"

    def test_parse_multiple_files(self):
        combined = SAMPLE_DIFF + SAMPLE_DIFF_NEW_FILE
        diffs = parse_diff(combined)
        assert len(diffs) == 2

    def test_hunk_line_ranges(self):
        diffs = parse_diff(SAMPLE_DIFF)
        ranges = diffs[0].changed_line_ranges
        assert len(ranges) > 0
        for start, end in ranges:
            assert start > 0
            assert end >= start

    def test_parse_empty(self):
        diffs = parse_diff("")
        assert diffs == []

# tests/test_graph.py:165-168
    def test_find_symbol_partial(self, tmp_project: Path):
        query = self._build_query(tmp_project)
        results = query.find_symbol("helper")
        assert len(results) > 0

# tests/test_graph.py:160-163
    def test_find_symbol(self, tmp_project: Path):
        query = self._build_query(tmp_project)
        results = query.find_symbol("main")
        assert len(results) > 0

# tests/test_tools.py:55-60
    def test_read_file_with_lines(self, tmp_project: Path):
        tools = self._build_tools(tmp_project)
        result = tools.read_file("main.py", start_line=1, end_line=5)
        assert "1" in result  # Line numbers
        lines = [l for l in result.splitlines() if l.strip()]
        assert len(lines) <= 5

# tests/test_context.py:257-263
    def test_extract_entities_snake_case(self, cag_engine: ContextAssembler):
        """Test snake_case entity extraction."""
        entities = cag_engine._extract_entities(
            "refactor the calculate_total function"
        )
        names = [e["name"] for e in entities]
        assert "calculate_total" in names

# tests/test_mcp.py:139-145
    def test_unknown_tool(self, mcp_server: MCPServer):
        """Test calling an unknown tool."""
        result = mcp_server._dispatch("tools/call", {
            "name": "nonexistent_tool",
            "arguments": {},
        })
        assert result.get("isError")

# tests/test_search.py:49-53
    def test_search_symbols(self, tmp_project: Path):
        search = self._build_search(tmp_project)
        results = search.search_symbols("User")
        assert len(results) > 0
        assert any(r["name"] == "User" for r in results)

# tests/test_tools.py:198-206
    async def test_registry_execute_unknown_tool(self, tmp_project: Path):
        builder = GraphBuilder()
        graph = builder.build_from_directory(tmp_project)
        query = GraphQuery(graph)
        search = HybridSearch(tmp_project, graph)
        registry = get_all_tools(tmp_project, graph, query, search)

        result = await registry.execute("nonexistent_tool", {})
        assert "Unknown tool" in result

# tests/test_search.py:32-37
    def test_search_context_lines(self, tmp_project: Path):
        search = self._build_search(tmp_project)
        results = search.search("calculate_total", context_lines=3)
        if results:
            # Should have context
            assert len(results[0].context_before) > 0 or len(results[0].context_after) > 0

# tests/conftest.py:9-9
import pytest

# tests/test_cli.py:7-7
import pytest