# tests/test_parser.py:39-119
class TestPythonParser:
    def test_parse_functions(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        assert result.language == "python"
        assert len(result.errors) == 0

        # Check functions are found
        func_names = [
            s.name for s in result.symbols if s.kind == SymbolKind.FUNCTION
        ]
        assert "create_processor" in func_names
        assert "run_pipeline" in func_names

    def test_parse_classes(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)

        class_names = [
            s.name for s in result.symbols if s.kind == SymbolKind.CLASS
        ]
        assert "BaseProcessor" in class_names
        assert "AdvancedProcessor" in class_names

    def test_parse_methods(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)

        methods = [s for s in result.symbols if s.kind == SymbolKind.METHOD]
        method_names = [m.name for m in methods]
        assert "__init__" in method_names
        assert "process" in method_names
        assert "_transform" in method_names
        assert "batch_process" in method_names

    def test_parse_imports(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        assert "os" in result.imports
        assert "typing.List" in result.imports
        assert "pathlib.Path" in result.imports

    def test_parse_constants(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        constants = [
            s for s in result.symbols if s.kind == SymbolKind.CONSTANT
        ]
        assert any(c.name == "CONSTANT_VALUE" for c in constants)

    def test_parse_inheritance(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        inherits = [
            r for r in result.relationships if r.kind == RelKind.INHERITS
        ]
        assert any("AdvancedProcessor" in r.source and "BaseProcessor" in r.target for r in inherits)

    def test_parse_calls(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        calls = [r for r in result.relationships if r.kind == RelKind.CALLS]
        # run_pipeline calls create_processor
        assert any(
            "run_pipeline" in r.source and "create_processor" in r.target
            for r in calls
        )

    def test_parse_docstrings(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        funcs = {s.name: s for s in result.symbols if s.kind in (SymbolKind.FUNCTION, SymbolKind.METHOD)}
        assert "Factory function" in funcs["create_processor"].docstring
        assert "Transform a single item" in funcs["_transform"].docstring

    def test_parse_contains_relationships(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        contains = [r for r in result.relationships if r.kind == RelKind.CONTAINS]
        # BaseProcessor should contain process, _transform, __init__
        assert any("BaseProcessor" in r.source and "process" in r.target for r in contains)

    def test_syntax_error_handling(self):
        result = parse_python_file("bad.py", "def broken(:\n  pass")
        assert len(result.errors) > 0

    def test_empty_file(self):
        result = parse_python_file("empty.py", "")
        assert result.language == "python"
        assert len(result.symbols) == 0

# tests/conftest.py:143-200
def sample_python_source() -> str:
    """Sample Python source code for parser testing."""
    return '''"""Sample module."""

import os
from typing import List, Optional
from pathlib import Path


CONSTANT_VALUE = 42


class BaseProcessor:
    """Base class for processors."""

    def __init__(self, name: str):
        self.name = name

    def process(self, data: List[str]) -> List[str]:
        """Process the data."""
        return [self._transform(item) for item in data]

    def _transform(self, item: str) -> str:
        """Transform a single item."""
        return item.strip()


class AdvancedProcessor(BaseProcessor):
    """Advanced processor with extra features."""

    def __init__(self, name: str, verbose: bool = False):
        super().__init__(name)
        self.verbose = verbose

    def process(self, data: List[str]) -> List[str]:
        """Process with logging."""
        if self.verbose:
            print(f"Processing {len(data)} items")
        return super().process(data)

    def batch_process(self, batches: List[List[str]]) -> List[List[str]]:
        """Process multiple batches."""
        return [self.process(batch) for batch in batches]


def create_processor(name: str, advanced: bool = False) -> BaseProcessor:
    """Factory function for creating processors."""
    if advanced:
        return AdvancedProcessor(name, verbose=True)
    return BaseProcessor(name)


def run_pipeline(items: List[str], processor_name: str = "default") -> List[str]:
    """Run the processing pipeline."""
    processor = create_processor(processor_name)
    result = processor.process(items)
    return result
'''

# tests/test_parser.py:155-158
    def test_auto_detect_python(self, sample_python_source: str):
        result = parse_file("sample.py", sample_python_source)
        assert result is not None
        assert result.language == "python"

# tests/test_parser.py:116-119
    def test_empty_file(self):
        result = parse_python_file("empty.py", "")
        assert result.language == "python"
        assert len(result.symbols) == 0

# tests/test_parser.py:91-98
    def test_parse_calls(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        calls = [r for r in result.relationships if r.kind == RelKind.CALLS]
        # run_pipeline calls create_processor
        assert any(
            "run_pipeline" in r.source and "create_processor" in r.target
            for r in calls
        )

# tests/test_parser.py:52-59
    def test_parse_classes(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)

        class_names = [
            s.name for s in result.symbols if s.kind == SymbolKind.CLASS
        ]
        assert "BaseProcessor" in class_names
        assert "AdvancedProcessor" in class_names

# tests/test_parser.py:61-69
    def test_parse_methods(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)

        methods = [s for s in result.symbols if s.kind == SymbolKind.METHOD]
        method_names = [m.name for m in methods]
        assert "__init__" in method_names
        assert "process" in method_names
        assert "_transform" in method_names
        assert "batch_process" in method_names

# tests/test_parser.py:71-75
    def test_parse_imports(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        assert "os" in result.imports
        assert "typing.List" in result.imports
        assert "pathlib.Path" in result.imports

# tests/test_parser.py:40-50
    def test_parse_functions(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        assert result.language == "python"
        assert len(result.errors) == 0

        # Check functions are found
        func_names = [
            s.name for s in result.symbols if s.kind == SymbolKind.FUNCTION
        ]
        assert "create_processor" in func_names
        assert "run_pipeline" in func_names

# tests/test_parser.py:77-82
    def test_parse_constants(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        constants = [
            s for s in result.symbols if s.kind == SymbolKind.CONSTANT
        ]
        assert any(c.name == "CONSTANT_VALUE" for c in constants)

# tests/test_parser.py:100-104
    def test_parse_docstrings(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        funcs = {s.name: s for s in result.symbols if s.kind in (SymbolKind.FUNCTION, SymbolKind.METHOD)}
        assert "Factory function" in funcs["create_processor"].docstring
        assert "Transform a single item" in funcs["_transform"].docstring

# tests/test_parser.py:84-89
    def test_parse_inheritance(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        inherits = [
            r for r in result.relationships if r.kind == RelKind.INHERITS
        ]
        assert any("AdvancedProcessor" in r.source and "BaseProcessor" in r.target for r in inherits)

# tests/test_parser.py:112-114
    def test_syntax_error_handling(self):
        result = parse_python_file("bad.py", "def broken(:\n  pass")
        assert len(result.errors) > 0

# tests/test_impact_bot.py:69-110
class TestDiffParser:
    def test_parse_modified_file(self):
        diffs = parse_diff(SAMPLE_DIFF)
        assert len(diffs) == 1
        assert diffs[0].path == "utils.py"
        assert diffs[0].status == "modified"
        assert len(diffs[0].hunks) == 2

    def test_parse_added_lines(self):
        diffs = parse_diff(SAMPLE_DIFF)
        assert diffs[0].added_lines > 0

    def test_parse_deleted_lines(self):
        diffs = parse_diff(SAMPLE_DIFF)
        assert diffs[0].deleted_lines > 0

    def test_parse_new_file(self):
        diffs = parse_diff(SAMPLE_DIFF_NEW_FILE)
        assert len(diffs) == 1
        assert diffs[0].status == "added"

    def test_parse_deleted_file(self):
        diffs = parse_diff(SAMPLE_DIFF_DELETED)
        assert len(diffs) == 1
        assert diffs[0].status == "deleted"

    def test_parse_multiple_files(self):
        combined = SAMPLE_DIFF + SAMPLE_DIFF_NEW_FILE
        diffs = parse_diff(combined)
        assert len(diffs) == 2

    def test_hunk_line_ranges(self):
        diffs = parse_diff(SAMPLE_DIFF)
        ranges = diffs[0].changed_line_ranges
        assert len(ranges) > 0
        for start, end in ranges:
            assert start > 0
            assert end >= start

    def test_parse_empty(self):
        diffs = parse_diff("")
        assert diffs == []

# tests/test_parser.py:154-167
class TestCoreParser:
    def test_auto_detect_python(self, sample_python_source: str):
        result = parse_file("sample.py", sample_python_source)
        assert result is not None
        assert result.language == "python"

    def test_auto_detect_javascript(self, sample_js_source: str):
        result = parse_file("app.js", sample_js_source)
        assert result is not None
        assert result.language == "javascript"

    def test_unsupported_file(self):
        result = parse_file("readme.md", "# Hello")
        assert result is None

# tests/test_parser.py:122-151
class TestJavaScriptParser:
    def test_parse_classes(self, sample_js_source: str):
        result = parse_file("app.js", sample_js_source)
        assert result is not None
        class_names = [s.name for s in result.symbols if s.kind == SymbolKind.CLASS]
        assert "UserService" in class_names

    def test_parse_functions(self, sample_js_source: str):
        result = parse_file("app.js", sample_js_source)
        assert result is not None
        func_names = [s.name for s in result.symbols if s.kind == SymbolKind.FUNCTION]
        assert "formatName" in func_names

    def test_parse_methods(self, sample_js_source: str):
        result = parse_file("app.js", sample_js_source)
        assert result is not None
        method_names = [s.name for s in result.symbols if s.kind == SymbolKind.METHOD]
        assert "getUser" in method_names
        assert "createUser" in method_names

    def test_parse_imports(self, sample_js_source: str):
        result = parse_file("app.js", sample_js_source)
        assert result is not None
        # tree-sitter captures import statements as raw text
        assert any("react" in imp for imp in result.imports)

    def test_typescript_detection(self):
        result = parse_file("app.ts", "const x: number = 1;")
        assert result is not None
        assert result.language == "typescript"

# src/cegraph/exceptions.py:12-13
class ParserError(CeGraphError):
    """Code parsing errors."""

# tests/test_parser.py:106-110
    def test_parse_contains_relationships(self, sample_python_source: str):
        result = parse_python_file("sample.py", sample_python_source)
        contains = [r for r in result.relationships if r.kind == RelKind.CONTAINS]
        # BaseProcessor should contain process, _transform, __init__
        assert any("BaseProcessor" in r.source and "process" in r.target for r in contains)

# src/cegraph/parser/python_parser.py:17-32
def parse_python_file(file_path: str, source: str | None = None) -> FileSymbols:
    """Parse a Python file and extract symbols and relationships."""
    if source is None:
        source = Path(file_path).read_text(encoding="utf-8", errors="replace")

    result = FileSymbols(file_path=file_path, language="python")

    try:
        tree = ast.parse(source, filename=file_path)
    except SyntaxError as e:
        result.errors.append(f"SyntaxError: {e}")
        return result

    lines = source.splitlines()
    _extract_from_module(tree, file_path, lines, result)
    return result

# tests/test_impact_bot.py:95-98
    def test_parse_multiple_files(self):
        combined = SAMPLE_DIFF + SAMPLE_DIFF_NEW_FILE
        diffs = parse_diff(combined)
        assert len(diffs) == 2

# tests/test_parser.py:13-15
    def test_python(self):
        assert detect_language("main.py") == "python"
        assert detect_language("types.pyi") == "python"

# src/cegraph/parser/python_parser.py:17-32
def parse_python_file(file_path: str, source: str | None = None) -> FileSymbols:
    """Parse a Python file and extract symbols and relationships."""
    if source is None:
        source = Path(file_path).read_text(encoding="utf-8", errors="replace")

    result = FileSymbols(file_path=file_path, language="python")

    try:
        tree = ast.parse(source, filename=file_path)
    except SyntaxError as e:
        result.errors.append(f"SyntaxError: {e}")
        return result

    lines = source.splitlines()
    _extract_from_module(tree, file_path, lines, result)
    return result

# src/cegraph/parser/__init__.py:4-4
from cegraph.parser.core import parse_file, parse_directory

# tests/test_impact_bot.py:108-110
    def test_parse_empty(self):
        diffs = parse_diff("")
        assert diffs == []

# tests/conftest.py:204-235
def sample_js_source() -> str:
    """Sample JavaScript source code for parser testing."""
    return '''import { useState, useEffect } from "react";
import axios from "axios";

const API_URL = "https://api.example.com";

export class UserService {
    constructor(baseUrl) {
        this.baseUrl = baseUrl;
    }

    async getUser(id) {
        const response = await axios.get(`${this.baseUrl}/users/${id}`);
        return response.data;
    }

    async createUser(data) {
        const response = await axios.post(`${this.baseUrl}/users`, data);
        return response.data;
    }
}

export function formatName(first, last) {
    return `${first} ${last}`;
}

export const fetchData = async (url) => {
    const response = await fetch(url);
    return response.json();
};
'''

# tests/conftest.py:13-139
def tmp_project(tmp_path: Path) -> Path:
    """Create a temporary project directory with sample Python files."""
    # Main module
    (tmp_path / "main.py").write_text('''"""Main application entry point."""

from utils import helper_function, calculate_total
from models import User, Order


def main():
    """Run the main application."""
    user = User("Alice", "alice@example.com")
    order = Order(user, items=["widget", "gadget"])
    total = calculate_total(order.items)
    result = helper_function(total)
    print(f"Order total: {result}")
    return result


def parse_arguments():
    """Parse command line arguments."""
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--verbose", action="store_true")
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_arguments()
    main()
''')

    # Utils module
    (tmp_path / "utils.py").write_text('''"""Utility functions."""

TAX_RATE = 0.08


def helper_function(value):
    """Apply formatting to a value."""
    return f"${value:.2f}"


def calculate_total(items):
    """Calculate total price for a list of items."""
    prices = {"widget": 9.99, "gadget": 24.99, "doohickey": 4.99}
    subtotal = sum(prices.get(item, 0) for item in items)
    tax = subtotal * TAX_RATE
    return subtotal + tax


def validate_email(email):
    """Validate an email address."""
    import re
    pattern = r"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$"
    return bool(re.match(pattern, email))
''')

    # Models module
    (tmp_path / "models.py").write_text('''"""Data models."""


class User:
    """Represents a user in the system."""

    def __init__(self, name: str, email: str):
        self.name = name
        self.email = email

    def display_name(self):
        """Get the display name."""
        return self.name.title()

    def is_valid(self):
        """Check if user data is valid."""
        from utils import validate_email
        return bool(self.name) and validate_email(self.email)


class Order:
    """Represents an order."""

    def __init__(self, user: User, items: list):
        self.user = user
        self.items = items

    def get_total(self):
        """Get the order total."""
        from utils import calculate_total
        return calculate_total(self.items)

    def summary(self):
        """Get order summary string."""
        total = self.get_total()
        return f"Order for {self.user.display_name()}: {len(self.items)} items, ${total:.2f}"
''')

    # A subdirectory with more files
    api_dir = tmp_path / "api"
    api_dir.mkdir()

    (api_dir / "__init__.py").write_text('"""API package."""\n')

    (api_dir / "routes.py").write_text('''"""API routes."""

from models import User, Order


def get_user(user_id):
    """Get a user by ID."""
    # Simulated database lookup
    return User("Test User", "test@example.com")


def create_order(user_id, items):
    """Create a new order."""
    user = get_user(user_id)
    order = Order(user, items)
    return {"total": order.get_total(), "summary": order.summary()}


def health_check():
    """Health check endpoint."""
    return {"status": "ok"}
''')

    return tmp_path

# tests/test_impact_bot.py:85-88
    def test_parse_new_file(self):
        diffs = parse_diff(SAMPLE_DIFF_NEW_FILE)
        assert len(diffs) == 1
        assert diffs[0].status == "added"

# tests/test_impact_bot.py:100-106
    def test_hunk_line_ranges(self):
        diffs = parse_diff(SAMPLE_DIFF)
        ranges = diffs[0].changed_line_ranges
        assert len(ranges) > 0
        for start, end in ranges:
            assert start > 0
            assert end >= start

# tests/test_parser.py:123-127
    def test_parse_classes(self, sample_js_source: str):
        result = parse_file("app.js", sample_js_source)
        assert result is not None
        class_names = [s.name for s in result.symbols if s.kind == SymbolKind.CLASS]
        assert "UserService" in class_names

# tests/test_parser.py:135-140
    def test_parse_methods(self, sample_js_source: str):
        result = parse_file("app.js", sample_js_source)
        assert result is not None
        method_names = [s.name for s in result.symbols if s.kind == SymbolKind.METHOD]
        assert "getUser" in method_names
        assert "createUser" in method_names

# tests/test_parser.py:142-146
    def test_parse_imports(self, sample_js_source: str):
        result = parse_file("app.js", sample_js_source)
        assert result is not None
        # tree-sitter captures import statements as raw text
        assert any("react" in imp for imp in result.imports)

# tests/test_parser.py:165-167
    def test_unsupported_file(self):
        result = parse_file("readme.md", "# Hello")
        assert result is None

# tests/test_impact_bot.py:77-79
    def test_parse_added_lines(self):
        diffs = parse_diff(SAMPLE_DIFF)
        assert diffs[0].added_lines > 0

# tests/test_impact_bot.py:90-93
    def test_parse_deleted_file(self):
        diffs = parse_diff(SAMPLE_DIFF_DELETED)
        assert len(diffs) == 1
        assert diffs[0].status == "deleted"

# tests/test_parser.py:129-133
    def test_parse_functions(self, sample_js_source: str):
        result = parse_file("app.js", sample_js_source)
        assert result is not None
        func_names = [s.name for s in result.symbols if s.kind == SymbolKind.FUNCTION]
        assert "formatName" in func_names

# tests/test_impact_bot.py:70-75
    def test_parse_modified_file(self):
        diffs = parse_diff(SAMPLE_DIFF)
        assert len(diffs) == 1
        assert diffs[0].path == "utils.py"
        assert diffs[0].status == "modified"
        assert len(diffs[0].hunks) == 2

# tests/test_impact_bot.py:81-83
    def test_parse_deleted_lines(self):
        diffs = parse_diff(SAMPLE_DIFF)
        assert diffs[0].deleted_lines > 0

# src/cegraph/tools/definitions.py:195-218
    def list_files(self, path: str = "", pattern: str = "") -> str:
        """List files in the repository."""
        target = self.root / path if path else self.root
        if not target.exists():
            return f"Path not found: {path}"

        try:
            target.resolve().relative_to(self.root.resolve())
        except ValueError:
            return f"Access denied: {path} is outside the project root"

        files = []
        if pattern:
            import fnmatch

            for p in sorted(target.rglob("*")):
                if p.is_file() and fnmatch.fnmatch(p.name, pattern):
                    files.append(str(p.relative_to(self.root)))
        else:
            for p in sorted(target.iterdir()):
                prefix = "d " if p.is_dir() else "f "
                files.append(prefix + str(p.relative_to(self.root)))

        return "\n".join(files) if files else "No files found"

# tests/test_parser.py:160-163
    def test_auto_detect_javascript(self, sample_js_source: str):
        result = parse_file("app.js", sample_js_source)
        assert result is not None
        assert result.language == "javascript"

# tests/test_parser.py:148-151
    def test_typescript_detection(self):
        result = parse_file("app.ts", "const x: number = 1;")
        assert result is not None
        assert result.language == "typescript"

# src/cegraph/parser/core.py:10-10
from cegraph.parser.models import FileSymbols, detect_language

# src/cegraph/parser/core.py:10-10
from cegraph.parser.models import FileSymbols, detect_language

# paper/experiments/baselines.py:52-111
def baseline_grep(
    repo_path: Path,
    task: str,
    budget: int,
    graph,
) -> BaselineResult:
    """Select all files containing any task keyword, truncate to budget."""
    start = time.time()

    keywords = set(re.findall(r"\b([A-Za-z_]\w{2,})\b", task))
    stop = {
        "the", "and", "for", "that", "this", "with", "from", "have",
        "fix", "bug", "add", "class", "function", "method", "file",
    }
    keywords -= stop

    matched_files: list[tuple[str, str]] = []
    for node_id, data in graph.nodes(data=True):
        if data.get("type") != "file":
            continue
        fp = data.get("path", "")
        full_path = repo_path / fp
        if not full_path.exists():
            continue
        try:
            content = full_path.read_text(encoding="utf-8", errors="replace")
        except OSError:
            continue
        if any(kw.lower() in content.lower() for kw in keywords):
            matched_files.append((fp, content))

    # Pack files until budget
    total_tokens = 0
    selected_content: list[str] = []
    files_used = 0
    for fp, content in matched_files:
        tokens = TokenEstimator.estimate(content)
        if total_tokens + tokens > budget:
            remaining = budget - total_tokens
            if remaining > 50:
                chars = int(remaining * TokenEstimator.CHARS_PER_TOKEN)
                selected_content.append(content[:chars])
                total_tokens += remaining
                files_used += 1
            break
        selected_content.append(content)
        total_tokens += tokens
        files_used += 1

    elapsed = (time.time() - start) * 1000

    return BaselineResult(
        method="grep",
        task=task,
        budget=budget,
        tokens_used=total_tokens,
        symbols_selected=0,
        files_included=files_used,
        assembly_time_ms=round(elapsed, 1),
    )

# paper/experiments/benchmark.py:816-828
def _apply_mutation(repo_path: Path, mutation: dict) -> str | None:
    """Apply a mutation to the repo. Returns original content for restoration."""
    if not mutation:
        return None
    file_path = repo_path / mutation["file"]
    if not file_path.exists():
        return None
    original = file_path.read_text()
    mutated = original.replace(mutation["original"], mutation["mutated"], 1)
    if mutated == original:
        return None  # mutation string not found
    file_path.write_text(mutated)
    return original

# src/cegraph/agent/loop.py:16-16
from cegraph.agent.prompts import get_system_prompt

# src/cegraph/context/engine.py:480-565
    def _expand_context(
        self, seeds: list[dict], config: dict
    ) -> list[dict]:
        """Pure Python context expansion via weighted BFS."""
        max_depth = config["max_depth"]
        min_score = config["min_score"]

        candidates: dict[str, dict] = {}

        for seed in seeds:
            sid = seed["symbol_id"]
            candidates[sid] = {
                "symbol_id": sid,
                "score": seed["score"],
                "depth": 0,
                "reason": seed["reason"],
                "via": [],
            }

        frontier = [(s["symbol_id"], s["score"], 0) for s in seeds]

        while frontier:
            next_frontier = []

            for node_id, parent_score, depth in frontier:
                if depth >= max_depth:
                    continue

                # Forward edges
                for succ in self.graph.successors(node_id):
                    edge_data = self.graph.edges[node_id, succ]
                    edge_kind = edge_data.get("kind", "")
                    succ_data = self.graph.nodes.get(succ, {})

                    if succ_data.get("type") != "symbol":
                        continue

                    weight = self._edge_weights.get(edge_kind, 0.3)
                    kind_mult = _KIND_WEIGHTS.get(succ_data.get("kind", ""), 0.5)
                    new_score = parent_score * weight * kind_mult

                    if new_score < min_score:
                        continue

                    if succ not in candidates or new_score > candidates[succ]["score"]:
                        node_name = self.graph.nodes.get(node_id, {}).get("name", node_id)
                        candidates[succ] = {
                            "symbol_id": succ,
                            "score": new_score,
                            "depth": depth + 1,
                            "reason": f"{edge_kind} from {node_name}",
                            "via": candidates.get(node_id, {}).get("via", []) + [node_id],
                        }
                        next_frontier.append((succ, new_score, depth + 1))

                # Backward edges (callers)
                if config.get("include_callers"):
                    for pred in self.graph.predecessors(node_id):
                        edge_data = self.graph.edges[pred, node_id]
                        edge_kind = edge_data.get("kind", "")
                        pred_data = self.graph.nodes.get(pred, {})

                        if pred_data.get("type") != "symbol":
                            continue

                        weight = self._edge_weights.get(edge_kind, 0.3) * 0.7
                        kind_mult = _KIND_WEIGHTS.get(pred_data.get("kind", ""), 0.5)
                        new_score = parent_score * weight * kind_mult

                        if new_score < min_score:
                            continue

                        if pred not in candidates or new_score > candidates[pred]["score"]:
                            node_name = self.graph.nodes.get(node_id, {}).get("name", node_id)
                            candidates[pred] = {
                                "symbol_id": pred,
                                "score": new_score,
                                "depth": depth + 1,
                                "reason": f"calls {node_name}",
                                "via": candidates.get(node_id, {}).get("via", []) + [node_id],
                            }
                            next_frontier.append((pred, new_score, depth + 1))

            frontier = next_frontier

        return list(candidates.values())

# src/cegraph/github/diff_parser.py:205-209
def get_pr_diff(root: Path) -> str:
    """Get the diff for the current PR (GitHub Actions context)."""
    import os
    base_ref = os.environ.get("GITHUB_BASE_REF", "main")
    return get_git_diff(root, base=f"origin/{base_ref}")

# src/cegraph/graph/builder.py:12-12
from cegraph.parser.models import FileSymbols, RelKind, Relationship, Symbol, SymbolKind

# src/cegraph/graph/builder.py:12-12
from cegraph.parser.models import FileSymbols, RelKind, Relationship, Symbol, SymbolKind