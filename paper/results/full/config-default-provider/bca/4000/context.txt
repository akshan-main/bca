# Codebase Context for: Default LLM provider is set to openai instead of anthropic, breaking configurations that rely on the anthropic default.
# 27 symbols from 13 files (~3,481 tokens, 87% of budget)

## paper/experiments/ablation.py
# Included because: graph expansion (depth 3)

# [class] AblationResult (relevance: 0.15, depth: 3)
  27 | class AblationResult:
  28 |     """Result of a single ablation run."""
  29 | 
  30 |     config_name: str
  31 |     task: str
  32 |     budget: int
  33 |     symbols_selected: int
  34 |     symbols_available: int
  35 |     tokens_used: int
  36 |     budget_used_pct: float
  37 |     assembly_time_ms: float
  38 |     selected_symbols: list[str] = field(default_factory=list)
  39 |     closure_violations: int = 0
  40 |     recall: float | None = None  # Set if ground-truth symbols provided

## paper/experiments/baselines.py
# Included because: graph expansion (depth 3)

# [class] BaselineResult (relevance: 0.23, depth: 3)
  34 | class BaselineResult:
  35 |     """Result of a single baseline run."""
  36 | 
  37 |     method: str
  38 |     task: str
  39 |     budget: int
  40 |     tokens_used: int
  41 |     symbols_selected: int
  42 |     files_included: int
  43 |     assembly_time_ms: float
  44 |     selected_symbols: list[str] = field(default_factory=list)
  45 |     recall: float | None = None

# [function] run_comparison (relevance: 0.33, depth: 3)
 381 | def run_comparison(
 382 |     repo_path: Path,
 383 |     task: str,
 384 |     budgets: list[int],
 385 |     ground_truth_symbols: list[str] | None = None,
 386 | ) -> list[BaselineResult]:
 387 |     """Run all baselines for a single task across budgets."""
 388 |     builder = GraphBuilder()
 389 |     graph = builder.build_from_directory(repo_path)
 390 |     query = GraphQuery(graph)
 391 | 
 392 |     results: list[BaselineResult] = []
 393 | 
 394 |     for budget in budgets:
 395 |         methods = [
 396 |             baseline_grep(repo_path, task, budget, graph),
 397 |             baseline_bm25(repo_path, task, budget, graph),
 398 |             baseline_repo_map(repo_path, task, budget, graph),
 399 |             baseline_unweighted_bfs(repo_path, task, budget, graph, query),
 400 |             run_bca(repo_path, task, budget, graph, query),
 401 |         ]
 402 | 
 403 |         for r in methods:
 404 |             # Compute recall if ground truth provided
 405 |             if ground_truth_symbols and r.selected_symbols:
 406 |                 hits = sum(
 407 |                     1 for gt in ground_truth_symbols
 408 |                     if any(gt in s or s in gt for s in r.selected_symbols)
 409 |                 )
 410 |                 r.recall = hits / len(ground_truth_symbols)
 411 |             results.append(r)
 412 | 
 413 |     return results

## paper/experiments/benchmark.py
# Included because: graph expansion (depth 2); graph expansion (depth 1)

# [function] _vector_score_tfidf (relevance: 0.43, depth: 1)
 381 | def _vector_score_tfidf(query: str, symbols: list[dict]) -> list[float]:
 382 |     """TF-IDF cosine similarity scoring."""
 383 |     import math
 384 |     from collections import Counter
 385 | 
 386 |     def tokenize(text: str) -> list[str]:
 387 |         return re.findall(r"\b\w+\b", text.lower())
 388 | 
 389 |     query_tokens = tokenize(query)
 390 |     doc_tokens = [tokenize(s["text"]) for s in symbols]
 391 | 
 392 |     # Build vocabulary
 393 |     all_docs = doc_tokens + [query_tokens]
 394 |     doc_freq: Counter[str] = Counter()
 395 |     for doc in all_docs:
 396 |         for token in set(doc):
 397 |             doc_freq[token] += 1
 398 | 
 399 |     n = len(all_docs)
 400 | 
 401 |     def tfidf_vector(tokens: list[str]) -> dict[str, float]:
 402 |         tf = Counter(tokens)
 403 |         vec = {}
 404 |         for term, count in tf.items():
 405 |             idf = math.log((n + 1) / (doc_freq.get(term, 0) + 1)) + 1
 406 |             vec[term] = count * idf
 407 |         return vec
 408 | 
 409 |     def cosine_sim(a: dict[str, float], b: dict[str, float]) -> float:
 410 |         common = set(a) & set(b)
 411 |         if not common:
 412 |             return 0.0
 413 |         dot = sum(a[k] * b[k] for k in common)
 414 |         norm_a = math.sqrt(sum(v * v for v in a.values()))
 415 |         norm_b = math.sqrt(sum(v * v for v in b.values()))
 416 |         if norm_a == 0 or norm_b == 0:
 417 |             return 0.0
 418 |         return dot / (norm_a * norm_b)
 419 | 
 420 |     query_vec = tfidf_vector(query_tokens)
 421 |     return [cosine_sim(query_vec, tfidf_vector(dt)) for dt in doc_tokens]

# [function] _vector_score_dense (relevance: 0.24, depth: 2)
 424 | def _vector_score_dense(query: str, symbols: list[dict]) -> list[float]:
 425 |     """Dense embedding scoring using sentence-transformers."""
 426 |     try:
 427 |         from sentence_transformers import SentenceTransformer
 428 |         import numpy as np
 429 |     except ImportError:
 430 |         print("sentence-transformers not installed, falling back to TF-IDF")
 431 |         return _vector_score_tfidf(query, symbols)
 432 | 
 433 |     model = SentenceTransformer("all-MiniLM-L6-v2")
 434 |     texts = [s["text"] for s in symbols]
 435 |     query_emb = model.encode([query], normalize_embeddings=True)
 436 |     doc_embs = model.encode(texts, normalize_embeddings=True, batch_size=64)
 437 |     scores = (doc_embs @ query_emb.T).flatten()
 438 |     return scores.tolist()

# [function] call_llm (relevance: 0.31, depth: 2)
 606 | async def call_llm(
 607 |     provider, context: str, task: str,
 608 | ) -> tuple[str, float, int, int]:
 609 |     """Call the LLM and return (response_text, time_ms, input_tokens, output_tokens)."""
 610 |     messages = [
 611 |         Message(role="system", content=SYSTEM_PROMPT),
 612 |         Message(role="user", content=build_prompt(context, task)),
 613 |     ]
 614 | 
 615 |     start = time.time()
 616 |     response: LLMResponse = await provider.complete(
 617 |         messages=messages,
 618 |         temperature=0.0,
 619 |         max_tokens=4096,
 620 |     )
 621 |     elapsed = (time.time() - start) * 1000
 622 | 
 623 |     input_tokens = response.usage.get("prompt_tokens", 0) or response.usage.get("input_tokens", 0)
 624 |     output_tokens = response.usage.get("completion_tokens", 0) or response.usage.get("output_tokens", 0)
 625 | 
 626 |     return (response.content, round(elapsed, 1), input_tokens, output_tokens)

## src/cegraph/cli.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [function] _get_project_root (relevance: 0.41, depth: 3)
  28 | def _get_project_root(path: str | None = None) -> Path:
  29 |     """Find the project root or error."""
  30 |     if path:
  31 |         root = Path(path).resolve()
  32 |         if not root.exists():
  33 |             console.error(f"Path does not exist: {path}")
  34 |             sys.exit(1)
  35 |         return root
  36 | 
  37 |     root = find_project_root()
  38 |     if root is None:
  39 |         console.error(
  40 |             "No CeGraph project found. Run 'cegraph init' first, "
  41 |             "or specify a path with --path."
  42 |         )
  43 |         sys.exit(1)
  44 |     return root

# [function] _load_graph (relevance: 0.39, depth: 3)
  47 | def _load_graph(root: Path):
  48 |     """Load the knowledge graph and related objects."""
  49 |     from cegraph.graph.store import GraphStore
  50 | 
  51 |     db_path = get_cegraph_dir(root) / GRAPH_DB_FILE
  52 |     store = GraphStore(db_path)
  53 |     graph = store.load()
  54 |     if graph is None:
  55 |         console.error("No index found. Run 'cegraph init' or 'cegraph reindex' first.")
  56 |         sys.exit(1)
  57 |     return graph, store

# [function] _do_index (relevance: 0.43, depth: 2)
 107 | def _do_index(root: Path, config: ProjectConfig):
 108 |     """Index the codebase and build the knowledge graph."""
 109 |     from cegraph.graph.builder import GraphBuilder
 110 |     from cegraph.graph.store import GraphStore
 111 | 
 112 |     builder = GraphBuilder()
 113 | 
 114 |     console.info("Scanning and parsing source files...")
 115 |     start_time = time.time()
 116 | 
 117 |     with console.indexing_progress() as progress:
 118 |         task = progress.add_task("Indexing...", total=None)
 119 |         file_count = 0
 120 | 
 121 |         def on_progress(file_path: str, current: int, total: int):
 122 |             nonlocal file_count
 123 |             file_count = total
 124 |             progress.update(task, total=total, completed=current, description=f"Parsing {file_path}")
 125 | 
 126 |         graph = builder.build_from_directory(root, config, on_progress)
 127 | 
 128 |     elapsed = time.time() - start_time
 129 |     stats = builder.get_stats()
 130 | 
 131 |     console.success(f"Indexed {stats.get('files', 0)} files in {elapsed:.1f}s")
 132 |     console.show_stats(stats)
 133 | 
 134 |     # Persist the graph
 135 |     db_path = get_cegraph_dir(root) / GRAPH_DB_FILE
 136 |     store = GraphStore(db_path)
 137 |     store.save(graph, metadata={"stats": stats, "root": str(root)})
 138 |     store.close()
 139 | 
 140 |     console.success(f"Knowledge graph saved to .cegraph/")

## src/cegraph/config.py
# Included because: matches 'set'

# [function] set_config_value (relevance: 0.40, depth: 0)
 125 | def set_config_value(config: ProjectConfig, key: str, value: Any) -> ProjectConfig:
 126 |     """Set a nested config value using dot notation (e.g., 'llm.provider')."""
 127 |     parts = key.split(".")
 128 |     data = config.model_dump()
 129 |     target = data
 130 |     for part in parts[:-1]:
 131 |         if part not in target or not isinstance(target[part], dict):
 132 |             raise KeyError(f"Invalid config key: {key}")
 133 |         target = target[part]
 134 |     if parts[-1] not in target:
 135 |         raise KeyError(f"Invalid config key: {key}")
 136 |     target[parts[-1]] = value
 137 |     return ProjectConfig(**data)

## src/cegraph/context/_native.py
# Included because: graph expansion (depth 1)

# [function] _load_library (relevance: 0.38, depth: 1)
  55 | def _load_library():
  56 |     """Load the native library, or return None."""
  57 |     global _lib, _lib_path
  58 | 
  59 |     if _lib is not None:
  60 |         return _lib
  61 | 
  62 |     path = _find_library()
  63 |     if path is None:
  64 |         return None
  65 | 
  66 |     try:
  67 |         lib = ctypes.CDLL(path)
  68 | 
  69 |         # Verify it's the right library
  70 |         lib.cag_is_available.restype = ctypes.c_int32
  71 |         if lib.cag_is_available() != 1:
  72 |             return None
  73 | 
  74 |         # Set up function signatures
  75 |         _setup_signatures(lib)
  76 | 
  77 |         _lib = lib
  78 |         _lib_path = path
  79 |         return lib
  80 |     except (OSError, AttributeError):
  81 |         return None

## src/cegraph/context/models.py
# Included because: graph expansion (depth 2); required dependency of estimate_lines

# [class] TokenEstimator (relevance: 0.13, depth: 3)
 159 | class TokenEstimator:
 160 |     """Estimate token counts for code."""
 161 | 
 162 |     # Rough heuristic: 1 token â‰ˆ 4 characters for code
 163 |     CHARS_PER_TOKEN = 4.0
 164 | 
 165 |     @classmethod
 166 |     def estimate(cls, text: str) -> int:
 167 |         """Estimate token count for a string."""
 168 |         return max(1, int(len(text) / cls.CHARS_PER_TOKEN))
 169 | 
 170 |     @classmethod
 171 |     def estimate_lines(cls, line_count: int, avg_line_length: int = 40) -> int:
 172 |         """Estimate tokens for a given number of lines."""
 173 |         return max(1, int(line_count * avg_line_length / cls.CHARS_PER_TOKEN))

# [method] TokenEstimator.estimate_lines (relevance: 0.27, depth: 2)
 171 |     def estimate_lines(cls, line_count: int, avg_line_length: int = 40) -> int:
 172 |         """Estimate tokens for a given number of lines."""
 173 |         return max(1, int(line_count * avg_line_length / cls.CHARS_PER_TOKEN))

## src/cegraph/exceptions.py
# Included because: graph expansion (depth 2); graph expansion (depth 3); required dependency of LLMError

# [class] CeGraphError (relevance: 0.10, depth: 4)
   4 | class CeGraphError(Exception):
   5 |     """Base exception for all CeGraph errors."""

# [class] LLMError (relevance: 0.20, depth: 3)
  20 | class LLMError(CeGraphError):
  21 |     """LLM provider errors."""

# [class] ProviderNotAvailable (relevance: 0.25, depth: 2)
  32 | class ProviderNotAvailable(LLMError):
  33 |     """Raised when an LLM provider's SDK is not installed."""
  34 | 
  35 |     def __init__(self, provider: str, package: str):
  36 |         super().__init__(
  37 |             f"Provider '{provider}' requires the '{package}' package. "
  38 |             f"Install it with: pip install cegraph[{provider}]"
  39 |         )

## src/cegraph/github/diff_parser.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [class] ChangedSymbol (relevance: 0.17, depth: 3)
  47 | class ChangedSymbol:
  48 |     """A symbol that was affected by the diff."""
  49 |     name: str
  50 |     qualified_name: str
  51 |     kind: str
  52 |     file_path: str
  53 |     line_start: int
  54 |     line_end: int
  55 |     change_type: str  # 'modified', 'added', 'deleted'
  56 |     lines_changed: int = 0

# [function] get_pr_diff (relevance: 0.21, depth: 2)
 205 | def get_pr_diff(root: Path) -> str:
 206 |     """Get the diff for the current PR (GitHub Actions context)."""
 207 |     import os
 208 |     base_ref = os.environ.get("GITHUB_BASE_REF", "main")
 209 |     return get_git_diff(root, base=f"origin/{base_ref}")

## src/cegraph/github/renderer.py
# Included because: graph expansion (depth 3)

# [function] _risk_badge (relevance: 0.23, depth: 3)
 137 | def _risk_badge(risk: float) -> tuple[str, str, str]:
 138 |     """Return (emoji, label, color) for a risk score."""
 139 |     if risk < 0.1:
 140 |         return ("ðŸŸ¢", "LOW", "green")
 141 |     elif risk < 0.2:
 142 |         return ("ðŸŸ¡", "LOW", "yellow")
 143 |     elif risk < 0.4:
 144 |         return ("ðŸŸ ", "MEDIUM", "orange")
 145 |     elif risk < 0.6:
 146 |         return ("ðŸ”´", "HIGH", "red")
 147 |     else:
 148 |         return ("â›”", "CRITICAL", "red")

# [function] _render_file_tree (relevance: 0.19, depth: 3)
 151 | def _render_file_tree(files: list[str]) -> list[str]:
 152 |     """Render a list of file paths as an ASCII tree."""
 153 |     if not files:
 154 |         return []
 155 | 
 156 |     # Build tree structure
 157 |     tree: dict = {}
 158 |     for fp in sorted(files):
 159 |         parts = fp.split("/")
 160 |         node = tree
 161 |         for part in parts:
 162 |             node = node.setdefault(part, {})
 163 | 
 164 |     lines: list[str] = []
 165 |     _render_tree_recursive(tree, "", lines, is_last=True, is_root=True)
 166 |     return lines

# [function] _footer (relevance: 0.15, depth: 3)
 192 | def _footer() -> str:
 193 |     return (
 194 |         "---\n"
 195 |         "*Powered by [CeGraph](https://github.com/cegraph-ai/cegraph) "
 196 |         "â€” CAG-driven code intelligence*"
 197 |     )

## src/cegraph/parser/models.py
# Included because: graph expansion (depth 2)

# [function] detect_language (relevance: 0.19, depth: 2)
 100 | def detect_language(file_path: str) -> str | None:
 101 |     """Detect programming language from file extension."""
 102 |     from pathlib import Path
 103 | 
 104 |     ext = Path(file_path).suffix.lower()
 105 |     return EXTENSION_LANGUAGE_MAP.get(ext)

## src/cegraph/parser/tree_sitter_parser.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [function] _get_language (relevance: 0.19, depth: 2)
  94 | def _get_language(lang: str):
  95 |     """Get a tree-sitter Language object for the given language."""
  96 |     from tree_sitter import Language
  97 | 
  98 |     module_name = _TS_LANGUAGE_MODULES.get(lang)
  99 |     if not module_name:
 100 |         raise ValueError(f"No tree-sitter grammar for language: {lang}")
 101 | 
 102 |     module = __import__(module_name)
 103 |     return Language(module.language())

# [function] _extract_name (relevance: 0.15, depth: 3)
 207 | def _extract_name(node, language: str) -> str:
 208 |     """Extract the name of a symbol from its tree-sitter node."""
 209 |     # Look for a name/identifier child
 210 |     for child in node.children:
 211 |         if child.type in ("identifier", "name", "type_identifier", "property_identifier"):
 212 |             return child.text.decode("utf-8")
 213 |     # For some languages, try named children
 214 |     name_child = node.child_by_field_name("name")
 215 |     if name_child:
 216 |         return name_child.text.decode("utf-8")
 217 |     return ""

# [function] _extract_ts_import (relevance: 0.15, depth: 3)
 250 | def _extract_ts_import(node, file_path: str, source: bytes, result: FileSymbols) -> None:
 251 |     """Extract import information from a tree-sitter node."""
 252 |     text = node.text.decode("utf-8")
 253 |     result.imports.append(text)

## src/cegraph/tools/registry.py
# Included because: required dependency of get; graph expansion (depth 1)

# [class] ToolRegistry (relevance: 0.27, depth: 2)
  11 | class ToolRegistry:
  12 |     """Registry that manages available agent tools.
  13 | 
  14 |     Tools are functions decorated with @tool that the LLM agent can call.
  15 |     """
  16 | 
  17 |     def __init__(self) -> None:
  18 |         self._tools: dict[str, Callable] = {}
  19 |         self._definitions: dict[str, ToolDefinition] = {}
  20 | 
  21 |     def register(self, func: Callable, definition: ToolDefinition) -> None:
  22 |         """Register a tool function with its definition."""
  23 |         self._tools[definition.name] = func
  24 |         self._definitions[definition.name] = definition
  25 | 
  26 |     def get(self, name: str) -> Callable | None:
  27 |         """Get a tool function by name."""
  28 |         return self._tools.get(name)
  29 | 
  30 |     def get_definition(self, name: str) -> ToolDefinition | None:
  31 |         """Get a tool definition by name."""
  32 |         return self._definitions.get(name)
  33 | 
  34 |     def list_tools(self) -> list[str]:
  35 |         """List all registered tool names."""
  36 |         return list(self._tools.keys())
  37 | 
  38 |     def get_definitions(self) -> list[ToolDefinition]:
  39 |         """Get all tool definitions (for passing to LLM)."""
  40 |         return list(self._definitions.values())
  41 | 
  42 |     async def execute(self, name: str, arguments: dict[str, Any]) -> str:
  43 |         """Execute a tool by name with the given arguments.
  44 | 
  45 |         Returns the result as a string.
  46 |         """
  47 |         func = self._tools.get(name)
  48 |         if func is None:
  49 |             return f"Error: Unknown tool '{name}'"
  50 | 
  51 |         try:
  52 |             if inspect.iscoroutinefunction(func):
  53 |                 result = await func(**arguments)
  54 |             else:
  55 |                 result = func(**arguments)
  56 |             return str(result) if result is not None else "Done."
  57 |         except Exception as e:
  58 |             return f"Error executing tool '{name}': {e}"

# [method] ToolRegistry.get (relevance: 0.51, depth: 1)
  26 |     def get(self, name: str) -> Callable | None:
  27 |         """Get a tool function by name."""
  28 |         return self._tools.get(name)
