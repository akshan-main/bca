# Codebase Context for: Default LLM provider is set to openai instead of anthropic, breaking configurations that rely on the anthropic default.
# 42 symbols from 15 files (~7,150 tokens, 89% of budget)

## paper/experiments/ablation.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [class] AblationResult (relevance: 0.15, depth: 3)
  27 | class AblationResult:
  28 |     """Result of a single ablation run."""
  29 | 
  30 |     config_name: str
  31 |     task: str
  32 |     budget: int
  33 |     symbols_selected: int
  34 |     symbols_available: int
  35 |     tokens_used: int
  36 |     budget_used_pct: float
  37 |     assembly_time_ms: float
  38 |     selected_symbols: list[str] = field(default_factory=list)
  39 |     closure_violations: int = 0
  40 |     recall: float | None = None  # Set if ground-truth symbols provided

# [function] main (relevance: 0.27, depth: 2)
 159 | def main():
 160 |     parser = argparse.ArgumentParser(description="BCA ablation study")
 161 |     parser.add_argument("--repo", required=True, help="Path to repository")
 162 |     parser.add_argument("--task", help="Single task description")
 163 |     parser.add_argument("--tasks-file", help="JSONL file with tasks")
 164 |     parser.add_argument(
 165 |         "--budgets", default="1000,2000,4000,8000",
 166 |         help="Comma-separated budget values",
 167 |     )
 168 |     parser.add_argument("--output", help="Output JSON file")
 169 |     parser.add_argument("--ground-truth", help="Comma-separated ground-truth symbol names")
 170 |     args = parser.parse_args()
 171 | 
 172 |     repo_path = Path(args.repo).resolve()
 173 |     budgets = [int(b) for b in args.budgets.split(",")]
 174 |     gt_symbols = args.ground_truth.split(",") if args.ground_truth else None
 175 | 
 176 |     tasks: list[dict] = []
 177 |     if args.task:
 178 |         tasks.append({"task": args.task, "ground_truth": gt_symbols})
 179 |     elif args.tasks_file:
 180 |         with open(args.tasks_file) as f:
 181 |             for line in f:
 182 |                 tasks.append(json.loads(line))
 183 |     else:
 184 |         parser.error("Provide --task or --tasks-file")
 185 | 
 186 |     all_results: list[AblationResult] = []
 187 |     for t in tasks:
 188 |         task_str = t["task"]
 189 |         gt = t.get("ground_truth", gt_symbols)
 190 |         print(f"\nTask: {task_str}")
 191 |         results = run_ablation(repo_path, task_str, budgets, gt)
 192 |         all_results.extend(results)
 193 |         print(format_results_table(results))
 194 | 
 195 |     if args.output:
 196 |         with open(args.output, "w") as f:
 197 |             json.dump([asdict(r) for r in all_results], f, indent=2)
 198 |         print(f"\nResults written to {args.output}")

## paper/experiments/baselines.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [class] BaselineResult (relevance: 0.23, depth: 3)
  34 | class BaselineResult:
  35 |     """Result of a single baseline run."""
  36 | 
  37 |     method: str
  38 |     task: str
  39 |     budget: int
  40 |     tokens_used: int
  41 |     symbols_selected: int
  42 |     files_included: int
  43 |     assembly_time_ms: float
  44 |     selected_symbols: list[str] = field(default_factory=list)
  45 |     recall: float | None = None

# [function] run_comparison (relevance: 0.33, depth: 3)
 381 | def run_comparison(
 382 |     repo_path: Path,
 383 |     task: str,
 384 |     budgets: list[int],
 385 |     ground_truth_symbols: list[str] | None = None,
 386 | ) -> list[BaselineResult]:
 387 |     """Run all baselines for a single task across budgets."""
 388 |     builder = GraphBuilder()
 389 |     graph = builder.build_from_directory(repo_path)
 390 |     query = GraphQuery(graph)
 391 | 
 392 |     results: list[BaselineResult] = []
 393 | 
 394 |     for budget in budgets:
 395 |         methods = [
 396 |             baseline_grep(repo_path, task, budget, graph),
 397 |             baseline_bm25(repo_path, task, budget, graph),
 398 |             baseline_repo_map(repo_path, task, budget, graph),
 399 |             baseline_unweighted_bfs(repo_path, task, budget, graph, query),
 400 |             run_bca(repo_path, task, budget, graph, query),
 401 |         ]
 402 | 
 403 |         for r in methods:
 404 |             # Compute recall if ground truth provided
 405 |             if ground_truth_symbols and r.selected_symbols:
 406 |                 hits = sum(
 407 |                     1 for gt in ground_truth_symbols
 408 |                     if any(gt in s or s in gt for s in r.selected_symbols)
 409 |                 )
 410 |                 r.recall = hits / len(ground_truth_symbols)
 411 |             results.append(r)
 412 | 
 413 |     return results

# [function] main (relevance: 0.27, depth: 2)
 444 | def main():
 445 |     parser = argparse.ArgumentParser(description="BCA baseline comparison")
 446 |     parser.add_argument("--repo", required=True, help="Path to repository")
 447 |     parser.add_argument("--task", help="Single task description")
 448 |     parser.add_argument("--tasks-file", help="JSONL file with tasks")
 449 |     parser.add_argument(
 450 |         "--budgets", default="1000,2000,4000,8000",
 451 |         help="Comma-separated budget values",
 452 |     )
 453 |     parser.add_argument("--output", help="Output JSON file")
 454 |     parser.add_argument("--ground-truth", help="Comma-separated ground-truth symbol names")
 455 |     args = parser.parse_args()
 456 | 
 457 |     repo_path = Path(args.repo).resolve()
 458 |     budgets = [int(b) for b in args.budgets.split(",")]
 459 |     gt_symbols = args.ground_truth.split(",") if args.ground_truth else None
 460 | 
 461 |     tasks: list[dict] = []
 462 |     if args.task:
 463 |         tasks.append({"task": args.task, "ground_truth": gt_symbols})
 464 |     elif args.tasks_file:
 465 |         with open(args.tasks_file) as f:
 466 |             for line in f:
 467 |                 tasks.append(json.loads(line))
 468 |     else:
 469 |         parser.error("Provide --task or --tasks-file")
 470 | 
 471 |     all_results: list[BaselineResult] = []
 472 |     for t in tasks:
 473 |         task_str = t["task"]
 474 |         gt = t.get("ground_truth", gt_symbols)
 475 |         print(f"\nTask: {task_str}")
 476 |         results = run_comparison(repo_path, task_str, budgets, gt)
 477 |         all_results.extend(results)
 478 |         print(format_comparison_table(results))
 479 | 
 480 |     if args.output:
 481 |         with open(args.output, "w") as f:
 482 |             json.dump([asdict(r) for r in all_results], f, indent=2)
 483 |         print(f"\nResults written to {args.output}")

## paper/experiments/benchmark.py
# Included because: matches 'openai'; graph expansion (depth 2); graph expansion (depth 1)

# [function] _vector_score_tfidf (relevance: 0.43, depth: 1)
 381 | def _vector_score_tfidf(query: str, symbols: list[dict]) -> list[float]:
 382 |     """TF-IDF cosine similarity scoring."""
 383 |     import math
 384 |     from collections import Counter
 385 | 
 386 |     def tokenize(text: str) -> list[str]:
 387 |         return re.findall(r"\b\w+\b", text.lower())
 388 | 
 389 |     query_tokens = tokenize(query)
 390 |     doc_tokens = [tokenize(s["text"]) for s in symbols]
 391 | 
 392 |     # Build vocabulary
 393 |     all_docs = doc_tokens + [query_tokens]
 394 |     doc_freq: Counter[str] = Counter()
 395 |     for doc in all_docs:
 396 |         for token in set(doc):
 397 |             doc_freq[token] += 1
 398 | 
 399 |     n = len(all_docs)
 400 | 
 401 |     def tfidf_vector(tokens: list[str]) -> dict[str, float]:
 402 |         tf = Counter(tokens)
 403 |         vec = {}
 404 |         for term, count in tf.items():
 405 |             idf = math.log((n + 1) / (doc_freq.get(term, 0) + 1)) + 1
 406 |             vec[term] = count * idf
 407 |         return vec
 408 | 
 409 |     def cosine_sim(a: dict[str, float], b: dict[str, float]) -> float:
 410 |         common = set(a) & set(b)
 411 |         if not common:
 412 |             return 0.0
 413 |         dot = sum(a[k] * b[k] for k in common)
 414 |         norm_a = math.sqrt(sum(v * v for v in a.values()))
 415 |         norm_b = math.sqrt(sum(v * v for v in b.values()))
 416 |         if norm_a == 0 or norm_b == 0:
 417 |             return 0.0
 418 |         return dot / (norm_a * norm_b)
 419 | 
 420 |     query_vec = tfidf_vector(query_tokens)
 421 |     return [cosine_sim(query_vec, tfidf_vector(dt)) for dt in doc_tokens]

# [function] _vector_score_dense (relevance: 0.24, depth: 2)
 424 | def _vector_score_dense(query: str, symbols: list[dict]) -> list[float]:
 425 |     """Dense embedding scoring using sentence-transformers."""
 426 |     try:
 427 |         from sentence_transformers import SentenceTransformer
 428 |         import numpy as np
 429 |     except ImportError:
 430 |         print("sentence-transformers not installed, falling back to TF-IDF")
 431 |         return _vector_score_tfidf(query, symbols)
 432 | 
 433 |     model = SentenceTransformer("all-MiniLM-L6-v2")
 434 |     texts = [s["text"] for s in symbols]
 435 |     query_emb = model.encode([query], normalize_embeddings=True)
 436 |     doc_embs = model.encode(texts, normalize_embeddings=True, batch_size=64)
 437 |     scores = (doc_embs @ query_emb.T).flatten()
 438 |     return scores.tolist()

# [function] _embedding_score_openai (relevance: 0.44, depth: 0)
 507 | def _embedding_score_openai(query_text: str, symbols: list[dict]) -> list[float]:
 508 |     """Score symbols using OpenAI text-embedding-3-small."""
 509 |     import math
 510 | 
 511 |     api_key = os.environ.get("OPENAI_API_KEY", "")
 512 |     if not api_key:
 513 |         print("  WARNING: OPENAI_API_KEY not set, falling back to TF-IDF for embedding")
 514 |         return _vector_score_tfidf(query_text, symbols)
 515 | 
 516 |     try:
 517 |         from openai import OpenAI
 518 |         client = OpenAI(api_key=api_key)
 519 | 
 520 |         texts = [s["text"] for s in symbols]
 521 |         # Batch embed (API limit ~2048 inputs per call)
 522 |         all_embeddings = []
 523 |         batch_size = 512
 524 |         for i in range(0, len(texts), batch_size):
 525 |             batch = texts[i:i + batch_size]
 526 |             resp = client.embeddings.create(
 527 |                 model="text-embedding-3-small",
 528 |                 input=batch,
 529 |             )
 530 |             all_embeddings.extend([d.embedding for d in resp.data])
 531 | 
 532 |         # Embed query
 533 |         q_resp = client.embeddings.create(
 534 |             model="text-embedding-3-small",
 535 |             input=[query_text],
 536 |         )
 537 |         q_emb = q_resp.data[0].embedding
 538 | 
 539 |         # Cosine similarity
 540 |         def cosine(a, b):
 541 |             dot = sum(x * y for x, y in zip(a, b))
 542 |             na = math.sqrt(sum(x * x for x in a))
 543 |             nb = math.sqrt(sum(x * x for x in b))
 544 |             if na == 0 or nb == 0:
 545 |                 return 0.0
 546 |             return dot / (na * nb)
 547 | 
 548 |         return [cosine(q_emb, emb) for emb in all_embeddings]
 549 | 
 550 |     except Exception as e:
 551 |         print(f"  WARNING: OpenAI embedding failed ({e}), falling back to TF-IDF")
 552 |         return _vector_score_tfidf(query_text, symbols)

# [function] call_llm (relevance: 0.31, depth: 2)
 606 | async def call_llm(
 607 |     provider, context: str, task: str,
 608 | ) -> tuple[str, float, int, int]:
 609 |     """Call the LLM and return (response_text, time_ms, input_tokens, output_tokens)."""
 610 |     messages = [
 611 |         Message(role="system", content=SYSTEM_PROMPT),
 612 |         Message(role="user", content=build_prompt(context, task)),
 613 |     ]
 614 | 
 615 |     start = time.time()
 616 |     response: LLMResponse = await provider.complete(
 617 |         messages=messages,
 618 |         temperature=0.0,
 619 |         max_tokens=4096,
 620 |     )
 621 |     elapsed = (time.time() - start) * 1000
 622 | 
 623 |     input_tokens = response.usage.get("prompt_tokens", 0) or response.usage.get("input_tokens", 0)
 624 |     output_tokens = response.usage.get("completion_tokens", 0) or response.usage.get("output_tokens", 0)
 625 | 
 626 |     return (response.content, round(elapsed, 1), input_tokens, output_tokens)

## src/cegraph/cli.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [function] _get_project_root (relevance: 0.41, depth: 3)
  28 | def _get_project_root(path: str | None = None) -> Path:
  29 |     """Find the project root or error."""
  30 |     if path:
  31 |         root = Path(path).resolve()
  32 |         if not root.exists():
  33 |             console.error(f"Path does not exist: {path}")
  34 |             sys.exit(1)
  35 |         return root
  36 | 
  37 |     root = find_project_root()
  38 |     if root is None:
  39 |         console.error(
  40 |             "No CeGraph project found. Run 'cegraph init' first, "
  41 |             "or specify a path with --path."
  42 |         )
  43 |         sys.exit(1)
  44 |     return root

# [function] _load_graph (relevance: 0.39, depth: 3)
  47 | def _load_graph(root: Path):
  48 |     """Load the knowledge graph and related objects."""
  49 |     from cegraph.graph.store import GraphStore
  50 | 
  51 |     db_path = get_cegraph_dir(root) / GRAPH_DB_FILE
  52 |     store = GraphStore(db_path)
  53 |     graph = store.load()
  54 |     if graph is None:
  55 |         console.error("No index found. Run 'cegraph init' or 'cegraph reindex' first.")
  56 |         sys.exit(1)
  57 |     return graph, store

# [function] _do_index (relevance: 0.43, depth: 2)
 107 | def _do_index(root: Path, config: ProjectConfig):
 108 |     """Index the codebase and build the knowledge graph."""
 109 |     from cegraph.graph.builder import GraphBuilder
 110 |     from cegraph.graph.store import GraphStore
 111 | 
 112 |     builder = GraphBuilder()
 113 | 
 114 |     console.info("Scanning and parsing source files...")
 115 |     start_time = time.time()
 116 | 
 117 |     with console.indexing_progress() as progress:
 118 |         task = progress.add_task("Indexing...", total=None)
 119 |         file_count = 0
 120 | 
 121 |         def on_progress(file_path: str, current: int, total: int):
 122 |             nonlocal file_count
 123 |             file_count = total
 124 |             progress.update(task, total=total, completed=current, description=f"Parsing {file_path}")
 125 | 
 126 |         graph = builder.build_from_directory(root, config, on_progress)
 127 | 
 128 |     elapsed = time.time() - start_time
 129 |     stats = builder.get_stats()
 130 | 
 131 |     console.success(f"Indexed {stats.get('files', 0)} files in {elapsed:.1f}s")
 132 |     console.show_stats(stats)
 133 | 
 134 |     # Persist the graph
 135 |     db_path = get_cegraph_dir(root) / GRAPH_DB_FILE
 136 |     store = GraphStore(db_path)
 137 |     store.save(graph, metadata={"stats": stats, "root": str(root)})
 138 |     store.close()
 139 | 
 140 |     console.success(f"Knowledge graph saved to .cegraph/")

# [function] impact_pr (relevance: 0.29, depth: 2)
 423 | def impact_pr(path: str | None, base: str, output_format: str):
 424 |     """Analyze PR impact and generate blast radius report.
 425 | 
 426 |     Parses the git diff, maps changes to symbols in the knowledge graph,
 427 |     and generates a detailed impact analysis.
 428 | 
 429 |     Usage in CI:
 430 | 
 431 |         cegraph impact-pr --format github-comment
 432 | 
 433 |     Local usage:
 434 | 
 435 |         cegraph impact-pr --base main --format markdown
 436 |     """
 437 |     root = _get_project_root(path)
 438 | 
 439 |     from cegraph.github.impact_bot import run_impact_analysis, post_github_comment
 440 | 
 441 |     import os
 442 |     is_pr = bool(os.environ.get("GITHUB_EVENT_PATH"))
 443 | 
 444 |     result = run_impact_analysis(root, base=base, is_pr=is_pr)
 445 | 
 446 |     if "error" in result:
 447 |         console.error(result["error"])
 448 |         sys.exit(1)
 449 | 
 450 |     if output_format == "json":
 451 |         click.echo(json.dumps(result, indent=2, default=str))
 452 |     elif output_format == "github-comment":
 453 |         click.echo(result["comment"])
 454 |         if is_pr:
 455 |             if post_github_comment(result["comment"]):
 456 |                 console.success("Posted impact comment to PR")
 457 |             else:
 458 |                 console.warning("Could not post comment (missing GITHUB_TOKEN or PR context)")
 459 |     else:
 460 |         click.echo(result["comment"])

## src/cegraph/config.py
# Included because: required dependency of api_key; graph expansion (depth 2); matches 'set'

# [import] BaseModel (relevance: 0.10, depth: 3)
  10 | from pydantic import BaseModel, Field

# [class] LLMConfig (relevance: 0.10, depth: 3)
  18 | class LLMConfig(BaseModel):
  19 |     """LLM provider configuration."""
  20 | 
  21 |     provider: str = "openai"
  22 |     model: str = "claude-sonnet-4-5-20250929"
  23 |     api_key_env: str = ""
  24 |     max_tokens: int = 4096
  25 |     temperature: float = 0.0
  26 |     base_url: str | None = None
  27 | 
  28 |     @property
  29 |     def api_key(self) -> str | None:
  30 |         if self.api_key_env:
  31 |             return os.environ.get(self.api_key_env)
  32 |         # Try common env vars
  33 |         env_map = {
  34 |             "openai": "OPENAI_API_KEY",
  35 |             "anthropic": "ANTHROPIC_API_KEY",
  36 |         }
  37 |         env_var = env_map.get(self.provider, "")
  38 |         return os.environ.get(env_var)

# [method] LLMConfig.api_key (relevance: 0.21, depth: 2)
  29 |     def api_key(self) -> str | None:
  30 |         if self.api_key_env:
  31 |             return os.environ.get(self.api_key_env)
  32 |         # Try common env vars
  33 |         env_map = {
  34 |             "openai": "OPENAI_API_KEY",
  35 |             "anthropic": "ANTHROPIC_API_KEY",
  36 |         }
  37 |         env_var = env_map.get(self.provider, "")
  38 |         return os.environ.get(env_var)

# [function] set_config_value (relevance: 0.40, depth: 0)
 125 | def set_config_value(config: ProjectConfig, key: str, value: Any) -> ProjectConfig:
 126 |     """Set a nested config value using dot notation (e.g., 'llm.provider')."""
 127 |     parts = key.split(".")
 128 |     data = config.model_dump()
 129 |     target = data
 130 |     for part in parts[:-1]:
 131 |         if part not in target or not isinstance(target[part], dict):
 132 |             raise KeyError(f"Invalid config key: {key}")
 133 |         target = target[part]
 134 |     if parts[-1] not in target:
 135 |         raise KeyError(f"Invalid config key: {key}")
 136 |     target[parts[-1]] = value
 137 |     return ProjectConfig(**data)

## src/cegraph/context/_native.py
# Included because: graph expansion (depth 2); graph expansion (depth 1); matches 'set'

# [function] _find_library (relevance: 0.24, depth: 2)
  27 | def _find_library() -> str | None:
  28 |     """Search for the compiled C++ library."""
  29 |     # Platform-specific extension
  30 |     system = platform.system()
  31 |     if system == "Darwin":
  32 |         ext = "dylib"
  33 |     elif system == "Windows":
  34 |         ext = "dll"
  35 |     else:
  36 |         ext = "so"
  37 | 
  38 |     name = f"cag_fast.{ext}"
  39 | 
  40 |     # Search locations (in priority order)
  41 |     search_dirs = [
  42 |         Path(__file__).parent,                          # Installed alongside Python code
  43 |         Path(__file__).parent.parent.parent.parent / "csrc",  # Development: csrc/
  44 |         Path.cwd() / "csrc",                           # Current directory
  45 |     ]
  46 | 
  47 |     for d in search_dirs:
  48 |         candidate = d / name
  49 |         if candidate.exists():
  50 |             return str(candidate)
  51 | 
  52 |     return None

# [function] _load_library (relevance: 0.38, depth: 1)
  55 | def _load_library():
  56 |     """Load the native library, or return None."""
  57 |     global _lib, _lib_path
  58 | 
  59 |     if _lib is not None:
  60 |         return _lib
  61 | 
  62 |     path = _find_library()
  63 |     if path is None:
  64 |         return None
  65 | 
  66 |     try:
  67 |         lib = ctypes.CDLL(path)
  68 | 
  69 |         # Verify it's the right library
  70 |         lib.cag_is_available.restype = ctypes.c_int32
  71 |         if lib.cag_is_available() != 1:
  72 |             return None
  73 | 
  74 |         # Set up function signatures
  75 |         _setup_signatures(lib)
  76 | 
  77 |         _lib = lib
  78 |         _lib_path = path
  79 |         return lib
  80 |     except (OSError, AttributeError):
  81 |         return None

# [function] _setup_signatures (relevance: 0.40, depth: 0)
  84 | def _setup_signatures(lib):
  85 |     """Define ctypes function signatures for type safety."""
  86 |     # Graph creation
  87 |     lib.cag_graph_create.argtypes = [ctypes.c_int32]
  88 |     lib.cag_graph_create.restype = ctypes.c_void_p
  89 | 
  90 |     lib.cag_graph_add_edge.argtypes = [ctypes.c_void_p, ctypes.c_int32, ctypes.c_int32, ctypes.c_float]
  91 |     lib.cag_graph_add_edge.restype = None
  92 | 
  93 |     lib.cag_graph_set_node_weight.argtypes = [ctypes.c_void_p, ctypes.c_int32, ctypes.c_float]
  94 |     lib.cag_graph_set_node_weight.restype = None
  95 | 
  96 |     lib.cag_graph_set_lines.argtypes = [ctypes.c_void_p, ctypes.c_int32, ctypes.c_int32, ctypes.c_int32]
  97 |     lib.cag_graph_set_lines.restype = None
  98 | 
  99 |     # Weighted BFS
 100 |     lib.cag_weighted_bfs.argtypes = [
 101 |         ctypes.c_void_p,                                    # graph
 102 |         ctypes.POINTER(ctypes.c_int32),                     # seed_nodes
 103 |         ctypes.POINTER(ctypes.c_float),                     # seed_scores
 104 |         ctypes.c_int32,                                     # num_seeds
 105 |         ctypes.c_int32,                                     # max_depth
 106 |         ctypes.c_float,                                     # min_score
 107 |         ctypes.c_float,                                     # backward_decay
 108 |         ctypes.POINTER(ctypes.c_int32),                     # out_nodes
 109 |         ctypes.POINTER(ctypes.c_float),                     # out_scores
 110 |         ctypes.POINTER(ctypes.c_int32),                     # out_depths
 111 |         ctypes.c_int32,                                     # max_results
 112 |     ]
 113 |     lib.cag_weighted_bfs.restype = ctypes.c_int32
 114 | 
 115 |     # Token estimation
 116 |     lib.cag_estimate_tokens.argtypes = [ctypes.c_char_p, ctypes.c_int32]
 117 |     lib.cag_estimate_tokens.restype = ctypes.c_int32
 118 | 
 119 |     # Topological sort
 120 |     lib.cag_topological_sort.argtypes = [
 121 |         ctypes.c_void_p,
 122 |         ctypes.POINTER(ctypes.c_int32),
 123 |         ctypes.c_int32,
 124 |         ctypes.POINTER(ctypes.c_int32),
 125 |     ]
 126 |     lib.cag_topological_sort.restype = ctypes.c_int32
 127 | 
 128 |     # Entity extraction
 129 |     lib.cag_extract_entities.argtypes = [
 130 |         ctypes.c_char_p,
 131 |         ctypes.c_int32,
 132 |         ctypes.POINTER(ctypes.c_int32),
 133 |         ctypes.POINTER(ctypes.c_int32),
 134 |         ctypes.POINTER(ctypes.c_int32),
 135 |         ctypes.c_int32,
 136 |     ]
 137 |     lib.cag_extract_entities.restype = ctypes.c_int32
 138 | 
 139 |     # Cleanup
 140 |     lib.cag_graph_destroy.argtypes = [ctypes.c_void_p]
 141 |     lib.cag_graph_destroy.restype = None
 142 | 
 143 |     # Version
 144 |     lib.cag_version.argtypes = []
 145 |     lib.cag_version.restype = ctypes.c_char_p

## src/cegraph/context/models.py
# Included because: graph expansion (depth 2); required dependency of estimate_lines

# [class] TokenEstimator (relevance: 0.13, depth: 3)
 159 | class TokenEstimator:
 160 |     """Estimate token counts for code."""
 161 | 
 162 |     # Rough heuristic: 1 token â‰ˆ 4 characters for code
 163 |     CHARS_PER_TOKEN = 4.0
 164 | 
 165 |     @classmethod
 166 |     def estimate(cls, text: str) -> int:
 167 |         """Estimate token count for a string."""
 168 |         return max(1, int(len(text) / cls.CHARS_PER_TOKEN))
 169 | 
 170 |     @classmethod
 171 |     def estimate_lines(cls, line_count: int, avg_line_length: int = 40) -> int:
 172 |         """Estimate tokens for a given number of lines."""
 173 |         return max(1, int(line_count * avg_line_length / cls.CHARS_PER_TOKEN))

# [method] TokenEstimator.estimate_lines (relevance: 0.27, depth: 2)
 171 |     def estimate_lines(cls, line_count: int, avg_line_length: int = 40) -> int:
 172 |         """Estimate tokens for a given number of lines."""
 173 |         return max(1, int(line_count * avg_line_length / cls.CHARS_PER_TOKEN))

## src/cegraph/exceptions.py
# Included because: graph expansion (depth 2); graph expansion (depth 3); required dependency of LLMError

# [class] CeGraphError (relevance: 0.10, depth: 4)
   4 | class CeGraphError(Exception):
   5 |     """Base exception for all CeGraph errors."""

# [class] LLMError (relevance: 0.20, depth: 3)
  20 | class LLMError(CeGraphError):
  21 |     """LLM provider errors."""

# [class] ProviderNotAvailable (relevance: 0.25, depth: 2)
  32 | class ProviderNotAvailable(LLMError):
  33 |     """Raised when an LLM provider's SDK is not installed."""
  34 | 
  35 |     def __init__(self, provider: str, package: str):
  36 |         super().__init__(
  37 |             f"Provider '{provider}' requires the '{package}' package. "
  38 |             f"Install it with: pip install cegraph[{provider}]"
  39 |         )

## src/cegraph/github/diff_parser.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [class] ChangedSymbol (relevance: 0.17, depth: 3)
  47 | class ChangedSymbol:
  48 |     """A symbol that was affected by the diff."""
  49 |     name: str
  50 |     qualified_name: str
  51 |     kind: str
  52 |     file_path: str
  53 |     line_start: int
  54 |     line_end: int
  55 |     change_type: str  # 'modified', 'added', 'deleted'
  56 |     lines_changed: int = 0

# [function] get_git_diff (relevance: 0.19, depth: 3)
 180 | def get_git_diff(root: Path, base: str = "main") -> str:
 181 |     """Get the git diff between the current branch and base."""
 182 |     try:
 183 |         result = subprocess.run(
 184 |             ["git", "diff", f"{base}...HEAD"],
 185 |             cwd=root,
 186 |             capture_output=True,
 187 |             text=True,
 188 |             timeout=30,
 189 |         )
 190 |         if result.returncode == 0:
 191 |             return result.stdout
 192 |         # Fallback: diff against base directly
 193 |         result = subprocess.run(
 194 |             ["git", "diff", base],
 195 |             cwd=root,
 196 |             capture_output=True,
 197 |             text=True,
 198 |             timeout=30,
 199 |         )
 200 |         return result.stdout
 201 |     except (subprocess.TimeoutExpired, FileNotFoundError):
 202 |         return ""

# [function] get_pr_diff (relevance: 0.21, depth: 2)
 205 | def get_pr_diff(root: Path) -> str:
 206 |     """Get the diff for the current PR (GitHub Actions context)."""
 207 |     import os
 208 |     base_ref = os.environ.get("GITHUB_BASE_REF", "main")
 209 |     return get_git_diff(root, base=f"origin/{base_ref}")

## src/cegraph/github/renderer.py
# Included because: graph expansion (depth 3)

# [function] _risk_badge (relevance: 0.23, depth: 3)
 137 | def _risk_badge(risk: float) -> tuple[str, str, str]:
 138 |     """Return (emoji, label, color) for a risk score."""
 139 |     if risk < 0.1:
 140 |         return ("ðŸŸ¢", "LOW", "green")
 141 |     elif risk < 0.2:
 142 |         return ("ðŸŸ¡", "LOW", "yellow")
 143 |     elif risk < 0.4:
 144 |         return ("ðŸŸ ", "MEDIUM", "orange")
 145 |     elif risk < 0.6:
 146 |         return ("ðŸ”´", "HIGH", "red")
 147 |     else:
 148 |         return ("â›”", "CRITICAL", "red")

# [function] _render_file_tree (relevance: 0.19, depth: 3)
 151 | def _render_file_tree(files: list[str]) -> list[str]:
 152 |     """Render a list of file paths as an ASCII tree."""
 153 |     if not files:
 154 |         return []
 155 | 
 156 |     # Build tree structure
 157 |     tree: dict = {}
 158 |     for fp in sorted(files):
 159 |         parts = fp.split("/")
 160 |         node = tree
 161 |         for part in parts:
 162 |             node = node.setdefault(part, {})
 163 | 
 164 |     lines: list[str] = []
 165 |     _render_tree_recursive(tree, "", lines, is_last=True, is_root=True)
 166 |     return lines

# [function] _footer (relevance: 0.15, depth: 3)
 192 | def _footer() -> str:
 193 |     return (
 194 |         "---\n"
 195 |         "*Powered by [CeGraph](https://github.com/cegraph-ai/cegraph) "
 196 |         "â€” CAG-driven code intelligence*"
 197 |     )

## src/cegraph/parser/models.py
# Included because: graph expansion (depth 2)

# [function] detect_language (relevance: 0.19, depth: 2)
 100 | def detect_language(file_path: str) -> str | None:
 101 |     """Detect programming language from file extension."""
 102 |     from pathlib import Path
 103 | 
 104 |     ext = Path(file_path).suffix.lower()
 105 |     return EXTENSION_LANGUAGE_MAP.get(ext)

## src/cegraph/parser/tree_sitter_parser.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [function] _get_language (relevance: 0.19, depth: 2)
  94 | def _get_language(lang: str):
  95 |     """Get a tree-sitter Language object for the given language."""
  96 |     from tree_sitter import Language
  97 | 
  98 |     module_name = _TS_LANGUAGE_MODULES.get(lang)
  99 |     if not module_name:
 100 |         raise ValueError(f"No tree-sitter grammar for language: {lang}")
 101 | 
 102 |     module = __import__(module_name)
 103 |     return Language(module.language())

# [function] _extract_name (relevance: 0.15, depth: 3)
 207 | def _extract_name(node, language: str) -> str:
 208 |     """Extract the name of a symbol from its tree-sitter node."""
 209 |     # Look for a name/identifier child
 210 |     for child in node.children:
 211 |         if child.type in ("identifier", "name", "type_identifier", "property_identifier"):
 212 |             return child.text.decode("utf-8")
 213 |     # For some languages, try named children
 214 |     name_child = node.child_by_field_name("name")
 215 |     if name_child:
 216 |         return name_child.text.decode("utf-8")
 217 |     return ""

# [function] _extract_ts_calls (relevance: 0.21, depth: 3)
 220 | def _extract_ts_calls(
 221 |     node, file_path: str, language: str, source: bytes,
 222 |     caller_id: str, call_types: list[str], result: FileSymbols
 223 | ) -> None:
 224 |     """Extract function calls from a tree-sitter node."""
 225 |     if node.type in call_types:
 226 |         # Get the function being called
 227 |         func_node = node.child_by_field_name("function")
 228 |         if func_node is None and node.children:
 229 |             func_node = node.children[0]
 230 |         if func_node:
 231 |             callee = func_node.text.decode("utf-8")
 232 |             # Clean up multiline callees
 233 |             callee = callee.split("(")[0].strip()
 234 |             if callee and len(callee) < 100:
 235 |                 result.relationships.append(
 236 |                     Relationship(
 237 |                         source=caller_id,
 238 |                         target=callee,
 239 |                         kind=RelKind.CALLS,
 240 |                         file_path=file_path,
 241 |                         line=node.start_point[0] + 1,
 242 |                     )
 243 |                 )
 244 |         return
 245 | 
 246 |     for child in node.children:
 247 |         _extract_ts_calls(child, file_path, language, source, caller_id, call_types, result)

# [function] _extract_ts_import (relevance: 0.15, depth: 3)
 250 | def _extract_ts_import(node, file_path: str, source: bytes, result: FileSymbols) -> None:
 251 |     """Extract import information from a tree-sitter node."""
 252 |     text = node.text.decode("utf-8")
 253 |     result.imports.append(text)

## src/cegraph/tools/definitions.py
# Included because: graph expansion (depth 2)

# [function] get_all_tools (relevance: 0.23, depth: 2)
 473 | def get_all_tools(
 474 |     root: Path,
 475 |     graph: nx.DiGraph,
 476 |     query: GraphQuery,
 477 |     search: HybridSearch,
 478 | ) -> ToolRegistry:
 479 |     """Create a ToolRegistry populated with all built-in tools."""
 480 |     tools = CeGraphTools(root, graph, query, search)
 481 |     registry = ToolRegistry()
 482 | 
 483 |     # Map tool definitions to their implementations
 484 |     impl_map = {
 485 |         "search_code": tools.search_code,
 486 |         "search_symbols": tools.search_symbols,
 487 |         "who_calls": tools.who_calls,
 488 |         "what_calls": tools.what_calls,
 489 |         "impact_of": tools.impact_of,
 490 |         "read_file": tools.read_file,
 491 |         "edit_file": tools.edit_file,
 492 |         "write_file": tools.write_file,
 493 |         "list_files": tools.list_files,
 494 |         "get_context": tools.get_context,
 495 |         "get_structure": tools.get_structure,
 496 |         "run_command": tools.run_command,
 497 |     }
 498 | 
 499 |     for defn in _TOOL_DEFINITIONS:
 500 |         func = impl_map.get(defn.name)
 501 |         if func:
 502 |             registry.register(func, defn)
 503 | 
 504 |     return registry

## src/cegraph/tools/registry.py
# Included because: required dependency of get; graph expansion (depth 1)

# [class] ToolRegistry (relevance: 0.27, depth: 2)
  11 | class ToolRegistry:
  12 |     """Registry that manages available agent tools.
  13 | 
  14 |     Tools are functions decorated with @tool that the LLM agent can call.
  15 |     """
  16 | 
  17 |     def __init__(self) -> None:
  18 |         self._tools: dict[str, Callable] = {}
  19 |         self._definitions: dict[str, ToolDefinition] = {}
  20 | 
  21 |     def register(self, func: Callable, definition: ToolDefinition) -> None:
  22 |         """Register a tool function with its definition."""
  23 |         self._tools[definition.name] = func
  24 |         self._definitions[definition.name] = definition
  25 | 
  26 |     def get(self, name: str) -> Callable | None:
  27 |         """Get a tool function by name."""
  28 |         return self._tools.get(name)
  29 | 
  30 |     def get_definition(self, name: str) -> ToolDefinition | None:
  31 |         """Get a tool definition by name."""
  32 |         return self._definitions.get(name)
  33 | 
  34 |     def list_tools(self) -> list[str]:
  35 |         """List all registered tool names."""
  36 |         return list(self._tools.keys())
  37 | 
  38 |     def get_definitions(self) -> list[ToolDefinition]:
  39 |         """Get all tool definitions (for passing to LLM)."""
  40 |         return list(self._definitions.values())
  41 | 
  42 |     async def execute(self, name: str, arguments: dict[str, Any]) -> str:
  43 |         """Execute a tool by name with the given arguments.
  44 | 
  45 |         Returns the result as a string.
  46 |         """
  47 |         func = self._tools.get(name)
  48 |         if func is None:
  49 |             return f"Error: Unknown tool '{name}'"
  50 | 
  51 |         try:
  52 |             if inspect.iscoroutinefunction(func):
  53 |                 result = await func(**arguments)
  54 |             else:
  55 |                 result = func(**arguments)
  56 |             return str(result) if result is not None else "Done."
  57 |         except Exception as e:
  58 |             return f"Error executing tool '{name}': {e}"

# [method] ToolRegistry.get (relevance: 0.51, depth: 1)
  26 |     def get(self, name: str) -> Callable | None:
  27 |         """Get a tool function by name."""
  28 |         return self._tools.get(name)

## tests/test_mcp.py
# Included because: graph expansion (depth 2); required dependency of test_resources_read_valid_file

# [class] TestMCPSecurity (relevance: 0.10, depth: 3)
 170 | class TestMCPSecurity:
 171 |     def test_resources_read_path_traversal(self, mcp_server: MCPServer):
 172 |         """Regression: reading files outside the project root must be denied."""
 173 |         result = mcp_server._dispatch("resources/read", {
 174 |             "uri": "file://../../../../etc/hosts",
 175 |         })
 176 |         text = result["contents"][0].get("text", "")
 177 |         assert "Access denied" in text
 178 |         assert "localhost" not in text
 179 | 
 180 |     def test_resources_read_valid_file(self, mcp_server: MCPServer):
 181 |         """Reading a file inside the project root should work."""
 182 |         result = mcp_server._dispatch("resources/read", {
 183 |             "uri": "file://main.py",
 184 |         })
 185 |         text = result["contents"][0].get("text", "")
 186 |         assert "Access denied" not in text

# [method] TestMCPSecurity.test_resources_read_path_traversal (relevance: 0.20, depth: 2)
 171 |     def test_resources_read_path_traversal(self, mcp_server: MCPServer):
 172 |         """Regression: reading files outside the project root must be denied."""
 173 |         result = mcp_server._dispatch("resources/read", {
 174 |             "uri": "file://../../../../etc/hosts",
 175 |         })
 176 |         text = result["contents"][0].get("text", "")
 177 |         assert "Access denied" in text
 178 |         assert "localhost" not in text

# [method] TestMCPSecurity.test_resources_read_valid_file (relevance: 0.20, depth: 2)
 180 |     def test_resources_read_valid_file(self, mcp_server: MCPServer):
 181 |         """Reading a file inside the project root should work."""
 182 |         result = mcp_server._dispatch("resources/read", {
 183 |             "uri": "file://main.py",
 184 |         })
 185 |         text = result["contents"][0].get("text", "")
 186 |         assert "Access denied" not in text
