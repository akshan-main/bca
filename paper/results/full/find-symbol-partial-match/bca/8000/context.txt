# Codebase Context for: GraphQuery.find_symbol no longer finds symbols by partial name match â€” only exact matches work.
# 42 symbols from 14 files (~7,123 tokens, 89% of budget)

## paper/experiments/ablation.py
# Included because: graph expansion (depth 3)

# [class] AblationResult (relevance: 0.32, depth: 3)
  27 | class AblationResult:
  28 |     """Result of a single ablation run."""
  29 | 
  30 |     config_name: str
  31 |     task: str
  32 |     budget: int
  33 |     symbols_selected: int
  34 |     symbols_available: int
  35 |     tokens_used: int
  36 |     budget_used_pct: float
  37 |     assembly_time_ms: float
  38 |     selected_symbols: list[str] = field(default_factory=list)
  39 |     closure_violations: int = 0
  40 |     recall: float | None = None  # Set if ground-truth symbols provided

## paper/experiments/baselines.py
# Included because: graph expansion (depth 3)

# [class] BaselineResult (relevance: 0.40, depth: 3)
  34 | class BaselineResult:
  35 |     """Result of a single baseline run."""
  36 | 
  37 |     method: str
  38 |     task: str
  39 |     budget: int
  40 |     tokens_used: int
  41 |     symbols_selected: int
  42 |     files_included: int
  43 |     assembly_time_ms: float
  44 |     selected_symbols: list[str] = field(default_factory=list)
  45 |     recall: float | None = None

## paper/experiments/benchmark.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [function] _vector_score_dense (relevance: 0.34, depth: 3)
 424 | def _vector_score_dense(query: str, symbols: list[dict]) -> list[float]:
 425 |     """Dense embedding scoring using sentence-transformers."""
 426 |     try:
 427 |         from sentence_transformers import SentenceTransformer
 428 |         import numpy as np
 429 |     except ImportError:
 430 |         print("sentence-transformers not installed, falling back to TF-IDF")
 431 |         return _vector_score_tfidf(query, symbols)
 432 | 
 433 |     model = SentenceTransformer("all-MiniLM-L6-v2")
 434 |     texts = [s["text"] for s in symbols]
 435 |     query_emb = model.encode([query], normalize_embeddings=True)
 436 |     doc_embs = model.encode(texts, normalize_embeddings=True, batch_size=64)
 437 |     scores = (doc_embs @ query_emb.T).flatten()
 438 |     return scores.tolist()

# [function] build_prompt (relevance: 0.32, depth: 3)
 591 | def build_prompt(context: str, task: str) -> str:
 592 |     """Build the user prompt from assembled context and task."""
 593 |     return f"""## Source Code Context
 594 | 
 595 | {context}
 596 | 
 597 | ## Bug Report
 598 | 
 599 | {task}
 600 | 
 601 | ## Fix
 602 | 
 603 | Produce SEARCH/REPLACE blocks to fix this bug."""

# [function] call_llm (relevance: 0.47, depth: 2)
 606 | async def call_llm(
 607 |     provider, context: str, task: str,
 608 | ) -> tuple[str, float, int, int]:
 609 |     """Call the LLM and return (response_text, time_ms, input_tokens, output_tokens)."""
 610 |     messages = [
 611 |         Message(role="system", content=SYSTEM_PROMPT),
 612 |         Message(role="user", content=build_prompt(context, task)),
 613 |     ]
 614 | 
 615 |     start = time.time()
 616 |     response: LLMResponse = await provider.complete(
 617 |         messages=messages,
 618 |         temperature=0.0,
 619 |         max_tokens=4096,
 620 |     )
 621 |     elapsed = (time.time() - start) * 1000
 622 | 
 623 |     input_tokens = response.usage.get("prompt_tokens", 0) or response.usage.get("input_tokens", 0)
 624 |     output_tokens = response.usage.get("completion_tokens", 0) or response.usage.get("output_tokens", 0)
 625 | 
 626 |     return (response.content, round(elapsed, 1), input_tokens, output_tokens)

## src/cegraph/cli.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [function] _get_project_root (relevance: 0.61, depth: 3)
  28 | def _get_project_root(path: str | None = None) -> Path:
  29 |     """Find the project root or error."""
  30 |     if path:
  31 |         root = Path(path).resolve()
  32 |         if not root.exists():
  33 |             console.error(f"Path does not exist: {path}")
  34 |             sys.exit(1)
  35 |         return root
  36 | 
  37 |     root = find_project_root()
  38 |     if root is None:
  39 |         console.error(
  40 |             "No CeGraph project found. Run 'cegraph init' first, "
  41 |             "or specify a path with --path."
  42 |         )
  43 |         sys.exit(1)
  44 |     return root

# [function] _load_graph (relevance: 0.59, depth: 3)
  47 | def _load_graph(root: Path):
  48 |     """Load the knowledge graph and related objects."""
  49 |     from cegraph.graph.store import GraphStore
  50 | 
  51 |     db_path = get_cegraph_dir(root) / GRAPH_DB_FILE
  52 |     store = GraphStore(db_path)
  53 |     graph = store.load()
  54 |     if graph is None:
  55 |         console.error("No index found. Run 'cegraph init' or 'cegraph reindex' first.")
  56 |         sys.exit(1)
  57 |     return graph, store

# [function] reindex (relevance: 0.28, depth: 3)
 100 | def reindex(path: str | None):
 101 |     """Rebuild the knowledge graph from scratch."""
 102 |     root = _get_project_root(path)
 103 |     config = load_config(root)
 104 |     _do_index(root, config)

# [function] status (relevance: 0.40, depth: 3)
 145 | def status(path: str | None):
 146 |     """Show the current index status and graph statistics."""
 147 |     root = _get_project_root(path)
 148 |     graph, store = _load_graph(root)
 149 | 
 150 |     stats = store.get_metadata("stats")
 151 |     if stats:
 152 |         console.banner()
 153 |         console.info(f"Project: {root.name}")
 154 |         console.show_stats(stats)
 155 |     else:
 156 |         from cegraph.graph.builder import GraphBuilder
 157 | 
 158 |         b = GraphBuilder()
 159 |         b.graph = graph
 160 |         console.show_stats(b.get_stats())
 161 |     store.close()

# [function] search (relevance: 0.66, depth: 2)
 168 | def search(query: str, path: str | None, kind: str):
 169 |     """Search for code or symbols in the repository."""
 170 |     root = _get_project_root(path)
 171 |     graph, store = _load_graph(root)
 172 | 
 173 |     from cegraph.search.hybrid import HybridSearch
 174 | 
 175 |     search_engine = HybridSearch(root, graph)
 176 | 
 177 |     # Try symbol search first
 178 |     symbol_results = search_engine.search_symbols(query, kind=kind)
 179 |     if symbol_results:
 180 |         console.info(f"Found {len(symbol_results)} symbol(s) matching '{query}':")
 181 |         console.show_search_results(symbol_results)
 182 |     else:
 183 |         console.info(f"No symbol definitions found for '{query}', searching code...")
 184 |         code_results = search_engine.search(query)
 185 |         if code_results:
 186 |             for r in code_results:
 187 |                 console.console.print(
 188 |                     f"  [cyan]{r.file_path}:{r.line_number}[/cyan] {r.line_content.strip()}"
 189 |                 )
 190 |                 if r.symbol_name:
 191 |                     console.console.print(f"    [dim]in {r.symbol_name}[/dim]")
 192 |         else:
 193 |             console.warning(f"No results found for '{query}'")
 194 | 
 195 |     store.close()

# [function] who_calls (relevance: 0.64, depth: 2)
 202 | def who_calls(symbol_name: str, path: str | None, depth: int):
 203 |     """Find all callers of a function or method."""
 204 |     root = _get_project_root(path)
 205 |     graph, store = _load_graph(root)
 206 | 
 207 |     from cegraph.graph.query import GraphQuery
 208 | 
 209 |     query = GraphQuery(graph, store)
 210 |     callers = query.who_calls(symbol_name, max_depth=depth)
 211 | 
 212 |     if callers:
 213 |         console.info(f"Callers of '{symbol_name}':")
 214 |         console.show_callers(callers, symbol_name)
 215 |     else:
 216 |         console.warning(f"No callers found for '{symbol_name}'")
 217 | 
 218 |     store.close()

# [function] impact (relevance: 0.48, depth: 2)
 224 | def impact(symbol_name: str, path: str | None):
 225 |     """Analyze the blast radius of changing a symbol."""
 226 |     root = _get_project_root(path)
 227 |     graph, store = _load_graph(root)
 228 | 
 229 |     from cegraph.graph.query import GraphQuery
 230 | 
 231 |     query = GraphQuery(graph, store)
 232 |     result = query.impact_of(symbol_name)
 233 |     console.show_impact(result)
 234 | 
 235 |     store.close()

# [function] ask (relevance: 0.29, depth: 3)
 504 | def ask(question: str, path: str | None):
 505 |     """Ask a question about the codebase (uses LLM + knowledge graph)."""
 506 |     root = _get_project_root(path)
 507 |     config = load_config(root)
 508 |     graph, store = _load_graph(root)
 509 | 
 510 |     _run_agent(root, config, graph, store, question, agent_mode=False)

# [function] agent (relevance: 0.29, depth: 3)
 517 | def agent(task: str, path: str | None, auto: bool):
 518 |     """Run an agentic task (coding, debugging, refactoring)."""
 519 |     root = _get_project_root(path)
 520 |     config = load_config(root)
 521 |     graph, store = _load_graph(root)
 522 | 
 523 |     _run_agent(root, config, graph, store, task, agent_mode=True, auto_approve=auto)

## src/cegraph/config.py
# Included because: required dependency of FileSymbols

# [import] BaseModel (relevance: 0.20, depth: 1)
  10 | from pydantic import BaseModel, Field

## src/cegraph/context/models.py
# Included because: required dependency of estimate; graph expansion (depth 3)

# [class] TokenEstimator (relevance: 0.23, depth: 4)
 159 | class TokenEstimator:
 160 |     """Estimate token counts for code."""
 161 | 
 162 |     # Rough heuristic: 1 token â‰ˆ 4 characters for code
 163 |     CHARS_PER_TOKEN = 4.0
 164 | 
 165 |     @classmethod
 166 |     def estimate(cls, text: str) -> int:
 167 |         """Estimate token count for a string."""
 168 |         return max(1, int(len(text) / cls.CHARS_PER_TOKEN))
 169 | 
 170 |     @classmethod
 171 |     def estimate_lines(cls, line_count: int, avg_line_length: int = 40) -> int:
 172 |         """Estimate tokens for a given number of lines."""
 173 |         return max(1, int(line_count * avg_line_length / cls.CHARS_PER_TOKEN))

# [method] TokenEstimator.estimate (relevance: 0.47, depth: 3)
 166 |     def estimate(cls, text: str) -> int:
 167 |         """Estimate token count for a string."""
 168 |         return max(1, int(len(text) / cls.CHARS_PER_TOKEN))

## src/cegraph/github/diff_parser.py
# Included because: graph expansion (depth 2); graph expansion (depth 3)

# [class] DiffHunk (relevance: 0.26, depth: 2)
  18 | class DiffHunk:
  19 |     """A single hunk from a unified diff."""
  20 |     old_start: int
  21 |     old_count: int
  22 |     new_start: int
  23 |     new_count: int
  24 |     lines: list[str] = field(default_factory=list)

# [class] ChangedSymbol (relevance: 0.42, depth: 3)
  47 | class ChangedSymbol:
  48 |     """A symbol that was affected by the diff."""
  49 |     name: str
  50 |     qualified_name: str
  51 |     kind: str
  52 |     file_path: str
  53 |     line_start: int
  54 |     line_end: int
  55 |     change_type: str  # 'modified', 'added', 'deleted'
  56 |     lines_changed: int = 0

# [function] get_pr_diff (relevance: 0.51, depth: 2)
 205 | def get_pr_diff(root: Path) -> str:
 206 |     """Get the diff for the current PR (GitHub Actions context)."""
 207 |     import os
 208 |     base_ref = os.environ.get("GITHUB_BASE_REF", "main")
 209 |     return get_git_diff(root, base=f"origin/{base_ref}")

## src/cegraph/github/renderer.py
# Included because: graph expansion (depth 3)

# [function] _risk_badge (relevance: 0.40, depth: 3)
 137 | def _risk_badge(risk: float) -> tuple[str, str, str]:
 138 |     """Return (emoji, label, color) for a risk score."""
 139 |     if risk < 0.1:
 140 |         return ("ðŸŸ¢", "LOW", "green")
 141 |     elif risk < 0.2:
 142 |         return ("ðŸŸ¡", "LOW", "yellow")
 143 |     elif risk < 0.4:
 144 |         return ("ðŸŸ ", "MEDIUM", "orange")
 145 |     elif risk < 0.6:
 146 |         return ("ðŸ”´", "HIGH", "red")
 147 |     else:
 148 |         return ("â›”", "CRITICAL", "red")

# [function] _render_file_tree (relevance: 0.36, depth: 3)
 151 | def _render_file_tree(files: list[str]) -> list[str]:
 152 |     """Render a list of file paths as an ASCII tree."""
 153 |     if not files:
 154 |         return []
 155 | 
 156 |     # Build tree structure
 157 |     tree: dict = {}
 158 |     for fp in sorted(files):
 159 |         parts = fp.split("/")
 160 |         node = tree
 161 |         for part in parts:
 162 |             node = node.setdefault(part, {})
 163 | 
 164 |     lines: list[str] = []
 165 |     _render_tree_recursive(tree, "", lines, is_last=True, is_root=True)
 166 |     return lines

# [function] _footer (relevance: 0.32, depth: 3)
 192 | def _footer() -> str:
 193 |     return (
 194 |         "---\n"
 195 |         "*Powered by [CeGraph](https://github.com/cegraph-ai/cegraph) "
 196 |         "â€” CAG-driven code intelligence*"
 197 |     )

## src/cegraph/graph/query.py
# Included because: matches 'find_symbol'; graph expansion (depth 2); graph expansion (depth 1); matches 'GraphQuery'

# [class] SymbolInfo (relevance: 0.67, depth: 2)
  13 | class SymbolInfo:
  14 |     """Rich information about a symbol."""
  15 | 
  16 |     id: str
  17 |     name: str
  18 |     qualified_name: str
  19 |     kind: str
  20 |     file_path: str
  21 |     line_start: int
  22 |     line_end: int
  23 |     signature: str
  24 |     docstring: str = ""
  25 |     callers: list[str] = field(default_factory=list)
  26 |     callees: list[str] = field(default_factory=list)
  27 |     children: list[str] = field(default_factory=list)
  28 |     parent: str = ""

# [class] GraphQuery (relevance: 1.11, depth: 0)
  31 | class GraphQuery:
  32 |     """Query engine for the code knowledge graph.
  33 | 
  34 |     Provides high-level methods for common queries: who calls what,
  35 |     impact analysis, related symbols, etc.
  36 |     """
  37 | 
  38 |     def __init__(self, graph: nx.DiGraph, store: GraphStore | None = None) -> None:
  39 |         self.graph = graph
  40 |         self.store = store
  41 |         self._name_index: dict[str, list[str]] = {}
  42 |         self._build_index()
  43 | 
  44 |     def _build_index(self) -> None:
  45 |         """Build a name->node_id lookup index."""
  46 |         for node_id, data in self.graph.nodes(data=True):
  47 |             if data.get("type") != "symbol":
  48 |                 continue
  49 |             name = data.get("name", "")
  50 |             qname = data.get("qualified_name", "")
  51 |             if name:
  52 |                 self._name_index.setdefault(name, []).append(node_id)
  53 |             if qname and qname != name:
  54 |                 self._name_index.setdefault(qname, []).append(node_id)
  55 | 
  56 |     def find_symbol(self, name: str) -> list[str]:
  57 |         """Find symbol node IDs matching a name (exact or qualified)."""
  58 |         results = self._name_index.get(name, [])
  59 |         if not results:
  60 |             # Try partial match
  61 |             for key, ids in self._name_index.items():
  62 |                 if name.lower() == key.lower():
  63 |                     results.extend(ids)
  64 |         return list(set(results))
  65 | 
  66 |     def get_symbol_info(self, symbol_id: str) -> SymbolInfo | None:
  67 |         """Get detailed information about a symbol."""
  68 |         if not self.graph.has_node(symbol_id):
  69 |             return None
  70 | 
  71 |         data = self.graph.nodes[symbol_id]
  72 |         if data.get("type") != "symbol":
  73 |             return None
  74 | 
  75 |         # Get callers (reverse edges with kind=calls)
  76 |         callers = []
  77 |         for pred in self.graph.predecessors(symbol_id):
  78 |             edge_data = self.graph.edges[pred, symbol_id]
  79 |             if edge_data.get("kind") == "calls":
  80 |                 callers.append(pred)
  81 | 
  82 |         # Get callees (forward edges with kind=calls)
  83 |         callees = []
  84 |         for succ in self.graph.successors(symbol_id):
  85 |             edge_data = self.graph.edges[symbol_id, succ]
  86 |             if edge_data.get("kind") == "calls":
  87 |                 callees.append(succ)
  88 | 
  89 |         # Get children (contains edges)
  90 |         children = []
  91 |         for succ in self.graph.successors(symbol_id):
  92 |             edge_data = self.graph.edges[symbol_id, succ]
  93 |             if edge_data.get("kind") == "contains":
  94 |                 children.append(succ)
  95 | 
  96 |         # Get parent
  97 |         parent = ""
  98 |         for pred in self.graph.predecessors(symbol_id):
  99 |             edge_data = self.graph.edges[pred, symbol_id]
 100 |             if edge_data.get("kind") == "contains":
 101 |                 pred_data = self.graph.nodes.get(pred, {})
 102 |                 if pred_data.get("type") == "symbol":
 103 |                     parent = pred
 104 |                     break
 105 | 
 106 |         return SymbolInfo(
 107 |             id=symbol_id,
 108 |             name=data.get("name", ""),
 109 |             qualified_name=data.get("qualified_name", ""),
 110 |             kind=data.get("kind", ""),
 111 |             file_path=data.get("file_path", ""),
 112 |             line_start=data.get("line_start", 0),
 113 |             line_end=data.get("line_end", 0),
 114 |             signature=data.get("signature", ""),
 115 |             docstring=data.get("docstring", ""),
 116 |             callers=callers,
 117 |             callees=callees,
 118 |             children=children,
 119 |             parent=parent,
 120 |         )
 121 | 
 122 |     def who_calls(self, name: str, max_depth: int = 1) -> list[dict]:
 123 |         """Find all callers of a symbol, optionally going N levels deep.
 124 | 
 125 |         Returns list of {symbol_id, name, file_path, line, depth}
 126 |         """
 127 |         symbol_ids = self.find_symbol(name)
 128 |         if not symbol_ids:
 129 |             return []
 130 | 
 131 |         results = []
 132 |         visited = set()
 133 | 
 134 |         def _traverse(node_id: str, depth: int) -> None:
 135 |             if depth > max_depth or node_id in visited:
 136 |                 return
 137 |             visited.add(node_id)
 138 | 
 139 |             for pred in self.graph.predecessors(node_id):
 140 |                 edge_data = self.graph.edges[pred, node_id]
 141 |                 if edge_data.get("kind") != "calls":
 142 |                     continue
 143 |                 pred_data = self.graph.nodes.get(pred, {})
 144 |                 if pred_data.get("type") != "symbol":
 145 |                     continue
 146 | 
 147 |                 results.append({
 148 |                     "symbol_id": pred,
 149 |                     "name": pred_data.get("qualified_name", pred_data.get("name", "")),
 150 |                     "kind": pred_data.get("kind", ""),
 151 |                     "file_path": pred_data.get("file_path", ""),
 152 |                     "line": pred_data.get("line_start", 0),
 153 |                     "depth": depth,
 154 |                 })
 155 |                 _traverse(pred, depth + 1)
 156 | 
 157 |         for sid in symbol_ids:
 158 |             _traverse(sid, 1)
 159 | 
 160 |         return results
 161 | 
 162 |     def what_calls(self, name: str) -> list[dict]:
 163 |         """Find all symbols called by the given symbol."""
 164 |         symbol_ids = self.find_symbol(name)
 165 |         results = []
 166 | 
 167 |         for sid in symbol_ids:
 168 |             for succ in self.graph.successors(sid):
 169 |                 edge_data = self.graph.edges[sid, succ]
 170 |                 if edge_data.get("kind") != "calls":
 171 |                     continue
 172 |                 succ_data = self.graph.nodes.get(succ, {})
 173 |                 if succ_data.get("type") != "symbol":
 174 |                     continue
 175 |                 results.append({
 176 |                     "symbol_id": succ,
 177 |                     "name": succ_data.get("qualified_name", succ_data.get("name", "")),
 178 |                     "kind": succ_data.get("kind", ""),
 179 |                     "file_path": succ_data.get("file_path", ""),
 180 |                     "line": succ_data.get("line_start", 0),
 181 |                 })
 182 | 
 183 |         return results
 184 | 
 185 |     def impact_of(self, name: str, max_depth: int = 3) -> dict:
 186 |         """Analyze the impact of changing a symbol.
 187 | 
 188 |         Returns a dict with:
 189 |         - direct_callers: immediate callers
 190 |         - transitive_callers: all callers up to max_depth
 191 |         - affected_files: set of files that could be affected
 192 |         - risk_score: rough risk assessment (0-1)
 193 |         """
 194 |         symbol_ids = self.find_symbol(name)
 195 |         if not symbol_ids:
 196 |             return {
 197 |                 "symbol": name,
 198 |                 "found": False,
 199 |                 "direct_callers": [],
 200 |                 "transitive_callers": [],
 201 |                 "affected_files": [],
 202 |                 "risk_score": 0.0,
 203 |             }
 204 | 
 205 |         direct = self.who_calls(name, max_depth=1)
 206 |         transitive = self.who_calls(name, max_depth=max_depth)
 207 | 
 208 |         affected_files = set()
 209 |         for item in transitive:
 210 |             if item.get("file_path"):
 211 |                 affected_files.add(item["file_path"])
 212 |         # Also include the symbol's own file
 213 |         for sid in symbol_ids:
 214 |             data = self.graph.nodes.get(sid, {})
 215 |             if data.get("file_path"):
 216 |                 affected_files.add(data["file_path"])
 217 | 
 218 |         # Risk score based on impact breadth
 219 |         total_files = sum(1 for _, d in self.graph.nodes(data=True) if d.get("type") == "file")
 220 |         risk_score = min(len(affected_files) / max(total_files, 1), 1.0)
 221 | 
 222 |         return {
 223 |             "symbol": name,
 224 |             "found": True,
 225 |             "direct_callers": direct,
 226 |             "transitive_callers": transitive,
 227 |             "affected_files": sorted(affected_files),
 228 |             "risk_score": round(risk_score, 3),
 229 |         }
 230 | 
 231 |     def get_file_symbols(self, file_path: str) -> list[dict]:
 232 |         """Get all symbols defined in a file."""
 233 |         file_node = f"file::{file_path}"
 234 |         if not self.graph.has_node(file_node):
 235 |             return []
 236 | 
 237 |         symbols = []
 238 |         for succ in self.graph.successors(file_node):
 239 |             data = self.graph.nodes.get(succ, {})
 240 |             if data.get("type") == "symbol":
 241 |                 symbols.append({
 242 |                     "id": succ,
 243 |                     **{k: v for k, v in data.items() if k != "type"},
 244 |                 })
 245 | 
 246 |         return sorted(symbols, key=lambda s: s.get("line_start", 0))
 247 | 
 248 |     def get_structure(self, path_prefix: str = "") -> dict:
 249 |         """Get the directory/file structure with symbol counts."""
 250 |         structure: dict = {}
 251 | 
 252 |         for node_id, data in self.graph.nodes(data=True):
 253 |             if data.get("type") != "file":
 254 |                 continue
 255 |             file_path = data.get("path", "")
 256 |             if path_prefix and not file_path.startswith(path_prefix):
 257 |                 continue
 258 | 
 259 |             parts = file_path.split("/")
 260 |             current = structure
 261 |             for part in parts[:-1]:
 262 |                 current = current.setdefault(part, {})
 263 |             current[parts[-1]] = {
 264 |                 "_language": data.get("language", ""),
 265 |                 "_symbols": data.get("symbol_count", 0),
 266 |             }
 267 | 
 268 |         return structure
 269 | 
 270 |     def find_related(self, name: str, max_hops: int = 2) -> list[dict]:
 271 |         """Find symbols related to the given one within N hops."""
 272 |         symbol_ids = self.find_symbol(name)
 273 |         if not symbol_ids:
 274 |             return []
 275 | 
 276 |         related = set()
 277 |         visited = set()
 278 | 
 279 |         def _bfs(start: str, hops: int) -> None:
 280 |             if hops > max_hops or start in visited:
 281 |                 return
 282 |             visited.add(start)
 283 | 
 284 |             # Forward edges
 285 |             for succ in self.graph.successors(start):
 286 |                 succ_data = self.graph.nodes.get(succ, {})
 287 |                 if succ_data.get("type") == "symbol":
 288 |                     related.add(succ)
 289 |                     _bfs(succ, hops + 1)
 290 | 
 291 |             # Backward edges
 292 |             for pred in self.graph.predecessors(start):
 293 |                 pred_data = self.graph.nodes.get(pred, {})
 294 |                 if pred_data.get("type") == "symbol":
 295 |                     related.add(pred)
 296 |                     _bfs(pred, hops + 1)
 297 | 
 298 |         for sid in symbol_ids:
 299 |             _bfs(sid, 0)
 300 | 
 301 |         # Remove the original symbols
 302 |         related -= set(symbol_ids)
 303 | 
 304 |         results = []
 305 |         for node_id in related:
 306 |             data = self.graph.nodes.get(node_id, {})
 307 |             results.append({
 308 |                 "symbol_id": node_id,
 309 |                 "name": data.get("qualified_name", data.get("name", "")),
 310 |                 "kind": data.get("kind", ""),
 311 |                 "file_path": data.get("file_path", ""),
 312 |                 "line": data.get("line_start", 0),
 313 |             })
 314 | 
 315 |         return results

# [method] GraphQuery.__init__ (relevance: 0.80, depth: 1)
  38 |     def __init__(self, graph: nx.DiGraph, store: GraphStore | None = None) -> None:
  39 |         self.graph = graph
  40 |         self.store = store
  41 |         self._name_index: dict[str, list[str]] = {}
  42 |         self._build_index()

# [method] GraphQuery._build_index (relevance: 0.82, depth: 1)
  44 |     def _build_index(self) -> None:
  45 |         """Build a name->node_id lookup index."""
  46 |         for node_id, data in self.graph.nodes(data=True):
  47 |             if data.get("type") != "symbol":
  48 |                 continue
  49 |             name = data.get("name", "")
  50 |             qname = data.get("qualified_name", "")
  51 |             if name:
  52 |                 self._name_index.setdefault(name, []).append(node_id)
  53 |             if qname and qname != name:
  54 |                 self._name_index.setdefault(qname, []).append(node_id)

# [method] GraphQuery.find_symbol (relevance: 1.22, depth: 0)
  56 |     def find_symbol(self, name: str) -> list[str]:
  57 |         """Find symbol node IDs matching a name (exact or qualified)."""
  58 |         results = self._name_index.get(name, [])
  59 |         if not results:
  60 |             # Try partial match
  61 |             for key, ids in self._name_index.items():
  62 |                 if name.lower() == key.lower():
  63 |                     results.extend(ids)
  64 |         return list(set(results))

# [method] GraphQuery.what_calls (relevance: 0.86, depth: 1)
 162 |     def what_calls(self, name: str) -> list[dict]:
 163 |         """Find all symbols called by the given symbol."""
 164 |         symbol_ids = self.find_symbol(name)
 165 |         results = []
 166 | 
 167 |         for sid in symbol_ids:
 168 |             for succ in self.graph.successors(sid):
 169 |                 edge_data = self.graph.edges[sid, succ]
 170 |                 if edge_data.get("kind") != "calls":
 171 |                     continue
 172 |                 succ_data = self.graph.nodes.get(succ, {})
 173 |                 if succ_data.get("type") != "symbol":
 174 |                     continue
 175 |                 results.append({
 176 |                     "symbol_id": succ,
 177 |                     "name": succ_data.get("qualified_name", succ_data.get("name", "")),
 178 |                     "kind": succ_data.get("kind", ""),
 179 |                     "file_path": succ_data.get("file_path", ""),
 180 |                     "line": succ_data.get("line_start", 0),
 181 |                 })
 182 | 
 183 |         return results

# [method] GraphQuery.impact_of (relevance: 0.98, depth: 1)
 185 |     def impact_of(self, name: str, max_depth: int = 3) -> dict:
 186 |         """Analyze the impact of changing a symbol.
 187 | 
 188 |         Returns a dict with:
 189 |         - direct_callers: immediate callers
 190 |         - transitive_callers: all callers up to max_depth
 191 |         - affected_files: set of files that could be affected
 192 |         - risk_score: rough risk assessment (0-1)
 193 |         """
 194 |         symbol_ids = self.find_symbol(name)
 195 |         if not symbol_ids:
 196 |             return {
 197 |                 "symbol": name,
 198 |                 "found": False,
 199 |                 "direct_callers": [],
 200 |                 "transitive_callers": [],
 201 |                 "affected_files": [],
 202 |                 "risk_score": 0.0,
 203 |             }
 204 | 
 205 |         direct = self.who_calls(name, max_depth=1)
 206 |         transitive = self.who_calls(name, max_depth=max_depth)
 207 | 
 208 |         affected_files = set()
 209 |         for item in transitive:
 210 |             if item.get("file_path"):
 211 |                 affected_files.add(item["file_path"])
 212 |         # Also include the symbol's own file
 213 |         for sid in symbol_ids:
 214 |             data = self.graph.nodes.get(sid, {})
 215 |             if data.get("file_path"):
 216 |                 affected_files.add(data["file_path"])
 217 | 
 218 |         # Risk score based on impact breadth
 219 |         total_files = sum(1 for _, d in self.graph.nodes(data=True) if d.get("type") == "file")
 220 |         risk_score = min(len(affected_files) / max(total_files, 1), 1.0)
 221 | 
 222 |         return {
 223 |             "symbol": name,
 224 |             "found": True,
 225 |             "direct_callers": direct,
 226 |             "transitive_callers": transitive,
 227 |             "affected_files": sorted(affected_files),
 228 |             "risk_score": round(risk_score, 3),
 229 |         }

# [method] GraphQuery.get_file_symbols (relevance: 0.82, depth: 1)
 231 |     def get_file_symbols(self, file_path: str) -> list[dict]:
 232 |         """Get all symbols defined in a file."""
 233 |         file_node = f"file::{file_path}"
 234 |         if not self.graph.has_node(file_node):
 235 |             return []
 236 | 
 237 |         symbols = []
 238 |         for succ in self.graph.successors(file_node):
 239 |             data = self.graph.nodes.get(succ, {})
 240 |             if data.get("type") == "symbol":
 241 |                 symbols.append({
 242 |                     "id": succ,
 243 |                     **{k: v for k, v in data.items() if k != "type"},
 244 |                 })
 245 | 
 246 |         return sorted(symbols, key=lambda s: s.get("line_start", 0))

# [method] GraphQuery.get_structure (relevance: 0.84, depth: 1)
 248 |     def get_structure(self, path_prefix: str = "") -> dict:
 249 |         """Get the directory/file structure with symbol counts."""
 250 |         structure: dict = {}
 251 | 
 252 |         for node_id, data in self.graph.nodes(data=True):
 253 |             if data.get("type") != "file":
 254 |                 continue
 255 |             file_path = data.get("path", "")
 256 |             if path_prefix and not file_path.startswith(path_prefix):
 257 |                 continue
 258 | 
 259 |             parts = file_path.split("/")
 260 |             current = structure
 261 |             for part in parts[:-1]:
 262 |                 current = current.setdefault(part, {})
 263 |             current[parts[-1]] = {
 264 |                 "_language": data.get("language", ""),
 265 |                 "_symbols": data.get("symbol_count", 0),
 266 |             }
 267 | 
 268 |         return structure

## src/cegraph/parser/models.py
# Included because: graph expansion (depth 2); matches 'symbols'

# [class] FileSymbols (relevance: 0.40, depth: 0)
  74 | class FileSymbols(BaseModel):
  75 |     """All symbols and relationships extracted from a single file."""
  76 | 
  77 |     file_path: str
  78 |     language: str
  79 |     symbols: list[Symbol] = Field(default_factory=list)
  80 |     relationships: list[Relationship] = Field(default_factory=list)
  81 |     imports: list[str] = Field(default_factory=list)  # raw import strings
  82 |     errors: list[str] = Field(default_factory=list)

# [function] detect_language (relevance: 0.49, depth: 2)
 100 | def detect_language(file_path: str) -> str | None:
 101 |     """Detect programming language from file extension."""
 102 |     from pathlib import Path
 103 | 
 104 |     ext = Path(file_path).suffix.lower()
 105 |     return EXTENSION_LANGUAGE_MAP.get(ext)

## src/cegraph/parser/python_parser.py
# Included because: matches 'name'; graph expansion (depth 2)

# [function] _get_docstring (relevance: 0.24, depth: 2)
  35 | def _get_docstring(node: ast.AST) -> str:
  36 |     """Extract docstring from a node if present."""
  37 |     if (
  38 |         isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef, ast.Module))
  39 |         and node.body
  40 |         and isinstance(node.body[0], ast.Expr)
  41 |         and isinstance(node.body[0].value, (ast.Constant,))
  42 |         and isinstance(node.body[0].value.value, str)
  43 |     ):
  44 |         return node.body[0].value.value.strip()
  45 |     return ""

# [function] _node_to_name (relevance: 0.48, depth: 0)
 305 | def _node_to_name(node: ast.AST) -> str:
 306 |     """Convert an AST node to a dotted name string."""
 307 |     if isinstance(node, ast.Name):
 308 |         return node.id
 309 |     elif isinstance(node, ast.Attribute):
 310 |         parent = _node_to_name(node.value)
 311 |         if parent:
 312 |             return f"{parent}.{node.attr}"
 313 |         return node.attr
 314 |     elif isinstance(node, ast.Subscript):
 315 |         return _node_to_name(node.value)
 316 |     return ""

## src/cegraph/parser/tree_sitter_parser.py
# Included because: graph expansion (depth 2); graph expansion (depth 3); matches 'name'

# [function] is_available (relevance: 0.47, depth: 2)
  73 | def is_available(language: str | None = None) -> bool:
  74 |     """Check if tree-sitter and the required language grammar are available."""
  75 |     try:
  76 |         import tree_sitter  # noqa: F401
  77 |     except ImportError:
  78 |         return False
  79 | 
  80 |     if language is None:
  81 |         return True
  82 | 
  83 |     module_name = _TS_LANGUAGE_MODULES.get(language)
  84 |     if not module_name:
  85 |         return False
  86 | 
  87 |     try:
  88 |         __import__(module_name)
  89 |         return True
  90 |     except ImportError:
  91 |         return False

# [function] _get_language (relevance: 0.49, depth: 2)
  94 | def _get_language(lang: str):
  95 |     """Get a tree-sitter Language object for the given language."""
  96 |     from tree_sitter import Language
  97 | 
  98 |     module_name = _TS_LANGUAGE_MODULES.get(lang)
  99 |     if not module_name:
 100 |         raise ValueError(f"No tree-sitter grammar for language: {lang}")
 101 | 
 102 |     module = __import__(module_name)
 103 |     return Language(module.language())

# [function] _extract_name (relevance: 0.40, depth: 0)
 207 | def _extract_name(node, language: str) -> str:
 208 |     """Extract the name of a symbol from its tree-sitter node."""
 209 |     # Look for a name/identifier child
 210 |     for child in node.children:
 211 |         if child.type in ("identifier", "name", "type_identifier", "property_identifier"):
 212 |             return child.text.decode("utf-8")
 213 |     # For some languages, try named children
 214 |     name_child = node.child_by_field_name("name")
 215 |     if name_child:
 216 |         return name_child.text.decode("utf-8")
 217 |     return ""

# [function] _extract_ts_import (relevance: 0.40, depth: 3)
 250 | def _extract_ts_import(node, file_path: str, source: bytes, result: FileSymbols) -> None:
 251 |     """Extract import information from a tree-sitter node."""
 252 |     text = node.text.decode("utf-8")
 253 |     result.imports.append(text)

## src/cegraph/search/hybrid.py
# Included because: graph expansion (depth 3)

# [function] _tokenize (relevance: 0.31, depth: 3)
 170 | def _tokenize(text: str) -> list[str]:
 171 |     """Simple tokenizer that splits on non-alphanumeric and camelCase."""
 172 |     import re
 173 | 
 174 |     # Split camelCase and snake_case
 175 |     text = re.sub(r"([a-z])([A-Z])", r"\1 \2", text)
 176 |     text = text.replace("_", " ").replace(".", " ")
 177 |     tokens = re.findall(r"[a-zA-Z]{2,}", text.lower())
 178 |     return tokens

## tests/test_context.py
# Included because: graph expansion (depth 3)

# [function] cag_engine (relevance: 0.29, depth: 3)
  21 | def cag_engine(tmp_project: Path):
  22 |     """Create a context assembler with a built graph."""
  23 |     builder = GraphBuilder()
  24 |     graph = builder.build_from_directory(tmp_project)
  25 |     query = GraphQuery(graph)
  26 |     return ContextAssembler(tmp_project, graph, query)
