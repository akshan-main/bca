# src/cegraph/graph/builder.py:15-213
class GraphBuilder:
    """Builds and maintains a code knowledge graph.

    The graph has two types of nodes:
    - File nodes: represent source files
    - Symbol nodes: represent code symbols (functions, classes, etc.)

    Edges represent relationships (calls, imports, inherits, contains, etc.)
    """

    def __init__(self) -> None:
        self.graph = nx.DiGraph()
        self._file_hashes: dict[str, str] = {}
        self._unresolved: list[Relationship] = []

    def build_from_directory(
        self,
        root: str | Path,
        config: ProjectConfig | None = None,
        progress_callback: callable | None = None,
    ) -> nx.DiGraph:
        """Build the full knowledge graph from a directory.

        Args:
            root: Root directory to index.
            config: Project configuration.
            progress_callback: Optional callback(file_path, current, total).

        Returns:
            The constructed NetworkX directed graph.
        """
        root = Path(root).resolve()
        indexer_config = config.indexer if config else IndexerConfig()

        # Reset state so reusing a builder doesn't accumulate stale data
        # self.graph = nx.DiGraph()
        # self._file_hashes = {}
        # self._unresolved = []

        # Parse all files
        all_parsed = parse_directory(root, indexer_config, progress_callback)

        # Build graph from parsed results
        for file_symbols in all_parsed:
            self._add_file(file_symbols, root)

        # Resolve cross-file references
        self._resolve_references()

        return self.graph

    def _add_file(self, fs: FileSymbols, root: Path) -> None:
        """Add a file and its symbols to the graph."""
        file_path = fs.file_path

        # Add file node
        self.graph.add_node(
            f"file::{file_path}",
            type="file",
            path=file_path,
            language=fs.language,
            symbol_count=len(fs.symbols),
            import_count=len(fs.imports),
        )

        # Compute file hash for change detection
        try:
            full_path = root / file_path
            content = full_path.read_bytes()
            self._file_hashes[file_path] = hashlib.sha256(content).hexdigest()[:16]
        except OSError:
            pass

        # Add symbol nodes
        for symbol in fs.symbols:
            attrs = {
                "type": "symbol",
                "name": symbol.name,
                "qualified_name": symbol.qualified_name,
                "kind": symbol.kind.value,
                "file_path": symbol.file_path,
                "line_start": symbol.line_start,
                "line_end": symbol.line_end,
                "signature": symbol.signature,
                "docstring": symbol.docstring,
            }
            self.graph.add_node(symbol.id, **attrs)

            # Link symbol to its file
            self.graph.add_edge(
                f"file::{file_path}",
                symbol.id,
                kind="contains",
            )

        # Add relationships
        for rel in fs.relationships:
            if rel.resolved or self._try_resolve(rel):
                self.graph.add_edge(
                    rel.source,
                    rel.target,
                    kind=rel.kind.value,
                    file_path=rel.file_path,
                    line=rel.line,
                )
            else:
                self._unresolved.append(rel)

    def _try_resolve(self, rel: Relationship) -> bool:
        """Try to resolve a relationship's target to an existing node."""
        target = rel.target

        # Direct match
        if self.graph.has_node(target):
            return True

        # Try finding by name across all files
        for node_id, data in self.graph.nodes(data=True):
            if data.get("type") != "symbol":
                continue
            if data.get("name") == target or data.get("qualified_name") == target:
                rel.target = node_id
                rel.resolved = True
                return True

        return False

    def _resolve_references(self) -> None:
        """Try to resolve all unresolved references after the full graph is built."""
        still_unresolved = []

        # Build a lookup index: name -> [node_ids]
        name_index: dict[str, list[str]] = {}
        for node_id, data in self.graph.nodes(data=True):
            if data.get("type") != "symbol":
                continue
            name = data.get("name", "")
            qname = data.get("qualified_name", "")
            if name:
                name_index.setdefault(name, []).append(node_id)
            if qname and qname != name:
                name_index.setdefault(qname, []).append(node_id)

        for rel in self._unresolved:
            target = rel.target
            # Try exact match by name
            candidates = name_index.get(target, [])

            # Try dotted parts (e.g., "module.func" -> "func")
            if not candidates and "." in target:
                parts = target.split(".")
                candidates = name_index.get(parts[-1], [])

            if candidates:
                # Pick the best candidate (same file first, then any)
                best = None
                for c in candidates:
                    c_data = self.graph.nodes[c]
                    if c_data.get("file_path") == rel.file_path:
                        best = c
                        break
                if best is None:
                    best = candidates[0]

                self.graph.add_edge(
                    rel.source,
                    best,
                    kind=rel.kind.value,
                    file_path=rel.file_path,
                    line=rel.line,
                )
            else:
                still_unresolved.append(rel)

        self._unresolved = still_unresolved

    def get_stats(self) -> dict:
        """Get graph statistics."""
        node_types: dict[str, int] = {}
        edge_types: dict[str, int] = {}

        for _, data in self.graph.nodes(data=True):
            kind = data.get("kind", data.get("type", "unknown"))
            node_types[kind] = node_types.get(kind, 0) + 1

        for _, _, data in self.graph.edges(data=True):
            kind = data.get("kind", "unknown")
            edge_types[kind] = edge_types.get(kind, 0) + 1

        return {
            "total_nodes": self.graph.number_of_nodes(),
            "total_edges": self.graph.number_of_edges(),
            "node_types": node_types,
            "edge_types": edge_types,
            "files": node_types.get("file", 0),
            "functions": node_types.get("function", 0) + node_types.get("method", 0),
            "classes": node_types.get("class", 0),
            "unresolved_refs": len(self._unresolved),
        }

# src/cegraph/graph/builder.py:30-64
    def build_from_directory(
        self,
        root: str | Path,
        config: ProjectConfig | None = None,
        progress_callback: callable | None = None,
    ) -> nx.DiGraph:
        """Build the full knowledge graph from a directory.

        Args:
            root: Root directory to index.
            config: Project configuration.
            progress_callback: Optional callback(file_path, current, total).

        Returns:
            The constructed NetworkX directed graph.
        """
        root = Path(root).resolve()
        indexer_config = config.indexer if config else IndexerConfig()

        # Reset state so reusing a builder doesn't accumulate stale data
        # self.graph = nx.DiGraph()
        # self._file_hashes = {}
        # self._unresolved = []

        # Parse all files
        all_parsed = parse_directory(root, indexer_config, progress_callback)

        # Build graph from parsed results
        for file_symbols in all_parsed:
            self._add_file(file_symbols, root)

        # Resolve cross-file references
        self._resolve_references()

        return self.graph

# examples/demo.py:9-9
from cegraph.graph.builder import GraphBuilder

# paper/experiments/ablation.py:22-22
from cegraph.graph.builder import GraphBuilder

# paper/experiments/baselines.py:29-29
from cegraph.graph.builder import GraphBuilder

# paper/experiments/benchmark.py:56-56
from cegraph.graph.builder import GraphBuilder

# src/cegraph/graph/__init__.py:3-3
from cegraph.graph.builder import GraphBuilder

# tests/test_context.py:16-16
from cegraph.graph.builder import GraphBuilder

# tests/test_graph.py:10-10
from cegraph.graph.builder import GraphBuilder

# tests/test_impact_bot.py:17-17
from cegraph.graph.builder import GraphBuilder

# tests/test_mcp.py:10-10
from cegraph.graph.builder import GraphBuilder

# tests/test_search.py:9-9
from cegraph.graph.builder import GraphBuilder

# tests/test_tools.py:9-9
from cegraph.graph.builder import GraphBuilder

# src/cegraph/context/engine.py:906-938
    def _marginal_utility(
        self, symbol_id: str, covered_edges: set[tuple[str, str]]
    ) -> float:
        """Compute marginal coverage gain of adding symbol_id.

        This makes the utility submodular: each new symbol covers some edges
        in the graph. As more symbols are selected, each new symbol covers
        fewer NEW edges → diminishing returns.

        Returns a value in [0, 1] representing the fraction of new edges.
        """
        new_edges = 0
        total_edges = 0

        for succ in self.graph.successors(symbol_id):
            succ_data = self.graph.nodes.get(succ, {})
            if succ_data.get("type") == "symbol":
                total_edges += 1
                edge_key = (symbol_id, succ)
                if edge_key not in covered_edges:
                    new_edges += 1

        for pred in self.graph.predecessors(symbol_id):
            pred_data = self.graph.nodes.get(pred, {})
            if pred_data.get("type") == "symbol":
                total_edges += 1
                edge_key = (pred, symbol_id)
                if edge_key not in covered_edges:
                    new_edges += 1

        if total_edges == 0:
            return 1.0
        return new_edges / total_edges

# src/cegraph/cli.py:107-140
def _do_index(root: Path, config: ProjectConfig):
    """Index the codebase and build the knowledge graph."""
    from cegraph.graph.builder import GraphBuilder
    from cegraph.graph.store import GraphStore

    builder = GraphBuilder()

    console.info("Scanning and parsing source files...")
    start_time = time.time()

    with console.indexing_progress() as progress:
        task = progress.add_task("Indexing...", total=None)
        file_count = 0

        def on_progress(file_path: str, current: int, total: int):
            nonlocal file_count
            file_count = total
            progress.update(task, total=total, completed=current, description=f"Parsing {file_path}")

        graph = builder.build_from_directory(root, config, on_progress)

    elapsed = time.time() - start_time
    stats = builder.get_stats()

    console.success(f"Indexed {stats.get('files', 0)} files in {elapsed:.1f}s")
    console.show_stats(stats)

    # Persist the graph
    db_path = get_cegraph_dir(root) / GRAPH_DB_FILE
    store = GraphStore(db_path)
    store.save(graph, metadata={"stats": stats, "root": str(root)})
    store.close()

    console.success(f"Knowledge graph saved to .cegraph/")

# src/cegraph/graph/store.py:17-503
class GraphStore:
    """Persists and loads the knowledge graph using SQLite.

    Storage is compact: file paths are interned (stored once), nodes
    use integer IDs, and text node IDs are reconstructed on load.
    """

    def __init__(self, db_path: str | Path) -> None:
        self.db_path = Path(db_path)
        self._conn: sqlite3.Connection | None = None

    def _get_conn(self) -> sqlite3.Connection:
        if self._conn is None:
            self.db_path.parent.mkdir(parents=True, exist_ok=True)
            self._conn = sqlite3.connect(str(self.db_path))
            self._conn.row_factory = sqlite3.Row
            self._conn.execute("PRAGMA journal_mode=WAL")
            self._create_tables()
        return self._conn

    def _create_tables(self) -> None:
        conn = self._get_conn()
        conn.executescript("""
            -- Intern file paths (stored once, referenced by integer)
            CREATE TABLE IF NOT EXISTS path_map (
                pid INTEGER PRIMARY KEY,
                path TEXT UNIQUE NOT NULL
            );

            -- Unified node table (symbols + files)
            -- NULL columns cost 0 bytes in SQLite storage
            CREATE TABLE IF NOT EXISTS nodes (
                nid INTEGER PRIMARY KEY,
                node_type TEXT NOT NULL,         -- 'symbol' or 'file'
                path_id INTEGER NOT NULL REFERENCES path_map(pid),
                -- Symbol-only fields
                name TEXT,
                qualified_name TEXT,
                kind TEXT,                       -- 'function', 'class', etc.
                line_start INTEGER,
                line_end INTEGER,
                signature TEXT,
                docstring TEXT,
                -- File-only fields
                language TEXT,
                symbol_count INTEGER,
                import_count INTEGER
            );

            -- Edges between nodes (integer FKs)
            CREATE TABLE IF NOT EXISTS edges (
                source_nid INTEGER NOT NULL REFERENCES nodes(nid),
                target_nid INTEGER NOT NULL REFERENCES nodes(nid),
                kind TEXT NOT NULL,
                path_id INTEGER REFERENCES path_map(pid),
                line INTEGER,
                PRIMARY KEY (source_nid, target_nid, kind)
            );

            CREATE TABLE IF NOT EXISTS metadata (
                key TEXT PRIMARY KEY,
                value TEXT
            );

            CREATE INDEX IF NOT EXISTS idx_nodes_name ON nodes(name);
            CREATE INDEX IF NOT EXISTS idx_nodes_kind ON nodes(kind);
            CREATE INDEX IF NOT EXISTS idx_nodes_path ON nodes(path_id);
            CREATE INDEX IF NOT EXISTS idx_nodes_type ON nodes(node_type);
            CREATE INDEX IF NOT EXISTS idx_edges_source ON edges(source_nid);
            CREATE INDEX IF NOT EXISTS idx_edges_target ON edges(target_nid);
        """)
        conn.commit()

    # ------------------------------------------------------------------
    # Text ID reconstruction
    # ------------------------------------------------------------------

    @staticmethod
    def _make_text_id(node_type: str, path: str, qualified_name: str = "") -> str:
        """Reconstruct a text node ID from stored fields."""
        if node_type == "file":
            return f"file::{path}"
        return f"{path}::{qualified_name}"

    def _resolve_text_id(self, conn: sqlite3.Connection, text_id: str) -> int | None:
        """Find the nid for a text-based node ID."""
        if text_id.startswith("file::"):
            fp = text_id[6:]  # strip "file::"
            row = conn.execute(
                """SELECT n.nid FROM nodes n
                   JOIN path_map p ON p.pid = n.path_id
                   WHERE n.node_type = 'file' AND p.path = ?""",
                (fp,),
            ).fetchone()
        elif "::" in text_id:
            fp, qname = text_id.split("::", 1)
            row = conn.execute(
                """SELECT n.nid FROM nodes n
                   JOIN path_map p ON p.pid = n.path_id
                   WHERE n.node_type = 'symbol' AND p.path = ? AND n.qualified_name = ?""",
                (fp, qname),
            ).fetchone()
        else:
            # Bare name — search by name or qualified_name
            row = conn.execute(
                "SELECT nid FROM nodes WHERE name = ? OR qualified_name = ?",
                (text_id, text_id),
            ).fetchone()
        return row["nid"] if row else None

    # ------------------------------------------------------------------
    # Save / Load
    # ------------------------------------------------------------------

    def save(self, graph: nx.DiGraph, metadata: dict | None = None) -> None:
        """Save the full graph to compact SQLite tables."""
        conn = self._get_conn()

        # Drop all legacy tables
        for legacy in ("graph_data", "symbols", "relationships", "files", "node_map"):
            conn.execute(f"DROP TABLE IF EXISTS {legacy}")

        # Clear current data
        conn.execute("DELETE FROM nodes")
        conn.execute("DELETE FROM edges")
        conn.execute("DELETE FROM path_map")

        path_cache: dict[str, int] = {}
        text_to_nid: dict[str, int] = {}
        nid_counter = 1

        def intern_path(fp: str) -> int:
            if fp in path_cache:
                return path_cache[fp]
            conn.execute("INSERT OR IGNORE INTO path_map (path) VALUES (?)", (fp,))
            row = conn.execute("SELECT pid FROM path_map WHERE path = ?", (fp,)).fetchone()
            pid = row["pid"]
            path_cache[fp] = pid
            return pid

        # Insert all nodes
        for node_id, data in graph.nodes(data=True):
            ntype = data.get("type", "")
            if ntype == "symbol":
                fp = data.get("file_path", "")
                pid = intern_path(fp) if fp else 0
                conn.execute(
                    """INSERT INTO nodes
                    (nid, node_type, path_id, name, qualified_name, kind,
                     line_start, line_end, signature, docstring)
                    VALUES (?, 'symbol', ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        nid_counter, pid,
                        data.get("name", ""),
                        data.get("qualified_name", ""),
                        data.get("kind", ""),
                        data.get("line_start", 0),
                        data.get("line_end", 0),
                        data.get("signature", ""),
                        data.get("docstring", ""),
                    ),
                )
            elif ntype == "file":
                fp = data.get("path", "")
                pid = intern_path(fp) if fp else 0
                conn.execute(
                    """INSERT INTO nodes
                    (nid, node_type, path_id, language, symbol_count, import_count)
                    VALUES (?, 'file', ?, ?, ?, ?)""",
                    (
                        nid_counter, pid,
                        data.get("language", ""),
                        data.get("symbol_count", 0),
                        data.get("import_count", 0),
                    ),
                )
            else:
                # Unknown node type — store minimally
                conn.execute(
                    "INSERT INTO nodes (nid, node_type, path_id) VALUES (?, ?, 0)",
                    (nid_counter, ntype or "unknown"),
                )

            text_to_nid[node_id] = nid_counter
            nid_counter += 1

        # Insert all edges
        for src, tgt, data in graph.edges(data=True):
            src_nid = text_to_nid.get(src)
            tgt_nid = text_to_nid.get(tgt)
            if src_nid is None or tgt_nid is None:
                continue
            fp = data.get("file_path", "")
            pid = intern_path(fp) if fp else None
            try:
                conn.execute(
                    """INSERT OR REPLACE INTO edges
                    (source_nid, target_nid, kind, path_id, line)
                    VALUES (?, ?, ?, ?, ?)""",
                    (src_nid, tgt_nid, data.get("kind", ""), pid, data.get("line", 0)),
                )
            except sqlite3.IntegrityError:
                pass

        if metadata:
            for key, value in metadata.items():
                conn.execute(
                    "INSERT OR REPLACE INTO metadata (key, value) VALUES (?, ?)",
                    (key, json.dumps(value)),
                )

        conn.commit()
        conn.execute("VACUUM")

    def load(self) -> nx.DiGraph | None:
        """Reconstruct the full NetworkX graph from SQLite."""
        conn = self._get_conn()

        # Detect which schema version we have
        has_nodes = False
        try:
            row = conn.execute("SELECT COUNT(*) as cnt FROM nodes").fetchone()
            has_nodes = row is not None and row["cnt"] > 0
        except sqlite3.OperationalError:
            pass

        if not has_nodes:
            return self._load_legacy()

        # Load path lookup
        pid_to_path: dict[int, str] = {}
        for row in conn.execute("SELECT pid, path FROM path_map").fetchall():
            pid_to_path[row["pid"]] = row["path"]

        # Load nid → text_id mapping
        nid_to_text: dict[int, str] = {}
        graph = nx.DiGraph()

        for row in conn.execute("SELECT * FROM nodes").fetchall():
            nid = row["nid"]
            ntype = row["node_type"]
            fp = pid_to_path.get(row["path_id"], "")

            if ntype == "file":
                text_id = f"file::{fp}"
                nid_to_text[nid] = text_id
                graph.add_node(
                    text_id,
                    type="file",
                    path=fp,
                    language=row["language"] or "",
                    symbol_count=row["symbol_count"] or 0,
                    import_count=row["import_count"] or 0,
                )
            elif ntype == "symbol":
                qname = row["qualified_name"] or ""
                text_id = f"{fp}::{qname}"
                nid_to_text[nid] = text_id
                graph.add_node(
                    text_id,
                    type="symbol",
                    name=row["name"] or "",
                    qualified_name=qname,
                    kind=row["kind"] or "",
                    file_path=fp,
                    line_start=row["line_start"] or 0,
                    line_end=row["line_end"] or 0,
                    signature=row["signature"] or "",
                    docstring=row["docstring"] or "",
                )

        # Load edges
        for row in conn.execute("SELECT * FROM edges").fetchall():
            src = nid_to_text.get(row["source_nid"])
            tgt = nid_to_text.get(row["target_nid"])
            if src and tgt:
                fp = pid_to_path.get(row["path_id"]) if row["path_id"] else ""
                graph.add_edge(
                    src, tgt,
                    kind=row["kind"],
                    file_path=fp or "",
                    line=row["line"] or 0,
                )

        return graph

    def _load_legacy(self) -> nx.DiGraph | None:
        """Fallback: load from any older schema version."""
        conn = self._get_conn()

        # Try normalized schema v1 (node_map + symbols + relationships)
        try:
            row = conn.execute("SELECT COUNT(*) as cnt FROM node_map").fetchone()
            if row and row["cnt"] > 0:
                return self._load_v1_normalized()
        except sqlite3.OperationalError:
            pass

        # Try text-ID schema (symbols with text id column)
        try:
            row = conn.execute("SELECT COUNT(*) as cnt FROM files").fetchone()
            if row and row["cnt"] > 0:
                test = conn.execute("SELECT id FROM symbols LIMIT 1").fetchone()
                if test is not None:
                    return self._load_text_tables()
        except sqlite3.OperationalError:
            pass

        # Try JSON blob (oldest)
        try:
            row = conn.execute("SELECT data FROM graph_data WHERE id = 1").fetchone()
        except sqlite3.OperationalError:
            return None
        if row is None:
            return None
        from networkx.readwrite import json_graph
        return json_graph.node_link_graph(json.loads(row["data"]))

    def _load_v1_normalized(self) -> nx.DiGraph | None:
        """Load from node_map + symbols + relationships schema."""
        conn = self._get_conn()
        nid_to_text = {}
        for row in conn.execute("SELECT nid, text_id FROM node_map").fetchall():
            nid_to_text[row["nid"]] = row["text_id"]

        pid_to_path = {}
        try:
            for row in conn.execute("SELECT pid, path FROM path_map").fetchall():
                pid_to_path[row["pid"]] = row["path"]
        except sqlite3.OperationalError:
            pass

        graph = nx.DiGraph()
        for row in conn.execute("SELECT * FROM files").fetchall():
            text_id = nid_to_text.get(row["nid"], "")
            fp = pid_to_path.get(row["path_id"], "") if "path_id" in row.keys() else ""
            if not fp and text_id.startswith("file::"):
                fp = text_id[6:]
            graph.add_node(
                text_id, type="file", path=fp,
                language=row["language"] or "",
                symbol_count=row["symbol_count"] or 0,
                import_count=row.get("import_count", 0) or 0,
            )

        for row in conn.execute("SELECT * FROM symbols").fetchall():
            text_id = nid_to_text.get(row["nid"], "")
            fp = pid_to_path.get(row["path_id"], "") if "path_id" in row.keys() else ""
            graph.add_node(
                text_id, type="symbol",
                name=row["name"], qualified_name=row["qualified_name"],
                kind=row["kind"], file_path=fp,
                line_start=row["line_start"] or 0, line_end=row["line_end"] or 0,
                signature=row["signature"] or "", docstring=row["docstring"] or "",
            )

        for row in conn.execute("SELECT * FROM relationships").fetchall():
            src = nid_to_text.get(row["source_nid"], "")
            tgt = nid_to_text.get(row["target_nid"], "")
            fp = pid_to_path.get(row["path_id"]) if row["path_id"] else ""
            graph.add_edge(src, tgt, kind=row["kind"], file_path=fp or "", line=row["line"] or 0)

        return graph

    def _load_text_tables(self) -> nx.DiGraph | None:
        """Load from old text-ID table schema."""
        conn = self._get_conn()
        graph = nx.DiGraph()
        for row in conn.execute("SELECT * FROM files").fetchall():
            graph.add_node(
                f"file::{row['path']}", type="file", path=row["path"],
                language=row["language"] or "", symbol_count=row["symbol_count"] or 0,
                import_count=0,
            )
        for row in conn.execute("SELECT * FROM symbols").fetchall():
            graph.add_node(
                row["id"], type="symbol", name=row["name"],
                qualified_name=row["qualified_name"], kind=row["kind"],
                file_path=row["file_path"],
                line_start=row["line_start"] or 0, line_end=row["line_end"] or 0,
                signature=row["signature"] or "", docstring=row["docstring"] or "",
            )
        for row in conn.execute("SELECT * FROM relationships").fetchall():
            graph.add_edge(
                row["source"], row["target"], kind=row["kind"],
                file_path=row["file_path"] or "", line=row["line"] or 0,
            )
        return graph

    # ------------------------------------------------------------------
    # Query methods (external API uses text node IDs)
    # ------------------------------------------------------------------

    def search_symbols(
        self,
        query: str = "",
        kind: str = "",
        file_path: str = "",
        limit: int = 50,
    ) -> list[dict]:
        """Search symbols using the indexed SQLite tables."""
        conn = self._get_conn()
        conditions = ["n.node_type = 'symbol'"]
        params: list = []

        if query:
            conditions.append("(n.name LIKE ? OR n.qualified_name LIKE ? OR n.signature LIKE ?)")
            like = f"%{query}%"
            params.extend([like, like, like])
        if kind:
            conditions.append("n.kind = ?")
            params.append(kind)
        if file_path:
            conditions.append("p.path LIKE ?")
            params.append(f"%{file_path}%")

        where = " AND ".join(conditions)
        rows = conn.execute(
            f"""SELECT (p.path || '::' || n.qualified_name) as id,
                       n.name, n.qualified_name, n.kind,
                       p.path as file_path, n.line_start, n.line_end,
                       n.signature, n.docstring
                FROM nodes n
                JOIN path_map p ON p.pid = n.path_id
                WHERE {where} LIMIT ?""",
            params + [limit],
        ).fetchall()

        return [dict(row) for row in rows]

    def get_callers(self, symbol_id: str) -> list[dict]:
        """Get all symbols that call the given symbol."""
        conn = self._get_conn()
        target_nid = self._resolve_text_id(conn, symbol_id)
        if target_nid is None:
            return []

        rows = conn.execute(
            """SELECT (sp.path || '::' || s.qualified_name) as id,
                      s.name, s.qualified_name, s.kind,
                      sp.path as file_path, s.line_start, s.line_end,
                      s.signature, s.docstring,
                      e.line as call_line, rp.path as call_file
               FROM edges e
               JOIN nodes s ON s.nid = e.source_nid AND s.node_type = 'symbol'
               JOIN path_map sp ON sp.pid = s.path_id
               LEFT JOIN path_map rp ON rp.pid = e.path_id
               WHERE e.target_nid = ? AND e.kind = 'calls'""",
            (target_nid,),
        ).fetchall()
        return [dict(row) for row in rows]

    def get_callees(self, symbol_id: str) -> list[dict]:
        """Get all symbols called by the given symbol."""
        conn = self._get_conn()
        source_nid = self._resolve_text_id(conn, symbol_id)
        if source_nid is None:
            return []

        rows = conn.execute(
            """SELECT (sp.path || '::' || s.qualified_name) as id,
                      s.name, s.qualified_name, s.kind,
                      sp.path as file_path, s.line_start, s.line_end,
                      s.signature, s.docstring,
                      e.line as call_line, rp.path as call_file
               FROM edges e
               JOIN nodes s ON s.nid = e.target_nid AND s.node_type = 'symbol'
               JOIN path_map sp ON sp.pid = s.path_id
               LEFT JOIN path_map rp ON rp.pid = e.path_id
               WHERE e.source_nid = ? AND e.kind = 'calls'""",
            (source_nid,),
        ).fetchall()
        return [dict(row) for row in rows]

    def get_metadata(self, key: str) -> str | None:
        """Get a metadata value."""
        conn = self._get_conn()
        row = conn.execute("SELECT value FROM metadata WHERE key = ?", (key,)).fetchone()
        if row:
            return json.loads(row["value"])
        return None

    def close(self) -> None:
        """Close the database connection."""
        if self._conn:
            self._conn.close()
            self._conn = None