# pydantic_ai_slim/pydantic_ai/models/instrumented.py:40-57
MODEL_SETTING_ATTRIBUTES: tuple[
    Literal[
        'max_tokens',
        'top_p',
        'seed',
        'temperature',
        'presence_penalty',
        'frequency_penalty',
    ],
    ...,
] = (
    'max_tokens',
    'top_p',
    'seed',
    'temperature',
    'presence_penalty',
    'frequency_penalty',
)

# pydantic_ai_slim/pydantic_ai/embeddings/instrumented.py:11-11
from opentelemetry.util.types import AttributeValue

# pydantic_ai_slim/pydantic_ai/embeddings/instrumented.py:11-11
from opentelemetry.util.types import AttributeValue

# pydantic_ai_slim/pydantic_ai/embeddings/instrumented.py:11-11
from opentelemetry.util.types import AttributeValue

# pydantic_ai_slim/pydantic_ai/_utils.py:150-153
class Unset:
    """A singleton to represent an unset value."""

    pass

# pydantic_ai_slim/pydantic_ai/_utils.py:150-153
class Unset:
    """A singleton to represent an unset value."""

    pass

# pydantic_evals/pydantic_evals/otel/span_tree.py:43-43
    has_attributes: dict[str, Any]

# pydantic_ai_slim/pydantic_ai/models/cerebras.py:52-52
    cerebras_disable_reasoning: bool

# pydantic_evals/pydantic_evals/otel/span_tree.py:44-44
    has_attribute_keys: list[str]

# tests/models/test_cerebras.py:37-49
async def test_cerebras_disable_reasoning_setting(allow_model_requests: None, cerebras_api_key: str):
    """Test that cerebras_disable_reasoning setting is properly transformed to extra_body.

    Note: disable_reasoning is only supported on reasoning models: zai-glm-4.6 and gpt-oss-120b.
    """
    provider = CerebrasProvider(api_key=cerebras_api_key)
    model = CerebrasModel('zai-glm-4.6', provider=provider)

    settings = CerebrasModelSettings(cerebras_disable_reasoning=True)
    response = await model_request(model, [ModelRequest.user_text_prompt('What is 2 + 2?')], model_settings=settings)

    text_part = cast(TextPart, response.parts[0])
    assert '4' in text_part.content

# tests/models/test_model_settings.py:121-144
def test_none_settings_in_hierarchy():
    """Test that None settings at any level don't break the merge hierarchy."""
    captured_settings = None

    def capture_settings(messages: list[ModelMessage], agent_info: AgentInfo) -> ModelResponse:
        nonlocal captured_settings
        captured_settings = agent_info.model_settings
        return ModelResponse(parts=[TextPart('captured')])

    # Model with no settings
    model = FunctionModel(capture_settings, settings=None)

    # Agent with settings
    agent_settings = ModelSettings(max_tokens=150, temperature=0.5)
    agent = Agent(model=model, model_settings=agent_settings)

    # Run with no additional settings
    result = agent.run_sync('test', model_settings=None)
    assert result.output == 'captured'

    # Should have agent settings
    assert captured_settings is not None
    assert captured_settings['max_tokens'] == 150
    assert captured_settings['temperature'] == 0.5

# pydantic_ai_slim/pydantic_ai/usage.py:99-101
    def has_values(self) -> bool:
        """Whether any values are set and non-zero."""
        return any(dataclasses.asdict(self).values())

# pydantic_ai_slim/pydantic_ai/_utils.py:150-153
class Unset:
    """A singleton to represent an unset value."""

    pass

# pydantic_evals/pydantic_evals/dataset.py:959-966
    def record_attribute(self, name: str, value: Any) -> None:
        """Record an attribute value.

        Args:
            name: The name of the attribute.
            value: The value of the attribute.
        """
        self.attributes[name] = value

# tests/test_prefect.py:1217-1248
async def test_disabled_tool():
    """Test that tools can be disabled via tool_task_config_by_name."""

    # Create an agent with a tool
    test_agent = Agent(TestModel(), name='test_disabled_tool')

    @test_agent.tool_plain
    def my_tool() -> str:
        return 'Tool executed'

    # Create PrefectAgent with the tool disabled
    test_prefect_agent = PrefectAgent(
        test_agent,
        tool_task_config_by_name={
            'my_tool': None,
        },
    )

    # Test outside a flow
    result = await test_prefect_agent.run('Call my_tool')
    messages = result.all_messages()
    assert any('my_tool' in str(msg) for msg in messages)

    # Test inside a flow to ensure disabled tools work there too
    @flow
    async def test_flow():
        result = await test_prefect_agent.run('Call my_tool')
        return result

    flow_result = await test_flow()
    flow_messages = flow_result.all_messages()
    assert any('my_tool' in str(msg) for msg in flow_messages)

# tests/test_usage_limits.py:258-284
def test_add_usages_with_none_detail_value():
    """Test that None values in details are skipped when incrementing usage."""
    usage = RunUsage(
        requests=1,
        input_tokens=10,
        output_tokens=20,
        details={'reasoning_tokens': 5},
    )

    # Create a usage with None in details (simulating model response with missing detail)
    incr_usage = RunUsage(
        requests=1,
        input_tokens=5,
        output_tokens=10,
    )
    # Manually set a None value in details to simulate edge case from model responses
    incr_usage.details = {'reasoning_tokens': None, 'other_tokens': 10}  # type: ignore[dict-item]

    result = usage + incr_usage
    assert result == snapshot(
        RunUsage(
            requests=2,
            input_tokens=15,
            output_tokens=30,
            details={'reasoning_tokens': 5, 'other_tokens': 10},
        )
    )

# pydantic_ai_slim/pydantic_ai/_utils.py:159-160
def is_set(t_or_unset: T | Unset) -> TypeGuard[T]:
    return t_or_unset is not UNSET

# pydantic_ai_slim/pydantic_ai/embeddings/__init__.py:18-18
from .settings import EmbeddingSettings, merge_embedding_settings

# pydantic_evals/pydantic_evals/__init__.py:9-9
from .dataset import Case, Dataset, increment_eval_metric, set_eval_attribute

# pydantic_ai_slim/pydantic_ai/_utils.py:55-55
_disable_threads: ContextVar[bool] = ContextVar('_disable_threads', default=False)

# pydantic_ai_slim/pydantic_ai/_utils.py:156-156
UNSET = Unset()

# pydantic_ai_slim/pydantic_ai/_utils.py:156-156
UNSET = Unset()

# pydantic_ai_slim/pydantic_ai/_utils.py:156-156
UNSET = Unset()

# pydantic_ai_slim/pydantic_ai/_utils.py:150-153
class Unset:
    """A singleton to represent an unset value."""

    pass

# pydantic_ai_slim/pydantic_ai/_utils.py:156-156
UNSET = Unset()

# pydantic_ai_slim/pydantic_ai/_utils.py:156-156
UNSET = Unset()

# pydantic_ai_slim/pydantic_ai/_utils.py:150-153
class Unset:
    """A singleton to represent an unset value."""

    pass

# tests/evals/test_utils.py:32-35
def test_unset():
    """Test Unset singleton."""
    assert isinstance(UNSET, Unset)
    assert UNSET is not Unset()  # note: we might want to change this and make it a true singleton..