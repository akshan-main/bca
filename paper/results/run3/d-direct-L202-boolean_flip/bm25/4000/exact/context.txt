# pydantic_ai_slim/pydantic_ai/models/function.py:231-231
    model_request_parameters: ModelRequestParameters

# pydantic_ai_slim/pydantic_ai/result.py:50-50
    _model_request_parameters: models.ModelRequestParameters

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_model.py:35-35
    model_request_parameters: ModelRequestParameters

# pydantic_ai_slim/pydantic_ai/models/__init__.py:923-923
    model_request_parameters: ModelRequestParameters

# pydantic_ai_slim/pydantic_ai/models/test.py:82-82
    last_model_request_parameters: ModelRequestParameters | None = field(default=None, init=False)

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_model.py:239-241
    def _validate_model_request_parameters(self, model_request_parameters: ModelRequestParameters) -> None:
        if model_request_parameters.allow_image_output:
            raise UserError('Image output is not supported with Temporal because of the 2MB payload size limit.')

# pydantic_ai_slim/pydantic_ai/models/instrumented.py:543-546
    def model_request_parameters_attributes(
        model_request_parameters: ModelRequestParameters,
    ) -> dict[str, AttributeValue]:
        return {'model_request_parameters': json.dumps(InstrumentedModel.serialize_any(model_request_parameters))}

# tests/models/test_model_request_parameters.py:18-144
def test_model_request_parameters_are_serializable():
    params = ModelRequestParameters(
        function_tools=[],
        builtin_tools=[],
        output_mode='text',
        allow_text_output=True,
        output_tools=[],
        output_object=None,
    )
    dumped = ta.dump_python(params)
    assert dumped == snapshot(
        {
            'function_tools': [],
            'builtin_tools': [],
            'output_mode': 'text',
            'output_object': None,
            'output_tools': [],
            'prompted_output_template': None,
            'allow_text_output': True,
            'allow_image_output': False,
        }
    )
    assert ta.validate_python(dumped) == params

    params = ModelRequestParameters(
        function_tools=[ToolDefinition(name='test')],
        builtin_tools=[
            WebSearchTool(user_location=WebSearchUserLocation(city='New York', country='US')),
            CodeExecutionTool(),
            WebFetchTool(),
            ImageGenerationTool(size='1024x1024'),
            MemoryTool(),
            MCPServerTool(id='deepwiki', url='https://mcp.deepwiki.com/mcp'),
            MCPServerTool(id='github', url='https://api.githubcopilot.com/mcp'),
        ],
        output_mode='text',
        allow_text_output=True,
        output_tools=[ToolDefinition(name='final_result')],
        output_object=None,
    )
    dumped = ta.dump_python(params)
    assert dumped == snapshot(
        {
            'function_tools': [
                {
                    'name': 'test',
                    'parameters_json_schema': {'type': 'object', 'properties': {}},
                    'description': None,
                    'outer_typed_dict_key': None,
                    'strict': None,
                    'sequential': False,
                    'kind': 'function',
                    'metadata': None,
                    'timeout': None,
                }
            ],
            'builtin_tools': [
                {
                    'kind': 'web_search',
                    'search_context_size': 'medium',
                    'user_location': {'city': 'New York', 'country': 'US'},
                    'blocked_domains': None,
                    'allowed_domains': None,
                    'max_uses': None,
                },
                {'kind': 'code_execution'},
                {
                    'kind': 'web_fetch',
                    'max_uses': None,
                    'allowed_domains': None,
                    'blocked_domains': None,
                    'enable_citations': False,
                    'max_content_tokens': None,
                },
                {
                    'kind': 'image_generation',
                    'background': 'auto',
                    'input_fidelity': None,
                    'moderation': 'auto',
                    'output_compression': None,
                    'output_format': None,
                    'partial_images': 0,
                    'quality': 'auto',
                    'size': '1024x1024',
                    'aspect_ratio': None,
                },
                {'kind': 'memory'},
                {
                    'kind': 'mcp_server',
                    'id': 'deepwiki',
                    'url': 'https://mcp.deepwiki.com/mcp',
                    'authorization_token': None,
                    'description': None,
                    'allowed_tools': None,
                    'headers': None,
                },
                {
                    'kind': 'mcp_server',
                    'id': 'github',
                    'url': 'https://api.githubcopilot.com/mcp',
                    'authorization_token': None,
                    'description': None,
                    'allowed_tools': None,
                    'headers': None,
                },
            ],
            'output_mode': 'text',
            'output_object': None,
            'output_tools': [
                {
                    'name': 'final_result',
                    'parameters_json_schema': {'type': 'object', 'properties': {}},
                    'description': None,
                    'outer_typed_dict_key': None,
                    'strict': None,
                    'sequential': False,
                    'kind': 'function',
                    'metadata': None,
                    'timeout': None,
                }
            ],
            'prompted_output_template': None,
            'allow_text_output': True,
            'allow_image_output': False,
        }
    )
    assert ta.validate_python(dumped) == params

# tests/test_cli.py:685-704
def test_run_web_command_cli_models_passed_to_create_web_app(
    mocker: MockerFixture, create_test_module: Callable[..., None]
):
    """Test that CLI models are passed directly to create_web_app (agent model merging happens there)."""
    mock_uvicorn_run = mocker.patch('uvicorn.run')
    mock_create_app = mocker.patch('pydantic_ai._cli.web.create_web_app')

    test_agent = Agent(TestModel(custom_output_text='test'))
    create_test_module(custom_agent=test_agent)

    result = run_web_command(
        agent_path='test_module:custom_agent', models=['openai:gpt-5', 'anthropic:claude-sonnet-4-5']
    )

    assert result == 0
    mock_uvicorn_run.assert_called_once()

    call_kwargs = mock_create_app.call_args.kwargs
    # CLI models passed as list; agent model merging/deduplication happens in create_web_app
    assert call_kwargs.get('models') == ['openai:gpt-5', 'anthropic:claude-sonnet-4-5']

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:16-16
from pydantic_ai.models import Model, ModelRequestParameters, StreamedResponse

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# examples/pydantic_ai_examples/stream_markdown.py:28-32
models: list[tuple[KnownModelName, str]] = [
    ('google-gla:gemini-3-flash-preview', 'GEMINI_API_KEY'),
    ('openai:gpt-5-mini', 'OPENAI_API_KEY'),
    ('groq:llama-3.3-70b-versatile', 'GROQ_API_KEY'),
]

# tests/test_usage_limits.py:3-3
import operator

# pydantic_ai_slim/pydantic_ai/ui/_web/__init__.py:3-3
from .api import ModelsParam

# pydantic_ai_slim/pydantic_ai/ui/_web/__init__.py:3-3
from .api import ModelsParam

# pydantic_ai_slim/pydantic_ai/ui/_web/__init__.py:3-3
from .api import ModelsParam

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/models/fallback.py:30-30
    models: list[Model]

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# docs/.hooks/main.py:147-147
GATEWAY_MODELS = tuple(GATEWAY_MODEL_MAP.keys())

# pydantic_ai_slim/pydantic_ai/ui/_web/api.py:44-44
    models: list[ModelInfo]

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:206-206
    openrouter_models: list[str]

# tests/conftest.py:26-26
import pydantic_ai.models

# pydantic_ai_slim/pydantic_ai/direct.py:23-23
from .models import StreamedResponse, instrumented as instrumented_models