# Repository structure
.github/set_docs_main_preview_url.py
.github/set_docs_pr_preview_url.py
clai/clai/__init__.py
clai/clai/__main__.py
clai/update_readme.py
docs/.hooks/algolia.py
docs/.hooks/main.py
docs/.hooks/snippets.py
docs/.hooks/test_snippets.py
examples/pydantic_ai_examples/__main__.py
examples/pydantic_ai_examples/ag_ui/__init__.py
examples/pydantic_ai_examples/ag_ui/api/__init__.py
examples/pydantic_ai_examples/ag_ui/api/agentic_chat.py
examples/pydantic_ai_examples/ag_ui/api/agentic_generative_ui.py
examples/pydantic_ai_examples/ag_ui/api/human_in_the_loop.py
examples/pydantic_ai_examples/ag_ui/api/predictive_state_updates.py
examples/pydantic_ai_examples/ag_ui/api/shared_state.py
examples/pydantic_ai_examples/ag_ui/api/tool_based_generative_ui.py
examples/pydantic_ai_examples/bank_support.py
examples/pydantic_ai_examples/chat_app.py
examples/pydantic_ai_examples/data_analyst.py
examples/pydantic_ai_examples/evals/__init__.py
examples/pydantic_ai_examples/evals/agent.py
examples/pydantic_ai_examples/evals/custom_evaluators.py
examples/pydantic_ai_examples/evals/example_01_generate_dataset.py
examples/pydantic_ai_examples/evals/example_02_add_custom_evaluators.py
examples/pydantic_ai_examples/evals/example_03_unit_testing.py
examples/pydantic_ai_examples/evals/example_04_compare_models.py
examples/pydantic_ai_examples/evals/models.py
examples/pydantic_ai_examples/flight_booking.py
examples/pydantic_ai_examples/pydantic_model.py
examples/pydantic_ai_examples/question_graph.py
examples/pydantic_ai_examples/rag.py
examples/pydantic_ai_examples/roulette_wheel.py
examples/pydantic_ai_examples/slack_lead_qualifier/agent.py
examples/pydantic_ai_examples/slack_lead_qualifier/app.py
examples/pydantic_ai_examples/slack_lead_qualifier/functions.py
examples/pydantic_ai_examples/slack_lead_qualifier/modal.py
examples/pydantic_ai_examples/slack_lead_qualifier/models.py
examples/pydantic_ai_examples/slack_lead_qualifier/slack.py
examples/pydantic_ai_examples/slack_lead_qualifier/store.py
examples/pydantic_ai_examples/sql_gen.py
examples/pydantic_ai_examples/stream_markdown.py
examples/pydantic_ai_examples/stream_whales.py
examples/pydantic_ai_examples/weather_agent.py
examples/pydantic_ai_examples/weather_agent_gradio.py
pydantic_ai_slim/pydantic_ai/__init__.py
pydantic_ai_slim/pydantic_ai/__main__.py
pydantic_ai_slim/pydantic_ai/_a2a.py
pydantic_ai_slim/pydantic_ai/_agent_graph.py
pydantic_ai_slim/pydantic_ai/_cli/__init__.py
pydantic_ai_slim/pydantic_ai/_cli/web.py
pydantic_ai_slim/pydantic_ai/_function_schema.py
pydantic_ai_slim/pydantic_ai/_griffe.py
pydantic_ai_slim/pydantic_ai/_instrumentation.py
pydantic_ai_slim/pydantic_ai/_json_schema.py
pydantic_ai_slim/pydantic_ai/_mcp.py
pydantic_ai_slim/pydantic_ai/_otel_messages.py
pydantic_ai_slim/pydantic_ai/_output.py
pydantic_ai_slim/pydantic_ai/_parts_manager.py
pydantic_ai_slim/pydantic_ai/_run_context.py
pydantic_ai_slim/pydantic_ai/_ssrf.py
pydantic_ai_slim/pydantic_ai/_system_prompt.py
pydantic_ai_slim/pydantic_ai/_thinking_part.py
pydantic_ai_slim/pydantic_ai/_tool_manager.py
pydantic_ai_slim/pydantic_ai/_utils.py
pydantic_ai_slim/pydantic_ai/ag_ui.py
pydantic_ai_slim/pydantic_ai/agent/__init__.py
pydantic_ai_slim/pydantic_ai/agent/abstract.py
pydantic_ai_slim/pydantic_ai/agent/wrapper.py
pydantic_ai_slim/pydantic_ai/builtin_tools.py
pydantic_ai_slim/pydantic_ai/common_tools/duckduckgo.py
pydantic_ai_slim/pydantic_ai/common_tools/exa.py
pydantic_ai_slim/pydantic_ai/common_tools/tavily.py
pydantic_ai_slim/pydantic_ai/concurrency.py
pydantic_ai_slim/pydantic_ai/direct.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/__init__.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_agent.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_fastmcp_toolset.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_mcp.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_mcp_server.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_util


# Relevant source code


# pydantic_ai_slim/pydantic_ai/agent/abstract.py:1245-1352
    def to_ag_ui(
        self,
        *,
        # Agent.iter parameters
        output_type: OutputSpec[OutputDataT] | None = None,
        message_history: Sequence[_messages.ModelMessage] | None = None,
        deferred_tool_results: DeferredToolResults | None = None,
        model: models.Model | models.KnownModelName | str | None = None,
        deps: AgentDepsT = None,
        model_settings: ModelSettings | None = None,
        usage_limits: UsageLimits | None = None,
        usage: RunUsage | None = None,
        infer_name: bool = True,
        toolsets: Sequence[AbstractToolset[AgentDepsT]] | None = None,
        # Starlette
        debug: bool = False,
        routes: Sequence[BaseRoute] | None = None,
        middleware: Sequence[Middleware] | None = None,
        exception_handlers: Mapping[Any, ExceptionHandler] | None = None,
        on_startup: Sequence[Callable[[], Any]] | None = None,
        on_shutdown: Sequence[Callable[[], Any]] | None = None,
        lifespan: Lifespan[AGUIApp[AgentDepsT, OutputDataT]] | None = None,
    ) -> AGUIApp[AgentDepsT, OutputDataT]:
        """Returns an ASGI application that handles every AG-UI request by running the agent.

        Note that the `deps` will be the same for each request, with the exception of the AG-UI state that's
        injected into the `state` field of a `deps` object that implements the [`StateHandler`][pydantic_ai.ag_ui.StateHandler] protocol.
        To provide different `deps` for each request (e.g. based on the authenticated user),
        use [`pydantic_ai.ag_ui.run_ag_ui`][pydantic_ai.ag_ui.run_ag_ui] or
        [`pydantic_ai.ag_ui.handle_ag_ui_request`][pydantic_ai.ag_ui.handle_ag_ui_request] instead.

        Example:
        ```python
        from pydantic_ai import Agent

        agent = Agent('openai:gpt-5.2')
        app = agent.to_ag_ui()
        ```

        The `app` is an ASGI application that can be used with any ASGI server.

        To run the application, you can use the following command:

        ```bash
        uvicorn app:app --host 0.0.0.0 --port 8000
        ```

        See [AG-UI docs](../ui/ag-ui.md) for more information.

        Args:
            output_type: Custom output type to use for this run, `output_type` may only be used if the agent has
                no output validators since output validators would expect an argument that matches the agent's
                output type.
            message_history: History of the conversation so far.
            deferred_tool_results: Optional results for deferred tool calls in the message history.
            model: Optional model to use for this run, required if `model` was not set when creating the agent.
            deps: Optional dependencies to use for this run.
            model_settings: Optional settings to use for this model's request.
            usage_limits: Optional limits on model request count or token usage.
            usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.
            infer_name: Whether to try to infer the agent name from the call frame if it's not set.
            toolsets: Optional additional toolsets for this run.

            debug: Boolean indicating if debug tracebacks should be returned on errors.
            routes: A list of routes to serve incoming HTTP and WebSocket requests.
            middleware: A list of middleware to run for every request. A starlette application will always
                automatically include two middleware classes. `ServerErrorMiddleware` is added as the very
                outermost middleware, to handle any uncaught errors occurring anywhere in the entire stack.
                `ExceptionMiddleware` is added as the very innermost middleware, to deal with handled
                exception cases occurring in the routing or endpoints.
            exception_handlers: A mapping of either integer status codes, or exception class types onto
                callables which handle the exceptions. Exception handler callables should be of the form
                `handler(request, exc) -> response` and may be either standard functions, or async functions.
            on_startup: A list of callables to run on application startup. Startup handler callables do not
                take any arguments, and may be either standard functions, or async functions.
            on_shutdown: A list of callables to run on application shutdown. Shutdown handler callables do
                not take any arguments, and may be either standard functions, or async functions.
            lifespan: A lifespan context function, which can be used to perform startup and shutdown tasks.
                This is a newer style that replaces the `on_startup` and `on_shutdown` handlers. Use one or
                the other, not both.

        Returns:
            An ASGI application for running Pydantic AI agents with AG-UI protocol support.
        """
        from pydantic_ai.ui.ag_ui.app import AGUIApp

        return AGUIApp(
            agent=self,
            # Agent.iter parameters
            output_type=output_type,
            message_history=message_history,
            deferred_tool_results=deferred_tool_results,
            model=model,
            deps=deps,
            model_settings=model_settings,
            usage_limits=usage_limits,
            usage=usage,
            infer_name=infer_name,
            toolsets=toolsets,
            # Starlette
            debug=debug,
            routes=routes,
            middleware=middleware,
            exception_handlers=exception_handlers,
            on_startup=on_startup,
            on_shutdown=on_shutdown,
            lifespan=lifespan,
        )

# pydantic_ai_slim/pydantic_ai/messages.py:1779-1802
    def apply(
        self, part: ModelResponsePart | ToolCallPartDelta
    ) -> ToolCallPart | BuiltinToolCallPart | ToolCallPartDelta:
        """Apply this delta to a part or delta, returning a new part or delta with the changes applied.

        Args:
            part: The existing model response part or delta to update.

        Returns:
            Either a new `ToolCallPart` or `BuiltinToolCallPart`, or an updated `ToolCallPartDelta`.

        Raises:
            ValueError: If `part` is neither a `ToolCallPart`, `BuiltinToolCallPart`, nor a `ToolCallPartDelta`.
            UnexpectedModelBehavior: If applying JSON deltas to dict arguments or vice versa.
        """
        if isinstance(part, ToolCallPart | BuiltinToolCallPart):
            return self._apply_to_part(part)

        if isinstance(part, ToolCallPartDelta):
            return self._apply_to_delta(part)

        raise ValueError(  # pragma: no cover
            f'Can only apply ToolCallPartDeltas to ToolCallParts, BuiltinToolCallParts, or ToolCallPartDeltas, not {part}'
        )

# pydantic_ai_slim/pydantic_ai/retries.py:117-212
class TenacityTransport(BaseTransport):
    """Synchronous HTTP transport with tenacity-based retry functionality.

    This transport wraps another BaseTransport and adds retry capabilities using the tenacity library.
    It can be configured to retry requests based on various conditions such as specific exception types,
    response status codes, or custom validation logic.

    The transport works by intercepting HTTP requests and responses, allowing the tenacity controller
    to determine when and how to retry failed requests. The validate_response function can be used
    to convert HTTP responses into exceptions that trigger retries.

    Args:
        wrapped: The underlying transport to wrap and add retry functionality to.
        config: The arguments to use for the tenacity `retry` decorator, including retry conditions,
            wait strategy, stop conditions, etc. See the tenacity docs for more info.
        validate_response: Optional callable that takes a Response and can raise an exception
            to be handled by the controller if the response should trigger a retry.
            Common use case is to raise exceptions for certain HTTP status codes.
            If None, no response validation is performed.

    Example:
        ```python
        from httpx import Client, HTTPStatusError, HTTPTransport
        from tenacity import retry_if_exception_type, stop_after_attempt

        from pydantic_ai.retries import RetryConfig, TenacityTransport, wait_retry_after

        transport = TenacityTransport(
            RetryConfig(
                retry=retry_if_exception_type(HTTPStatusError),
                wait=wait_retry_after(max_wait=300),
                stop=stop_after_attempt(5),
                reraise=True
            ),
            HTTPTransport(),
            validate_response=lambda r: r.raise_for_status()
        )
        client = Client(transport=transport)
        ```
    """

    def __init__(
        self,
        config: RetryConfig,
        wrapped: BaseTransport | None = None,
        validate_response: Callable[[Response], Any] | None = None,
    ):
        self.config = config
        self.wrapped = wrapped or HTTPTransport()
        self.validate_response = validate_response

    def handle_request(self, request: Request) -> Response:
        """Handle an HTTP request with retry logic.

        Args:
            request: The HTTP request to handle.

        Returns:
            The HTTP response.

        Raises:
            RuntimeError: If the retry controller did not make any attempts.
            Exception: Any exception raised by the wrapped transport or validation function.
        """

        @retry(**self.config)
        def handle_request(req: Request) -> Response:
            response = self.wrapped.handle_request(req)

            # this is normally set by httpx _after_ calling this function, but we want the request in the validator:
            response.request = req

            if self.validate_response:
                try:
                    self.validate_response(response)
                except Exception:
                    response.close()
                    raise
            return response

        return handle_request(request)

    def __enter__(self) -> TenacityTransport:
        self.wrapped.__enter__()
        return self

    def __exit__(
        self,
        exc_type: type[BaseException] | None = None,
        exc_value: BaseException | None = None,
        traceback: TracebackType | None = None,
    ) -> None:
        self.wrapped.__exit__(exc_type, exc_value, traceback)

    def close(self) -> None:
        self.wrapped.close()  # pragma: no cover

# pydantic_graph/pydantic_graph/beta/decision.py:41-80
class Decision(Generic[StateT, DepsT, HandledT]):
    """Decision node for conditional branching in graph execution.

    A Decision node evaluates conditions and routes execution to different
    branches based on the input data type or custom matching logic.
    """

    id: NodeID
    """Unique identifier for this decision node."""

    branches: list[DecisionBranch[Any]]
    """List of branches that can be taken from this decision."""

    note: str | None
    """Optional documentation note for this decision."""

    def branch(self, branch: DecisionBranch[T]) -> Decision[StateT, DepsT, HandledT | T]:
        """Add a new branch to this decision.

        Args:
            branch: The branch to add to this decision.

        Returns:
            A new Decision with the additional branch.
        """
        return Decision(id=self.id, branches=self.branches + [branch], note=self.note)

    def _force_handled_contravariant(self, inputs: HandledT) -> Never:  # pragma: no cover
        """Forces this type to be contravariant in the HandledT type variable.

        This is an implementation detail of how we can type-check that all possible input types have
        been exhaustively covered.

        Args:
            inputs: Input data of handled types.

        Raises:
            RuntimeError: Always, as this method should never be executed.
        """
        raise RuntimeError('This method should never be called, it is just defined for typing purposes.')

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:374-387
    async def _sys_parts(self, run_context: RunContext[DepsT]) -> list[_messages.ModelRequestPart]:
        """Build the initial messages for the conversation."""
        messages: list[_messages.ModelRequestPart] = [_messages.SystemPromptPart(p) for p in self.system_prompts]
        for sys_prompt_runner in self.system_prompt_functions:
            prompt = await sys_prompt_runner.run(run_context)
            if sys_prompt_runner.dynamic:
                # To enable dynamic system prompt refs in future runs, use a placeholder string
                messages.append(
                    _messages.SystemPromptPart(prompt or '', dynamic_ref=sys_prompt_runner.function.__qualname__)
                )
            elif prompt:
                # omit empty system prompts
                messages.append(_messages.SystemPromptPart(prompt))
        return messages

# pydantic_ai_slim/pydantic_ai/_utils.py:86-101
def is_model_like(type_: Any) -> bool:
    """Check if something is a pydantic model, dataclass or typedict.

    These should all generate a JSON Schema with `{"type": "object"}` and therefore be usable directly as
    function parameters.
    """
    return (
        isinstance(type_, type)
        and not isinstance(type_, GenericAlias)
        and (
            issubclass(type_, BaseModel)
            or is_dataclass(type_)  # pyright: ignore[reportUnknownArgumentType]
            or is_typeddict(type_)  # pyright: ignore[reportUnknownArgumentType]
            or getattr(type_, '__is_model_like__', False)  # pyright: ignore[reportUnknownArgumentType]
        )
    )

# tests/example_modules/weather_service.py:8-9
    def get_historic_weather(self, location: str, forecast_date: date) -> str:
        return 'Sunny with a chance of rain'