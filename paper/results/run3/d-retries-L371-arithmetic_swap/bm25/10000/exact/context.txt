# tests/test_agent.py:3080-3144
def test_unknown_tool_multiple_retries():
    num_retries = 2

    def empty(_: list[ModelMessage], _info: AgentInfo) -> ModelResponse:
        return ModelResponse(parts=[ToolCallPart('foobar', '{}')])

    agent = Agent(FunctionModel(empty), retries=num_retries)

    with capture_run_messages() as messages:
        with pytest.raises(UnexpectedModelBehavior, match=r'Exceeded maximum retries \(2\) for output validation'):
            agent.run_sync('Hello')
    assert messages == snapshot(
        [
            ModelRequest(
                parts=[UserPromptPart(content='Hello', timestamp=IsNow(tz=timezone.utc))],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelResponse(
                parts=[ToolCallPart(tool_name='foobar', args='{}', tool_call_id=IsStr())],
                usage=RequestUsage(input_tokens=51, output_tokens=2),
                model_name='function:empty:',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelRequest(
                parts=[
                    RetryPromptPart(
                        tool_name='foobar',
                        content="Unknown tool name: 'foobar'. No tools available.",
                        tool_call_id=IsStr(),
                        timestamp=IsNow(tz=timezone.utc),
                    )
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelResponse(
                parts=[ToolCallPart(tool_name='foobar', args='{}', tool_call_id=IsStr())],
                usage=RequestUsage(input_tokens=65, output_tokens=4),
                model_name='function:empty:',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelRequest(
                parts=[
                    RetryPromptPart(
                        tool_name='foobar',
                        content="Unknown tool name: 'foobar'. No tools available.",
                        tool_call_id=IsStr(),
                        timestamp=IsNow(tz=timezone.utc),
                    )
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelResponse(
                parts=[ToolCallPart(tool_name='foobar', args='{}', tool_call_id=IsStr())],
                usage=RequestUsage(input_tokens=79, output_tokens=6),
                model_name='function:empty:',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
        ]
    )

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:22-22
from pydantic_ai._utils import dataclasses_no_defaults_repr, get_union_args, is_async_callable, now_utc, run_in_executor

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:22-22
from pydantic_ai._utils import dataclasses_no_defaults_repr, get_union_args, is_async_callable, now_utc, run_in_executor

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:22-22
from pydantic_ai._utils import dataclasses_no_defaults_repr, get_union_args, is_async_callable, now_utc, run_in_executor

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:22-22
from pydantic_ai._utils import dataclasses_no_defaults_repr, get_union_args, is_async_callable, now_utc, run_in_executor

# pydantic_ai_slim/pydantic_ai/embeddings/result.py:8-8
from pydantic_ai._utils import now_utc as _now_utc

# pydantic_ai_slim/pydantic_ai/embeddings/result.py:8-8
from pydantic_ai._utils import now_utc as _now_utc

# pydantic_ai_slim/pydantic_ai/embeddings/result.py:8-8
from pydantic_ai._utils import now_utc as _now_utc

# pydantic_ai_slim/pydantic_ai/embeddings/result.py:8-8
from pydantic_ai._utils import now_utc as _now_utc

# tests/test_dbos.py:987-988
def now_func() -> datetime:
    return datetime.now()

# tests/test_dbos.py:987-988
def now_func() -> datetime:
    return datetime.now()

# examples/pydantic_ai_examples/evals/agent.py:20-20
    now: datetime = field(default_factory=lambda: datetime.now().astimezone())

# examples/pydantic_ai_examples/evals/models.py:57-57
    now: AwareDatetime

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# tests/test_tools.py:402-404
def unknown_docstring(**kwargs: int) -> str:  # pragma: no cover
    """Unknown style docstring."""
    return str(kwargs)

# tests/test_agent.py:2986-3029
def test_unknown_tool():
    def empty(_: list[ModelMessage], _info: AgentInfo) -> ModelResponse:
        return ModelResponse(parts=[ToolCallPart('foobar', '{}')])

    agent = Agent(FunctionModel(empty))

    with capture_run_messages() as messages:
        with pytest.raises(UnexpectedModelBehavior, match=r'Exceeded maximum retries \(1\) for output validation'):
            agent.run_sync('Hello')
    assert messages == snapshot(
        [
            ModelRequest(
                parts=[UserPromptPart(content='Hello', timestamp=IsNow(tz=timezone.utc))],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelResponse(
                parts=[ToolCallPart(tool_name='foobar', args='{}', tool_call_id=IsStr())],
                usage=RequestUsage(input_tokens=51, output_tokens=2),
                model_name='function:empty:',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelRequest(
                parts=[
                    RetryPromptPart(
                        tool_name='foobar',
                        content="Unknown tool name: 'foobar'. No tools available.",
                        tool_call_id=IsStr(),
                        timestamp=IsNow(tz=timezone.utc),
                    )
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelResponse(
                parts=[ToolCallPart(tool_name='foobar', args='{}', tool_call_id=IsStr())],
                usage=RequestUsage(input_tokens=65, output_tokens=4),
                model_name='function:empty:',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
        ]
    )

# tests/graph/test_mermaid.py:387-395
def test_save_pdf_known(tmp_path: Path, httpx_with_handler: HttpxWithHandler):
    def get_pdf(request: httpx.Request) -> httpx.Response:
        assert dict(request.url.params) == snapshot({})
        assert request.url.path.startswith('/pdf/')
        return httpx.Response(200, content=b'fake pdf')

    path2 = tmp_path / 'graph'
    graph1.mermaid_save(str(path2), start_node=Foo(), image_type='pdf', httpx_client=httpx_with_handler(get_pdf))
    assert path2.read_bytes() == b'fake pdf'

# tests/test_tools.py:747-758
def test_return_unknown():
    agent = Agent('test')

    class Foobar:
        pass

    @agent.tool_plain
    def return_pydantic_model() -> Foobar:
        return Foobar()

    with pytest.raises(PydanticSerializationError, match='Unable to serialize unknown type:'):
        agent.run_sync('')

# tests/test_agent.py:3032-3077
def test_unknown_tool_fix():
    def empty(m: list[ModelMessage], _info: AgentInfo) -> ModelResponse:
        if len(m) > 1:
            return ModelResponse(parts=[TextPart('success')])
        else:
            return ModelResponse(parts=[ToolCallPart('foobar', '{}')])

    agent = Agent(FunctionModel(empty))

    result = agent.run_sync('Hello')
    assert result.output == 'success'
    assert result.all_messages() == snapshot(
        [
            ModelRequest(
                parts=[UserPromptPart(content='Hello', timestamp=IsNow(tz=timezone.utc))],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelResponse(
                parts=[ToolCallPart(tool_name='foobar', args='{}', tool_call_id=IsStr())],
                usage=RequestUsage(input_tokens=51, output_tokens=2),
                model_name='function:empty:',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelRequest(
                parts=[
                    RetryPromptPart(
                        tool_name='foobar',
                        content="Unknown tool name: 'foobar'. No tools available.",
                        tool_call_id=IsStr(),
                        timestamp=IsNow(tz=timezone.utc),
                    )
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelResponse(
                parts=[TextPart(content='success')],
                usage=RequestUsage(input_tokens=65, output_tokens=3),
                model_name='function:empty:',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
        ]
    )

# tests/models/test_model.py:264-266
def test_infer_str_unknown():
    with pytest.raises(UserError, match='Unknown model: foobar'):
        infer_model('foobar')

# tests/models/test_model_names.py:78-115
def test_known_model_names():  # pragma: lax no cover
    # Coverage seems to be misbehaving..?
    def get_model_names(model_name_type: Any) -> Iterator[str]:
        for arg in get_args(model_name_type):
            if isinstance(arg, str):
                yield arg
            else:
                yield from get_model_names(arg)

    all_generated_names = [
        f'{provider}:{n}'
        for provider, model_names in _PROVIDER_TO_MODEL_NAMES.items()
        for n in get_model_names(model_names)
    ]

    cerebras_names = get_cerebras_model_names()
    heroku_names = get_heroku_model_names()
    gateway_names = [
        f'gateway/{provider}:{model_name}'
        for provider in GatewayModelProvider.__args__
        for model_name in get_model_names(_PROVIDER_TO_MODEL_NAMES[provider])
    ]

    extra_names = ['test']

    generated_names = sorted(all_generated_names + gateway_names + heroku_names + cerebras_names + extra_names)

    known_model_names = sorted(get_args(KnownModelName.__value__))

    if generated_names != known_model_names:
        errors: list[str] = []
        missing_names = set(generated_names) - set(known_model_names)
        if missing_names:
            errors.append(f'Missing names: {missing_names}')
        extra_names = set(known_model_names) - set(generated_names)
        if extra_names:
            errors.append(f'Extra names: {extra_names}')
        raise AssertionError('\n'.join(errors))

# tests/test_tools.py:407-425
def test_docstring_unknown():
    agent = Agent(FunctionModel(get_json_schema))
    agent.tool_plain(unknown_docstring)

    result = agent.run_sync('Hello')
    json_schema = json.loads(result.output)
    assert json_schema == snapshot(
        {
            'name': 'unknown_docstring',
            'description': 'Unknown style docstring.',
            'parameters_json_schema': {'additionalProperties': {'type': 'integer'}, 'properties': {}, 'type': 'object'},
            'outer_typed_dict_key': None,
            'strict': None,
            'kind': 'function',
            'sequential': False,
            'metadata': None,
            'timeout': None,
        }
    )

# pydantic_ai_slim/pydantic_ai/embeddings/__init__.py:36-68
KnownEmbeddingModelName = TypeAliasType(
    'KnownEmbeddingModelName',
    Literal[
        'google-gla:gemini-embedding-001',
        'google-vertex:gemini-embedding-001',
        'google-vertex:text-embedding-005',
        'google-vertex:text-multilingual-embedding-002',
        'openai:text-embedding-ada-002',
        'openai:text-embedding-3-small',
        'openai:text-embedding-3-large',
        'cohere:embed-v4.0',
        'cohere:embed-english-v3.0',
        'cohere:embed-english-light-v3.0',
        'cohere:embed-multilingual-v3.0',
        'cohere:embed-multilingual-light-v3.0',
        'voyageai:voyage-4-large',
        'voyageai:voyage-4',
        'voyageai:voyage-4-lite',
        'voyageai:voyage-3-large',
        'voyageai:voyage-3.5',
        'voyageai:voyage-3.5-lite',
        'voyageai:voyage-code-3',
        'voyageai:voyage-finance-2',
        'voyageai:voyage-law-2',
        'voyageai:voyage-code-2',
        'bedrock:amazon.titan-embed-text-v1',
        'bedrock:amazon.titan-embed-text-v2:0',
        'bedrock:cohere.embed-english-v3',
        'bedrock:cohere.embed-multilingual-v3',
        'bedrock:cohere.embed-v4:0',
        'bedrock:amazon.nova-2-multimodal-embeddings-v1:0',
    ],
)

# pydantic_ai_slim/pydantic_ai/embeddings/__init__.py:36-68
KnownEmbeddingModelName = TypeAliasType(
    'KnownEmbeddingModelName',
    Literal[
        'google-gla:gemini-embedding-001',
        'google-vertex:gemini-embedding-001',
        'google-vertex:text-embedding-005',
        'google-vertex:text-multilingual-embedding-002',
        'openai:text-embedding-ada-002',
        'openai:text-embedding-3-small',
        'openai:text-embedding-3-large',
        'cohere:embed-v4.0',
        'cohere:embed-english-v3.0',
        'cohere:embed-english-light-v3.0',
        'cohere:embed-multilingual-v3.0',
        'cohere:embed-multilingual-light-v3.0',
        'voyageai:voyage-4-large',
        'voyageai:voyage-4',
        'voyageai:voyage-4-lite',
        'voyageai:voyage-3-large',
        'voyageai:voyage-3.5',
        'voyageai:voyage-3.5-lite',
        'voyageai:voyage-code-3',
        'voyageai:voyage-finance-2',
        'voyageai:voyage-law-2',
        'voyageai:voyage-code-2',
        'bedrock:amazon.titan-embed-text-v1',
        'bedrock:amazon.titan-embed-text-v2:0',
        'bedrock:cohere.embed-english-v3',
        'bedrock:cohere.embed-multilingual-v3',
        'bedrock:cohere.embed-v4:0',
        'bedrock:amazon.nova-2-multimodal-embeddings-v1:0',
    ],
)

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:58-122
KnownOpenRouterProviders = Literal[
    'z-ai',
    'cerebras',
    'venice',
    'moonshotai',
    'morph',
    'stealth',
    'wandb',
    'klusterai',
    'openai',
    'sambanova',
    'amazon-bedrock',
    'mistral',
    'nextbit',
    'atoma',
    'ai21',
    'minimax',
    'baseten',
    'anthropic',
    'featherless',
    'groq',
    'lambda',
    'azure',
    'ncompass',
    'deepseek',
    'hyperbolic',
    'crusoe',
    'cohere',
    'mancer',
    'avian',
    'perplexity',
    'novita',
    'siliconflow',
    'switchpoint',
    'xai',
    'inflection',
    'fireworks',
    'deepinfra',
    'inference-net',
    'inception',
    'atlas-cloud',
    'nvidia',
    'alibaba',
    'friendli',
    'infermatic',
    'targon',
    'ubicloud',
    'aion-labs',
    'liquid',
    'nineteen',
    'cloudflare',
    'nebius',
    'chutes',
    'enfer',
    'crofai',
    'open-inference',
    'phala',
    'gmicloud',
    'meta',
    'relace',
    'parasail',
    'together',
    'google-ai-studio',
    'google-vertex',
]

# tests/test_examples.py:66-66
    known_first_party: list[str] = field(default_factory=list[str])

# pydantic_ai_slim/pydantic_ai/toolsets/fastmcp.py:54-54
UNKNOWN_BINARY_MEDIA_TYPE = 'application/octet-stream'

# tests/test_examples.py:67-67
    known_local_folder: list[str] = field(default_factory=list[str])

# tests/providers/test_sambanova_provider.py:85-89
def test_unknown_model_profile():
    provider = SambaNovaProvider(api_key='key')
    # Unknown model -> should return OpenAI compatibility wrapper with None base profile
    profile = provider.model_profile('unknown-model')
    assert isinstance(profile, OpenAIModelProfile)

# tests/test_usage_limits.py:458-459
def test_usage_unknown_provider():
    assert RequestUsage.extract({}, provider='unknown', provider_url='', provider_fallback='') == RequestUsage()

# tests/providers/test_gateway.py:110-112
def test_gateway_provider_unknown():
    with raises(snapshot('UserError: Unknown upstream provider: foo')):
        gateway_provider('foo')

# tests/test_embeddings.py:1426-1455
def test_known_embedding_model_names():  # pragma: lax no cover
    # Coverage seems to be misbehaving..?
    def get_model_names(model_name_type: Any) -> Iterator[str]:
        for arg in get_args(model_name_type):
            if isinstance(arg, str):
                yield arg
            else:
                yield from get_model_names(arg)

    openai_names = [f'openai:{n}' for n in get_model_names(LatestOpenAIEmbeddingModelNames)]
    cohere_names = [f'cohere:{n}' for n in get_model_names(LatestCohereEmbeddingModelNames)]
    google_gla_names = [f'google-gla:{n}' for n in get_model_names(LatestGoogleGLAEmbeddingModelNames)]
    google_vertex_names = [f'google-vertex:{n}' for n in get_model_names(LatestGoogleVertexEmbeddingModelNames)]
    voyageai_names = [f'voyageai:{n}' for n in get_model_names(LatestVoyageAIEmbeddingModelNames)]
    bedrock_names = [f'bedrock:{n}' for n in get_model_names(LatestBedrockEmbeddingModelNames)]

    generated_names = sorted(
        openai_names + cohere_names + google_gla_names + google_vertex_names + voyageai_names + bedrock_names
    )

    known_model_names = sorted(get_args(KnownEmbeddingModelName.__value__))
    if generated_names != known_model_names:
        errors: list[str] = []
        missing_names = set(generated_names) - set(known_model_names)
        if missing_names:
            errors.append(f'Missing names: {missing_names}')
        extra_names = set(known_model_names) - set(generated_names)
        if extra_names:
            errors.append(f'Extra names: {extra_names}')
        raise AssertionError('\n'.join(errors))

# tests/test_cli.py:628-639
def test_run_web_command_unknown_tool(mocker: MockerFixture, capfd: CaptureFixture[str]):
    """Test run_web_command warns about unknown tool IDs."""

    mock_uvicorn_run = mocker.patch('uvicorn.run')
    mocker.patch('pydantic_ai._cli.web.create_web_app')

    result = run_web_command(models=['test'], tools=['unknown_tool_xyz'])

    assert result == 0
    mock_uvicorn_run.assert_called_once()
    output = capfd.readouterr().out
    assert 'Unknown tool "unknown_tool_xyz"' in output

# tests/test_utils.py:537-540
def test_validate_empty_kwargs_with_unknown():
    """Test that unknown kwargs raise UserError."""
    with pytest.raises(UserError, match='Unknown keyword arguments: `unknown_arg`'):
        validate_empty_kwargs({'unknown_arg': 'value'})

# tests/providers/test_vercel.py:138-143
def test_vercel_provider_unknown_provider():
    provider = VercelProvider(api_key='api-key')

    profile = provider.model_profile('unknown/gpt-4')
    assert profile is not None
    assert profile.json_schema_transformer == OpenAIJsonSchemaTransformer

# tests/test_messages.py:262-265
def test_binary_content_unknown_media_type():
    with pytest.raises(ValueError, match='Unknown media type: application/custom'):
        binary_content = BinaryContent(data=b'Hello, world!', media_type='application/custom')
        binary_content.format

# pydantic_graph/pydantic_graph/beta/join.py:132-132
NumericT = TypeVar('NumericT', bound=SupportsSum, infer_variance=True)

# tests/test_utils.py:543-546
def test_validate_empty_kwargs_multiple_unknown():
    """Test that multiple unknown kwargs are properly formatted."""
    with pytest.raises(UserError, match='Unknown keyword arguments: `arg1`, `arg2`'):
        validate_empty_kwargs({'arg1': 'value1', 'arg2': 'value2'})

# tests/evals/test_dataset.py:1939-1950
async def test_from_text_with_unknown_report_evaluator():
    """Loading a YAML with an unknown report evaluator name raises an error."""
    yaml_text = """\
cases:
  - name: c1
    inputs:
      query: hello
report_evaluators:
  - NonExistentEvaluator
"""
    with pytest.raises(ExceptionGroup, match='error.*loading evaluators'):
        Dataset[TaskInput, TaskOutput, TaskMetadata].from_text(yaml_text)

# tests/test_concurrency.py:62-67
    async def test_nowait_acquisition(self):
        """Test that immediate acquisition works."""
        limiter = ConcurrencyLimiter(max_running=10)
        # With high limit, should acquire immediately
        async with get_concurrency_context(limiter, 'test'):
            pass  # No waiting

# tests/test_embeddings.py:1082-1085
    async def test_unknown_model_max_tokens_returns_none(self, bedrock_provider: BedrockProvider):
        """Test that unknown models with valid prefixes return None for max_input_tokens."""
        model = BedrockEmbeddingModel('amazon.titan-embed-text-v99:0', provider=bedrock_provider)
        assert await model.max_input_tokens() is None

# tests/test_usage_limits.py:3-3
import operator

# tests/providers/test_bedrock.py:174-180
def test_bedrock_provider_model_profile_with_unknown_geo_prefix(env: TestEnv):
    env.set('AWS_DEFAULT_REGION', 'us-east-1')
    provider = BedrockProvider()

    model_name = 'narnia.anthropic.claude-sonnet-4-5-20250929-v1:0'
    profile = provider.model_profile(model_name)
    assert profile is None, f'model_profile returned {profile} for {model_name}'

# tests/typed_agent.py:79-80
def wrong_tool_prepare(ctx: RunContext[MyDeps], x: int, y: str) -> str:
    return f'{ctx.deps.foo} {x} {y}'

# pydantic_ai_slim/pydantic_ai/mcp.py:241-241
    tools_list_changed: bool = False