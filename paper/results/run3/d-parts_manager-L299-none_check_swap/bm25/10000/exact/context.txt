# pydantic_ai_slim/pydantic_ai/_utils.py:140-143
class Some(Generic[T]):
    """Analogous to Rust's `Option::Some` type."""

    value: T

# tests/test_usage_limits.py:258-284
def test_add_usages_with_none_detail_value():
    """Test that None values in details are skipped when incrementing usage."""
    usage = RunUsage(
        requests=1,
        input_tokens=10,
        output_tokens=20,
        details={'reasoning_tokens': 5},
    )

    # Create a usage with None in details (simulating model response with missing detail)
    incr_usage = RunUsage(
        requests=1,
        input_tokens=5,
        output_tokens=10,
    )
    # Manually set a None value in details to simulate edge case from model responses
    incr_usage.details = {'reasoning_tokens': None, 'other_tokens': 10}  # type: ignore[dict-item]

    result = usage + incr_usage
    assert result == snapshot(
        RunUsage(
            requests=2,
            input_tokens=15,
            output_tokens=30,
            details={'reasoning_tokens': 5, 'other_tokens': 10},
        )
    )

# tests/test_tools.py:2665-2675
def test_tool_timeout_default_none():
    """Test that timeout defaults to None when not specified."""
    agent = Agent(TestModel())

    @agent.tool_plain
    def tool_without_timeout() -> str:
        return 'done'  # pragma: no cover

    tool = agent._function_toolset.tools['tool_without_timeout']
    assert tool.timeout is None
    assert tool.tool_def.timeout is None

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# tests/mcp_server.py:164-165
async def get_none():
    return None

# pydantic_ai_slim/pydantic_ai/format_prompt.py:84-84
    none_str: str

# tests/models/test_model_function.py:279-296
def test_deps_none():
    agent = Agent(FunctionModel(call_tool))

    @agent.tool
    async def get_none(ctx: RunContext[None]):
        nonlocal called

        called = True
        assert ctx.deps is None
        return ''

    called = False
    agent.run_sync('Hello')
    assert called

    called = False
    agent.run_sync('Hello')
    assert called

# tests/models/test_openai.py:808-822
async def test_none_delta(allow_model_requests: None):
    stream = [
        none_delta_chunk(),
        text_chunk('hello '),
        text_chunk('world'),
    ]
    mock_client = MockOpenAI.create_mock_stream(stream)
    m = OpenAIChatModel('gpt-4o', provider=OpenAIProvider(openai_client=mock_client))
    agent = Agent(m)

    async with agent.run_stream('') as result:
        assert not result.is_complete
        assert [c async for c in result.stream_text(debounce_by=None)] == snapshot(['hello ', 'hello world'])
        assert result.is_complete
        assert result.usage() == snapshot(RunUsage(requests=1, input_tokens=6, output_tokens=3))

# tests/typed_deps.py:53-54
async def my_prepare_none(ctx: RunContext, tool_defn: ToolDefinition) -> None:
    pass

# tests/models/test_openai.py:794-805
def none_delta_chunk(finish_reason: FinishReason | None = None) -> chat.ChatCompletionChunk:
    choice = ChunkChoice(index=0, delta=ChoiceDelta())
    # When using Azure OpenAI and an async content filter is enabled, the openai SDK can return None deltas.
    choice.delta = None  # pyright: ignore[reportAttributeAccessIssue]
    return chat.ChatCompletionChunk(
        id='123',
        choices=[choice],
        created=1704067200,  # 2024-01-01
        model='gpt-4o-123',
        object='chat.completion.chunk',
        usage=CompletionUsage(completion_tokens=1, prompt_tokens=2, total_tokens=3),
    )

# pydantic_ai_slim/pydantic_ai/_parts_manager.py:434-437
    def _stop_tracking_vendor_id(self, vendor_part_id: VendorId | None) -> None:
        """Stop tracking a vendor_part_id (no-op if None or not tracked)."""
        if vendor_part_id is not None:  # pragma: no branch
            self._vendor_id_to_part_index.pop(vendor_part_id, None)

# tests/models/test_xai.py:989-1003
async def test_xai_none_delta(allow_model_requests: None):
    # Test handling of chunks without deltas
    stream = [
        get_grok_text_chunk('hello '),
        get_grok_text_chunk('world'),
    ]
    mock_client = MockXai.create_mock_stream([stream])
    m = XaiModel(XAI_NON_REASONING_MODEL, provider=XaiProvider(xai_client=mock_client))
    agent = Agent(m)

    async with agent.run_stream('') as result:
        assert not result.is_complete
        assert [c async for c in result.stream_text(debounce_by=None)] == snapshot(['hello ', 'hello world'])
        assert result.is_complete
        assert result.usage() == snapshot(RunUsage(input_tokens=2, output_tokens=1, requests=1))

# tests/test_agent.py:4821-4850
def test_dynamic_system_prompt_none_return():
    """Test dynamic system prompts with None return values."""
    agent = Agent('test')

    dynamic_values = [None, 'DYNAMIC']

    @agent.system_prompt(dynamic=True)
    def dynamic_sys() -> str | None:
        return dynamic_values.pop(0)

    with capture_run_messages() as base_messages:
        agent.run_sync('Hi', model=TestModel(custom_output_text='baseline'))

    base_req = base_messages[0]
    assert isinstance(base_req, ModelRequest)
    sys_texts = [p.content for p in base_req.parts if isinstance(p, SystemPromptPart)]
    # The None value should have a '' placeholder due to keeping a reference to the dynamic prompt
    assert '' in sys_texts
    assert 'DYNAMIC' not in sys_texts

    # Run a second time to capture the updated system prompt
    with capture_run_messages() as messages:
        agent.run_sync('Hi', model=TestModel(custom_output_text='baseline'))

    req = messages[0]
    assert isinstance(req, ModelRequest)
    sys_texts = [p.content for p in req.parts if isinstance(p, SystemPromptPart)]
    # The None value should have a '' placeholder due to keep a reference to the dynamic prompt
    assert '' not in sys_texts
    assert 'DYNAMIC' in sys_texts

# tests/test_vercel_ai.py:4409-4434
    async def test_dump_provider_metadata_filters_none_values(self):
        """Test that dump_provider_metadata only includes non-None values."""

        # All None - should return None
        result = dump_provider_metadata(id=None, provider_name=None, provider_details=None)
        assert result is None

        # Some values
        result = dump_provider_metadata(id='test_id', provider_name=None, provider_details={'key': 'val'})
        assert result == {'pydantic_ai': {'id': 'test_id', 'provider_details': {'key': 'val'}}}

        # All values
        result = dump_provider_metadata(
            id='full_id',
            signature='sig',
            provider_name='provider',
            provider_details={'detail': 1},
        )
        assert result == {
            'pydantic_ai': {
                'id': 'full_id',
                'signature': 'sig',
                'provider_name': 'provider',
                'provider_details': {'detail': 1},
            }
        }

# tests/graph/beta/test_edge_cases.py:60-80
async def test_step_with_zero_value():
    """Test handling of zero values (ensure they're not confused with None/falsy)."""
    g = GraphBuilder(state_type=EdgeCaseState, output_type=int)

    @g.step
    async def return_zero(ctx: StepContext[EdgeCaseState, None, None]) -> int:
        return 0

    @g.step
    async def process_zero(ctx: StepContext[EdgeCaseState, None, int]) -> int:
        return ctx.inputs + 1

    g.add(
        g.edge_from(g.start_node).to(return_zero),
        g.edge_from(return_zero).to(process_zero),
        g.edge_from(process_zero).to(g.end_node),
    )

    graph = g.build()
    result = await graph.run(state=EdgeCaseState())
    assert result == 1

# tests/test_concurrency.py:216-219
    async def test_returns_null_context_when_none(self):
        """Test that get_concurrency_context returns a no-op context when None."""
        async with get_concurrency_context(None, 'test'):
            pass  # Should be a no-op

# tests/graph/beta/test_edge_cases.py:34-57
async def test_step_returning_none():
    """Test steps that return None."""
    g = GraphBuilder(state_type=EdgeCaseState)

    @g.step
    async def do_nothing(ctx: StepContext[EdgeCaseState, None, None]) -> None:
        ctx.state.value = 99
        return None

    @g.step
    async def return_none(ctx: StepContext[EdgeCaseState, None, None]) -> None:
        return None

    g.add(
        g.edge_from(g.start_node).to(do_nothing),
        g.edge_from(do_nothing).to(return_none),
        g.edge_from(return_none).to(g.end_node),
    )

    graph = g.build()
    state = EdgeCaseState()
    result = await graph.run(state=state)
    assert result is None
    assert state.value == 99

# tests/test_ag_ui.py:244-262
async def test_agui_adapter_state_none() -> None:
    """Ensure adapter exposes `None` state when no frontend state provided."""
    agent = Agent(
        model=FunctionModel(stream_function=simple_stream),
    )

    run_input = RunAgentInput(
        thread_id=uuid_str(),
        run_id=uuid_str(),
        messages=[],
        state=None,
        context=[],
        tools=[],
        forwarded_props=None,
    )

    adapter = AGUIAdapter(agent=agent, run_input=run_input, accept=None)

    assert adapter.state is None

# tests/test_agent.py:4853-4869
def test_system_prompt_none_return_are_omitted():
    """Test dynamic system prompts with None return values."""
    agent = Agent('test', system_prompt='STATIC')

    @agent.system_prompt
    def dynamic_sys() -> str | None:
        return None

    with capture_run_messages() as base_messages:
        agent.run_sync('Hi', model=TestModel(custom_output_text='baseline'))

    base_req = base_messages[0]
    assert isinstance(base_req, ModelRequest)
    sys_texts = [p.content for p in base_req.parts if isinstance(p, SystemPromptPart)]
    # The None value should be omitted
    assert 'STATIC' in sys_texts
    assert '' not in sys_texts

# tests/test_mcp.py:1384-1461
async def test_tool_returning_none(allow_model_requests: None, agent: Agent):
    async with agent:
        result = await agent.run('Call the none tool and say Hello')
        assert result.output == snapshot('Hello! How can I assist you today?')
        assert result.all_messages() == snapshot(
            [
                ModelRequest(
                    parts=[
                        UserPromptPart(
                            content='Call the none tool and say Hello',
                            timestamp=IsDatetime(),
                        )
                    ],
                    timestamp=IsDatetime(),
                    run_id=IsStr(),
                ),
                ModelResponse(
                    parts=[ToolCallPart(tool_name='get_none', args='{}', tool_call_id='call_mJTuQ2Cl5SaHPTJbIILEUhJC')],
                    usage=RequestUsage(
                        input_tokens=193,
                        output_tokens=11,
                        details={
                            'accepted_prediction_tokens': 0,
                            'audio_tokens': 0,
                            'reasoning_tokens': 0,
                            'rejected_prediction_tokens': 0,
                        },
                    ),
                    model_name='gpt-4o-2024-08-06',
                    timestamp=IsDatetime(),
                    provider_name='openai',
                    provider_url='https://api.openai.com/v1/',
                    provider_details={
                        'finish_reason': 'tool_calls',
                        'timestamp': IsDatetime(),
                    },
                    provider_response_id='chatcmpl-BRloX2RokWc9j9PAXAuNXGR73WNqY',
                    finish_reason='tool_call',
                    run_id=IsStr(),
                ),
                ModelRequest(
                    parts=[
                        ToolReturnPart(
                            tool_name='get_none',
                            content=[],
                            tool_call_id='call_mJTuQ2Cl5SaHPTJbIILEUhJC',
                            timestamp=IsDatetime(),
                        )
                    ],
                    timestamp=IsDatetime(),
                    run_id=IsStr(),
                ),
                ModelResponse(
                    parts=[TextPart(content='Hello! How can I assist you today?')],
                    usage=RequestUsage(
                        input_tokens=212,
                        output_tokens=11,
                        details={
                            'accepted_prediction_tokens': 0,
                            'audio_tokens': 0,
                            'reasoning_tokens': 0,
                            'rejected_prediction_tokens': 0,
                        },
                    ),
                    model_name='gpt-4o-2024-08-06',
                    timestamp=IsDatetime(),
                    provider_name='openai',
                    provider_url='https://api.openai.com/v1/',
                    provider_details={
                        'finish_reason': 'stop',
                        'timestamp': IsDatetime(),
                    },
                    provider_response_id='chatcmpl-BRloYWGujk8yE94gfVSsM1T1Ol2Ej',
                    finish_reason='stop',
                    run_id=IsStr(),
                ),
            ]
        )

# tests/profiles/test_anthropic.py:191-209
def test_strict_none_simple_schema():
    """With strict=None, simple schemas are not transformed (only title/$schema removed)."""

    class Person(BaseModel):
        name: str
        age: int

    transformer = AnthropicJsonSchemaTransformer(Person.model_json_schema(), strict=None)
    transformed = transformer.walk()

    assert transformer.is_strict_compatible is False
    # No additionalProperties added, title removed
    assert transformed == snapshot(
        {
            'type': 'object',
            'properties': {'name': {'type': 'string'}, 'age': {'type': 'integer'}},
            'required': ['name', 'age'],
        }
    )

# tests/models/test_model_settings.py:121-144
def test_none_settings_in_hierarchy():
    """Test that None settings at any level don't break the merge hierarchy."""
    captured_settings = None

    def capture_settings(messages: list[ModelMessage], agent_info: AgentInfo) -> ModelResponse:
        nonlocal captured_settings
        captured_settings = agent_info.model_settings
        return ModelResponse(parts=[TextPart('captured')])

    # Model with no settings
    model = FunctionModel(capture_settings, settings=None)

    # Agent with settings
    agent_settings = ModelSettings(max_tokens=150, temperature=0.5)
    agent = Agent(model=model, model_settings=agent_settings)

    # Run with no additional settings
    result = agent.run_sync('test', model_settings=None)
    assert result.output == 'captured'

    # Should have agent settings
    assert captured_settings is not None
    assert captured_settings['max_tokens'] == 150
    assert captured_settings['temperature'] == 0.5

# tests/profiles/test_anthropic.py:167-188
def test_strict_none_preserves_schema():
    """With strict=None (default), schemas are not transformed (only title/$schema removed)."""

    class User(BaseModel):
        username: Annotated[str, Field(min_length=3)]
        age: int

    transformer = AnthropicJsonSchemaTransformer(User.model_json_schema(), strict=None)
    transformed = transformer.walk()

    assert transformer.is_strict_compatible is False
    # Constraints preserved, title removed
    assert transformed == snapshot(
        {
            'type': 'object',
            'properties': {
                'username': {'minLength': 3, 'type': 'string'},
                'age': {'type': 'integer'},
            },
            'required': ['username', 'age'],
        }
    )

# docs/.hooks/test_snippets.py:598-602
def test_inject_snippets_nonexistent_file():
    """Test that nonexistent files raise an error.."""
    markdown = '```snippet {path="nonexistent.py"}```'
    with pytest.raises(FileNotFoundError):
        inject_snippets(markdown, REPO_ROOT)

# tests/test_parts_manager.py:649-666
def test_handle_thinking_delta_provider_details_callback_from_none():
    """Test callback when existing provider_details is None."""
    manager = ModelResponsePartsManager()

    # Create initial part without provider_details
    list(manager.handle_thinking_delta(vendor_part_id='t', content='initial'))

    # Update using callback that handles None
    def add_details(existing: dict[str, Any] | None) -> dict[str, Any]:
        details = dict(existing or {})
        details['new_key'] = 'new_value'
        return details

    list(manager.handle_thinking_delta(vendor_part_id='t', content=' more', provider_details=add_details))

    assert manager.get_parts() == snapshot(
        [ThinkingPart(content='initial more', provider_details={'new_key': 'new_value'})]
    )

# tests/evals/test_multi_run.py:180-189
async def test_case_groups_returns_none_for_single_run():
    """case_groups() should return None when no cases have source_case_name (single-run experiment)."""

    async def task(inputs: str) -> str:
        return inputs.upper()

    dataset = Dataset(cases=[Case(name='case1', inputs='hello')])
    report = await dataset.evaluate(task, name='test', progress=False, repeat=1)

    assert report.case_groups() is None

# tests/profiles/test_openai.py:28-28
    supports_reasoning_effort_none: bool = False

# pydantic_evals/pydantic_evals/otel/span_tree.py:158-160
    def first_child(self, predicate: SpanQuery | SpanPredicate) -> SpanNode | None:
        """Return the first immediate child that satisfies the given predicate, or None if none match."""
        return next(self._filter_children(predicate), None)

# pydantic_evals/pydantic_evals/otel/span_tree.py:211-215
    def first_ancestor(
        self, predicate: SpanQuery | SpanPredicate, stop_recursing_when: SpanQuery | SpanPredicate | None = None
    ) -> SpanNode | None:
        """Return the closest ancestor that satisfies the given predicate, or `None` if none match."""
        return next(self._filter_ancestors(predicate, stop_recursing_when), None)

# tests/evals/test_report_evaluators.py:220-233
def test_confusion_matrix_evaluator_skips_none():
    cases = [
        _make_report_case('c1', output='cat', expected_output='cat'),
        _make_report_case('c2', output='dog', expected_output=None),  # should be skipped
    ]
    report = _make_report(cases)

    evaluator = ConfusionMatrixEvaluator(predicted_from='output', expected_from='expected_output')
    ctx = ReportEvaluatorContext(name='test', report=report, experiment_metadata=None)
    result = evaluator.evaluate(ctx)

    assert isinstance(result, ConfusionMatrix)
    assert result.class_labels == ['cat']
    assert result.matrix == [[1]]

# pydantic_ai_slim/pydantic_ai/_utils.py:150-153
class Unset:
    """A singleton to represent an unset value."""

    pass

# tests/test_agent.py:7142-7156
def test_override_none_clears_instructions():
    """Test that passing None for instructions clears all instructions."""
    agent = Agent('test', instructions='BASE')

    @agent.instructions
    def instr_fn() -> str:  # pragma: no cover - ignored under override
        return 'ALSO_BASE'

    with agent.override(instructions=None):
        with capture_run_messages() as messages:
            agent.run_sync('Hello', model=TestModel(custom_output_text='ok'))

    req = messages[0]
    assert isinstance(req, ModelRequest)
    assert req.instructions is None

# tests/models/anthropic/test_output.py:398-416
def test_strict_none_tool_no_output(
    allow_model_requests: None,
    anthropic_model: ANTHROPIC_MODEL_FIXTURE,
) -> None:
    """Tool with strict=None, no output_type → no beta header, tool has no strict field."""
    model = anthropic_model('claude-sonnet-4-5')
    hook = create_header_verification_hook(expect_beta=False, test_name='test_strict_none_tool_no_output')
    model.client._client.event_hooks['request'].append(hook)  # pyright: ignore[reportPrivateUsage]

    agent = Agent(model)

    @agent.tool_plain
    def search_database(query: str) -> str:
        return f'Found 42 results for "{query}"'

    agent.run_sync('Find cities in Europe')

    if errors := hook.errors:  # type: ignore[attr-defined]
        assert False, '\n'.join(sorted(errors))

# pydantic_evals/pydantic_evals/evaluators/evaluator.py:77-94
    def downcast(self, *value_types: type[T]) -> EvaluationResult[T] | None:
        """Attempt to downcast this result to a more specific type.

        Args:
            *value_types: The types to check the value against.

        Returns:
            A downcast version of this result if the value is an instance of one of the given types,
            otherwise None.
        """
        # Check if value matches any of the target types, handling bool as a special case
        for value_type in value_types:
            if isinstance(self.value, value_type):
                # Only match bool with explicit bool type
                if isinstance(self.value, bool) and value_type is not bool:
                    continue
                return cast(EvaluationResult[T], self)
        return None

# tests/providers/test_huggingface.py:139-142
def test_huggingface_provider_init_api_key_is_none(monkeypatch: pytest.MonkeyPatch):
    monkeypatch.delenv('HF_TOKEN', raising=False)
    with pytest.raises(UserError):
        HuggingFaceProvider(api_key=None)

# pydantic_ai_slim/pydantic_ai/profiles/openai.py:108-108
    openai_supports_reasoning_effort_none: bool = False

# pydantic_evals/pydantic_evals/otel/span_tree.py:94-96
    def duration(self) -> timedelta:
        """Return the span's duration as a timedelta, or None if start/end not set."""
        return self.end_timestamp - self.start_timestamp

# pydantic_ai_slim/pydantic_ai/_utils.py:159-160
def is_set(t_or_unset: T | Unset) -> TypeGuard[T]:
    return t_or_unset is not UNSET

# tests/models/anthropic/test_output.py:420-438
def test_strict_none_tool_basemodel_output(
    allow_model_requests: None,
    anthropic_model: ANTHROPIC_MODEL_FIXTURE,
) -> None:
    """Tool with strict=None, BaseModel output_type → no beta header, tool has no strict field."""
    model = anthropic_model('claude-sonnet-4-5')
    hook = create_header_verification_hook(expect_beta=False, test_name='test_strict_none_tool_basemodel_output')
    model.client._client.event_hooks['request'].append(hook)  # pyright: ignore[reportPrivateUsage]

    agent = Agent(model, output_type=CityInfo)

    @agent.tool_plain
    def get_timezone(city: str) -> str:  # pragma: no cover
        return 'UTC+10:00' if city == 'Sydney' else 'UTC+1:00'

    agent.run_sync('Give me info about Sydney including its timezone')

    if errors := hook.errors:  # type: ignore[attr-defined]
        assert False, '\n'.join(sorted(errors))

# tests/models/anthropic/test_output.py:297-311
def test_no_tools_native_output_strict_none(
    allow_model_requests: None,
    anthropic_model: ANTHROPIC_MODEL_FIXTURE,
) -> None:
    """Agent with NativeOutput(strict=None) → forces strict=True, beta header + output_format."""
    model = anthropic_model('claude-sonnet-4-5')
    hook = create_header_verification_hook(expect_beta=True, test_name='test_no_tools_native_output_strict_none')
    model.client._client.event_hooks['request'].append(hook)  # pyright: ignore[reportPrivateUsage]

    agent = Agent(model, output_type=NativeOutput(CityInfo))
    result = agent.run_sync('Give me facts about Berlin')

    assert isinstance(result.output, CityInfo)
    if errors := hook.errors:  # type: ignore[attr-defined]
        assert False, '\n'.join(sorted(errors))

# pydantic_evals/pydantic_evals/otel/span_tree.py:178-182
    def first_descendant(
        self, predicate: SpanQuery | SpanPredicate, stop_recursing_when: SpanQuery | SpanPredicate | None = None
    ) -> SpanNode | None:
        """DFS: Return the first descendant (in DFS order) that satisfies the given predicate, or `None` if none match."""
        return next(self._filter_descendants(predicate, stop_recursing_when), None)

# tests/models/anthropic/test_output.py:442-461
def test_strict_none_tool_native_output(
    allow_model_requests: None,
    anthropic_model: ANTHROPIC_MODEL_FIXTURE,
) -> None:
    """Tool with strict=None, NativeOutput → beta from native only, tool has no strict field + output_format."""
    model = anthropic_model('claude-sonnet-4-5')
    hook = create_header_verification_hook(expect_beta=True, test_name='test_strict_none_tool_native_output')
    model.client._client.event_hooks['request'].append(hook)  # pyright: ignore[reportPrivateUsage]

    agent = Agent(model, output_type=NativeOutput(CityInfo))

    @agent.tool_plain
    def get_coordinates(city: str) -> str:
        return '41.3874° N, 2.1686° E' if city == 'Barcelona' else 'Unknown'

    result = agent.run_sync('Give me details about Barcelona')

    assert isinstance(result.output, CityInfo)
    if errors := hook.errors:  # type: ignore[attr-defined]
        assert False, '\n'.join(sorted(errors))

# tests/test_embeddings.py:1082-1085
    async def test_unknown_model_max_tokens_returns_none(self, bedrock_provider: BedrockProvider):
        """Test that unknown models with valid prefixes return None for max_input_tokens."""
        model = BedrockEmbeddingModel('amazon.titan-embed-text-v99:0', provider=bedrock_provider)
        assert await model.max_input_tokens() is None

# tests/test_streaming.py:2446-2449
def test_streamed_run_result_metadata_none_without_sources() -> None:
    run_result = _make_run_result(metadata=None)
    streamed = StreamedRunResult(all_messages=[], new_message_index=0, run_result=run_result)
    assert streamed.metadata is None

# pydantic_evals/pydantic_evals/reporting/__init__.py:694-694
    diff_checker: Callable[[Any, Any], bool] | None = lambda x, y: x != y

# pydantic_evals/pydantic_evals/reporting/__init__.py:686-686
    diff_checker: Callable[[Any, Any], bool] | None

# tests/test_streaming.py:2452-2454
def test_streamed_run_result_metadata_none_without_run_or_stream() -> None:
    streamed = StreamedRunResult(all_messages=[], new_message_index=0, stream_response=None, on_complete=None)
    assert streamed.metadata is None

# tests/test_thinking_part.py:109-116
def test_thinking_part_delta_applies_to_part_with_none_signature():
    thinking_part_no_sig = ThinkingPart(content='No sig content', signature=None)
    delta_to_none_sig = ThinkingPartDelta(content_delta=' extra', signature_delta='added_sig')

    result_none_sig = delta_to_none_sig.apply(thinking_part_no_sig)

    # The content is appended, and the signature is updated.
    assert result_none_sig == snapshot(ThinkingPart(content='No sig content extra', signature='added_sig'))

# pydantic_ai_slim/pydantic_ai/profiles/openai.py:114-114
    openai_responses_requires_function_call_status_none: bool = False

# pydantic_graph/pydantic_graph/graph.py:652-661
    def result(self) -> GraphRunResult[StateT, RunEndT] | None:
        """The final result of the graph run if the run is completed, otherwise `None`."""
        if not isinstance(self._next_node, End):
            return None  # The GraphRun has not finished running
        return GraphRunResult[StateT, RunEndT](
            self._next_node.data,
            state=self.state,
            persistence=self.persistence,
            traceparent=self._traceparent(required=False),
        )

# pydantic_ai_slim/pydantic_ai/messages.py:1754-1769
    def as_part(self) -> ToolCallPart | None:
        """Convert this delta to a fully formed `ToolCallPart` if possible, otherwise return `None`.

        Returns:
            A `ToolCallPart` if `tool_name_delta` is set, otherwise `None`.
        """
        if self.tool_name_delta is None:
            return None

        return ToolCallPart(
            self.tool_name_delta,
            self.args_delta,
            self.tool_call_id or _generate_tool_call_id(),
            provider_name=self.provider_name,
            provider_details=self.provider_details,
        )

# pydantic_graph/pydantic_graph/beta/graph.py:509-517
    def output(self) -> OutputT | None:
        """Get the final output if the graph has completed.

        Returns:
            The output value if execution is complete, None otherwise
        """
        if isinstance(self._next, EndMarker):
            return self._next.value
        return None

# pydantic_ai_slim/pydantic_ai/_parts_manager.py:258-350
    def handle_tool_call_delta(
        self,
        *,
        vendor_part_id: Hashable | None,
        tool_name: str | None = None,
        args: str | dict[str, Any] | None = None,
        tool_call_id: str | None = None,
        provider_name: str | None = None,
        provider_details: dict[str, Any] | None = None,
    ) -> ModelResponseStreamEvent | None:
        """Handle or update a tool call, creating or updating a `ToolCallPart`, `BuiltinToolCallPart`, or `ToolCallPartDelta`.

        Managed items remain as `ToolCallPartDelta`s until they have at least a tool_name, at which
        point they are upgraded to `ToolCallPart`s.

        If `vendor_part_id` is None, updates the latest matching ToolCallPart (or ToolCallPartDelta)
        if any. Otherwise, a new part (or delta) may be created.

        Args:
            vendor_part_id: The ID the vendor uses for this tool call.
                If None, the latest matching tool call may be updated.
            tool_name: The name of the tool. If None, the manager does not enforce
                a name match when `vendor_part_id` is None.
            args: Arguments for the tool call, either as a string, a dictionary of key-value pairs, or None.
            tool_call_id: An optional string representing an identifier for this tool call.
            provider_name: An optional provider name for the tool call part.
            provider_details: An optional dictionary of provider-specific details for the tool call part.

        Returns:
            - A `PartStartEvent` if a new ToolCallPart or BuiltinToolCallPart is created.
            - A `PartDeltaEvent` if an existing part is updated.
            - `None` if no new event is emitted (e.g., the part is still incomplete).

        Raises:
            UnexpectedModelBehavior: If attempting to apply a tool call delta to a part that is not
                a ToolCallPart, BuiltinToolCallPart, or ToolCallPartDelta.
        """
        existing_matching_part_and_index: tuple[ToolCallPartDelta | ToolCallPart | BuiltinToolCallPart, int] | None = (
            None
        )

        if vendor_part_id is not None:
            # vendor_part_id is None, so check if the latest part is a matching tool call or delta to update
            # When the vendor_part_id is None, if the tool_name is _not_ None, assume this should be a new part rather
            # than a delta on an existing one. We can change this behavior in the future if necessary for some model.
            if tool_name is None:
                existing_matching_part_and_index = self._latest_part_if_of_type(
                    ToolCallPart, BuiltinToolCallPart, ToolCallPartDelta
                )
        else:
            # vendor_part_id is provided, so look up the corresponding part or delta
            part_index = self._vendor_id_to_part_index.get(vendor_part_id)
            if part_index is not None:
                existing_part = self._parts[part_index]
                if not isinstance(existing_part, ToolCallPartDelta | ToolCallPart | BuiltinToolCallPart):
                    raise UnexpectedModelBehavior(f'Cannot apply a tool call delta to {existing_part=}')
                existing_matching_part_and_index = existing_part, part_index

        if existing_matching_part_and_index is None:
            # No matching part/delta was found, so create a new ToolCallPartDelta (or ToolCallPart if fully formed)
            delta = ToolCallPartDelta(
                tool_name_delta=tool_name,
                args_delta=args,
                tool_call_id=tool_call_id,
                provider_name=provider_name,
                provider_details=provider_details,
            )
            part = delta.as_part() or delta
            new_part_index = self._append_part(part, vendor_part_id)
            # Only emit a PartStartEvent if we have enough information to produce a full ToolCallPart
            if isinstance(part, ToolCallPart | BuiltinToolCallPart):
                return PartStartEvent(index=new_part_index, part=part)
        else:
            # Update the existing part or delta with the new information
            existing_part, part_index = existing_matching_part_and_index
            delta = ToolCallPartDelta(
                tool_name_delta=tool_name,
                args_delta=args,
                tool_call_id=tool_call_id,
                provider_name=self._resolve_provider_name(existing_part, provider_name),
                provider_details=provider_details,
            )
            updated_part = delta.apply(existing_part)
            self._parts[part_index] = updated_part
            if isinstance(updated_part, ToolCallPart | BuiltinToolCallPart):
                if isinstance(existing_part, ToolCallPartDelta):
                    # We just upgraded a delta to a full part, so emit a PartStartEvent
                    return PartStartEvent(index=part_index, part=updated_part)
                else:
                    # We updated an existing part, so emit a PartDeltaEvent
                    if updated_part.tool_call_id and not delta.tool_call_id:
                        delta = replace(delta, tool_call_id=updated_part.tool_call_id)
                    return PartDeltaEvent(index=part_index, delta=delta)

# pydantic_evals/pydantic_evals/evaluators/__init__.py:1-10
from .common import (
    Contains,
    Equals,
    EqualsExpected,
    HasMatchingSpan,
    IsInstance,
    LLMJudge,
    MaxDuration,
    OutputConfig,
)

# pydantic_evals/pydantic_evals/otel/span_tree.py:483-485
    def first(self, predicate: SpanQuery | SpanPredicate) -> SpanNode | None:
        """Find the first node that matches a predicate, scanning from each root in DFS order. Returns `None` if not found."""
        return next(self._filter(predicate), None)

# pydantic_ai_slim/pydantic_ai/models/__init__.py:931-931
    _parts_manager: ModelResponsePartsManager = field(default_factory=ModelResponsePartsManager, init=False)

# pydantic_evals/pydantic_evals/evaluators/__init__.py:1-10
from .common import (
    Contains,
    Equals,
    EqualsExpected,
    HasMatchingSpan,
    IsInstance,
    LLMJudge,
    MaxDuration,
    OutputConfig,
)

# pydantic_ai_slim/pydantic_ai/_utils.py:150-153
class Unset:
    """A singleton to represent an unset value."""

    pass

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_model.py:243-262
    def _get_model_id(self, model: models.Model | models.KnownModelName | str | None = None) -> str | None:
        """Get the model ID for the given model parameter.

        Returns a string that will be checked against registered model IDs,
        or passed to infer_model if not found. Returns None to use the default model.
        """
        if model in (None, 'default'):
            return None

        if isinstance(model, Model):
            # Check if this model instance is already registered
            model_id = next((model_id for model_id, m in self._models_by_id.items() if m is model), ...)
            if model_id is ...:
                raise UserError(
                    'Arbitrary model instances cannot be used at runtime inside a Temporal workflow. '
                    'Register the model via `models` or reference a registered model by id.'
                )
            return None if model_id == 'default' else model_id

        return model

# pydantic_ai_slim/pydantic_ai/models/mistral.py:779-807
def _map_content(content: MistralOptionalNullable[MistralContent]) -> tuple[str | None, list[str]]:
    """Maps the delta content from a Mistral Completion Chunk to a string or None."""
    text: str | None = None
    thinking: list[str] = []

    if isinstance(content, MistralUnset) or not content:
        return None, []
    elif isinstance(content, list):
        for chunk in content:
            if isinstance(chunk, MistralTextChunk):
                text = (text or '') + chunk.text
            elif isinstance(chunk, MistralThinkChunk):
                for thought in chunk.thinking:
                    if thought.type == 'text':  # pragma: no branch
                        thinking.append(thought.text)
            elif isinstance(chunk, MistralReferenceChunk):
                pass  # Reference chunks are not yet supported, skip silently
            else:
                assert False, (  # pragma: no cover
                    f'Other data types like (Image) are not yet supported, got {type(chunk)}'
                )
    elif isinstance(content, str):
        text = content

    # Note: Check len to handle potential mismatch between function calls and responses from the API. (`msg: not the same number of function class and responses`)
    if text and len(text) == 0:  # pragma: no cover
        text = None

    return text, thinking

# pydantic_graph/pydantic_graph/_utils.py:75-86
def unpack_annotated(tp: Any) -> tuple[Any, list[Any]]:
    """Strip `Annotated` from the type if present.

    Returns:
        `(tp argument, ())` if not annotated, otherwise `(stripped type, annotations)`.
    """
    origin = get_origin(tp)
    if typing_objects.is_annotated(origin):
        inner_tp, *args = get_args(tp)
        return inner_tp, args
    else:
        return tp, []

# pydantic_ai_slim/pydantic_ai/_tool_manager.py:112-120
    def get_tool_def(self, name: str) -> ToolDefinition | None:
        """Get the tool definition for a given tool name, or `None` if the tool is unknown."""
        if self.tools is None:
            raise ValueError('ToolManager has not been prepared for a run step yet')  # pragma: no cover

        try:
            return self.tools[name].tool_def
        except KeyError:
            return None

# tests/test_fastmcp.py:180-183
    async def test_id_property(self, fastmcp_client: Client[FastMCPTransport]):
        """Test that the id property returns None."""
        toolset = FastMCPToolset(fastmcp_client)
        assert toolset.id is None

# pydantic_ai_slim/pydantic_ai/_utils.py:286-294
def guard_tool_call_id(
    t: _messages.ToolCallPart
    | _messages.ToolReturnPart
    | _messages.RetryPromptPart
    | _messages.BuiltinToolCallPart
    | _messages.BuiltinToolReturnPart,
) -> str:
    """Type guard that either returns the tool call id or generates a new one if it's None."""
    return t.tool_call_id or generate_tool_call_id()

# tests/json_body_serializer.py:83-87
def str_presenter(dumper: Dumper, data: str):
    """If the string contains newlines, represent it as a literal block."""
    if '\n' in data:
        return dumper.represent_scalar('tag:yaml.org,2002:str', data, style='|')
    return dumper.represent_scalar('tag:yaml.org,2002:str', data)

# pydantic_graph/pydantic_graph/exceptions.py:59-62
    def check(cls, status: 'SnapshotStatus') -> None:
        """Check if the status is valid."""
        if status not in {'created', 'pending'}:
            raise cls(status)

# tests/models/test_bedrock.py:2668-2676
async def test_get_last_user_message_content_non_dict_block(
    allow_model_requests: None, bedrock_provider: BedrockProvider
):
    """Test _get_last_user_message_content returns None when last block is not a dict."""
    model = BedrockConverseModel('us.anthropic.claude-3-5-sonnet-20240620-v1:0', provider=bedrock_provider)
    # Directly test the helper with a message that has non-dict content
    messages: list[MessageUnionTypeDef] = [{'role': 'user', 'content': ['string content']}]  # type: ignore[list-item]
    result = model._get_last_user_message_content(messages)  # pyright: ignore[reportPrivateUsage]
    assert result is None

# pydantic_graph/pydantic_graph/beta/paths.py:141-150
    def last_fork(self) -> BroadcastMarker | MapMarker | None:
        """Get the most recent fork or map marker in this path.

        Returns:
            The last BroadcastMarker or MapMarker in the path, or None if no forks exist
        """
        for item in reversed(self.items):
            if isinstance(item, BroadcastMarker | MapMarker):
                return item
        return None

# pydantic_graph/pydantic_graph/beta/join.py:101-103
def reduce_null(current: None, inputs: Any) -> None:
    """A reducer that discards all input data and returns None."""
    return None

# tests/typed_graph.py:44-46
def use_double(node: BaseNode[None, None, X]) -> None:
    """Shoe that `Double` is valid as a `BaseNode[None, int, X]`."""
    print(node)

# tests/models/test_bedrock.py:2679-2687
async def test_get_last_user_message_content_empty_content(
    allow_model_requests: None, bedrock_provider: BedrockProvider
):
    """Test _get_last_user_message_content returns None when content is empty or not a list."""
    model = BedrockConverseModel('us.anthropic.claude-3-5-sonnet-20240620-v1:0', provider=bedrock_provider)
    # Test with empty content list
    messages: list[MessageUnionTypeDef] = [{'role': 'user', 'content': []}]
    result = model._get_last_user_message_content(messages)  # pyright: ignore[reportPrivateUsage]
    assert result is None

# tests/models/anthropic/test_output.py:143-165
def test_strict_tools_incompatible_schema_not_auto_enabled(allow_model_requests: None):
    """sonnet-4-5: strict=None → no strict field, no beta header."""
    mock_client = MockAnthropic.create_mock(
        completion_message([BetaTextBlock(text='Sure', type='text')], BetaUsage(input_tokens=5, output_tokens=2))
    )
    model = AnthropicModel('claude-sonnet-4-5', provider=AnthropicProvider(anthropic_client=mock_client))
    agent = Agent(model)

    @agent.tool_plain
    def constrained_tool(username: Annotated[str, Field(min_length=3)]) -> str:  # pragma: no cover
        return username

    agent.run_sync('Test')

    completion_kwargs = get_mock_chat_completion_kwargs(mock_client)[0]
    tools = completion_kwargs['tools']
    betas = completion_kwargs.get('betas')

    # strict is not auto-enabled, so no strict field
    assert 'strict' not in tools[0]
    # because the schema wasn't transformed, it keeps the pydantic constraint
    assert tools[0]['input_schema']['properties']['username']['minLength'] == 3
    assert betas is OMIT

# pydantic_ai_slim/pydantic_ai/embeddings/__init__.py:317-324
    async def max_input_tokens(self) -> int | None:
        """Get the maximum number of tokens the model can accept as input.

        Returns:
            The maximum token count, or `None` if the limit is unknown for this model.
        """
        model = self._get_model()
        return await model.max_input_tokens()

# pydantic_graph/pydantic_graph/beta/graph.py:500-506
    def next_task(self) -> EndMarker[OutputT] | Sequence[GraphTask]:
        """Get the next task(s) to be executed.

        Returns:
            The next execution item, or the initial task if none is set
        """
        return self._next or [self._first_task]