{
  "task_id": "d-messages-L641-condition_inversion",
  "method": "bm25",
  "budget": 4000,
  "query_type": "vague",
  "tokens_used": 4000,
  "symbols_selected": 21,
  "files_included": 9,
  "assembly_time_ms": 166.7,
  "llm_time_ms": 885.8,
  "llm_input_tokens": 4092,
  "llm_output_tokens": 52,
  "tests_passed": false,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: tests/evals/test_multi_run.py\nSEARCH:\n    assert all(c.source_case_name is not None for c in report.cases)\nREPLACE:\n    assert all(c.source_case_name is None for c in report.cases)\n",
  "error": "",
  "test_time_ms": 1018.5,
  "failure_mode": "test_fail",
  "target_file_hit": false,
  "target_symbol_hit": false,
  "context_patch_overlap": 0.111,
  "patch_files_changed": 1,
  "patch_lines_changed": 1,
  "edit_distance_lines": -1,
  "entity_count_extracted": 0,
  "entity_count_mapped": 0,
  "query_identifier_density": 0.0,
  "seed_symbol_keys": [],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/messages.py::BinaryImage.__post_init__",
  "min_hops_seed_to_mutation": -1,
  "median_hops_seed_to_mutation": -1.0,
  "bca_closure_added_symbols": 0,
  "bca_closure_added_tokens": 0,
  "bca_frontier_visited": 0,
  "context_symbol_keys": [
    "pydantic_evals/pydantic_evals/dataset.py::InputsT",
    "pydantic_evals/pydantic_evals/dataset.py::OutputT",
    "pydantic_evals/pydantic_evals/dataset.py::MetadataT",
    "pydantic_evals/pydantic_evals/dataset.py::_REPORT_CASES_ADAPTER",
    "pydantic_evals/pydantic_evals/dataset.py::_CaseModel",
    "pydantic_evals/pydantic_evals/dataset.py::Case",
    "pydantic_evals/pydantic_evals/dataset.py::Dataset",
    "pydantic_evals/pydantic_evals/dataset.py::Dataset.evaluate",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::InputsT",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::OutputT",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::MetadataT",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::ReportCase",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::EvaluationReport",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::EvaluationRenderer._all_cases",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::EvaluationRenderer._baseline_cases_to_include",
    "tests/evals/test_dataset.py::TaskInput",
    "tests/evals/test_dataset.py::TaskOutput",
    "tests/evals/test_dataset.py::TaskMetadata",
    "tests/evals/test_dataset.py::example_cases",
    "tests/evals/test_dataset.py::example_dataset",
    "tests/evals/test_dataset.py::test_dataset_evaluate_with_empty_cases",
    "tests/evals/test_dataset.py::test_unnamed_cases",
    "tests/evals/test_multi_run.py::test_repeat_3_produces_3x_cases",
    "tests/evals/test_multi_run.py::test_repeat_with_unnamed_cases",
    "tests/evals/test_report_evaluators.py::TaskInput",
    "tests/evals/test_report_evaluators.py::TaskOutput",
    "tests/evals/test_report_evaluators.py::test_dataset_with_report_evaluators",
    "tests/graph/beta/test_edge_cases.py::EdgeCaseState",
    "tests/models/test_model.py::TEST_CASES",
    "tests/profiles/test_openai.py::SamplingParamsCase",
    "tests/profiles/test_openai.py::SAMPLING_PARAMS_CASES",
    "tests/test_temporal.py::model",
    "tests/test_temporal.py::simple_temporal_agent",
    "tests/test_temporal.py::Response",
    "tests/test_temporal.py::source"
  ],
  "mutation_symbol_lines": 3,
  "mutation_symbol_kind": "method",
  "mutation_file_symbols": 351,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.265955,
  "retrieval_softmax_entropy": 4.3134,
  "retrieval_softmax_tau": 20.497264,
  "retrieval_effective_candidates": 19.88,
  "retrieval_top5_ratio": 0.9732,
  "retrieval_within95_count": 4,
  "retrieval_scored_symbols": 50,
  "retrieval_top1_score": 23.304706,
  "retrieval_top5_mean_score": 22.680596,
  "retrieval_budget_utilization": 1.0,
  "retrieval_file_concentration": 0.2381,
  "repo_name": "pydantic-ai",
  "category": "messages",
  "mutation_type": "condition_inversion",
  "source": "discovered"
}