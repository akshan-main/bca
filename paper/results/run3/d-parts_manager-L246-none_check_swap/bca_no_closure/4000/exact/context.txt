## examples/pydantic_ai_examples/pydantic_model.py

class MyModel(BaseModel):
    city: str
    country: str

## examples/pydantic_ai_examples/slack_lead_qualifier/store.py

    async def add(cls, analysis: Analysis):
        await cls._get_store().put.aio(analysis.profile.email, analysis.model_dump())

    async def list(cls) -> list[Analysis]:
        return [
            Analysis.model_validate(analysis)
            async for analysis in cls._get_store().values.aio()
        ]

## pydantic_ai_slim/pydantic_ai/_cli/__init__.py

    def __init__(self, special_suggestions: list[str] | None = None):
        super().__init__()
        self.special_suggestions = special_suggestions or []

## pydantic_ai_slim/pydantic_ai/_utils.py

def number_to_datetime(x: int | float) -> datetime:
    return _datetime_ta.validate_python(x)

## pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py

    def __init__(self, model_request_parameters: ModelRequestParameters, response: ModelResponse):
        super().__init__(model_request_parameters)
        self.response = response

    async def _get_event_iterator(self) -> AsyncIterator[ModelResponseStreamEvent]:
        return
        # noinspection PyUnreachableCode
        yield

    def get(self) -> ModelResponse:
        return self.response

    def usage(self) -> RequestUsage:
        return self.response.usage  # pragma: no cover

    def model_name(self) -> str:
        return self.response.model_name or ''  # pragma: no cover

    def provider_name(self) -> str:
        return self.response.provider_name or ''  # pragma: no cover

    def provider_url(self) -> str | None:
        return self.response.provider_url  # pragma: no cover

    def timestamp(self) -> datetime:
        return self.response.timestamp  # pragma: no cover

## pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py

    def __init__(self, model_request_parameters: ModelRequestParameters, response: ModelResponse):
        super().__init__(model_request_parameters)
        self.response = response

    def get(self) -> ModelResponse:
        return self.response

    def usage(self) -> RequestUsage:
        return self.response.usage  # pragma: no cover

    def model_name(self) -> str:
        return self.response.model_name or ''  # pragma: no cover

    def provider_name(self) -> str:
        return self.response.provider_name or ''  # pragma: no cover

    def provider_url(self) -> str | None:
        return self.response.provider_url  # pragma: no cover

    def timestamp(self) -> datetime:
        return self.response.timestamp  # pragma: no cover

## pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_model.py

    def __init__(self, model_request_parameters: ModelRequestParameters, response: ModelResponse):
        super().__init__(model_request_parameters)
        self.response = response

    async def _get_event_iterator(self) -> AsyncIterator[ModelResponseStreamEvent]:
        return
        # noinspection PyUnreachableCode
        yield

    def get(self) -> ModelResponse:
        return self.response

    def usage(self) -> RequestUsage:
        return self.response.usage  # pragma: no cover

    def model_name(self) -> str:
        return self.response.model_name or ''  # pragma: no cover

    def provider_name(self) -> str:
        return self.response.provider_name or ''  # pragma: no cover

    def provider_url(self) -> str | None:
        return self.response.provider_url  # pragma: no cover

    def timestamp(self) -> datetime:
        return self.response.timestamp  # pragma: no cover

    def _validate_model_request_parameters(self, model_request_parameters: ModelRequestParameters) -> None:
        if model_request_parameters.allow_image_output:
            raise UserError('Image output is not supported with Temporal because of the 2MB payload size limit.')

    def _current_model_id(self) -> str | None:
        return self._model_id_var.get()

## pydantic_ai_slim/pydantic_ai/messages.py

    def model_response_str(self) -> str:
        """Return a string representation of the content for the model."""
        if isinstance(self.content, str):
            return self.content
        else:
            return tool_return_ta.dump_json(self.content).decode()

    provider_name: str | None = None

    provider_name: str | None = None

    provider_name: str | None = None

    provider_name: str | None = None

## pydantic_ai_slim/pydantic_ai/models/__init__.py

    def usage(self) -> RequestUsage:
        """Get the usage of the response so far. This will not be the final usage until the stream is exhausted."""
        return self._usage

    def model_name(self) -> str:
        """Get the model name of the response."""
        raise NotImplementedError()

    def provider_name(self) -> str | None:
        """Get the provider name."""
        raise NotImplementedError()

    def provider_url(self) -> str | None:
        """Get the provider base URL."""
        raise NotImplementedError()

    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        raise NotImplementedError()

def get_user_agent() -> str:
    """Get the user agent string for the HTTP client."""
    from .. import __version__

    return f'pydantic-ai/{__version__}'

## pydantic_ai_slim/pydantic_ai/models/anthropic.py

    def model_name(self) -> AnthropicModelName:
        """Get the model name of the response."""
        return self._model_name

    def provider_name(self) -> str:
        """Get the provider name."""
        return self._provider_name

    def provider_url(self) -> str:
        """Get the provider base URL."""
        return self._provider_url

    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._timestamp

## pydantic_ai_slim/pydantic_ai/models/bedrock.py

    def _get_tools(self, model_request_parameters: ModelRequestParameters) -> list[ToolTypeDef]:
        return [self._map_tool_definition(r) for r in model_request_parameters.tool_defs.values()]

    def model_name(self) -> str:
        """Get the model name of the response."""
        return self._model_name

    def provider_name(self) -> str:
        """Get the provider name."""
        return self._provider_name

    def provider_url(self) -> str:
        """Get the provider base URL."""
        return self._provider_url

    def timestamp(self) -> datetime:
        return self._timestamp

## pydantic_ai_slim/pydantic_ai/models/function.py

    def __post_init__(self):
        self._usage += _estimate_usage([])

    def model_name(self) -> str:
        """Get the model name of the response."""
        return self._model_name

    def provider_name(self) -> None:
        """Get the provider name."""
        return None

    def provider_url(self) -> None:
        """Get the provider base URL."""
        return None

    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._timestamp

## pydantic_ai_slim/pydantic_ai/models/gemini.py

    def _get_tools(self, model_request_parameters: ModelRequestParameters) -> _GeminiTools | None:
        tools = [_function_from_abstract_tool(t) for t in model_request_parameters.tool_defs.values()]
        return _GeminiTools(function_declarations=tools) if tools else None

    async def headers(self) -> dict[str, str]: ...

    def model_name(self) -> GeminiModelName:
        """Get the model name of the response."""
        return self._model_name

    def provider_name(self) -> str:
        """Get the provider name."""
        return self._provider_name

    def provider_url(self) -> str:
        """Get the provider base URL."""
        return self._provider_url

    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._timestamp

class _GeminiContent(TypedDict):
    role: Literal['user', 'model']
    parts: list[_GeminiPartUnion]

class _BasePart(TypedDict):
    thought: NotRequired[bool]
    """Indicates if the part is thought from the model."""

class _GeminiTextPart(_BasePart):
    text: str

class _GeminiFileDataPart(_BasePart):
    file_data: Annotated[_GeminiFileData, pydantic.Field(alias='fileData')]

class _GeminiThoughtPart(TypedDict):
    thought: bool
    thought_signature: Annotated[str, pydantic.Field(alias='thoughtSignature')]

def _function_call_part_from_call(tool: ToolCallPart) -> _GeminiFunctionCallPart:
    return _GeminiFunctionCallPart(function_call=_GeminiFunctionCall(name=tool.tool_name, args=tool.args_as_dict()))

def _response_part_from_response(name: str, response: dict[str, Any]) -> _GeminiFunctionResponsePart:
    return _GeminiFunctionResponsePart(function_response=_GeminiFunctionResponse(name=name, response=response))

class _GeminiToolConfig(TypedDict):
    function_calling_config: _GeminiFunctionCallingConfig

class _GeminiFunctionCallingConfig(TypedDict):
    mode: Literal['ANY', 'AUTO']
    allowed_function_names: list[str]

## pydantic_ai_slim/pydantic_ai/models/google.py

    def _map_code_execution_result(self, code_execution_result: CodeExecutionResult) -> BuiltinToolReturnPart:
        """Map code execution result to a BuiltinToolReturnPart using instance state."""
        assert self._code_execution_tool_call_id is not None
        return _map_code_execution_result(code_execution_result, self.provider_name, self._code_execution_tool_call_id)

    def model_name(self) -> GoogleModelName:
        """Get the model name of the response."""
        return self._model_name

    def provider_name(self) -> str:
        """Get the provider name."""
        return self._provider_name

    def provider_url(self) -> str:
        """Get the provider base URL."""
        return self._provider_url

    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._timestamp

## pydantic_ai_slim/pydantic_ai/models/groq.py

    def _get_tools(self, model_request_parameters: ModelRequestParameters) -> list[chat.ChatCompletionToolParam]:
        return [self._map_tool_definition(r) for r in model_request_parameters.tool_defs.values()]

    def model_name(self) -> GroqModelName:
        """Get the model name of the response."""
        return self._model_name

    def provider_name(self) -> str:
        """Get the provider name."""
        return self._provider_name

    def provider_url(self) -> str:
        """Get the provider base URL."""
        return self._provider_url

    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._timestamp

## pydantic_ai_slim/pydantic_ai/models/huggingface.py

    def _get_tools(self, model_request_parameters: ModelRequestParameters) -> list[ChatCompletionInputTool]:
        return [self._map_tool_definition(r) for r in model_request_parameters.tool_defs.values()]

    def model_name(self) -> str:
        """Get the model name of the response."""
        return self._model_name

    def provider_name(self) -> str:
        """Get the provider name."""
        return self._provider_name

    def provider_url(self) -> str:
        """Get the provider base URL."""
        return self._provider_url

    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._timestamp

## pydantic_ai_slim/pydantic_ai/models/mistral.py

    def model_name(self) -> MistralModelName:
        """Get the model name of the response."""
        return self._model_name

    def provider_name(self) -> str:
        """Get the provider name."""
        return self._provider_name

    def provider_url(self) -> str:
        """Get the provider base URL."""
        return self._provider_url

    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._timestamp

## pydantic_ai_slim/pydantic_ai/models/openai.py

    def system_prompt_role(self) -> OpenAISystemPromptRole | None:
        return OpenAIModelProfile.from_profile(self.profile).openai_system_prompt_role

    def _map_usage(self, response: chat.ChatCompletion) -> usage.RequestUsage:
        return _map_usage(response, self._provider.name, self._provider.base_url, self.model_name)

    def _get_tools(self, model_request_parameters: ModelRequestParameters) -> list[chat.ChatCompletionToolParam]:
        return [self._map_tool_definition(r) for r in model_request_parameters.tool_defs.values()]

class OpenAIModel(OpenAIChatModel):
    """Deprecated alias for `OpenAIChatModel`."""

    def _get_tools(self, model_request_parameters: ModelRequestParameters) -> list[responses.FunctionToolParam]:
        return [self._map_tool_definition(r) for r in model_request_parameters.tool_defs.values()]

    def _map_usage(self, response: ChatCompletionChunk) -> usage.RequestUsage:
        return _map_usage(response, self._provider_name, self._provider_url, self.model_name)

    def model_name(self) -> OpenAIModelName:
        """Get the model name of the response."""
        return self._model_name

    def provider_name(self) -> str:
        """Get the provider name."""
        return self._provider_name

    def provider_url(self) -> str:
        """Get the provider base URL."""
        return self._provider_url

    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._timestamp

    def _map_usage(self, response: responses.Response) -> usage.RequestUsage:
        return _map_usage(response, self._provider_name, self._provider_url, self.model_name)

    def model_name(self) -> OpenAIModelName:
        """Get the model name of the response."""
        return self._model_name

    def provider_name(self) -> str:
        """Get the provider name."""
        return self._provider_name

    def provider_url(self) -> str:
        """Get the provider base URL."""
        return self._provider_url

    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._timestamp

## pydantic_ai_slim/pydantic_ai/models/outlines.py

    def model_name(self) -> str:
        """Get the model name of the response."""
        return self._model_name

    def provider_name(self) -> str:
        """Get the provider name."""
        return self._provider_name

    def provider_url(self) -> str | None:
        """Get the provider base URL."""
        return self._provider_url

    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._timestamp

## pydantic_ai_slim/pydantic_ai/models/test.py

    def gen_tool_args(self, tool_def: ToolDefinition) -> Any:
        return _JsonSchemaTestData(tool_def.parameters_json_schema, self.seed).generate()

    def __post_init__(self, _messages: Iterable[ModelMessage]):
        self._usage = _estimate_usage(_messages)

    def model_name(self) -> str:
        """Get the model name of the response."""
        return self._model_name

    def provider_name(self) -> str:
        """Get the provider name."""
        return self._provider_name

    def provider_url(self) -> str | None:
        """Get the provider base URL."""
        return self._provider_url

    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._timestamp

    def generate(self) -> dict[str, Any]:
        """Generate data for the JSON schema."""
        return self._gen_any(self.schema)

def _get_string_usage(text: str) -> RequestUsage:
    response_tokens = _estimate_string_tokens(text)
    return RequestUsage(output_tokens=response_tokens)

## pydantic_ai_slim/pydantic_ai/models/xai.py

    def system(self) -> str:
        """The model provider system name."""
        return self._provider.name

    def provider_url(self) -> str:
        """Get the provider base URL."""
        return self._provider.base_url

    def model_name(self) -> str:
        """Get the model name of the response."""
        return self._model_name

    def provider_name(self) -> str:
        """The model provider."""
        return self.system

    def timestamp(self) -> datetime:
        """Get the timestamp of the response."""
        return self._timestamp

## pydantic_ai_slim/pydantic_ai/profiles/__init__.py

    def from_profile(cls, profile: ModelProfile | None) -> Self:
        """Build a ModelProfile subclass instance from a ModelProfile instance."""
        if isinstance(profile, cls):
            return profile
        return cls().update(profile)

## pydantic_evals/pydantic_evals/otel/span_tree.py

    def any(self, predicate: SpanQuery | SpanPredicate) -> bool:
        """Returns True if any node in the tree matches the predicate."""
        return self.first(predicate) is not None

## pydantic_graph/pydantic_graph/beta/graph.py

    def value(self) -> OutputT:
        return self._value

## tests/conftest.py

    def set(self, name: str, value: str) -> None:
        self.envars[name] = os.getenv(name)
        os.environ[name] = value

## tests/graph/test_mermaid.py

class Foo(BaseNode):
    async def run(self, ctx: GraphRunContext) -> Bar:
        return Bar()

class Bar(BaseNode[None, None, None]):
    async def run(self, ctx: GraphRunContext) -> End[None]:
        return End(None)

## tests/models/test_instrumented.py

    def model_name(self) -> str:
        return 'gpt-4o-2024-11-20'

    def provider_name(self) -> str:
        return 'openai'

    def provider_url(self) -> str:
        return 'https://api.openai.com'

    def timestamp(self) -> datetime:
        return datetime(2022, 1, 1)

## tests/test_temporal.py

    async def decode(
        self, payloads: Sequence[temporalio.api.common.v1.Payload]
    ) -> list[temporalio.api.common.v1.Payload]:  # pragma: no cover
        return list(payloads)
