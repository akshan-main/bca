## docs/.hooks/algolia.py

class AlgoliaRecord(TypedDict):
    content: str
    pageID: str
    abs_url: str
    title: str
    objectID: str
    rank: int

## docs/.hooks/snippets.py

class SnippetDirective:
    path: str
    title: str | None = None
    fragment: str | None = None
    highlight: str | None = None
    extra_attrs: dict[str, str] | None = None

## docs/.hooks/test_snippets.py

def test_parse_snippet_directive_missing_path():
    """Test that missing path raises ValueError."""
    line = '```snippet {title="Test"}'
    with pytest.raises(ValueError, match='Missing required key "path" in snippet directive'):
        parse_snippet_directive(line)

def test_parse_snippet_directive_invalid_format():
    """Test that invalid format returns None."""
    assert parse_snippet_directive('```python') is None
    assert parse_snippet_directive("snippet {path='test.py'}") is None
    assert parse_snippet_directive('```snippet') is None
    assert parse_snippet_directive('```snippet```') is None

## examples/pydantic_ai_examples/chat_app.py

async def index() -> FileResponse:
    return FileResponse((THIS_DIR / 'chat_app.html'), media_type='text/html')

async def main_ts() -> FileResponse:
    """Get the raw typescript code, it's compiled in the browser, forgive me."""
    return FileResponse((THIS_DIR / 'chat_app.ts'), media_type='text/plain')

async def get_chat(database: Database = Depends(get_db)) -> Response:
    msgs = await database.get_messages()
    return Response(
        b'\n'.join(json.dumps(to_chat_message(m)).encode('utf-8') for m in msgs),
        media_type='text/plain',
    )

## examples/pydantic_ai_examples/data_analyst.py

def display(ctx: RunContext[AnalystAgentDeps], name: str) -> str:
    """Display at most 5 rows of the dataframe."""
    dataset = ctx.deps.get(name)
    return dataset.head().to_string()  # pyright: ignore[reportUnknownMemberType]

## examples/pydantic_ai_examples/flight_booking.py

class Deps:
    web_page_text: str
    req_origin: str
    req_destination: str
    req_date: datetime.date

## examples/pydantic_ai_examples/weather_agent_gradio.py

async def handle_retry(chatbot, past_messages: list, retry_data: gr.RetryData):
    new_history = chatbot[: retry_data.index]
    previous_prompt = chatbot[retry_data.index]['content']
    past_messages = past_messages[: retry_data.index]
    async for update in stream_from_agent(previous_prompt, new_history, past_messages):
        yield update

## pydantic_ai_slim/pydantic_ai/__init__.py

from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

## pydantic_ai_slim/pydantic_ai/_agent_graph.py

class _RunMessages:
    messages: list[_messages.ModelMessage]
    used: bool = False

def get_captured_run_messages() -> _RunMessages:
    return _messages_ctx_var.get()

## pydantic_ai_slim/pydantic_ai/_function_schema.py

def _is_call_ctx(annotation: Any) -> bool:
    """Return whether the annotation is the `RunContext` class, parameterized or not."""
    return annotation is RunContext or get_origin(annotation) is RunContext

## pydantic_ai_slim/pydantic_ai/_run_context.py

def get_current_run_context() -> RunContext[Any] | None:
    """Get the current run context, if one is set.

    Returns:
        The current [`RunContext`][pydantic_ai.tools.RunContext], or `None` if not in an agent run.
    """
    return _CURRENT_RUN_CONTEXT.get()

## pydantic_ai_slim/pydantic_ai/_utils.py

async def run_in_executor(func: Callable[_P, _R], *args: _P.args, **kwargs: _P.kwargs) -> _R:
    if _disable_threads.get():
        return func(*args, **kwargs)

    wrapped_func = partial(func, *args, **kwargs)
    return await run_sync(wrapped_func)

def is_set(t_or_unset: T | Unset) -> TypeGuard[T]:
    return t_or_unset is not UNSET

def get_traceparent(x: AgentRun | AgentRunResult | GraphRun | GraphRunResult) -> str:
    return x._traceparent(required=False) or ''  # type: ignore[reportPrivateUsage]

def number_to_datetime(x: int | float) -> datetime:
    return _datetime_ta.validate_python(x)

## pydantic_ai_slim/pydantic_ai/agent/__init__.py

    def _get_toolset(
        self,
        output_toolset: AbstractToolset[AgentDepsT] | None | _utils.Unset = _utils.UNSET,
        additional_toolsets: Sequence[AbstractToolset[AgentDepsT]] | None = None,
    ) -> AbstractToolset[AgentDepsT]:
        """Get the complete toolset.

        Args:
            output_toolset: The output toolset to use instead of the one built at agent construction time.
            additional_toolsets: Additional toolsets to add, unless toolsets have been overridden.
        """
        toolsets = self.toolsets
        # Don't add additional toolsets if the toolsets have been overridden
        if additional_toolsets and self._override_toolsets.get() is None:
            toolsets = [*toolsets, *additional_toolsets]

        toolset = CombinedToolset(toolsets)

        def copy_dynamic_toolsets(toolset: AbstractToolset[AgentDepsT]) -> AbstractToolset[AgentDepsT]:
            if isinstance(toolset, DynamicToolset):
                return toolset.copy()
            else:
                return toolset

        toolset = toolset.visit_and_replace(copy_dynamic_toolsets)

        if self._prepare_tools:
            toolset = PreparedToolset(toolset, self._prepare_tools)

        output_toolset = output_toolset if _utils.is_set(output_toolset) else self._output_toolset
        if output_toolset is not None:
            if self._prepare_output_tools:
                output_toolset = PreparedToolset(output_toolset, self._prepare_output_tools)
            toolset = CombinedToolset([output_toolset, toolset])

        return toolset

    def toolsets(self) -> Sequence[AbstractToolset[AgentDepsT]]:
        """All toolsets registered on the agent, including a function toolset holding tools that were registered on the agent directly.

        Output tools are not included.
        """
        toolsets: list[AbstractToolset[AgentDepsT]] = []

        if some_tools := self._override_tools.get():
            function_toolset = _AgentFunctionToolset(
                some_tools.value,
                max_retries=self._max_tool_retries,
                timeout=self._tool_timeout,
                output_schema=self._output_schema,
            )
        else:
            function_toolset = self._function_toolset
        toolsets.append(function_toolset)

        if some_user_toolsets := self._override_toolsets.get():
            user_toolsets = some_user_toolsets.value
        else:
            user_toolsets = [*self._user_toolsets, *self._dynamic_toolsets]
        toolsets.extend(user_toolsets)

        return toolsets

## pydantic_ai_slim/pydantic_ai/agent/abstract.py

    def toolsets(self) -> Sequence[AbstractToolset[AgentDepsT]]:
        """All toolsets registered on the agent.

        Output tools are not included.
        """
        raise NotImplementedError

## pydantic_ai_slim/pydantic_ai/builtin_tools.py

def _tool_discriminator(tool_data: dict[str, Any] | AbstractBuiltinTool) -> str:
    if isinstance(tool_data, dict):
        return tool_data.get('kind', AbstractBuiltinTool.kind)
    else:
        return tool_data.kind

## pydantic_ai_slim/pydantic_ai/concurrency.py

async def _null_context() -> AsyncIterator[None]:
    """A no-op async context manager."""
    yield

async def _limiter_context(limiter: AbstractConcurrencyLimiter, source: str) -> AsyncIterator[None]:
    """Context manager that acquires and releases a limiter with the given source."""
    await limiter.acquire(source)
    try:
        yield
    finally:
        limiter.release()

## pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_cache_policies.py

def _is_toolset_tool(obj: Any) -> TypeGuard[ToolsetTool]:
    return isinstance(obj, ToolsetTool)

def _replace_toolsets(
    inputs: dict[str, Any],
) -> Any:
    """Replace Toolset objects with a dict containing only hashable fields."""
    inputs = inputs.copy()
    for key, value in inputs.items():
        if _is_toolset_tool(value):
            inputs[key] = {field.name: getattr(value, field.name) for field in fields(value) if field.name != 'toolset'}
    return inputs

## pydantic_ai_slim/pydantic_ai/durable_exec/temporal/__init__.py

class AgentPlugin(SimplePlugin):
    """Temporal worker plugin for a specific Pydantic AI agent."""

    def __init__(self, agent: TemporalAgent[Any, Any]):
        super().__init__(  # type: ignore[reportUnknownMemberType]
            name='AgentPlugin',
            activities=agent.temporal_activities,
        )

## pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_dynamic_toolset.py

class _ToolInfo:
    """Serializable tool information returned from get_tools_activity."""

    tool_def: ToolDefinition
    max_retries: int

## pydantic_ai_slim/pydantic_ai/ext/aci.py

def _clean_schema(schema):
    if isinstance(schema, dict):
        # Remove non-standard keys (e.g., 'visible')
        return {k: _clean_schema(v) for k, v in schema.items() if k not in {'visible'}}
    elif isinstance(schema, list):
        return [_clean_schema(item) for item in schema]
    else:
        return schema

## pydantic_ai_slim/pydantic_ai/mcp.py

    async def list_tools(self) -> list[mcp_types.Tool]:
        """Retrieve tools that are currently active on the server.

        Tools are cached by default, with cache invalidation on:
        - `notifications/tools/list_changed` notifications from the server
        - Connection close (cache is cleared in `__aexit__`)

        Set `cache_tools=False` for servers that change tools without sending notifications.
        """
        async with self:
            if self.cache_tools:
                if self._cached_tools is not None:
                    return self._cached_tools
                result = await self._client.list_tools()
                self._cached_tools = result.tools
                return result.tools
            else:
                result = await self._client.list_tools()
                return result.tools

## pydantic_ai_slim/pydantic_ai/models/__init__.py

def get_user_agent() -> str:
    """Get the user agent string for the HTTP client."""
    from .. import __version__

    return f'pydantic-ai/{__version__}'

## pydantic_ai_slim/pydantic_ai/models/anthropic.py

def _map_web_search_tool_result_block(item: BetaWebSearchToolResultBlock, provider_name: str) -> BuiltinToolReturnPart:
    return BuiltinToolReturnPart(
        provider_name=provider_name,
        tool_name=WebSearchTool.kind,
        content=web_search_tool_result_content_ta.dump_python(item.content, mode='json'),
        tool_call_id=item.tool_use_id,
    )

def _map_web_fetch_tool_result_block(item: BetaWebFetchToolResultBlock, provider_name: str) -> BuiltinToolReturnPart:
    return BuiltinToolReturnPart(
        provider_name=provider_name,
        tool_name=WebFetchTool.kind,
        # Store just the content field (BetaWebFetchBlock) which has {content, type, url, retrieved_at}
        content=item.content.model_dump(mode='json'),
        tool_call_id=item.tool_use_id,
    )

## pydantic_ai_slim/pydantic_ai/models/gemini.py

class _GeminiContent(TypedDict):
    role: Literal['user', 'model']
    parts: list[_GeminiPartUnion]

class _GeminiTextPart(_BasePart):
    text: str

def _function_call_part_from_call(tool: ToolCallPart) -> _GeminiFunctionCallPart:
    return _GeminiFunctionCallPart(function_call=_GeminiFunctionCall(name=tool.tool_name, args=tool.args_as_dict()))

class _GeminiTextContent(TypedDict):
    role: Literal['user', 'model']
    parts: list[_GeminiTextPart]

def _tool_config(function_names: list[str]) -> _GeminiToolConfig:
    return _GeminiToolConfig(
        function_calling_config=_GeminiFunctionCallingConfig(mode='ANY', allowed_function_names=function_names)
    )

## pydantic_ai_slim/pydantic_ai/models/openai.py

def _drop_unsupported_params(profile: OpenAIModelProfile, model_settings: OpenAIChatModelSettings) -> None:
    """Drop unsupported parameters based on model profile.

    Used currently only by Cerebras
    """
    for setting in profile.openai_unsupported_model_settings:
        model_settings.pop(setting, None)

def _split_combined_tool_call_id(combined_id: str) -> tuple[str, str | None]:
    # When reasoning, the Responses API requires the `ResponseFunctionToolCall` to be returned with both the `call_id` and `id` fields.
    # Before our `ToolCallPart` gained the `id` field alongside `tool_call_id` field, we combined the two fields into a single string stored on `tool_call_id`.
    if '|' in combined_id:
        call_id, id = combined_id.split('|', 1)
        return call_id, id
    else:
        return combined_id, None

## pydantic_ai_slim/pydantic_ai/models/xai.py

def _map_json_object() -> chat_pb2.ResponseFormat:
    """Create a ResponseFormat for JSON object mode (prompted output)."""
    return chat_pb2.ResponseFormat(format_type=chat_pb2.FORMAT_TYPE_JSON_OBJECT)

def _map_model_settings(model_settings: XaiModelSettings) -> dict[str, Any]:
    """Map pydantic_ai ModelSettings to xAI SDK parameters."""
    return {
        _XAI_MODEL_SETTINGS_MAPPING[key]: value
        for key, value in model_settings.items()
        if key in _XAI_MODEL_SETTINGS_MAPPING
    }

## pydantic_ai_slim/pydantic_ai/toolsets/wrapper.py

class WrapperToolset(AbstractToolset[AgentDepsT]):
    """A toolset that wraps another toolset and delegates to it.

    See [toolset docs](../toolsets.md#wrapping-a-toolset) for more information.
    """

    wrapped: AbstractToolset[AgentDepsT]

    @property
    def id(self) -> str | None:
        return None  # pragma: no cover

    @property
    def label(self) -> str:
        return f'{self.__class__.__name__}({self.wrapped.label})'

    async def __aenter__(self) -> Self:
        await self.wrapped.__aenter__()
        return self

    async def __aexit__(self, *args: Any) -> bool | None:
        return await self.wrapped.__aexit__(*args)

    async def get_tools(self, ctx: RunContext[AgentDepsT]) -> dict[str, ToolsetTool[AgentDepsT]]:
        return await self.wrapped.get_tools(ctx)

    async def call_tool(
        self, name: str, tool_args: dict[str, Any], ctx: RunContext[AgentDepsT], tool: ToolsetTool[AgentDepsT]
    ) -> Any:
        return await self.wrapped.call_tool(name, tool_args, ctx, tool)

    def apply(self, visitor: Callable[[AbstractToolset[AgentDepsT]], None]) -> None:
        self.wrapped.apply(visitor)

    def visit_and_replace(
        self, visitor: Callable[[AbstractToolset[AgentDepsT]], AbstractToolset[AgentDepsT]]
    ) -> AbstractToolset[AgentDepsT]:
        return replace(self, wrapped=self.wrapped.visit_and_replace(visitor))

    def id(self) -> str | None:
        return None  # pragma: no cover

    def label(self) -> str:
        return f'{self.__class__.__name__}({self.wrapped.label})'

    async def __aenter__(self) -> Self:
        await self.wrapped.__aenter__()
        return self

    async def __aexit__(self, *args: Any) -> bool | None:
        return await self.wrapped.__aexit__(*args)

    async def get_tools(self, ctx: RunContext[AgentDepsT]) -> dict[str, ToolsetTool[AgentDepsT]]:
        return await self.wrapped.get_tools(ctx)

    async def call_tool(
        self, name: str, tool_args: dict[str, Any], ctx: RunContext[AgentDepsT], tool: ToolsetTool[AgentDepsT]
    ) -> Any:
        return await self.wrapped.call_tool(name, tool_args, ctx, tool)

    def apply(self, visitor: Callable[[AbstractToolset[AgentDepsT]], None]) -> None:
        self.wrapped.apply(visitor)

    def visit_and_replace(
        self, visitor: Callable[[AbstractToolset[AgentDepsT]], AbstractToolset[AgentDepsT]]
    ) -> AbstractToolset[AgentDepsT]:
        return replace(self, wrapped=self.wrapped.visit_and_replace(visitor))

## pydantic_ai_slim/pydantic_ai/ui/_adapter.py

    def toolset(self) -> AbstractToolset[AgentDepsT] | None:
        """Toolset representing frontend tools from the protocol-specific run input."""
        return None

## pydantic_ai_slim/pydantic_ai/ui/_web/api.py

class ModelInfo(BaseModel, alias_generator=to_camel, populate_by_name=True):
    """Defines an AI model with its associated built-in tools."""

    id: str
    name: str
    builtin_tools: list[str]

class BuiltinToolInfo(BaseModel, alias_generator=to_camel, populate_by_name=True):
    """Serializable info about a builtin tool for frontend config."""

    id: str
    name: str

class ConfigureFrontend(BaseModel, alias_generator=to_camel, populate_by_name=True):
    """Response model for frontend configuration."""

    models: list[ModelInfo]
    builtin_tools: list[BuiltinToolInfo]

## pydantic_ai_slim/pydantic_ai/ui/ag_ui/_adapter.py

    def toolset(self) -> AbstractToolset[AgentDepsT] | None:
        """Toolset representing frontend tools from the AG-UI run input."""
        if self.run_input.tools:
            return _AGUIFrontendToolset[AgentDepsT](self.run_input.tools)
        return None

## pydantic_ai_slim/pydantic_ai/ui/vercel_ai/_utils.py

def load_provider_metadata(provider_metadata: ProviderMetadata | None) -> dict[str, Any]:
    """Load the Pydantic AI metadata from the provider metadata."""
    return provider_metadata.get(PROVIDER_METADATA_KEY, {}) if provider_metadata else {}

## pydantic_evals/pydantic_evals/dataset.py

def set_eval_attribute(name: str, value: Any) -> None:
    """Set an attribute on the current task run.

    Args:
        name: The name of the attribute.
        value: The value of the attribute.
    """
    current_case = _CURRENT_TASK_RUN.get()
    if current_case is not None:  # pragma: no branch
        current_case.record_attribute(name, value)

def increment_eval_metric(name: str, amount: int | float) -> None:
    """Increment a metric on the current task run.

    Args:
        name: The name of the metric.
        amount: The amount to increment by.
    """
    current_case = _CURRENT_TASK_RUN.get()
    if current_case is not None:  # pragma: no branch
        current_case.increment_metric(name, amount)

## pydantic_graph/pydantic_graph/beta/graph.py

class _GraphTaskAsyncIterable:
    iterable: AsyncIterable[Sequence[GraphTask]]
    fork_stack: ForkStack

def _is_any_iterable(x: Any) -> TypeGuard[Iterable[Any]]:
    return isinstance(x, Iterable)

def _is_any_async_iterable(x: Any) -> TypeGuard[AsyncIterable[Any]]:
    return isinstance(x, AsyncIterable)

## pydantic_graph/pydantic_graph/beta/graph_builder.py

def _replace_placeholder_node_ids(nodes: dict[NodeID, AnyNode], edges_by_source: dict[NodeID, list[Path]]):
    node_id_remapping = _build_placeholder_node_id_remapping(nodes)
    replaced_nodes = {
        node_id_remapping.get(name, name): _update_node_with_id_remapping(node, node_id_remapping)
        for name, node in nodes.items()
    }
    replaced_edges_by_source = {
        node_id_remapping.get(source, source): [_update_path_with_id_remapping(p, node_id_remapping) for p in paths]
        for source, paths in edges_by_source.items()
    }
    return replaced_nodes, replaced_edges_by_source

## pydantic_graph/pydantic_graph/beta/mermaid.py

class MermaidNode:
    """A mermaid node."""

    id: str
    kind: NodeKind
    label: str | None
    note: str | None

class MermaidEdge:
    """A mermaid edge."""

    start_id: str
    end_id: str
    label: str | None

## pydantic_graph/pydantic_graph/beta/util.py

class Some(Generic[T]):
    """Container for explicitly present values in Maybe type pattern.

    This class represents a value that is definitely present, as opposed to None.
    It's part of the Maybe pattern, similar to Option/Maybe in functional programming,
    allowing distinction between "no value" (None) and "value is None" (Some(None)).
    """

    value: T
    """The wrapped value."""

## scripts/check_cassettes.py

def get_all_tests() -> dict[str, set[str]]:
    """Use pytest collection to get all VCR-marked tests and their cassette names."""
    collector = _CollectVcrTests()
    rc = pytest.main(['--collect-only', '-q', 'tests/'], plugins=[collector])
    if rc not in (pytest.ExitCode.OK, pytest.ExitCode.NO_TESTS_COLLECTED):
        raise SystemExit(rc)
    return dict(collector.tests)

## tests/evals/test_otel.py

async def test_span_tree_any(span_tree: SpanTree):
    """Test the any() method of SpanTree."""
    # Test existence of a node by name
    assert span_tree.any(lambda node: node.name == 'grandchild2')

    # Test non-existence
    assert not span_tree.any(lambda node: node.name == 'non_existent')

    # Test existence by attribute
    assert span_tree.any(lambda node: node.attributes.get('type') == 'important')

async def test_span_node_any_child(span_tree: SpanTree):
    """Test the any_child method of SpanNode."""
    root_node = span_tree.roots[0]

    # Test existence of child with normal type
    assert root_node.any_child(lambda node: node.attributes.get('type') == 'normal')

    # Test non-existence
    assert not root_node.any_child(lambda node: node.name == 'non_existent')

## tests/evals/test_utils.py

def test_is_set():
    """Test is_set function."""
    assert is_set(42) is True
    assert is_set(None) is True
    assert is_set(UNSET) is False

## tests/graph/beta/test_graph_iteration.py

class IterState:
    counter: int = 0

## tests/json_body_serializer.py

def normalize_body(obj: Any) -> Any:
    """Recursively normalize smart characters in all strings within a data structure."""
    if isinstance(obj, str):
        return normalize_smart_chars(obj)
    elif isinstance(obj, dict):
        return {k: normalize_body(v) for k, v in obj.items()}
    elif isinstance(obj, list):  # pragma: no cover
        return [normalize_body(item) for item in obj]
    return obj  # pragma: no cover

def str_presenter(dumper: Dumper, data: str):
    """If the string contains newlines, represent it as a literal block."""
    if '\n' in data:
        return dumper.represent_scalar('tag:yaml.org,2002:str', data, style='|')
    return dumper.represent_scalar('tag:yaml.org,2002:str', data)

## tests/mcp_server.py

async def enable_hidden_tool(ctx: Context[ServerSession, None]) -> str:
    """Enable the hidden tool, triggering a ToolListChangedNotification."""
    mcp._tool_manager.add_tool(hidden_tool)  # pyright: ignore[reportPrivateUsage]
    await ctx.session.send_tool_list_changed()
    return 'Hidden tool enabled'

## tests/models/mock_xai.py

def _get_proto_finish_reason(finish_reason: FinishReason) -> sample_pb2.FinishReason:
    """Map pydantic-ai FinishReason to xAI proto FinishReason."""
    return {
        'stop': sample_pb2.FinishReason.REASON_STOP,
        'length': sample_pb2.FinishReason.REASON_MAX_LEN,
        'tool_call': sample_pb2.FinishReason.REASON_TOOL_CALLS,
        'content_filter': sample_pb2.FinishReason.REASON_STOP,
    }.get(finish_reason, sample_pb2.FinishReason.REASON_STOP)

## tests/models/test_gemini.py

def test_map_empty_usage():
    response = gemini_response(_content_model_response(ModelResponse(parts=[TextPart('Hello world')])))
    assert 'usage_metadata' in response
    del response['usage_metadata']

    assert _metadata_as_usage(response) == RequestUsage()

## tests/models/test_model_names.py

def modify_response(response: dict[str, Any], filter_headers: list[str]) -> dict[str, Any]:  # pragma: lax no cover
    for header in response['headers'].copy():
        assert isinstance(header, str)
        if header.lower() in filter_headers:
            del response['headers'][header]
    return response

## tests/models/test_openai.py

def test_openai_image_generation_tool_aspect_ratio_invalid() -> None:
    """Test that invalid aspect_ratio raises UserError."""
    tool = ImageGenerationTool(aspect_ratio='16:9')
    with pytest.raises(UserError, match='OpenAI image generation only supports `aspect_ratio` values'):
        _resolve_openai_image_generation_size(tool)

## tests/models/xai_proto_cassettes.py

class SampleInteraction:
    """A single `chat.sample()` request/response pair."""

    request_raw: bytes
    response_raw: bytes
    request_json: dict[str, Any] | None = None
    response_json: dict[str, Any] | None = None

class StreamInteraction:
    """A single `chat.stream()` request/response pair."""

    request_raw: bytes
    chunks_raw: list[bytes]
    request_json: dict[str, Any] | None = None
    chunks_json: list[dict[str, Any]] | None = None

## tests/test_agent.py

async def test_implicit_context_manager():
    try:
        from pydantic_ai.mcp import MCPServerStdio
    except ImportError:  # pragma: lax no cover
        pytest.skip('mcp is not installed')

    server1 = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    server2 = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    toolset = CombinedToolset([server1, PrefixedToolset(server2, 'prefix')])
    agent = Agent('test', toolsets=[toolset])

    async with agent.iter(user_prompt='Hello'):
        assert server1.is_running
        assert server2.is_running

class UserContext:
    location: str | None

## tests/test_builtin_tools.py

async def test_builtin_tools_not_supported_file_search_stream(model: Model, allow_model_requests: None):
    agent = Agent(model=model, builtin_tools=[FileSearchTool(file_store_ids=['test-id'])])

    with pytest.raises(UserError):
        async with agent.run_stream('Search my files'):
            ...  # pragma: no cover

## tests/test_cli.py

def test_handle_slash_command_exit():
    io = StringIO()
    assert handle_slash_command('/exit', [], False, Console(file=io), 'default') == (0, False)
    assert io.getvalue() == snapshot('Exitingâ€¦\n')

## tests/test_dbos.py

class BasicSpan:
    content: str
    children: list[BasicSpan] = field(default_factory=list['BasicSpan'])
    parent_id: int | None = field(repr=False, compare=False, default=None)

## tests/test_direct.py

def test_model_request_stream_sync_intermediate_get():
    """Test getting properties of StreamedResponse before consuming all events."""
    messages: list[ModelMessage] = [ModelRequest.user_text_prompt('x')]

    with model_request_stream_sync('test', messages) as stream:
        response = stream.get()
        assert response is not None

        usage = stream.usage()
        assert usage is not None

## tests/test_function_schema.py

def test_regular_function_with_ctx():
    """Test regular function that takes RunContext as first parameter."""

    def func_with_ctx(ctx: RunContext[Any], x: int) -> str: ...  # pragma: no cover

    assert _takes_ctx(func_with_ctx) is True

def test_regular_function_without_ctx():
    """Test regular function that doesn't take RunContext as first parameter."""

    def func_without_ctx(x: int, y: str) -> str: ...  # pragma: no cover

    assert _takes_ctx(func_without_ctx) is False

def test_regular_function_no_params():
    """Test regular function with no parameters."""

    def func_no_params() -> str: ...  # pragma: no cover

    assert _takes_ctx(func_no_params) is False

def test_regular_function_ctx_not_first():
    """Test regular function where RunContext is not the first parameter."""

    def func_ctx_not_first(x: int, ctx: RunContext[Any]) -> str: ...  # pragma: no cover

    assert _takes_ctx(func_ctx_not_first) is False

def test_function_wrong_annotation_type():
    """Test function with wrong annotation type for first parameter."""

    def func_wrong_annotation(ctx: str, x: int) -> str: ...  # pragma: no cover

    assert _takes_ctx(func_wrong_annotation) is False

def test_lambda_with_ctx():
    """Test lambda function that takes RunContext as first parameter."""
    lambda_with_ctx = lambda ctx, x: f'{ctx.deps} {x}'  # type: ignore # noqa: E731

    # Lambda without annotations should return False
    assert _takes_ctx(lambda_with_ctx) is False  # type: ignore

def test_builtin_function():
    """Test builtin function."""
    assert _takes_ctx(len) is False
    assert _takes_ctx(str) is False
    assert _takes_ctx(int) is False

## tests/test_logfire.py

def get_logfire_summary(capfire: CaptureLogfire) -> Callable[[], LogfireSummary]:
    def get_summary() -> LogfireSummary:
        return LogfireSummary(capfire)

    return get_summary

class WeatherInfo(BaseModel):
    temperature: float
    description: str

## tests/test_mcp.py

def mcp_server() -> MCPServerStdio:
    return MCPServerStdio('python', ['-m', 'tests.mcp_server'])

async def test_stdio_server(run_context: RunContext[int]):
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        tools = [tool.tool_def for tool in (await server.get_tools(run_context)).values()]
        assert len(tools) == snapshot(20)
        assert tools[0].name == 'celsius_to_fahrenheit'
        assert isinstance(tools[0].description, str)
        assert tools[0].description.startswith('Convert Celsius to Fahrenheit.')

        # Test calling the temperature conversion tool
        result = await server.direct_call_tool('celsius_to_fahrenheit', {'celsius': 0})
        assert result == snapshot(32.0)

async def test_reentrant_context_manager():
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        async with server:
            pass

async def test_context_manager_initialization_error() -> None:
    """Test if streams are closed if client fails to initialize."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    from mcp.client.session import ClientSession

    with patch.object(ClientSession, 'initialize', side_effect=Exception):
        with pytest.raises(Exception):
            async with server:
                pass

    assert server._read_stream._closed  # pyright: ignore[reportPrivateUsage]
    assert server._write_stream._closed  # pyright: ignore[reportPrivateUsage]

async def test_aexit_called_more_times_than_aenter():
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])

    with pytest.raises(ValueError, match='MCPServer.__aexit__ called more times than __aenter__'):
        await server.__aexit__(None, None, None)

    async with server:
        pass  # This will call __aenter__ and __aexit__ once each

    with pytest.raises(ValueError, match='MCPServer.__aexit__ called more times than __aenter__'):
        await server.__aexit__(None, None, None)

async def test_stdio_server_with_tool_prefix(run_context: RunContext[int]):
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'], tool_prefix='foo')
    async with server:
        tools = await server.get_tools(run_context)
        assert all(name.startswith('foo_') for name in tools.keys())

        result = await server.call_tool(
            'foo_celsius_to_fahrenheit', {'celsius': 0}, run_context, tools['foo_celsius_to_fahrenheit']
        )
        assert result == snapshot(32.0)

async def test_stdio_server_with_cwd(run_context: RunContext[int]):
    test_dir = Path(__file__).parent
    server = MCPServerStdio('python', ['mcp_server.py'], cwd=test_dir)
    async with server:
        tools = await server.get_tools(run_context)
        assert len(tools) == snapshot(20)

async def test_agent_with_server_not_running(agent: Agent, allow_model_requests: None):
    result = await agent.run('What is 0 degrees Celsius in Fahrenheit?')
    assert result.output == snapshot('0 degrees Celsius is 32.0 degrees Fahrenheit.')

async def test_log_level_unset(run_context: RunContext[int]):
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    assert server.log_level is None
    async with server:
        result = await server.direct_call_tool('get_log_level', {})
        assert result == snapshot('unset')

async def test_stdio_server_list_resource_templates(run_context: RunContext[int]):
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        resource_templates = await server.list_resource_templates()
        assert resource_templates == snapshot(
            [
                ResourceTemplate(
                    name='greeting_resource_template',
                    description='Dynamic greeting resource template.',
                    mime_type='text/plain',
                    uri_template='resource://greeting/{name}',
                )
            ]
        )

async def test_log_level_set(run_context: RunContext[int]):
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'], log_level='info')
    assert server.log_level == 'info'
    async with server:
        result = await server.direct_call_tool('get_log_level', {})
        assert result == snapshot('info')

async def test_tool_metadata_extraction():
    """Test that MCP tool metadata is properly extracted into ToolDefinition."""

    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        ctx = RunContext(deps=None, model=TestModel(), usage=RunUsage())
        tools = [tool.tool_def for tool in (await server.get_tools(ctx)).values()]
        # find `celsius_to_fahrenheit`
        celsius_to_fahrenheit = next(tool for tool in tools if tool.name == 'celsius_to_fahrenheit')
        assert celsius_to_fahrenheit.metadata is not None
        assert celsius_to_fahrenheit.metadata.get('annotations') is not None
        assert celsius_to_fahrenheit.metadata.get('annotations', {}).get('title', None) == 'Celsius to Fahrenheit'
        assert celsius_to_fahrenheit.metadata.get('output_schema') is not None
        assert celsius_to_fahrenheit.metadata.get('output_schema', {}).get('type', None) == 'object'

async def test_client_sampling(run_context: RunContext[int]):
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    server.sampling_model = TestModel(custom_output_text='sampling model response')
    async with server:
        result = await server.direct_call_tool('use_sampling', {'foo': 'bar'})
        assert result == snapshot(
            {
                '_meta': None,
                'role': 'assistant',
                'content': {'type': 'text', 'text': 'sampling model response', 'annotations': None, '_meta': None},
                'model': 'test',
                'stopReason': None,
            }
        )

async def test_client_sampling_disabled(run_context: RunContext[int]):
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'], allow_sampling=False)
    server.sampling_model = TestModel(custom_output_text='sampling model response')
    async with server:
        with pytest.raises(ModelRetry, match='Error executing tool use_sampling: Sampling not supported'):
            await server.direct_call_tool('use_sampling', {'foo': 'bar'})

async def test_elicitation_callback_not_set(run_context: RunContext[int]):
    """Test that elicitation fails when no callback is set."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])

    async with server:
        # Should raise an error when elicitation is attempted without callback
        with pytest.raises(ModelRetry, match='Elicitation not supported'):
            await server.direct_call_tool('use_elicitation', {'question': 'Should I continue?'})

async def test_read_text_resource(run_context: RunContext[int]):
    """Test reading a text resource (converted to string)."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        # Test reading by URI string
        content = await server.read_resource('resource://product_name.txt')
        assert isinstance(content, str)
        assert content == snapshot('Pydantic AI\n')

        # Test reading by Resource object
        resource = Resource(uri='resource://product_name.txt', name='product_name_resource')
        content_from_resource = await server.read_resource(resource)
        assert isinstance(content_from_resource, str)
        assert content_from_resource == snapshot('Pydantic AI\n')

async def test_read_blob_resource(run_context: RunContext[int]):
    """Test reading a binary resource (converted to BinaryContent)."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        content = await server.read_resource('resource://kiwi.jpg')
        assert isinstance(content, BinaryContent)
        assert content.media_type == snapshot('image/jpeg')
        # Verify it's JPEG data (starts with JPEG magic bytes)
        assert content.data.startswith(bytes.fromhex('ffd8ffe0'))  # JPEG magic bytes

async def test_read_resource_template(run_context: RunContext[int]):
    """Test reading a resource template with parameters (converted to string)."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        content = await server.read_resource('resource://greeting/Alice')
        assert isinstance(content, str)
        assert content == snapshot('Hello, Alice!')

async def test_client_info_not_set() -> None:
    """Test that when client_info is not set, the default MCP client info is used."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])

    async with server:
        result = await server.direct_call_tool('get_client_info', {})
        # When client_info is not set, the MCP library provides default client info
        assert result is not None
        assert isinstance(result, dict)
        assert result['name'] == 'mcp'

async def test_custom_http_client_not_closed():
    custom_http_client = cached_async_http_client()

    assert not custom_http_client.is_closed

    my_mcp_server = MCPServerStreamableHTTP(
        url='https://mcp.deepwiki.com/mcp', http_client=custom_http_client, timeout=30
    )

    tools = await my_mcp_server.list_tools()
    assert len(tools) > 0

    assert not custom_http_client.is_closed

async def test_tools_caching_enabled_by_default() -> None:
    """Test that list_tools() caches results by default."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        # First call - should fetch from server and cache
        tools1 = await server.list_tools()
        assert len(tools1) > 0
        assert server._cached_tools is not None  # pyright: ignore[reportPrivateUsage]

        # Second call - should return cached value (cache is still populated)
        tools2 = await server.list_tools()
        assert tools2 == tools1
        assert server._cached_tools is not None  # pyright: ignore[reportPrivateUsage]

async def test_tools_no_caching_when_disabled() -> None:
    """Test that list_tools() does not cache when cache_tools=False."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'], cache_tools=False)
    async with server:
        # First call - should not populate cache
        tools1 = await server.list_tools()
        assert len(tools1) > 0
        assert server._cached_tools is None  # pyright: ignore[reportPrivateUsage]

        # Second call - cache should still be None
        tools2 = await server.list_tools()
        assert tools2 == tools1
        assert server._cached_tools is None  # pyright: ignore[reportPrivateUsage]

async def test_resources_caching_enabled_by_default() -> None:
    """Test that list_resources() caches results by default."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        assert server.capabilities.resources

        # First call - should fetch from server and cache
        resources1 = await server.list_resources()
        assert server._cached_resources is not None  # pyright: ignore[reportPrivateUsage]

        # Second call - should return cached value (cache is still populated)
        resources2 = await server.list_resources()
        assert resources2 == resources1
        assert server._cached_resources is not None  # pyright: ignore[reportPrivateUsage]

async def test_resources_no_caching_when_disabled() -> None:
    """Test that list_resources() does not cache when cache_resources=False."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'], cache_resources=False)
    async with server:
        assert server.capabilities.resources

        # First call - should not populate cache
        resources1 = await server.list_resources()
        assert server._cached_resources is None  # pyright: ignore[reportPrivateUsage]

        # Second call - cache should still be None
        resources2 = await server.list_resources()
        assert resources2 == resources1
        assert server._cached_resources is None  # pyright: ignore[reportPrivateUsage]

async def test_server_capabilities_list_changed_fields() -> None:
    """Test that ServerCapabilities correctly parses listChanged fields."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        caps = server.capabilities
        assert isinstance(caps.prompts_list_changed, bool)
        assert isinstance(caps.tools_list_changed, bool)
        assert isinstance(caps.resources_list_changed, bool)

## tests/test_temporal.py

def my_mcp_dynamic_toolset(ctx: RunContext[None]) -> MCPServerStreamableHTTP:
    """Dynamic toolset that returns an MCP toolset.

    This tests MCP lifecycle management (context manager enter/exit) within DynamicToolset + Temporal.
    """
    return MCPServerStreamableHTTP('https://mcp.deepwiki.com/mcp')

## tests/test_ui.py

    def toolset(self) -> AbstractToolset[AgentDepsT] | None:
        return ExternalToolset(self.run_input.tool_defs) if self.run_input.tool_defs else None

## tests/test_ui_web.py

def test_chat_app_health_endpoint():
    """Test the /api/health endpoint."""
    agent = Agent('test')
    app = create_web_app(agent)

    with TestClient(app) as client:
        response = client.get('/api/health')
        assert response.status_code == 200
        assert response.json() == {'ok': True}

def test_chat_app_configure_endpoint_empty():
    """Test the /api/configure endpoint with no models or tools."""
    agent = Agent('test')
    app = create_web_app(agent)

    with TestClient(app) as client:
        response = client.get('/api/configure')
        assert response.status_code == 200
        assert response.json() == snapshot(
            {'models': [{'id': 'test:test', 'name': 'Test', 'builtinTools': []}], 'builtinTools': []}
        )

def test_chat_app_index_file_not_found(tmp_path: Path):
    """Test that index endpoint raises FileNotFoundError for non-existent html_source file."""
    agent = Agent('test')
    nonexistent_file = tmp_path / 'nonexistent-ui.html'
    app = create_web_app(agent, html_source=str(nonexistent_file))

    with TestClient(app, raise_server_exceptions=True) as client:
        with pytest.raises(FileNotFoundError, match='Local UI file not found'):
            client.get('/')
