## examples/pydantic_ai_examples/data_analyst.py

class AnalystAgentDeps:
    output: dict[str, pd.DataFrame] = field(default_factory=dict[str, pd.DataFrame])

    def store(self, value: pd.DataFrame) -> str:
        """Store the output in deps and return the reference such as Out[1] to be used by the LLM."""
        ref = f'Out[{len(self.output) + 1}]'
        self.output[ref] = value
        return ref

    def get(self, ref: str) -> pd.DataFrame:
        if ref not in self.output:
            raise ModelRetry(
                f'Error: {ref} is not a valid variable reference. Check the previous messages and try again.'
            )
        return self.output[ref]

    def get(self, ref: str) -> pd.DataFrame:
        if ref not in self.output:
            raise ModelRetry(
                f'Error: {ref} is not a valid variable reference. Check the previous messages and try again.'
            )
        return self.output[ref]

## examples/pydantic_ai_examples/slack_lead_qualifier/store.py

class AnalysisStore:
    @classmethod
    @logfire.instrument('Add analysis to store')
    async def add(cls, analysis: Analysis):
        await cls._get_store().put.aio(analysis.profile.email, analysis.model_dump())

    @classmethod
    @logfire.instrument('List analyses from store')
    async def list(cls) -> list[Analysis]:
        return [
            Analysis.model_validate(analysis)
            async for analysis in cls._get_store().values.aio()
        ]

    @classmethod
    @logfire.instrument('Clear analyses from store')
    async def clear(cls):
        await cls._get_store().clear.aio()

    @classmethod
    def _get_store(cls) -> modal.Dict:
        return modal.Dict.from_name('analyses', create_if_missing=True)  # type: ignore ### [/analysis_store]

    async def list(cls) -> list[Analysis]:
        return [
            Analysis.model_validate(analysis)
            async for analysis in cls._get_store().values.aio()
        ]

## pydantic_ai_slim/pydantic_ai/_a2a.py

from typing import Any, Generic, TypeVar

## pydantic_ai_slim/pydantic_ai/models/__init__.py

    _parts_manager: ModelResponsePartsManager = field(default_factory=ModelResponsePartsManager, init=False)

## pydantic_ai_slim/pydantic_ai/models/test.py

    def _bool_gen(self) -> bool:
        """Generate a boolean from a JSON Schema boolean."""
        return bool(self.seed % 2)

## pydantic_evals/pydantic_evals/otel/span_tree.py

class SpanQuery(TypedDict, total=False):
    """A serializable query for filtering SpanNodes based on various conditions.

    All fields are optional and combined with AND logic by default.
    """

    # These fields are ordered to match the implementation of SpanNode.matches_query for easy review.
    # * Individual span conditions come first because these are generally the cheapest to evaluate
    # * Logical combinations come next because they may just be combinations of individual span conditions
    # * Related-span conditions come last because they may require the most work to evaluate

    # Individual span conditions
    ## Name conditions
    name_equals: str
    name_contains: str
    name_matches_regex: str  # regex pattern

    ## Attribute conditions
    has_attributes: dict[str, Any]
    has_attribute_keys: list[str]

    ## Timing conditions
    min_duration: timedelta | float
    max_duration: timedelta | float

    # Logical combinations of conditions
    not_: SpanQuery
    and_: list[SpanQuery]
    or_: list[SpanQuery]

    # Child conditions
    min_child_count: int
    max_child_count: int
    some_child_has: SpanQuery
    all_children_have: SpanQuery
    no_child_has: SpanQuery

    # Recursive conditions
    stop_recursing_when: SpanQuery
    """If present, stop recursing through ancestors or descendants at nodes that match this condition."""

    ## Descendant conditions
    min_descendant_count: int
    max_descendant_count: int
    some_descendant_has: SpanQuery
    all_descendants_have: SpanQuery
    no_descendant_has: SpanQuery

    ## Ancestor conditions
    min_depth: int  # depth is equivalent to ancestor count; roots have depth 0
    max_depth: int
    some_ancestor_has: SpanQuery
    all_ancestors_have: SpanQuery
    no_ancestor_has: SpanQuery

    def descendants(self) -> list[SpanNode]:
        """Return all descendants of this node in DFS order."""
        return self.find_descendants(lambda _: True)

    def ancestors(self) -> list[SpanNode]:
        """Return all ancestors of this node."""
        return self.find_ancestors(lambda _: True)

    def _filter_descendants(
        self, predicate: SpanQuery | SpanPredicate, stop_recursing_when: SpanQuery | SpanPredicate | None
    ) -> Iterator[SpanNode]:
        stack = list(self.children)
        while stack:
            node = stack.pop()
            if node.matches(predicate):
                yield node
            if stop_recursing_when is not None and node.matches(stop_recursing_when):
                continue
            stack.extend(node.children)

    def _filter_ancestors(
        self, predicate: SpanQuery | SpanPredicate, stop_recursing_when: SpanQuery | SpanPredicate | None
    ) -> Iterator[SpanNode]:
        node = self.parent
        while node:
            if node.matches(predicate):
                yield node
            if stop_recursing_when is not None and node.matches(stop_recursing_when):
                break
            node = node.parent

    def matches(self, query: SpanQuery | SpanPredicate) -> bool:
        """Check if the span node matches the query conditions or predicate."""
        if callable(query):
            return query(self)

        return self._matches_query(query)

    def _matches_query(self, query: SpanQuery) -> bool:  # noqa: C901
        """Check if the span matches the query conditions."""
        # Logical combinations
        if or_ := query.get('or_'):
            if len(query) > 1:
                raise ValueError("Cannot combine 'or_' conditions with other conditions at the same level")
            return any(self._matches_query(q) for q in or_)
        if not_ := query.get('not_'):
            if self._matches_query(not_):
                return False
        if and_ := query.get('and_'):
            results = [self._matches_query(q) for q in and_]
            if not all(results):
                return False
        # At this point, all existing ANDs and no existing ORs have passed, so it comes down to this condition

        # Name conditions
        if (name_equals := query.get('name_equals')) and self.name != name_equals:
            return False
        if (name_contains := query.get('name_contains')) and name_contains not in self.name:
            return False
        if (name_matches_regex := query.get('name_matches_regex')) and not re.match(name_matches_regex, self.name):
            return False

        # Attribute conditions
        if (has_attributes := query.get('has_attributes')) and not all(
            self.attributes.get(key) == value for key, value in has_attributes.items()
        ):
            return False
        if (has_attributes_keys := query.get('has_attribute_keys')) and not all(
            key in self.attributes for key in has_attributes_keys
        ):
            return False

        # Timing conditions
        if (min_duration := query.get('min_duration')) is not None:
            if not isinstance(min_duration, timedelta):
                min_duration = timedelta(seconds=min_duration)
            if self.duration < min_duration:
                return False
        if (max_duration := query.get('max_duration')) is not None:
            if not isinstance(max_duration, timedelta):
                max_duration = timedelta(seconds=max_duration)
            if self.duration > max_duration:
                return False

        # Children conditions
        if (min_child_count := query.get('min_child_count')) and len(self.children) < min_child_count:
            return False
        if (max_child_count := query.get('max_child_count')) and len(self.children) > max_child_count:
            return False
        if (some_child_has := query.get('some_child_has')) and not any(
            child._matches_query(some_child_has) for child in self.children
        ):
            return False
        if (all_children_have := query.get('all_children_have')) and not all(
            child._matches_query(all_children_have) for child in self.children
        ):
            return False
        if (no_child_has := query.get('no_child_has')) and any(
            child._matches_query(no_child_has) for child in self.children
        ):
            return False

        # Descendant conditions
        # The following local functions with cache decorators are used to avoid repeatedly evaluating these properties
        @cache
        def descendants():
            return self.descendants

        @cache
        def pruned_descendants():
            stop_recursing_when = query.get('stop_recursing_when')
            return (
                self._filter_descendants(lambda _: True, stop_recursing_when) if stop_recursing_when else descendants()
            )

        if (min_descendant_count := query.get('min_descendant_count')) and len(descendants()) < min_descendant_count:
            return False
        if (max_descendant_count := query.get('max_descendant_count')) and len(descendants()) > max_descendant_count:
            return False
        if (some_descendant_has := query.get('some_descendant_has')) and not any(
            descendant._matches_query(some_descendant_has) for descendant in pruned_descendants()
        ):
            return False
        if (all_descendants_have := query.get('all_descendants_have')) and not all(
            descendant._matches_query(all_descendants_have) for descendant in pruned_descendants()
        ):
            return False
        if (no_descendant_has := query.get('no_descendant_has')) and any(
            descendant._matches_query(no_descendant_has) for descendant in pruned_descendants()
        ):
            return False

        # Ancestor conditions
        # The following local functions with cache decorators are used to avoid repeatedly evaluating these properties
        @cache
        def ancestors():
            return self.ancestors

        @cache
        def pruned_ancestors():
            stop_recursing_when = query.get('stop_recursing_when')
            return self._filter_ancestors(lambda _: True, stop_recursing_when) if stop_recursing_when else ancestors()

        if (min_depth := query.get('min_depth')) and len(ancestors()) < min_depth:
            return False
        if (max_depth := query.get('max_depth')) and len(ancestors()) > max_depth:
            return False
        if (some_ancestor_has := query.get('some_ancestor_has')) and not any(
            ancestor._matches_query(some_ancestor_has) for ancestor in pruned_ancestors()
        ):
            return False
        if (all_ancestors_have := query.get('all_ancestors_have')) and not all(
            ancestor._matches_query(all_ancestors_have) for ancestor in pruned_ancestors()
        ):
            return False
        if (no_ancestor_has := query.get('no_ancestor_has')) and any(
            ancestor._matches_query(no_ancestor_has) for ancestor in pruned_ancestors()
        ):
            return False

        return True

    def find(self, predicate: SpanQuery | SpanPredicate) -> list[SpanNode]:
        """Find all nodes in the entire tree that match the predicate, scanning from each root in DFS order."""
        return list(self._filter(predicate))

    def first(self, predicate: SpanQuery | SpanPredicate) -> SpanNode | None:
        """Find the first node that matches a predicate, scanning from each root in DFS order. Returns `None` if not found."""
        return next(self._filter(predicate), None)

    def any(self, predicate: SpanQuery | SpanPredicate) -> bool:
        """Returns True if any node in the tree matches the predicate."""
        return self.first(predicate) is not None

## pydantic_graph/pydantic_graph/beta/decision.py

class Decision(Generic[StateT, DepsT, HandledT]):
    """Decision node for conditional branching in graph execution.

    A Decision node evaluates conditions and routes execution to different
    branches based on the input data type or custom matching logic.
    """

    id: NodeID
    """Unique identifier for this decision node."""

    branches: list[DecisionBranch[Any]]
    """List of branches that can be taken from this decision."""

    note: str | None
    """Optional documentation note for this decision."""

    def branch(self, branch: DecisionBranch[T]) -> Decision[StateT, DepsT, HandledT | T]:
        """Add a new branch to this decision.

        Args:
            branch: The branch to add to this decision.

        Returns:
            A new Decision with the additional branch.
        """
        return Decision(id=self.id, branches=self.branches + [branch], note=self.note)

    def _force_handled_contravariant(self, inputs: HandledT) -> Never:  # pragma: no cover
        """Forces this type to be contravariant in the HandledT type variable.

        This is an implementation detail of how we can type-check that all possible input types have
        been exhaustively covered.

        Args:
            inputs: Input data of handled types.

        Raises:
            RuntimeError: Always, as this method should never be executed.
        """
        raise RuntimeError('This method should never be called, it is just defined for typing purposes.')

    def branch(self, branch: DecisionBranch[T]) -> Decision[StateT, DepsT, HandledT | T]:
        """Add a new branch to this decision.

        Args:
            branch: The branch to add to this decision.

        Returns:
            A new Decision with the additional branch.
        """
        return Decision(id=self.id, branches=self.branches + [branch], note=self.note)

    def _force_handled_contravariant(self, inputs: HandledT) -> Never:  # pragma: no cover
        """Forces this type to be contravariant in the HandledT type variable.

        This is an implementation detail of how we can type-check that all possible input types have
        been exhaustively covered.

        Args:
            inputs: Input data of handled types.

        Raises:
            RuntimeError: Always, as this method should never be executed.
        """
        raise RuntimeError('This method should never be called, it is just defined for typing purposes.')

## pydantic_graph/pydantic_graph/beta/graph_builder.py

    def decision(self, *, note: str | None = None, node_id: str | None = None) -> Decision[StateT, DepsT, Never]:
        """Create a new decision node.

        Args:
            note: Optional note to describe the decision logic
            node_id: Optional ID for the node produced for this decision logic

        Returns:
            A new Decision node with no branches
        """
        return Decision(id=NodeID(node_id or generate_placeholder_node_id('decision')), branches=[], note=note)

    def match(
        self,
        source: TypeOrTypeExpression[SourceT],
        *,
        matches: Callable[[Any], bool] | None = None,
    ) -> DecisionBranchBuilder[StateT, DepsT, SourceT, SourceT, Never]:
        """Create a decision branch matcher.

        Args:
            source: The type or type expression to match against
            matches: Optional custom matching function

        Returns:
            A DecisionBranchBuilder for constructing the branch
        """
        # Note, the following node_id really is just a placeholder and shouldn't end up in the final graph
        # This is why we don't expose a way for end users to override the value used here.
        node_id = NodeID(generate_placeholder_node_id('match_decision'))
        decision = Decision[StateT, DepsT, Never](id=node_id, branches=[], note=None)
        new_path_builder = PathBuilder[StateT, DepsT, SourceT](working_items=[])
        return DecisionBranchBuilder(decision=decision, source=source, matches=matches, path_builder=new_path_builder)

## pydantic_graph/pydantic_graph/beta/mermaid.py

def _topological_sort(
    nodes: list[MermaidNode], edges: list[MermaidEdge]
) -> tuple[list[MermaidNode], list[MermaidEdge]]:
    """Sort nodes and edges in a logical topological order.

    Uses BFS from the start node to assign depths, then sorts:
    - Nodes by their distance from start
    - Edges by the distance of their source and target nodes
    """
    # Build adjacency list for BFS
    adjacency: dict[str, list[str]] = defaultdict(list)
    for edge in edges:
        adjacency[edge.start_id].append(edge.end_id)

    # BFS to assign depth to each node (distance from start)
    depths: dict[str, int] = {}
    queue: list[tuple[str, int]] = [(StartNode.id, 0)]
    depths[StartNode.id] = 0

    while queue:
        node_id, depth = queue.pop(0)
        for next_id in adjacency[node_id]:
            if next_id not in depths:  # pragma: no branch
                depths[next_id] = depth + 1
                queue.append((next_id, depth + 1))

    # Sort nodes by depth (distance from start), then by id for stability
    # Nodes not reachable from start get infinity depth (sorted to end)
    sorted_nodes = sorted(nodes, key=lambda n: (depths.get(n.id, float('inf')), n.id))

    # Sort edges by source depth, then target depth
    # This ensures edges closer to start come first, edges closer to end come last
    sorted_edges = sorted(
        edges,
        key=lambda e: (
            depths.get(e.start_id, float('inf')),
            depths.get(e.end_id, float('inf')),
            e.start_id,
            e.end_id,
        ),
    )

    return sorted_nodes, sorted_edges

## tests/conftest.py

def audio_content(assets_path: Path) -> BinaryContent:
    audio_bytes = assets_path.joinpath('marcelo.mp3').read_bytes()
    return BinaryContent(data=audio_bytes, media_type='audio/mpeg')

def video_content(assets_path: Path) -> BinaryContent:
    video_bytes = assets_path.joinpath('small_video.mp4').read_bytes()
    return BinaryContent(data=video_bytes, media_type='video/mp4')

## tests/evals/test_otel.py

async def test_span_node_find_descendants(span_tree: SpanTree):
    """Test the find_descendants method of SpanNode."""
    root_node = span_tree.roots[0]

    # Find all descendants with level 2
    level2_nodes = list(root_node.find_descendants(lambda node: node.attributes.get('level') == '2'))
    assert len(level2_nodes) == 3

    # Check that they have the expected names
    level2_names = {node.name for node in level2_nodes}
    assert level2_names == {'grandchild1', 'grandchild2', 'grandchild3'}

    # Test descendant counts
    assert root_node.matches({'min_descendant_count': 5, 'max_descendant_count': 5})
    assert not root_node.matches({'min_descendant_count': 4, 'max_descendant_count': 4})
    assert not root_node.matches({'min_descendant_count': 6, 'max_descendant_count': 6})

    child1_node = root_node.first_child(lambda node: node.name == 'child1')
    assert child1_node is not None
    assert child1_node.matches({'min_descendant_count': 2, 'max_descendant_count': 2})

async def test_span_node_matches(span_tree: SpanTree):
    """Test the matches method of SpanNode."""
    root_node = span_tree.roots[0]
    child1_node = root_node.first_child(lambda node: node.name == 'child1')
    assert child1_node is not None

    # Test matches by name
    assert child1_node.matches(SpanQuery(name_equals='child1'))
    assert not child1_node.matches(SpanQuery(name_equals='child2'))

    # Test matches by attributes
    assert child1_node.matches(SpanQuery(has_attributes={'level': '1', 'type': 'important'}))
    assert not child1_node.matches(SpanQuery(has_attributes={'level': '2', 'type': 'important'}))

    # Test matches by both name and attributes
    assert child1_node.matches(SpanQuery(name_equals='child1', has_attributes={'type': 'important'}))
    assert not child1_node.matches(SpanQuery(name_equals='child1', has_attributes={'type': 'normal'}))

async def test_span_tree_ancestors_methods():
    """Test the ancestor traversal methods in SpanNode."""
    # Create spans with a deep structure for testing ancestor methods
    with context_subtree() as tree:
        with logfire.span('root', depth=0):
            with logfire.span('level1', depth=1):
                with logfire.span('level2', depth=2):
                    with logfire.span('level3', depth=3):
                        with logfire.span('leaf', depth=4):
                            # Add a log message to test nested logs
                            logfire.info('This is a leaf node log message')
    assert isinstance(tree, SpanTree)

    # Get the leaf node
    leaf_node = tree.first(lambda node: node.name == 'leaf')
    assert leaf_node is not None

    # Test find_ancestors
    ancestors = list(leaf_node.find_ancestors(lambda node: True))
    assert len(ancestors) == 4
    ancestor_names = [node.name for node in ancestors]
    assert ancestor_names == ['level3', 'level2', 'level1', 'root']

    # Test first_ancestor by name instead of depth comparison to avoid type issues
    level2_ancestor = leaf_node.first_ancestor(lambda node: node.name == 'level2')
    assert level2_ancestor is not None
    assert level2_ancestor.name == 'level2'

    # Test any_ancestor
    assert leaf_node.any_ancestor(lambda node: node.name == 'root')
    assert not leaf_node.any_ancestor(lambda node: node.name == 'non_existent')

    # Test ancestor query matches
    assert leaf_node.matches({'min_depth': 4, 'max_depth': 4})
    assert not leaf_node.matches({'min_depth': 3, 'max_depth': 3})
    assert not leaf_node.matches({'min_depth': 5, 'max_depth': 5})

    assert [node.name for node in leaf_node.ancestors] == ['level3', 'level2', 'level1', 'root']
    assert leaf_node.matches({'some_ancestor_has': {'name_equals': 'level1'}})
    assert not leaf_node.matches({'some_ancestor_has': {'name_equals': 'level4'}})

    assert not leaf_node.matches({'all_ancestors_have': {'name_matches_regex': 'level'}})
    assert leaf_node.matches({'all_ancestors_have': {'name_matches_regex': 'level|root'}})

    assert not leaf_node.matches({'no_ancestor_has': {'name_matches_regex': 'root'}})
    assert leaf_node.matches({'no_ancestor_has': {'name_matches_regex': 'abc'}})

    # Test stop_recursing_when:
    assert not leaf_node.matches(
        {'some_ancestor_has': {'name_equals': 'level1'}, 'stop_recursing_when': {'name_equals': 'level2'}}
    )
    assert leaf_node.matches(
        {'all_ancestors_have': {'name_matches_regex': 'level'}, 'stop_recursing_when': {'name_equals': 'level1'}}
    )
    assert leaf_node.matches(
        {'no_ancestor_has': {'name_matches_regex': 'root'}, 'stop_recursing_when': {'name_equals': 'level1'}}
    )

async def test_span_query_basics(span_tree: SpanTree):
    """Test basic SpanQuery conditions on a span tree."""
    # Test name equality condition
    name_equals_query: SpanQuery = {'name_equals': 'child1'}
    matched_node = span_tree.first(name_equals_query)
    assert matched_node is not None
    assert matched_node.name == 'child1'

    # Test name contains condition
    name_contains_query: SpanQuery = {'name_contains': 'child'}
    matched_nodes = list(span_tree.find(name_contains_query))
    assert len(matched_nodes) == 5  # All nodes with "child" in name
    assert all('child' in node.name for node in matched_nodes)

    # Test name regex match condition
    name_regex_query: SpanQuery = {'name_matches_regex': r'^grand.*\d$'}
    matched_nodes = list(span_tree.find(name_regex_query))
    assert len(matched_nodes) == 3  # All grandchild nodes
    assert all(node.name.startswith('grand') and node.name[-1].isdigit() for node in matched_nodes)

    # Test has_attributes condition
    attr_query: SpanQuery = {'has_attributes': {'level': '1', 'type': 'important'}}
    matched_node = span_tree.first(attr_query)
    assert matched_node is not None
    assert matched_node.name == 'child1'
    assert matched_node.attributes.get('level') == '1'
    assert matched_node.attributes.get('type') == 'important'

    # Test has_attribute_keys condition
    attr_keys_query: SpanQuery = {'has_attribute_keys': ['level', 'type']}
    matched_nodes = list(span_tree.find(attr_keys_query))
    assert len(matched_nodes) == 5  # All nodes except root have both keys
    assert all('level' in node.attributes and 'type' in node.attributes for node in matched_nodes)

async def test_span_query_negation():
    """Test negation in SpanQuery."""

    # Create a simple tree for testing negation
    with context_subtree() as tree:
        with logfire.span('parent', category='main'):
            with logfire.span('child1', category='important'):
                pass
            with logfire.span('child2', category='normal'):
                pass
    assert isinstance(tree, SpanTree)

    # Test negation of name attribute
    not_query: SpanQuery = {'not_': {'name_equals': 'child1'}}
    matched_nodes = list(tree.find(not_query))
    assert len(matched_nodes) == 2
    assert all(node.name != 'child1' for node in matched_nodes)

    # Test negation of attribute condition
    not_attr_query: SpanQuery = {'not_': {'has_attributes': {'category': 'important'}}}
    matched_nodes = list(tree.find(not_attr_query))
    assert len(matched_nodes) == 2
    assert all(node.attributes.get('category') != 'important' for node in matched_nodes)

    # Test direct negation using the matches function
    parent_node = tree.first(lambda node: node.name == 'parent')
    assert parent_node is not None

    assert parent_node.matches({'name_equals': 'parent'})
    assert not parent_node.matches({'not_': {'name_equals': 'parent'}})

async def test_span_query_logical_combinations():
    """Test logical combinations (AND/OR) in SpanQuery."""

    with context_subtree() as tree:
        with logfire.span('root1', level='0'):
            with logfire.span('child1', level='1', category='important'):
                pass
            with logfire.span('child2', level='1', category='normal'):
                pass
            with logfire.span('special', level='1', category='important', priority='high'):
                pass
    assert isinstance(tree, SpanTree)

    # Test AND logic
    and_query: SpanQuery = {'and_': [{'name_contains': '1'}, {'has_attributes': {'level': '1'}}]}
    matched_nodes = list(tree.find(and_query))
    assert len(matched_nodes) == 1, matched_nodes
    assert all(node.name in ['child1'] for node in matched_nodes)

    # Test OR logic
    or_query: SpanQuery = {'or_': [{'name_contains': '2'}, {'has_attributes': {'level': '0'}}]}
    matched_nodes = list(tree.find(or_query))
    assert len(matched_nodes) == 2
    assert any(node.name == 'child2' for node in matched_nodes)
    assert any(node.attributes.get('level') == '0' for node in matched_nodes)

    # Test complex combination (AND + OR)
    complex_query: SpanQuery = {
        'and_': [
            {'has_attributes': {'level': '1'}},
            {'or_': [{'has_attributes': {'category': 'important'}}, {'name_equals': 'child2'}]},
        ]
    }
    matched_nodes = list(tree.find(complex_query))
    assert len(matched_nodes) == 3  # child1, child2, special
    matched_names = [node.name for node in matched_nodes]
    assert set(matched_names) == {'child1', 'child2', 'special'}

async def test_span_query_timing_conditions():
    """Test timing-related conditions in SpanQuery."""
    from datetime import timedelta

    with context_subtree() as tree:
        with logfire.span('fast_operation'):
            pass

        with logfire.span('medium_operation'):
            logfire.info('add a wait')

        with logfire.span('slow_operation'):
            logfire.info('add a wait')
            logfire.info('add a wait')
    assert isinstance(tree, SpanTree)

    durations = sorted([node.duration for node in tree if node.duration > timedelta(seconds=0)])
    fast_threshold = (durations[0] + durations[1]) / 2
    medium_threshold = (durations[1] + durations[2]) / 2

    # Test min_duration
    min_duration_query: SpanQuery = {'min_duration': fast_threshold}
    matched_nodes = list(tree.find(min_duration_query))
    assert len(matched_nodes) == 2
    assert 'fast_operation' not in [node.name for node in matched_nodes]

    # Test max_duration
    max_duration_queries: list[SpanQuery] = [
        {'min_duration': 0.001, 'max_duration': medium_threshold},
        {'min_duration': 0.001, 'max_duration': medium_threshold.seconds},
    ]
    for max_duration_query in max_duration_queries:
        matched_nodes = list(tree.find(max_duration_query))
        assert len(matched_nodes) == 2
        assert 'slow_operation' not in [node.name for node in matched_nodes]

    # Test min and max duration together using timedelta
    duration_range_query: SpanQuery = {
        'min_duration': fast_threshold,
        'max_duration': medium_threshold,
    }
    matched_node = tree.first(duration_range_query)
    assert matched_node is not None
    assert matched_node.name == 'medium_operation'

async def test_span_query_descendant_conditions():
    """Test descendant-related conditions in SpanQuery."""

    with context_subtree() as tree:
        with logfire.span('parent1'):
            with logfire.span('child1', type='important'):
                pass
            with logfire.span('child2', type='normal'):
                pass

        with logfire.span('parent2'):
            with logfire.span('child3', type='normal'):
                pass
            with logfire.span('child4', type='normal'):
                pass
    assert isinstance(tree, SpanTree)

    # Test some_child_has condition
    some_child_query: SpanQuery = {'some_child_has': {'has_attributes': {'type': 'important'}}}
    matched_node = tree.first(some_child_query)
    assert matched_node is not None
    assert matched_node.name == 'parent1'

    # Test all_children_have condition
    all_children_query: SpanQuery = {'all_children_have': {'has_attributes': {'type': 'normal'}}, 'min_child_count': 1}
    matched_node = tree.first(all_children_query)
    assert matched_node is not None
    assert matched_node.name == 'parent2'
    # A couple more tests for coverage reasons:
    assert tree.first({'all_children_have': {'has_attributes': {'type': 'unusual'}}, 'min_child_count': 1}) is None
    assert not matched_node.matches({'no_child_has': {'has_attributes': {'type': 'normal'}}})

    # Test no_child_has condition
    no_child_query: SpanQuery = {'no_child_has': {'has_attributes': {'type': 'important'}}, 'min_child_count': 1}
    matched_node = tree.first(no_child_query)
    assert matched_node is not None
    assert matched_node.name == 'parent2'

async def test_matches_function_directly():
    """Test the matches function directly with various SpanQuery combinations."""

    # Create a test span tree
    with context_subtree() as tree:
        with logfire.span('parent', level='1', category='main'):
            with logfire.span('child1', level='2', category='important'):
                pass
            with logfire.span('child2', level='2', category='normal'):
                pass
    assert isinstance(tree, SpanTree)

    parent_node = tree.roots[0]
    child1_node = parent_node.children[0]
    child2_node = parent_node.children[1]

    # Basic matches tests
    assert parent_node.matches({'name_equals': 'parent'})
    assert not child1_node.matches({'name_equals': 'parent'})

    # Test attribute matching
    assert parent_node.matches({'has_attributes': {'level': '1'}})
    assert not child1_node.matches({'has_attributes': {'level': '1'}})

    # Test logical combinations
    complex_query: SpanQuery = {'and_': [{'name_equals': 'child1'}, {'has_attributes': {'category': 'important'}}]}
    assert child1_node.matches(complex_query)
    assert not child2_node.matches(complex_query)

    # Test with descendants
    descendant_query: SpanQuery = {'some_child_has': {'name_equals': 'child1'}}
    assert parent_node.matches(descendant_query)
    assert not child1_node.matches(descendant_query)

async def test_span_query_child_count():
    """Test min_child_count and max_child_count conditions in SpanQuery."""

    # Create a tree with varying numbers of children
    with context_subtree() as tree:
        with logfire.span('parent_no_children'):
            pass

        with logfire.span('parent_one_child'):
            with logfire.span('child1'):
                pass

        with logfire.span('parent_two_children'):
            with logfire.span('child2'):
                pass
            with logfire.span('child3'):
                pass

        with logfire.span('parent_three_children'):
            with logfire.span('child4'):
                pass
            with logfire.span('child5'):
                pass
            with logfire.span('child6'):
                pass
    assert isinstance(tree, SpanTree)

    # Test min_child_count
    min_2_query: SpanQuery = {'min_child_count': 2}
    matched_nodes = list(tree.find(min_2_query))
    assert len(matched_nodes) == 2
    matched_names = {node.name for node in matched_nodes}
    assert matched_names == {'parent_two_children', 'parent_three_children'}

    # Test max_child_count
    max_1_query: SpanQuery = {'max_child_count': 1}
    matched_nodes = list(tree.find(max_1_query))
    assert len(matched_nodes) == 8  # parent_no_children, parent_one_child, and all the leaf nodes
    assert 'parent_two_children' not in {node.name for node in matched_nodes}
    assert 'parent_three_children' not in {node.name for node in matched_nodes}

    # Test both min and max together (range)
    child_range_query: SpanQuery = {'min_child_count': 1, 'max_child_count': 2}
    matched_nodes = list(tree.find(child_range_query))
    assert len(matched_nodes) == 2
    matched_names = {node.name for node in matched_nodes}
    assert matched_names == {'parent_one_child', 'parent_two_children'}

    # Test with other conditions
    complex_query: SpanQuery = {'name_contains': 'parent', 'min_child_count': 2}
    matched_nodes = list(tree.find(complex_query))
    assert len(matched_nodes) == 2
    assert all('parent' in node.name and len(node.children) >= 2 for node in matched_nodes)

    # Test direct usage of matches function
    parent_three = tree.first(lambda node: node.name == 'parent_three_children')
    assert parent_three is not None

    assert parent_three.matches({'min_child_count': 3})
    assert parent_three.matches({'min_child_count': 2, 'max_child_count': 3})
    assert not parent_three.matches({'max_child_count': 2})

    # Test with logical operators
    logical_query: SpanQuery = {
        'and_': [{'name_contains': 'parent'}, {'min_child_count': 1}],
        'not_': {'max_child_count': 1},
    }
    matched_nodes = list(tree.find(logical_query))
    assert len(matched_nodes) == 2
    matched_names = {node.name for node in matched_nodes}
    assert matched_names == {'parent_two_children', 'parent_three_children'}

## tests/graph/beta/test_node_and_step.py

def test_is_destination_type_guard():
    """Test is_destination type guard function."""
    # Test with EndNode
    end = EndNode[int]()
    assert is_destination(end)

    # Test with Step
    async def my_step(ctx: StepContext[Any, Any, Any]):
        return 42  # pragma: no cover

    step = Step[None, None, None, int](id=NodeID('test'), call=my_step)
    assert is_destination(step)

    # Test with Decision
    decision = Decision[None, None, int](id=NodeID('test_decision'), branches=[], note=None)
    assert is_destination(decision)

    # Test with StartNode (should be False)
    start = StartNode[int]()
    assert not is_destination(start)

## tests/graph/beta/test_v1_v2_integration.py

async def test_v1_node_conditional_return():
    """Test v1 nodes with conditional returns creating implicit decisions."""

    @dataclass
    class RouterNode(BaseNode[IntegrationState, None, str]):
        value: int

        async def run(self, ctx: GraphRunContext[IntegrationState, None]) -> PathA | PathB:
            if self.value < 10:
                return PathA()
            else:
                return PathB()

    @dataclass
    class PathA(BaseNode[IntegrationState, None, str]):
        async def run(self, ctx: GraphRunContext[IntegrationState, None]) -> End[str]:
            return End('Path A')

    @dataclass
    class PathB(BaseNode[IntegrationState, None, str]):
        async def run(self, ctx: GraphRunContext[IntegrationState, None]) -> End[str]:
            return End('Path B')

    g = GraphBuilder(state_type=IntegrationState, input_type=int, output_type=str)

    @g.step
    async def create_router(ctx: StepContext[IntegrationState, None, int]) -> RouterNode:
        return RouterNode(ctx.inputs)

    g.add(
        g.node(RouterNode),
        g.node(PathA),
        g.node(PathB),
        g.edge_from(g.start_node).to(create_router),
    )

    graph = g.build()

    assert str(graph) == snapshot("""\
stateDiagram-v2
  create_router
  RouterNode
  state decision <<choice>>
  PathA
  PathB

  [*] --> create_router
  create_router --> RouterNode
  RouterNode --> decision
  decision --> PathA
  decision --> PathB
  PathA --> [*]
  PathB --> [*]\
""")

    # Test path A
    result_a = await graph.run(state=IntegrationState(), inputs=5)
    assert result_a == 'Path A'

    # Test path B
    result_b = await graph.run(state=IntegrationState(), inputs=15)
    assert result_b == 'Path B'

## tests/test_prefect.py

def conditions(city: str) -> str:
    # Simplified version without RunContext
    return "It's raining"
