# pydantic_ai_slim/pydantic_ai/_ssrf.py:67-67
    is_https: bool

# tests/test_ssrf.py:235-240
    def test_http_default_port(self) -> None:
        resolved = ResolvedUrl(
            resolved_ip='203.0.113.50', hostname='example.com', port=80, is_https=False, path='/path'
        )
        url = build_url_with_ip(resolved)
        assert url == 'http://203.0.113.50/path'

# tests/test_ssrf.py:242-247
    def test_https_default_port(self) -> None:
        resolved = ResolvedUrl(
            resolved_ip='203.0.113.50', hostname='example.com', port=443, is_https=True, path='/path'
        )
        url = build_url_with_ip(resolved)
        assert url == 'https://203.0.113.50/path'

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/__init__.py:113-113
from .settings import ModelSettings

# pydantic_ai_slim/pydantic_ai/models/gemini.py:77-98
class GeminiModelSettings(ModelSettings, total=False):
    """Settings used for a Gemini model request."""

    # ALL FIELDS MUST BE `gemini_` PREFIXED SO YOU CAN MERGE THEM WITH OTHER MODELS.

    gemini_safety_settings: list[GeminiSafetySettings]
    """Safety settings options for Gemini model request."""

    gemini_thinking_config: ThinkingConfig
    """Thinking is "on" by default in both the API and AI Studio.

    Being on by default doesn't mean the model will send back thoughts. For that, you would need to set `include_thoughts`
    to `True`. If you want to avoid the model spending any tokens on thinking, you can set `thinking_budget` to `0`.

    See more about it on <https://ai.google.dev/gemini-api/docs/thinking>.
    """

    gemini_labels: dict[str, str]
    """User-defined metadata to break down billed charges. Only supported by the Vertex AI provider.

    See the [Gemini API docs](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/add-labels-to-api-calls) for use cases and limitations.
    """

# pydantic_ai_slim/pydantic_ai/models/gemini.py:77-98
class GeminiModelSettings(ModelSettings, total=False):
    """Settings used for a Gemini model request."""

    # ALL FIELDS MUST BE `gemini_` PREFIXED SO YOU CAN MERGE THEM WITH OTHER MODELS.

    gemini_safety_settings: list[GeminiSafetySettings]
    """Safety settings options for Gemini model request."""

    gemini_thinking_config: ThinkingConfig
    """Thinking is "on" by default in both the API and AI Studio.

    Being on by default doesn't mean the model will send back thoughts. For that, you would need to set `include_thoughts`
    to `True`. If you want to avoid the model spending any tokens on thinking, you can set `thinking_budget` to `0`.

    See more about it on <https://ai.google.dev/gemini-api/docs/thinking>.
    """

    gemini_labels: dict[str, str]
    """User-defined metadata to break down billed charges. Only supported by the Vertex AI provider.

    See the [Gemini API docs](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/add-labels-to-api-calls) for use cases and limitations.
    """

# tests/test_dbos.py:1492-1493
class CustomModelSettings(ModelSettings, total=False):
    custom_setting: str

# tests/test_dbos.py:1492-1493
class CustomModelSettings(ModelSettings, total=False):
    custom_setting: str

# tests/test_dbos.py:1492-1493
class CustomModelSettings(ModelSettings, total=False):
    custom_setting: str

# pydantic_ai_slim/pydantic_ai/models/openai.py:372-373
class OpenAIModelSettings(OpenAIChatModelSettings, total=False):
    """Deprecated alias for `OpenAIChatModelSettings`."""

# pydantic_ai_slim/pydantic_ai/_ssrf.py:58-58
    resolved_ip: str

# pydantic_ai_slim/pydantic_ai/settings.py:96-96
    seed: int

# pydantic_ai_slim/pydantic_ai/models/groq.py:107-116
class GroqModelSettings(ModelSettings, total=False):
    """Settings used for a Groq model request."""

    # ALL FIELDS MUST BE `groq_` PREFIXED SO YOU CAN MERGE THEM WITH OTHER MODELS.

    groq_reasoning_format: Literal['hidden', 'raw', 'parsed']
    """The format of the reasoning output.

    See [the Groq docs](https://console.groq.com/docs/reasoning#reasoning-format) for more details.
    """

# pydantic_ai_slim/pydantic_ai/settings.py:52-52
    top_p: float

# pydantic_ai_slim/pydantic_ai/models/cohere.py:89-90
class CohereModelSettings(ModelSettings, total=False):
    """Settings used for a Cohere model request."""

# pydantic_ai_slim/pydantic_ai/models/gemini.py:77-98
class GeminiModelSettings(ModelSettings, total=False):
    """Settings used for a Gemini model request."""

    # ALL FIELDS MUST BE `gemini_` PREFIXED SO YOU CAN MERGE THEM WITH OTHER MODELS.

    gemini_safety_settings: list[GeminiSafetySettings]
    """Safety settings options for Gemini model request."""

    gemini_thinking_config: ThinkingConfig
    """Thinking is "on" by default in both the API and AI Studio.

    Being on by default doesn't mean the model will send back thoughts. For that, you would need to set `include_thoughts`
    to `True`. If you want to avoid the model spending any tokens on thinking, you can set `thinking_budget` to `0`.

    See more about it on <https://ai.google.dev/gemini-api/docs/thinking>.
    """

    gemini_labels: dict[str, str]
    """User-defined metadata to break down billed charges. Only supported by the Vertex AI provider.

    See the [Gemini API docs](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/add-labels-to-api-calls) for use cases and limitations.
    """

# pydantic_ai_slim/pydantic_ai/settings.py:72-72
    timeout: float | Timeout

# pydantic_ai_slim/pydantic_ai/models/mistral.py:114-115
class MistralModelSettings(ModelSettings, total=False):
    """Settings used for a Mistral model request."""

# pydantic_ai_slim/pydantic_ai/models/xai.py:102-102
    xai_user: str

# pydantic_ai_slim/pydantic_ai/settings.py:14-14
    max_tokens: int

# pydantic_ai_slim/pydantic_ai/settings.py:137-137
    logit_bias: dict[str, int]