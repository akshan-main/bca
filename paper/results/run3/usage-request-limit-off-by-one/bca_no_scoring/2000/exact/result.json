{
  "task_id": "usage-request-limit-off-by-one",
  "method": "bca_no_scoring",
  "budget": 2000,
  "query_type": "exact",
  "tokens_used": 1900,
  "symbols_selected": 24,
  "files_included": 9,
  "assembly_time_ms": 506.8,
  "llm_time_ms": 3735.8,
  "llm_input_tokens": 1962,
  "llm_output_tokens": 174,
  "tests_passed": true,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: pydantic_ai_slim/pydantic_ai/usage.py\nSEARCH:\n        if request_limit is not None and usage.requests > request_limit:\nREPLACE:\n        if request_limit is not None and usage.requests >= request_limit:\n\nFILE: pydantic_ai_slim/pydantic_ai/usage.py\nSEARCH:\n        if self.input_tokens_limit is not None and input_tokens > self.input_tokens_limit:\nREPLACE:\n        if self.input_tokens_limit is not None and input_tokens >= self.input_tokens_limit:\n\nFILE: pydantic_ai_slim/pydantic_ai/usage.py\nSEARCH:\n        if self.total_tokens_limit is not None and total_tokens > self.total_tokens_limit:\nREPLACE:\n        if self.total_tokens_limit is not None and total_tokens >= self.total_tokens_limit:\n",
  "error": "",
  "test_time_ms": 1265.9,
  "failure_mode": "pass",
  "target_file_hit": true,
  "target_symbol_hit": true,
  "context_patch_overlap": 0.111,
  "patch_files_changed": 1,
  "patch_lines_changed": 3,
  "edit_distance_lines": 0,
  "entity_count_extracted": 3,
  "entity_count_mapped": 14,
  "query_identifier_density": 0.0556,
  "seed_symbol_keys": [
    "pydantic_ai_slim/pydantic_ai/__init__.py::UsageLimits",
    "examples/pydantic_ai_examples/flight_booking.py::UsageLimits",
    "pydantic_ai_slim/pydantic_ai/ui/ag_ui/app.py::UsageLimits",
    "pydantic_ai_slim/pydantic_ai/result.py::UsageLimits",
    "tests/test_usage_limits.py::UsageLimits",
    "pydantic_ai_slim/pydantic_ai/ag_ui.py::UsageLimits",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::UsageLimits",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits",
    "pydantic_ai_slim/pydantic_ai/ui/_adapter.py::UsageLimits",
    "tests/test_cli.py::UsageLimits",
    "tests/models/test_anthropic.py::UsageLimits",
    "tests/models/test_bedrock.py::UsageLimits",
    "tests/models/test_google.py::UsageLimits",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.check_before_request"
  ],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.check_before_request",
  "min_hops_seed_to_mutation": 0,
  "median_hops_seed_to_mutation": 5.0,
  "bca_closure_added_symbols": 0,
  "bca_closure_added_tokens": 0,
  "bca_frontier_visited": 2916,
  "context_symbol_keys": [
    "examples/pydantic_ai_examples/chat_app.py::agent",
    "examples/pydantic_ai_examples/chat_app.py::THIS_DIR",
    "examples/pydantic_ai_examples/chat_app.py::index",
    "pydantic_ai_slim/pydantic_ai/concurrency.py::AbstractConcurrencyLimiter",
    "pydantic_ai_slim/pydantic_ai/concurrency.py::ConcurrencyLimit",
    "pydantic_ai_slim/pydantic_ai/concurrency.py::ConcurrencyLimiter",
    "pydantic_ai_slim/pydantic_ai/concurrency.py::ConcurrencyLimiter.__init__",
    "pydantic_ai_slim/pydantic_ai/concurrency.py::ConcurrencyLimiter.from_limit",
    "pydantic_ai_slim/pydantic_ai/concurrency.py::AnyConcurrencyLimit",
    "pydantic_ai_slim/pydantic_ai/concurrency.py::get_concurrency_context",
    "pydantic_ai_slim/pydantic_ai/concurrency.py::normalize_to_limiter",
    "pydantic_ai_slim/pydantic_ai/messages.py::FileUrl.__init__",
    "pydantic_ai_slim/pydantic_ai/messages.py::VideoUrl.__init__",
    "pydantic_ai_slim/pydantic_ai/messages.py::AudioUrl.__init__",
    "pydantic_ai_slim/pydantic_ai/messages.py::ImageUrl.__init__",
    "pydantic_ai_slim/pydantic_ai/messages.py::DocumentUrl.__init__",
    "pydantic_ai_slim/pydantic_ai/messages.py::BinaryContent.__init__",
    "pydantic_ai_slim/pydantic_ai/messages.py::BinaryImage.__init__",
    "pydantic_ai_slim/pydantic_ai/messages.py::ModelRequest",
    "pydantic_ai_slim/pydantic_ai/messages.py::ModelResponse",
    "pydantic_ai_slim/pydantic_ai/messages.py::ModelMessage",
    "pydantic_ai_slim/pydantic_ai/messages.py::PartStartEvent.index",
    "pydantic_ai_slim/pydantic_ai/messages.py::PartDeltaEvent.index",
    "pydantic_ai_slim/pydantic_ai/messages.py::PartEndEvent.index",
    "pydantic_ai_slim/pydantic_ai/messages.py::ModelResponseStreamEvent",
    "pydantic_ai_slim/pydantic_ai/models/concurrency.py::ConcurrencyLimitedModel.__init__",
    "pydantic_ai_slim/pydantic_ai/models/concurrency.py::ConcurrencyLimitedModel.request",
    "pydantic_ai_slim/pydantic_ai/models/concurrency.py::ConcurrencyLimitedModel.request_stream",
    "pydantic_ai_slim/pydantic_ai/result.py::AgentStream.response",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.__init__",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.response",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.__init__",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.response",
    "pydantic_ai_slim/pydantic_ai/result.py::_get_usage_checking_stream_response",
    "pydantic_ai_slim/pydantic_ai/retries.py::TenacityTransport.__init__",
    "pydantic_ai_slim/pydantic_ai/retries.py::AsyncTenacityTransport.__init__",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.request_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.response_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::Usage",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.request_tokens_limit",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.response_tokens_limit",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.__init__",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.check_before_request",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.check_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.check_before_tool_call",
    "tests/models/test_google.py::google_provider",
    "tests/models/test_google.py::test_google_model",
    "tests/models/test_google.py::test_google_model_usage_limit_exceeded",
    "tests/test_usage_limits.py::test_request_token_limit",
    "tests/test_usage_limits.py::test_retry_limit"
  ],
  "mutation_symbol_lines": 17,
  "mutation_symbol_kind": "method",
  "mutation_file_symbols": 65,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.02,
  "retrieval_softmax_entropy": 4.3077,
  "retrieval_softmax_tau": 0.5,
  "retrieval_effective_candidates": 19.8,
  "retrieval_top5_ratio": 0.8661,
  "retrieval_within95_count": 2,
  "retrieval_scored_symbols": 24,
  "retrieval_top1_score": 0.72,
  "retrieval_top5_mean_score": 0.6236,
  "retrieval_budget_utilization": 0.95,
  "retrieval_file_concentration": 0.0,
  "repo_name": "pydantic-ai",
  "category": "usage",
  "mutation_type": "handcrafted",
  "source": "handcrafted"
}