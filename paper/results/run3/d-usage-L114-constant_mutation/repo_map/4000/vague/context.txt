# Repository structure
.github/set_docs_main_preview_url.py
.github/set_docs_pr_preview_url.py
clai/clai/__init__.py
clai/clai/__main__.py
clai/update_readme.py
docs/.hooks/algolia.py
docs/.hooks/main.py
docs/.hooks/snippets.py
docs/.hooks/test_snippets.py
examples/pydantic_ai_examples/__main__.py
examples/pydantic_ai_examples/ag_ui/__init__.py
examples/pydantic_ai_examples/ag_ui/api/__init__.py
examples/pydantic_ai_examples/ag_ui/api/agentic_chat.py
examples/pydantic_ai_examples/ag_ui/api/agentic_generative_ui.py
examples/pydantic_ai_examples/ag_ui/api/human_in_the_loop.py
examples/pydantic_ai_examples/ag_ui/api/predictive_state_updates.py
examples/pydantic_ai_examples/ag_ui/api/shared_state.py
examples/pydantic_ai_examples/ag_ui/api/tool_based_generative_ui.py
examples/pydantic_ai_examples/bank_support.py
examples/pydantic_ai_examples/chat_app.py
examples/pydantic_ai_examples/data_analyst.py
examples/pydantic_ai_examples/evals/__init__.py
examples/pydantic_ai_examples/evals/agent.py
examples/pydantic_ai_examples/evals/custom_evaluators.py
examples/pydantic_ai_examples/evals/example_01_generate_dataset.py
examples/pydantic_ai_examples/evals/example_02_add_custom_evaluators.py
examples/pydantic_ai_examples/evals/example_03_unit_testing.py
examples/pydantic_ai_examples/evals/example_04_compare_models.py
examples/pydantic_ai_examples/evals/models.py
examples/pydantic_ai_examples/flight_booking.py
examples/pydantic_ai_examples/pydantic_model.py
examples/pydantic_ai_examples/question_graph.py
examples/pydantic_ai_examples/rag.py
examples/pydantic_ai_examples/roulette_wheel.py
examples/pydantic_ai_examples/slack_lead_qualifier/agent.py
examples/pydantic_ai_examples/slack_lead_qualifier/app.py
examples/pydantic_ai_examples/slack_lead_qualifier/functions.py
examples/pydantic_ai_examples/slack_lead_qualifier/modal.py
examples/pydantic_ai_examples/slack_lead_qualifier/models.py
examples/pydantic_ai_examples/slack_lead_qualifier/slack.py
examples/pydantic_ai_examples/slack_lead_qualifier/store.py
examples/pydantic_ai_examples/sql_gen.py
examples/pydantic_ai_examples/stream_markdown.py
examples/pydantic_ai_examples/stream_whales.py
examples/pydantic_ai_examples/weather_agent.py
examples/pydantic_ai_examples/weather_agent_gradio.py
pydantic_ai_slim/pydantic_ai/__init__.py
pydantic_ai_slim/pydantic_ai/__main__.py
pydantic_ai_slim/pydantic_ai/_a2a.py
pydantic_ai_slim/pydantic_ai/_agent_graph.py
pydantic_ai_slim/pydantic_ai/_cli/__init__.py
pydantic_ai_slim/pydantic_ai/_cli/web.py
pydantic_ai_slim/pydantic_ai/_function_schema.py
pydantic_ai_slim/pydantic_ai/_griffe.py
pydantic_ai_slim/pydantic_ai/_instrumentation.py
pydantic_ai_slim/pydantic_ai/_json_schema.py
pydantic_ai_slim/pydantic_ai/_mcp.py
pydantic_ai_slim/pydantic_ai/_otel_messages.py
pydantic_ai_slim/pydantic_ai/_output.py
pydantic_ai_slim/pydantic_ai/_parts_manager.py
pydantic_ai_slim/pydantic_ai/_run_context.py
pydantic_ai_slim/pydantic_ai/_ssrf.py
pydantic_ai_slim/pydantic_ai/_system_prompt.py
pydantic_ai_slim/pydantic_ai/_thinking_part.py
pydantic_ai_slim/pydantic_ai/_tool_manager.py
pydantic_ai_slim/pydantic_ai/_utils.py
pydantic_ai_slim/pydantic_ai/ag_ui.py
pydantic_ai_slim/pydantic_ai/agent/__init__.py
pydantic_ai_slim/pydantic_ai/agent/abstract.py
pydantic_ai_slim/pydantic_ai/agent/wrapper.py
pydantic_ai_slim/pydantic_ai/builtin_tools.py
pydantic_ai_slim/pydantic_ai/common_tools/duckduckgo.py
pydantic_ai_slim/pydantic_ai/common_tools/exa.py
pydantic_ai_slim/pydantic_ai/common_tools/tavily.py
pydantic_ai_slim/pydantic_ai/concurrency.py
pydantic_ai_slim/pydantic_ai/direct.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/__init__.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_agent.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_fastmcp_toolset.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_mcp.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_mcp_server.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py
pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_util


# Relevant source code


# pydantic_ai_slim/pydantic_ai/agent/__init__.py:236-418
    def __init__(
        self,
        model: models.Model | models.KnownModelName | str | None = None,
        *,
        output_type: OutputSpec[OutputDataT] = str,
        instructions: Instructions[AgentDepsT] = None,
        system_prompt: str | Sequence[str] = (),
        deps_type: type[AgentDepsT] = NoneType,
        name: str | None = None,
        model_settings: ModelSettings | None = None,
        retries: int = 1,
        validation_context: Any | Callable[[RunContext[AgentDepsT]], Any] = None,
        output_retries: int | None = None,
        tools: Sequence[Tool[AgentDepsT] | ToolFuncEither[AgentDepsT, ...]] = (),
        builtin_tools: Sequence[AbstractBuiltinTool | BuiltinToolFunc[AgentDepsT]] = (),
        prepare_tools: ToolsPrepareFunc[AgentDepsT] | None = None,
        prepare_output_tools: ToolsPrepareFunc[AgentDepsT] | None = None,
        toolsets: Sequence[AbstractToolset[AgentDepsT] | ToolsetFunc[AgentDepsT]] | None = None,
        defer_model_check: bool = False,
        end_strategy: EndStrategy = 'early',
        instrument: InstrumentationSettings | bool | None = None,
        metadata: AgentMetadata[AgentDepsT] | None = None,
        history_processors: Sequence[HistoryProcessor[AgentDepsT]] | None = None,
        event_stream_handler: EventStreamHandler[AgentDepsT] | None = None,
        tool_timeout: float | None = None,
        max_concurrency: _concurrency.AnyConcurrencyLimit = None,
        **_deprecated_kwargs: Any,
    ):
        """Create an agent.

        Args:
            model: The default model to use for this agent, if not provided,
                you must provide the model when calling it. We allow `str` here since the actual list of allowed models changes frequently.
            output_type: The type of the output data, used to validate the data returned by the model,
                defaults to `str`.
            instructions: Instructions to use for this agent, you can also register instructions via a function with
                [`instructions`][pydantic_ai.agent.Agent.instructions] or pass additional, temporary, instructions when executing a run.
            system_prompt: Static system prompts to use for this agent, you can also register system
                prompts via a function with [`system_prompt`][pydantic_ai.agent.Agent.system_prompt].
            deps_type: The type used for dependency injection, this parameter exists solely to allow you to fully
                parameterize the agent, and therefore get the best out of static type checking.
                If you're not using deps, but want type checking to pass, you can set `deps=None` to satisfy Pyright
                or add a type hint `: Agent[None, <return type>]`.
            name: The name of the agent, used for logging. If `None`, we try to infer the agent name from the call frame
                when the agent is first run.
            model_settings: Optional model request settings to use for this agent's runs, by default.
            retries: The default number of retries to allow for tool calls and output validation, before raising an error.
                For model request retries, see the [HTTP Request Retries](../retries.md) documentation.
            validation_context: Pydantic [validation context](https://docs.pydantic.dev/latest/concepts/validators/#validation-context) used to validate tool arguments and outputs.
            output_retries: The maximum number of retries to allow for output validation, defaults to `retries`.
            tools: Tools to register with the agent, you can also register tools via the decorators
                [`@agent.tool`][pydantic_ai.agent.Agent.tool] and [`@agent.tool_plain`][pydantic_ai.agent.Agent.tool_plain].
            builtin_tools: The builtin tools that the agent will use. This depends on the model, as some models may not
                support certain tools. If the model doesn't support the builtin tools, an error will be raised.
            prepare_tools: Custom function to prepare the tool definition of all tools for each step, except output tools.
                This is useful if you want to customize the definition of multiple tools or you want to register
                a subset of tools for a given step. See [`ToolsPrepareFunc`][pydantic_ai.tools.ToolsPrepareFunc]
            prepare_output_tools: Custom function to prepare the tool definition of all output tools for each step.
                This is useful if you want to customize the definition of multiple output tools or you want to register
                a subset of output tools for a given step. See [`ToolsPrepareFunc`][pydantic_ai.tools.ToolsPrepareFunc]
            toolsets: Toolsets to register with the agent, including MCP servers and functions which take a run context
                and return a toolset. See [`ToolsetFunc`][pydantic_ai.toolsets.ToolsetFunc] for more information.
            defer_model_check: by default, if you provide a [named][pydantic_ai.models.KnownModelName] model,
                it's evaluated to create a [`Model`][pydantic_ai.models.Model] instance immediately,
                which checks for the necessary environment variables. Set this to `false`
                to defer the evaluation until the first run. Useful if you want to
                [override the model][pydantic_ai.agent.Agent.override] for testing.
            end_strategy: Strategy for handling tool calls that are requested alongside a final result.
                See [`EndStrategy`][pydantic_ai.agent.EndStrategy] for more information.
            instrument: Set to True to automatically instrument with OpenTelemetry,
                which will use Logfire if it's configured.
                Set to an instance of [`InstrumentationSettings`][pydantic_ai.agent.InstrumentationSettings] to customize.
                If this isn't set, then the last value set by
                [`Agent.instrument_all()`][pydantic_ai.agent.Agent.instrument_all]
                will be used, which defaults to False.
                See the [Debugging and Monitoring guide](https://ai.pydantic.dev/logfire/) for more info.
            metadata: Optional metadata to store with each run.
                Provide a dictionary of primitives, or a callable returning one
                computed from the [`RunContext`][pydantic_ai.tools.RunContext] on each run.
                Metadata is resolved when a run starts and recomputed after a successful run finishes so it
                can reflect the final state.
                Resolved metadata can be read after the run completes via
                [`AgentRun.metadata`][pydantic_ai.agent.AgentRun],
                [`AgentRunResult.metadata`][pydantic_ai.agent.AgentRunResult], and
                [`StreamedRunResult.metadata`][pydantic_ai.result.StreamedRunResult],
                and is attached to the agent run span when instrumentation is enabled.
            history_processors: Optional list of callables to process the message history before sending it to the model.
                Each processor takes a list of messages and returns a modified list of messages.
                Processors can be sync or async and are applied in sequence.
            event_stream_handler: Optional handler for events from the model's streaming response and the agent's execution of tools.
            tool_timeout: Default timeout in seconds for tool execution. If a tool takes longer than this,
                the tool is considered to have failed and a retry prompt is returned to the model (counting towards the retry limit).
                Individual tools can override this with their own timeout. Defaults to None (no timeout).
            max_concurrency: Optional limit on concurrent agent runs. Can be an integer for simple limiting,
                a [`ConcurrencyLimit`][pydantic_ai.ConcurrencyLimit] for advanced configuration with backpressure,
                a [`ConcurrencyLimiter`][pydantic_ai.ConcurrencyLimiter] for sharing limits across
                multiple agents, or None (default) for no limiting. When the limit is reached, additional calls
                to `run()` or `iter()` will wait until a slot becomes available.
        """
        if model is None or defer_model_check:
            self._model = model
        else:
            self._model = models.infer_model(model)

        self._name = name
        self.end_strategy = end_strategy
        self.model_settings = model_settings

        self._output_type = output_type
        self.instrument = instrument
        self._metadata = metadata
        self._deps_type = deps_type

        if mcp_servers := _deprecated_kwargs.pop('mcp_servers', None):
            if toolsets is not None:  # pragma: no cover
                raise TypeError('`mcp_servers` and `toolsets` cannot be set at the same time.')
            warnings.warn('`mcp_servers` is deprecated, use `toolsets` instead', DeprecationWarning)
            toolsets = mcp_servers

        _utils.validate_empty_kwargs(_deprecated_kwargs)

        self._output_schema = _output.OutputSchema[OutputDataT].build(output_type)
        self._output_validators = []

        self._instructions = self._normalize_instructions(instructions)

        self._system_prompts = (system_prompt,) if isinstance(system_prompt, str) else tuple(system_prompt)
        self._system_prompt_functions = []
        self._system_prompt_dynamic_functions = {}

        self._max_result_retries = output_retries if output_retries is not None else retries
        self._max_tool_retries = retries
        self._tool_timeout = tool_timeout

        self._validation_context = validation_context

        self._builtin_tools = builtin_tools

        self._prepare_tools = prepare_tools
        self._prepare_output_tools = prepare_output_tools

        self._output_toolset = self._output_schema.toolset
        if self._output_toolset:
            self._output_toolset.max_retries = self._max_result_retries

        self._function_toolset = _AgentFunctionToolset(
            tools,
            max_retries=self._max_tool_retries,
            timeout=self._tool_timeout,
            output_schema=self._output_schema,
        )
        self._dynamic_toolsets = [
            DynamicToolset[AgentDepsT](toolset_func=toolset)
            for toolset in toolsets or []
            if not isinstance(toolset, AbstractToolset)
        ]
        self._user_toolsets = [toolset for toolset in toolsets or [] if isinstance(toolset, AbstractToolset)]

        self.history_processors = history_processors or []

        self._event_stream_handler = event_stream_handler

        self._concurrency_limiter = _concurrency.normalize_to_limiter(max_concurrency)

        self._override_name: ContextVar[_utils.Option[str]] = ContextVar('_override_name', default=None)
        self._override_deps: ContextVar[_utils.Option[AgentDepsT]] = ContextVar('_override_deps', default=None)
        self._override_model: ContextVar[_utils.Option[models.Model]] = ContextVar('_override_model', default=None)
        self._override_toolsets: ContextVar[_utils.Option[Sequence[AbstractToolset[AgentDepsT]]]] = ContextVar(
            '_override_toolsets', default=None
        )
        self._override_tools: ContextVar[
            _utils.Option[Sequence[Tool[AgentDepsT] | ToolFuncEither[AgentDepsT, ...]]]
        ] = ContextVar('_override_tools', default=None)
        self._override_instructions: ContextVar[
            _utils.Option[list[str | _system_prompt.SystemPromptFunc[AgentDepsT]]]
        ] = ContextVar('_override_instructions', default=None)
        self._override_metadata: ContextVar[_utils.Option[AgentMetadata[AgentDepsT]]] = ContextVar(
            '_override_metadata', default=None
        )

        self._enter_lock = Lock()
        self._entered_count = 0
        self._exit_stack = None

# pydantic_ai_slim/pydantic_ai/mcp.py:1387-1420
def load_mcp_servers(config_path: str | Path) -> list[MCPServerStdio | MCPServerStreamableHTTP | MCPServerSSE]:
    """Load MCP servers from a configuration file.

    Environment variables can be referenced in the configuration file using:
    - `${VAR_NAME}` syntax - expands to the value of VAR_NAME, raises error if not defined
    - `${VAR_NAME:-default}` syntax - expands to VAR_NAME if set, otherwise uses the default value

    Args:
        config_path: The path to the configuration file.

    Returns:
        A list of MCP servers.

    Raises:
        FileNotFoundError: If the configuration file does not exist.
        ValidationError: If the configuration file does not match the schema.
        ValueError: If an environment variable referenced in the configuration is not defined and no default value is provided.
    """
    config_path = Path(config_path)

    if not config_path.exists():
        raise FileNotFoundError(f'Config file {config_path} not found')

    config_data = pydantic_core.from_json(config_path.read_bytes())
    expanded_config_data = _expand_env_vars(config_data)
    config = MCPServerConfig.model_validate(expanded_config_data)

    servers: list[MCPServerStdio | MCPServerStreamableHTTP | MCPServerSSE] = []
    for name, server in config.mcp_servers.items():
        server.id = name
        server.tool_prefix = name
        servers.append(server)

    return servers

# pydantic_evals/pydantic_evals/reporting/render_numbers.py:62-94
def default_render_number_diff(old: float | int, new: float | int) -> str | None:
    """Return a string representing the difference between old and new values.

    Rules:
      - If the two values are equal, return None.
      - For integers, return the raw difference (with a leading sign), e.g.:
            _default_format_number_diff(3, 4) -> '+1'
      - For floats (or a mix of float and int):
          * Compute the raw delta = new - old and format it with ABS_SIG_FIGS significant figures.
          * If `old` is nonzero, compute a relative change:
              - If |delta|/|old| ≤ 1, render the relative change as a percentage with
                PERC_DECIMALS decimal places, e.g. '+0.7 / +70.0%'.
              - If |delta|/|old| > 1, render a multiplier (new/old). Use one decimal place
                if the absolute multiplier is less than MULTIPLIER_ONE_DECIMAL_THRESHOLD,
                otherwise no decimals.
          * However, if the percentage rounds to 0.0% (e.g. '+0.0%'), return only the absolute diff.
          * Also, if |old| is below BASE_THRESHOLD and |delta| exceeds MULTIPLIER_DROP_FACTOR×|old|,
            drop the relative change indicator.
    """
    if old == new:
        return None

    if isinstance(old, int) and isinstance(new, int):
        diff_int = new - old
        return f'{diff_int:+d}'

    delta = new - old
    abs_diff_str = _render_signed(delta, ABS_SIG_FIGS)
    rel_diff_str = _render_relative(new, old, BASE_THRESHOLD)
    if rel_diff_str is None:
        return abs_diff_str
    else:
        return f'{abs_diff_str} / {rel_diff_str}'

# pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_toolset.py:31-67
def prefectify_toolset(
    toolset: AbstractToolset[AgentDepsT],
    mcp_task_config: TaskConfig,
    tool_task_config: TaskConfig,
    tool_task_config_by_name: dict[str, TaskConfig | None],
) -> AbstractToolset[AgentDepsT]:
    """Wrap a toolset to integrate it with Prefect.

    Args:
        toolset: The toolset to wrap.
        mcp_task_config: The Prefect task config to use for MCP server tasks.
        tool_task_config: The default Prefect task config to use for tool calls.
        tool_task_config_by_name: Per-tool task configuration. Keys are tool names, values are TaskConfig or None.
    """
    if isinstance(toolset, FunctionToolset):
        from ._function_toolset import PrefectFunctionToolset

        return PrefectFunctionToolset(
            wrapped=toolset,
            task_config=tool_task_config,
            tool_task_config=tool_task_config_by_name,
        )

    try:
        from pydantic_ai.mcp import MCPServer

        from ._mcp_server import PrefectMCPServer
    except ImportError:
        pass
    else:
        if isinstance(toolset, MCPServer):
            return PrefectMCPServer(
                wrapped=toolset,
                task_config=mcp_task_config,
            )

    return toolset

# examples/pydantic_ai_examples/evals/agent.py:12-20
class TimeRangeDeps:
    """Dependencies for the time range inference agent.

    While we could just get the current time using datetime.now() directly in the tools or system prompt, passing it
    via deps makes it easier to use a repeatable value during testing. While there are packages like `time-machine`
    that can do this for you, that kind of monkey-patching approach can become unwieldy as things get more complex.
    """

    now: datetime = field(default_factory=lambda: datetime.now().astimezone())

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:448-450
    def name(self, value: str | None) -> None:
        """Set the name of the agent, used for logging."""
        self._name = value

# pydantic_evals/pydantic_evals/reporting/__init__.py:923-923
_DEFAULT_VALUE_CONFIG = RenderValueConfig()