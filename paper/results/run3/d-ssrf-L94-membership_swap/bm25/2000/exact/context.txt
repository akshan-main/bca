# pydantic_ai_slim/pydantic_ai/_ssrf.py:23-37
_PRIVATE_NETWORKS: tuple[ipaddress.IPv4Network | ipaddress.IPv6Network, ...] = (
    # IPv4 private ranges
    ipaddress.IPv4Network('127.0.0.0/8'),  # Loopback
    ipaddress.IPv4Network('10.0.0.0/8'),  # Private
    ipaddress.IPv4Network('172.16.0.0/12'),  # Private
    ipaddress.IPv4Network('192.168.0.0/16'),  # Private
    ipaddress.IPv4Network('169.254.0.0/16'),  # Link-local (includes cloud metadata)
    ipaddress.IPv4Network('0.0.0.0/8'),  # "This" network
    ipaddress.IPv4Network('100.64.0.0/10'),  # CGNAT (RFC 6598), includes Alibaba Cloud metadata
    # IPv6 private ranges
    ipaddress.IPv6Network('::1/128'),  # Loopback
    ipaddress.IPv6Network('fe80::/10'),  # Link-local
    ipaddress.IPv6Network('fc00::/7'),  # Unique local address
    ipaddress.IPv6Network('2002::/16'),  # 6to4 (can embed private IPv4 addresses)
)

# pydantic_ai_slim/pydantic_ai/toolsets/abstract.py:98-103
    async def __aenter__(self) -> Self:
        """Enter the toolset context.

        This is where you can set up network connections in a concrete implementation.
        """
        return self

# pydantic_ai_slim/pydantic_ai/toolsets/abstract.py:105-110
    async def __aexit__(self, *args: Any) -> bool | None:
        """Exit the toolset context.

        This is where you can tear down network connections in a concrete implementation.
        """
        return None

# pydantic_evals/pydantic_evals/otel/span_tree.py:487-489
    def any(self, predicate: SpanQuery | SpanPredicate) -> bool:
        """Returns True if any node in the tree matches the predicate."""
        return self.first(predicate) is not None

# tests/test_agent.py:5882-5916
def test_many_multimodal_tool_response():
    """Test ToolReturn with custom content and tool return."""

    def llm(messages: list[ModelMessage], info: AgentInfo) -> ModelResponse:
        if len(messages) == 1:
            return ModelResponse(parts=[TextPart('Starting analysis'), ToolCallPart('analyze_data', {})])
        else:
            return ModelResponse(  # pragma: no cover
                parts=[
                    TextPart('Analysis completed'),
                ]
            )

    agent = Agent(FunctionModel(llm))

    @agent.tool_plain
    def analyze_data() -> list[Any]:
        return [
            ToolReturn(
                return_value='Data analysis completed successfully',
                content=[
                    'Here are the analysis results:',
                    ImageUrl('https://example.com/chart.jpg'),
                    'The chart shows positive trends.',
                ],
                metadata={'foo': 'bar'},
            ),
            'Something else',
        ]

    with pytest.raises(
        UserError,
        match="The return value of tool 'analyze_data' contains invalid nested `ToolReturn` objects. `ToolReturn` should be used directly.",
    ):
        agent.run_sync('Please analyze the data')

# pydantic_evals/pydantic_evals/otel/span_tree.py:217-221
    def any_ancestor(
        self, predicate: SpanQuery | SpanPredicate, stop_recursing_when: SpanQuery | SpanPredicate | None = None
    ) -> bool:
        """Returns True if any ancestor satisfies the predicate."""
        return self.first_ancestor(predicate, stop_recursing_when) is not None

# tests/graph/test_graph.py:283-299
async def test_run_return_other(mock_snapshot_id: object):
    @dataclass
    class Foo(BaseNode):
        async def run(self, ctx: GraphRunContext) -> Bar:
            return Bar()

    @dataclass
    class Bar(BaseNode[None, None, None]):
        async def run(self, ctx: GraphRunContext) -> End[None]:
            return 42  # type: ignore

    g = Graph(nodes=(Foo, Bar))
    assert g.inferred_types == (type(None), type(None))
    with pytest.raises(GraphRuntimeError) as exc_info:
        await g.run(Foo())

    assert exc_info.value.message == snapshot('Invalid node return type: `int`. Expected `BaseNode` or `End`.')

# pydantic_ai_slim/pydantic_ai/models/test.py:385-419
    def _gen_any(self, schema: dict[str, Any]) -> Any:
        """Generate data for any JSON Schema."""
        if const := schema.get('const'):
            return const
        elif enum := schema.get('enum'):
            return enum[self.seed % len(enum)]
        elif examples := schema.get('examples'):
            return examples[self.seed % len(examples)]
        elif ref := schema.get('$ref'):
            key = re.sub(r'^#/\$defs/', '', ref)
            js_def = self.defs[key]
            return self._gen_any(js_def)
        elif any_of := schema.get('anyOf'):
            return self._gen_any(any_of[self.seed % len(any_of)])

        type_ = schema.get('type')
        if type_ is None:
            # if there's no type or ref, we can't generate anything
            return self._char()
        elif type_ == 'object':
            return self._object_gen(schema)
        elif type_ == 'string':
            return self._str_gen(schema)
        elif type_ == 'integer':
            return self._int_gen(schema)
        elif type_ == 'number':
            return float(self._int_gen(schema))
        elif type_ == 'boolean':
            return self._bool_gen()
        elif type_ == 'array':
            return self._array_gen(schema)
        elif type_ == 'null':
            return None
        else:
            raise NotImplementedError(f'Unknown type: {type_}, please submit a PR to extend JsonSchemaTestData!')

# tests/graph/beta/test_parent_forks.py:56-79
def test_parent_fork_nested_forks():
    """Test parent fork identification with nested forks.

    In this case, it should return the most ancestral valid parent fork.
    """
    join_id = 'J'
    nodes = {'start', 'F1', 'F2', 'A', 'B', 'C', 'J', 'end'}
    start_ids = {'start'}
    fork_ids = {'F1', 'F2'}
    edges = {
        'start': ['F1'],
        'F1': ['F2'],
        'F2': ['A', 'B'],
        'A': ['J'],
        'B': ['J'],
        'J': ['end'],
    }

    finder = ParentForkFinder(nodes, start_ids, fork_ids, edges)
    parent_fork = finder.find_parent_fork(join_id)

    assert parent_fork is not None
    # Should find F1 as the most ancestral parent fork
    assert parent_fork.fork_id == 'F1'

# tests/graph/beta/test_parent_forks.py:228-249
def test_parent_fork_early_return_on_ancestor_with_cycle():
    """Test early return when encountering ancestor fork with cycle."""
    join_id = 'J'
    nodes = {'start', 'F1', 'F2', 'A', 'B', 'C', 'J', 'end'}
    start_ids = {'start'}
    fork_ids = {'F1', 'F2'}
    edges = {
        'start': ['F1'],
        'F1': ['F2', 'C'],  # F1 has two paths
        'F2': ['A', 'B'],  # F2 is the inner fork
        'A': ['J'],
        'B': ['J'],
        'J': ['end'],
        'C': ['J'],  # C creates a path from F1 to J but doesn't bypass it
    }

    finder = ParentForkFinder(nodes, start_ids, fork_ids, edges)
    parent_fork = finder.find_parent_fork(join_id)

    assert parent_fork is not None
    # Returns F1 as the most ancestral valid fork
    assert parent_fork.fork_id == 'F1'

# pydantic_ai_slim/pydantic_ai/ui/ag_ui/_adapter.py:88-90
    def label(self) -> str:
        """Return the label for this toolset."""
        return 'the AG-UI frontend tools'  # pragma: no cover

# pydantic_ai_slim/pydantic_ai/usage.py:366-382
    def check_before_request(self, usage: RunUsage) -> None:
        """Raises a `UsageLimitExceeded` exception if the next request would exceed any of the limits."""
        request_limit = self.request_limit
        if request_limit is not None and usage.requests >= request_limit:
            raise UsageLimitExceeded(f'The next request would exceed the request_limit of {request_limit}')

        input_tokens = usage.input_tokens
        if self.input_tokens_limit is not None and input_tokens > self.input_tokens_limit:
            raise UsageLimitExceeded(
                f'The next request would exceed the input_tokens_limit of {self.input_tokens_limit} ({input_tokens=})'
            )

        total_tokens = usage.total_tokens
        if self.total_tokens_limit is not None and total_tokens > self.total_tokens_limit:
            raise UsageLimitExceeded(  # pragma: lax no cover
                f'The next request would exceed the total_tokens_limit of {self.total_tokens_limit} ({total_tokens=})'
            )

# pydantic_evals/pydantic_evals/otel/span_tree.py:162-164
    def any_child(self, predicate: SpanQuery | SpanPredicate) -> bool:
        """Returns True if there is at least one child that satisfies the predicate."""
        return self.first_child(predicate) is not None

# pydantic_ai_slim/pydantic_ai/usage.py:99-101
    def has_values(self) -> bool:
        """Whether any values are set and non-zero."""
        return any(dataclasses.asdict(self).values())

# tests/models/test_model_function.py:531-533
async def test_pass_neither():
    with pytest.raises(TypeError, match='Either `function` or `stream_function` must be provided'):
        FunctionModel()  # pyright: ignore[reportCallIssue]

# examples/pydantic_ai_examples/ag_ui/api/agentic_generative_ui.py:6-6
from typing import Any, Literal

# examples/pydantic_ai_examples/ag_ui/api/agentic_generative_ui.py:6-6
from typing import Any, Literal

# examples/pydantic_ai_examples/ag_ui/api/agentic_generative_ui.py:6-6
from typing import Any, Literal