# tests/test_temporal.py:1579-1583
class SimpleAgentWorkflowWithEventStreamHandler:
    @workflow.run
    async def run(self, prompt: str) -> str:
        result = await simple_temporal_agent.run(prompt, event_stream_handler=simple_event_stream_handler)
        return result.output  # pragma: no cover

# pydantic_ai_slim/pydantic_ai/_ssrf.py:23-37
_PRIVATE_NETWORKS: tuple[ipaddress.IPv4Network | ipaddress.IPv6Network, ...] = (
    # IPv4 private ranges
    ipaddress.IPv4Network('127.0.0.0/8'),  # Loopback
    ipaddress.IPv4Network('10.0.0.0/8'),  # Private
    ipaddress.IPv4Network('172.16.0.0/12'),  # Private
    ipaddress.IPv4Network('192.168.0.0/16'),  # Private
    ipaddress.IPv4Network('169.254.0.0/16'),  # Link-local (includes cloud metadata)
    ipaddress.IPv4Network('0.0.0.0/8'),  # "This" network
    ipaddress.IPv4Network('100.64.0.0/10'),  # CGNAT (RFC 6598), includes Alibaba Cloud metadata
    # IPv6 private ranges
    ipaddress.IPv6Network('::1/128'),  # Loopback
    ipaddress.IPv6Network('fe80::/10'),  # Link-local
    ipaddress.IPv6Network('fc00::/7'),  # Unique local address
    ipaddress.IPv6Network('2002::/16'),  # 6to4 (can embed private IPv4 addresses)
)

# tests/test_temporal.py:1984-2022
class HitlAgentWorkflow:
    def __init__(self):
        self._status: Literal['running', 'waiting_for_results', 'done'] = 'running'
        self._deferred_tool_requests: DeferredToolRequests | None = None
        self._deferred_tool_results: DeferredToolResults | None = None

    @workflow.run
    async def run(self, prompt: str) -> AgentRunResult[str | DeferredToolRequests]:
        messages: list[ModelMessage] = [ModelRequest.user_text_prompt(prompt)]
        while True:
            result = await hitl_temporal_agent.run(
                message_history=messages, deferred_tool_results=self._deferred_tool_results
            )
            messages = result.all_messages()

            if isinstance(result.output, DeferredToolRequests):
                self._deferred_tool_requests = result.output
                self._deferred_tool_results = None
                self._status = 'waiting_for_results'

                await workflow.wait_condition(lambda: self._deferred_tool_results is not None)
                self._status = 'running'
            else:
                self._status = 'done'
                return result

    @workflow.query
    def get_status(self) -> Literal['running', 'waiting_for_results', 'done']:
        return self._status

    @workflow.query
    def get_deferred_tool_requests(self) -> DeferredToolRequests | None:
        return self._deferred_tool_requests

    @workflow.signal
    def set_deferred_tool_results(self, results: DeferredToolResults) -> None:
        self._status = 'running'
        self._deferred_tool_requests = None
        self._deferred_tool_results = results

# tests/graph/test_graph.py:184-208
def test_two_bad_nodes():
    class Foo(BaseNode):
        input_data: float

        async def run(self, ctx: GraphRunContext) -> Union[Bar, Spam]:  # noqa: UP007
            raise NotImplementedError()

    class Bar(BaseNode[None, None, None]):
        input_data: str

        async def run(self, ctx: GraphRunContext) -> End[None]:
            raise NotImplementedError()

    class Spam(BaseNode[None, None, None]):
        async def run(self, ctx: GraphRunContext) -> End[None]:
            raise NotImplementedError()

    with pytest.raises(GraphSetupError) as exc_info:
        Graph(nodes=(Foo,))

    assert exc_info.value.message == snapshot("""\
Nodes are referenced in the graph but not included in the graph:
 `Bar` is referenced by `Foo`
 `Spam` is referenced by `Foo`\
""")

# tests/test_temporal.py:2355-2359
class ImageAgentWorkflow:
    @workflow.run
    async def run(self, prompt: str) -> BinaryImage:
        result = await image_temporal_agent.run(prompt)
        return result.output  # pragma: no cover

# tests/test_temporal.py:216-220
class SimpleAgentWorkflow:
    @workflow.run
    async def run(self, prompt: str) -> str:
        result = await simple_temporal_agent.run(prompt)
        return result.output

# tests/test_temporal.py:315-319
class ComplexAgentWorkflow:
    @workflow.run
    async def run(self, prompt: str, deps: Deps) -> Response:
        result = await complex_temporal_agent.run(prompt, deps=deps)
        return result.output

# tests/test_temporal.py:2545-2549
class FastMCPAgentWorkflow:
    @workflow.run
    async def run(self, prompt: str) -> str:
        result = await fastmcp_temporal_agent.run(prompt)
        return result.output

# tests/test_agent.py:4853-4869
def test_system_prompt_none_return_are_omitted():
    """Test dynamic system prompts with None return values."""
    agent = Agent('test', system_prompt='STATIC')

    @agent.system_prompt
    def dynamic_sys() -> str | None:
        return None

    with capture_run_messages() as base_messages:
        agent.run_sync('Hi', model=TestModel(custom_output_text='baseline'))

    base_req = base_messages[0]
    assert isinstance(base_req, ModelRequest)
    sys_texts = [p.content for p in base_req.parts if isinstance(p, SystemPromptPart)]
    # The None value should be omitted
    assert 'STATIC' in sys_texts
    assert '' not in sys_texts

# tests/test_temporal.py:2325-2329
class SettingsAgentWorkflow:
    @workflow.run
    async def run(self, prompt: str) -> str:
        result = await settings_temporal_agent.run(prompt)
        return result.output

# tests/test_temporal.py:2451-2455
class WebSearchAgentWorkflow:
    @workflow.run
    async def run(self, prompt: str) -> str:
        result = await web_search_temporal_agent.run(prompt)
        return result.output

# tests/test_temporal.py:2396-2400
class DocumentUrlAgentWorkflow:
    @workflow.run
    async def run(self, prompt: str) -> DocumentUrl:
        result = await document_url_temporal_agent.run(prompt)
        return result.output

# tests/test_temporal.py:2598-2600
async def multiply_by_two(ctx: StepContext[GraphState, None, int]) -> int:
    """Multiply input by 2."""
    return ctx.inputs * 2

# tests/test_temporal.py:3181-3185
class MultiModalContentWorkflow:
    @workflow.run
    async def run(self, prompt: list[str | MultiModalContent]) -> list[ModelMessage]:
        result = await multimodal_content_temporal_agent.run(prompt)
        return result.all_messages()

# tests/test_temporal.py:1581-1583
    async def run(self, prompt: str) -> str:
        result = await simple_temporal_agent.run(prompt, event_stream_handler=simple_event_stream_handler)
        return result.output  # pragma: no cover

# tests/test_temporal.py:1151-1155
class DynamicToolsetAgentWorkflow:
    @workflow.run
    async def run(self, prompt: str, deps: DynamicToolsetDeps) -> str:
        result = await dynamic_toolset_temporal_agent.run(prompt, deps=deps)
        return result.output

# tests/test_temporal.py:1541-1547
class SimpleAgentWorkflowWithIter:
    @workflow.run
    async def run(self, prompt: str) -> str:
        async with simple_temporal_agent.iter(prompt) as run:
            async for _ in run:
                pass
        return 'done'  # pragma: no cover

# tests/test_temporal.py:1208-1212
class MCPDynamicToolsetAgentWorkflow:
    @workflow.run
    async def run(self, prompt: str) -> str:
        result = await mcp_dynamic_toolset_temporal_agent.run(prompt)
        return result.output

# tests/test_temporal.py:1371-1375
class SimpleAgentWorkflowWithRunSync:
    @workflow.run
    async def run(self, prompt: str) -> str:
        result = simple_temporal_agent.run_sync(prompt)
        return result.output  # pragma: no cover

# tests/test_temporal.py:1618-1622
class SimpleAgentWorkflowWithRunModel:
    @workflow.run
    async def run(self, prompt: str) -> str:
        result = await simple_temporal_agent.run(prompt, model=unregistered_model)
        return result.output  # pragma: no cover

# tests/test_temporal.py:1893-1897
class UnserializableDepsAgentWorkflow:
    @workflow.run
    async def run(self, prompt: str) -> str:
        result = await unserializable_deps_temporal_agent.run(prompt, deps=unserializable_deps_temporal_agent.model)
        return result.output  # pragma: no cover

# tests/typed_agent.py:79-80
def wrong_tool_prepare(ctx: RunContext[MyDeps], x: int, y: str) -> str:
    return f'{ctx.deps.foo} {x} {y}'

# tests/test_temporal.py:1483-1488
class SimpleAgentWorkflowWithRunStream:
    @workflow.run
    async def run(self, prompt: str) -> str:
        async with simple_temporal_agent.run_stream(prompt) as result:
            pass
        return await result.get_output()  # pragma: no cover

# pydantic_ai_slim/pydantic_ai/_a2a.py:119-307
class AgentWorker(Worker[list[ModelMessage]], Generic[WorkerOutputT, AgentDepsT]):
    """A worker that uses an agent to execute tasks."""

    agent: AbstractAgent[AgentDepsT, WorkerOutputT]

    async def run_task(self, params: TaskSendParams) -> None:
        task = await self.storage.load_task(params['id'])
        if task is None:
            raise ValueError(f'Task {params["id"]} not found')  # pragma: no cover

        # TODO(Marcelo): Should we lock `run_task` on the `context_id`?
        # Ensure this task hasn't been run before
        if task['status']['state'] != 'submitted':
            raise ValueError(  # pragma: no cover
                f'Task {params["id"]} has already been processed (state: {task["status"]["state"]})'
            )

        await self.storage.update_task(task['id'], state='working')

        # Load context - contains pydantic-ai message history from previous tasks in this conversation
        message_history = await self.storage.load_context(task['context_id']) or []
        message_history.extend(self.build_message_history(task.get('history', [])))

        try:
            result = await self.agent.run(message_history=message_history)  # type: ignore

            await self.storage.update_context(task['context_id'], result.all_messages())

            # Convert new messages to A2A format for task history
            a2a_messages: list[Message] = []

            for message in result.new_messages():
                if isinstance(message, ModelRequest):
                    # Skip user prompts - they're already in task history
                    continue
                else:
                    # Convert response parts to A2A format
                    a2a_parts = self._response_parts_to_a2a(message.parts)
                    if a2a_parts:  # Add if there are visible parts (text/thinking)
                        a2a_messages.append(
                            Message(role='agent', parts=a2a_parts, kind='message', message_id=str(uuid.uuid4()))
                        )

            artifacts = self.build_artifacts(result.output)
        except Exception:
            await self.storage.update_task(task['id'], state='failed')
            raise
        else:
            await self.storage.update_task(
                task['id'], state='completed', new_artifacts=artifacts, new_messages=a2a_messages
            )

    async def cancel_task(self, params: TaskIdParams) -> None:
        pass

    def build_artifacts(self, result: WorkerOutputT) -> list[Artifact]:
        """Build artifacts from agent result.

        All agent outputs become artifacts to mark them as durable task outputs.
        For string results, we use TextPart. For structured data, we use DataPart.
        Metadata is included to preserve type information.
        """
        artifact_id = str(uuid.uuid4())
        part = self._convert_result_to_part(result)
        return [Artifact(artifact_id=artifact_id, name='result', parts=[part])]

    def _convert_result_to_part(self, result: WorkerOutputT) -> Part:
        """Convert agent result to a Part (TextPart or DataPart).

        For string results, returns a TextPart.
        For structured data, returns a DataPart with properly serialized data.
        """
        if isinstance(result, str):
            return A2ATextPart(kind='text', text=result)
        else:
            output_type = type(result)
            type_adapter = TypeAdapter(output_type)
            data = type_adapter.dump_python(result, mode='json')
            json_schema = type_adapter.json_schema(mode='serialization')
            return DataPart(kind='data', data={'result': data}, metadata={'json_schema': json_schema})

    def build_message_history(self, history: list[Message]) -> list[ModelMessage]:
        model_messages: list[ModelMessage] = []
        for message in history:
            if message['role'] == 'user':
                model_messages.append(ModelRequest(parts=self._request_parts_from_a2a(message['parts'])))
            else:
                model_messages.append(ModelResponse(parts=self._response_parts_from_a2a(message['parts'])))
        return model_messages

    def _request_parts_from_a2a(self, parts: list[Part]) -> list[ModelRequestPart]:
        """Convert A2A Part objects to pydantic-ai ModelRequestPart objects.

        This handles the conversion from A2A protocol parts (text, file, data) to
        pydantic-ai's internal request parts (UserPromptPart with various content types).

        Args:
            parts: List of A2A Part objects from incoming messages

        Returns:
            List of ModelRequestPart objects for the pydantic-ai agent
        """
        model_parts: list[ModelRequestPart] = []
        for part in parts:
            if part['kind'] == 'text':
                model_parts.append(UserPromptPart(content=part['text']))
            elif part['kind'] == 'file':
                file_content = part['file']
                if 'bytes' in file_content:
                    data = base64.b64decode(file_content['bytes'])
                    mime_type = file_content.get('mime_type', 'application/octet-stream')
                    content = BinaryContent(data=data, media_type=mime_type)
                    model_parts.append(UserPromptPart(content=[content]))
                else:
                    url = file_content['uri']
                    for url_cls in (DocumentUrl, AudioUrl, ImageUrl, VideoUrl):
                        content = url_cls(url=url)
                        try:
                            content.media_type
                        except ValueError:  # pragma: no cover
                            continue
                        else:
                            break
                    else:
                        raise ValueError(f'Unsupported file type: {url}')  # pragma: no cover
                    model_parts.append(UserPromptPart(content=[content]))
            elif part['kind'] == 'data':
                raise NotImplementedError('Data parts are not supported yet.')
            else:
                assert_never(part)
        return model_parts

    def _response_parts_from_a2a(self, parts: list[Part]) -> list[ModelResponsePart]:
        """Convert A2A Part objects to pydantic-ai ModelResponsePart objects.

        This handles the conversion from A2A protocol parts (text, file, data) to
        pydantic-ai's internal response parts. Currently only supports text parts
        as agent responses in A2A are expected to be text-based.

        Args:
            parts: List of A2A Part objects from stored agent messages

        Returns:
            List of ModelResponsePart objects for message history
        """
        model_parts: list[ModelResponsePart] = []
        for part in parts:
            if part['kind'] == 'text':
                model_parts.append(TextPart(content=part['text']))
            elif part['kind'] == 'file':  # pragma: no cover
                raise NotImplementedError('File parts are not supported yet.')
            elif part['kind'] == 'data':  # pragma: no cover
                raise NotImplementedError('Data parts are not supported yet.')
            else:  # pragma: no cover
                assert_never(part)
        return model_parts

    def _response_parts_to_a2a(self, parts: Sequence[ModelResponsePart]) -> list[Part]:
        """Convert pydantic-ai ModelResponsePart objects to A2A Part objects.

        This handles the conversion from pydantic-ai's internal response parts to
        A2A protocol parts. Different part types are handled as follows:
        - TextPart: Converted directly to A2A TextPart
        - ThinkingPart: Converted to TextPart with metadata indicating it's thinking
        - ToolCallPart: Skipped (internal to agent execution)

        Args:
            parts: List of ModelResponsePart objects from agent response

        Returns:
            List of A2A Part objects suitable for sending via A2A protocol
        """
        a2a_parts: list[Part] = []
        for part in parts:
            if isinstance(part, TextPart):
                a2a_parts.append(A2ATextPart(kind='text', text=part.content))
            elif isinstance(part, ThinkingPart):
                # Convert thinking to text with metadata
                a2a_parts.append(
                    A2ATextPart(
                        kind='text',
                        text=part.content,
                        metadata={'type': 'thinking', 'thinking_id': part.id, 'signature': part.signature},
                    )
                )
            elif isinstance(part, ToolCallPart):
                # Skip tool calls - they're internal to agent execution
                pass
        return a2a_parts

# tests/test_temporal.py:1647-1651
class SimpleAgentWorkflowWithRunToolsets:
    @workflow.run
    async def run(self, prompt: str) -> str:
        result = await simple_temporal_agent.run(prompt, toolsets=[FunctionToolset()])
        return result.output  # pragma: no cover

# pydantic_ai_slim/pydantic_ai/_a2a.py:122-122
    agent: AbstractAgent[AgentDepsT, WorkerOutputT]

# tests/test_temporal.py:1763-1768
class SimpleAgentWorkflowWithOverrideDeps:
    @workflow.run
    async def run(self, prompt: str) -> str:
        with simple_temporal_agent.override(deps=None):
            result = await simple_temporal_agent.run(prompt)
            return result.output

# tests/test_temporal.py:1676-1680
class SimpleAgentWorkflowWithOverrideModel:
    @workflow.run
    async def run(self, prompt: str) -> None:
        with simple_temporal_agent.override(model=model):
            pass

# tests/test_temporal.py:1734-1738
class SimpleAgentWorkflowWithOverrideTools:
    @workflow.run
    async def run(self, prompt: str) -> None:
        with simple_temporal_agent.override(tools=[get_weather]):
            pass

# tests/test_temporal.py:1991-2008
    async def run(self, prompt: str) -> AgentRunResult[str | DeferredToolRequests]:
        messages: list[ModelMessage] = [ModelRequest.user_text_prompt(prompt)]
        while True:
            result = await hitl_temporal_agent.run(
                message_history=messages, deferred_tool_results=self._deferred_tool_results
            )
            messages = result.all_messages()

            if isinstance(result.output, DeferredToolRequests):
                self._deferred_tool_requests = result.output
                self._deferred_tool_results = None
                self._status = 'waiting_for_results'

                await workflow.wait_condition(lambda: self._deferred_tool_results is not None)
                self._status = 'running'
            else:
                self._status = 'done'
                return result

# tests/test_temporal.py:2357-2359
    async def run(self, prompt: str) -> BinaryImage:
        result = await image_temporal_agent.run(prompt)
        return result.output  # pragma: no cover

# tests/test_agent.py:935-960
def test_output_type_with_two_descriptions():
    class MyOutput(BaseModel):
        """Description from docstring"""

        valid: bool

    m = TestModel()
    agent = Agent(m, output_type=ToolOutput(MyOutput, description='Description from ToolOutput'))
    result = agent.run_sync('Hello')
    assert result.output == snapshot(MyOutput(valid=False))
    assert m.last_model_request_parameters is not None
    assert m.last_model_request_parameters.output_tools == snapshot(
        [
            ToolDefinition(
                name='final_result',
                description='Description from ToolOutput. Description from docstring',
                parameters_json_schema={
                    'properties': {'valid': {'type': 'boolean'}},
                    'required': ['valid'],
                    'title': 'MyOutput',
                    'type': 'object',
                },
                kind='output',
            )
        ]
    )

# tests/test_temporal.py:1513-1516
class SimpleAgentWorkflowWithRunStreamEvents:
    @workflow.run
    async def run(self, prompt: str) -> list[AgentStreamEvent | AgentRunResultEvent]:
        return [event async for event in simple_temporal_agent.run_stream_events(prompt)]

# tests/test_temporal.py:218-220
    async def run(self, prompt: str) -> str:
        result = await simple_temporal_agent.run(prompt)
        return result.output

# tests/test_temporal.py:1705-1709
class SimpleAgentWorkflowWithOverrideToolsets:
    @workflow.run
    async def run(self, prompt: str) -> None:
        with simple_temporal_agent.override(toolsets=[FunctionToolset()]):
            pass

# tests/test_temporal.py:317-319
    async def run(self, prompt: str, deps: Deps) -> Response:
        result = await complex_temporal_agent.run(prompt, deps=deps)
        return result.output

# tests/test_temporal.py:2547-2549
    async def run(self, prompt: str) -> str:
        result = await fastmcp_temporal_agent.run(prompt)
        return result.output

# tests/test_agent.py:4821-4850
def test_dynamic_system_prompt_none_return():
    """Test dynamic system prompts with None return values."""
    agent = Agent('test')

    dynamic_values = [None, 'DYNAMIC']

    @agent.system_prompt(dynamic=True)
    def dynamic_sys() -> str | None:
        return dynamic_values.pop(0)

    with capture_run_messages() as base_messages:
        agent.run_sync('Hi', model=TestModel(custom_output_text='baseline'))

    base_req = base_messages[0]
    assert isinstance(base_req, ModelRequest)
    sys_texts = [p.content for p in base_req.parts if isinstance(p, SystemPromptPart)]
    # The None value should have a '' placeholder due to keeping a reference to the dynamic prompt
    assert '' in sys_texts
    assert 'DYNAMIC' not in sys_texts

    # Run a second time to capture the updated system prompt
    with capture_run_messages() as messages:
        agent.run_sync('Hi', model=TestModel(custom_output_text='baseline'))

    req = messages[0]
    assert isinstance(req, ModelRequest)
    sys_texts = [p.content for p in req.parts if isinstance(p, SystemPromptPart)]
    # The None value should have a '' placeholder due to keep a reference to the dynamic prompt
    assert '' not in sys_texts
    assert 'DYNAMIC' in sys_texts

# pydantic_ai_slim/pydantic_ai/_a2a.py:124-169
    async def run_task(self, params: TaskSendParams) -> None:
        task = await self.storage.load_task(params['id'])
        if task is None:
            raise ValueError(f'Task {params["id"]} not found')  # pragma: no cover

        # TODO(Marcelo): Should we lock `run_task` on the `context_id`?
        # Ensure this task hasn't been run before
        if task['status']['state'] != 'submitted':
            raise ValueError(  # pragma: no cover
                f'Task {params["id"]} has already been processed (state: {task["status"]["state"]})'
            )

        await self.storage.update_task(task['id'], state='working')

        # Load context - contains pydantic-ai message history from previous tasks in this conversation
        message_history = await self.storage.load_context(task['context_id']) or []
        message_history.extend(self.build_message_history(task.get('history', [])))

        try:
            result = await self.agent.run(message_history=message_history)  # type: ignore

            await self.storage.update_context(task['context_id'], result.all_messages())

            # Convert new messages to A2A format for task history
            a2a_messages: list[Message] = []

            for message in result.new_messages():
                if isinstance(message, ModelRequest):
                    # Skip user prompts - they're already in task history
                    continue
                else:
                    # Convert response parts to A2A format
                    a2a_parts = self._response_parts_to_a2a(message.parts)
                    if a2a_parts:  # Add if there are visible parts (text/thinking)
                        a2a_messages.append(
                            Message(role='agent', parts=a2a_parts, kind='message', message_id=str(uuid.uuid4()))
                        )

            artifacts = self.build_artifacts(result.output)
        except Exception:
            await self.storage.update_task(task['id'], state='failed')
            raise
        else:
            await self.storage.update_task(
                task['id'], state='completed', new_artifacts=artifacts, new_messages=a2a_messages
            )

# tests/test_temporal.py:2327-2329
    async def run(self, prompt: str) -> str:
        result = await settings_temporal_agent.run(prompt)
        return result.output

# tests/test_temporal.py:1802-1806
class AgentWorkflowWithSyncToolActivityDisabled:
    @workflow.run
    async def run(self, prompt: str) -> str:
        result = await temporal_agent_with_sync_tool_activity_disabled.run(prompt)
        return result.output  # pragma: no cover

# tests/test_temporal.py:2453-2455
    async def run(self, prompt: str) -> str:
        result = await web_search_temporal_agent.run(prompt)
        return result.output

# pydantic_ai_slim/pydantic_ai/usage.py:99-101
    def has_values(self) -> bool:
        """Whether any values are set and non-zero."""
        return any(dataclasses.asdict(self).values())

# tests/test_temporal.py:2398-2400
    async def run(self, prompt: str) -> DocumentUrl:
        result = await document_url_temporal_agent.run(prompt)
        return result.output

# tests/test_temporal.py:3183-3185
    async def run(self, prompt: list[str | MultiModalContent]) -> list[ModelMessage]:
        result = await multimodal_content_temporal_agent.run(prompt)
        return result.all_messages()

# pydantic_ai_slim/pydantic_ai/_a2a.py:171-172
    async def cancel_task(self, params: TaskIdParams) -> None:
        pass

# tests/test_temporal.py:1153-1155
    async def run(self, prompt: str, deps: DynamicToolsetDeps) -> str:
        result = await dynamic_toolset_temporal_agent.run(prompt, deps=deps)
        return result.output

# tests/test_temporal.py:1543-1547
    async def run(self, prompt: str) -> str:
        async with simple_temporal_agent.iter(prompt) as run:
            async for _ in run:
                pass
        return 'done'  # pragma: no cover

# tests/test_temporal.py:1985-1988
    def __init__(self):
        self._status: Literal['running', 'waiting_for_results', 'done'] = 'running'
        self._deferred_tool_requests: DeferredToolRequests | None = None
        self._deferred_tool_results: DeferredToolResults | None = None

# tests/test_temporal.py:1210-1212
    async def run(self, prompt: str) -> str:
        result = await mcp_dynamic_toolset_temporal_agent.run(prompt)
        return result.output

# tests/test_temporal.py:1373-1375
    async def run(self, prompt: str) -> str:
        result = simple_temporal_agent.run_sync(prompt)
        return result.output  # pragma: no cover

# tests/test_temporal.py:1620-1622
    async def run(self, prompt: str) -> str:
        result = await simple_temporal_agent.run(prompt, model=unregistered_model)
        return result.output  # pragma: no cover

# tests/test_temporal.py:1895-1897
    async def run(self, prompt: str) -> str:
        result = await unserializable_deps_temporal_agent.run(prompt, deps=unserializable_deps_temporal_agent.model)
        return result.output  # pragma: no cover

# tests/test_temporal.py:2011-2012
    def get_status(self) -> Literal['running', 'waiting_for_results', 'done']:
        return self._status

# tests/test_temporal.py:1485-1488
    async def run(self, prompt: str) -> str:
        async with simple_temporal_agent.run_stream(prompt) as result:
            pass
        return await result.get_output()  # pragma: no cover

# tests/test_temporal.py:1649-1651
    async def run(self, prompt: str) -> str:
        result = await simple_temporal_agent.run(prompt, toolsets=[FunctionToolset()])
        return result.output  # pragma: no cover

# tests/test_temporal.py:1765-1768
    async def run(self, prompt: str) -> str:
        with simple_temporal_agent.override(deps=None):
            result = await simple_temporal_agent.run(prompt)
            return result.output

# tests/test_temporal.py:1678-1680
    async def run(self, prompt: str) -> None:
        with simple_temporal_agent.override(model=model):
            pass

# tests/test_temporal.py:1736-1738
    async def run(self, prompt: str) -> None:
        with simple_temporal_agent.override(tools=[get_weather]):
            pass

# tests/models/anthropic/test_output.py:510-532
def test_mixed_tools_no_output(
    allow_model_requests: None,
    anthropic_model: ANTHROPIC_MODEL_FIXTURE,
) -> None:
    """Mixed tools (one strict=True, one strict=None), no output_type → beta, only strict=True has strict field."""
    model = anthropic_model('claude-sonnet-4-5')
    hook = create_header_verification_hook(expect_beta=True, test_name='test_mixed_tools_no_output')
    model.client._client.event_hooks['request'].append(hook)  # pyright: ignore[reportPrivateUsage]

    agent = Agent(model)

    @agent.tool_plain(strict=True)
    def get_weather(city: str) -> str:
        return f'Weather in {city}: Sunny, 22°C'

    @agent.tool_plain
    def get_elevation(city: str) -> str:
        return f'Elevation of {city}: 650m above sea level'

    agent.run_sync("What's the weather and elevation in Denver?")

    if errors := hook.errors:  # type: ignore[attr-defined]
        assert False, '\n'.join(sorted(errors))

# tests/test_temporal.py:1515-1516
    async def run(self, prompt: str) -> list[AgentStreamEvent | AgentRunResultEvent]:
        return [event async for event in simple_temporal_agent.run_stream_events(prompt)]

# tests/test_temporal.py:1707-1709
    async def run(self, prompt: str) -> None:
        with simple_temporal_agent.override(toolsets=[FunctionToolset()]):
            pass

# tests/typed_deps.py:53-54
async def my_prepare_none(ctx: RunContext, tool_defn: ToolDefinition) -> None:
    pass

# tests/test_temporal.py:1804-1806
    async def run(self, prompt: str) -> str:
        result = await temporal_agent_with_sync_tool_activity_disabled.run(prompt)
        return result.output  # pragma: no cover

# tests/models/anthropic/test_output.py:536-558
def test_mixed_tools_basemodel_output(
    allow_model_requests: None,
    anthropic_model: ANTHROPIC_MODEL_FIXTURE,
) -> None:
    """Mixed tools (one strict=True, one strict=None), BaseModel output_type → beta, only strict=True has strict field."""
    model = anthropic_model('claude-sonnet-4-5')
    hook = create_header_verification_hook(expect_beta=True, test_name='test_mixed_tools_basemodel_output')
    model.client._client.event_hooks['request'].append(hook)  # pyright: ignore[reportPrivateUsage]

    agent = Agent(model, output_type=CityInfo)

    @agent.tool_plain(strict=True)
    def get_population(city: str) -> int:
        return 8_900_000 if city == 'London' else 1_000_000

    @agent.tool_plain
    def get_area(city: str) -> str:
        return f'Area of {city}: 1,572 km²'

    agent.run_sync('Tell me about London including population and area')

    if errors := hook.errors:  # type: ignore[attr-defined]
        assert False, '\n'.join(sorted(errors))

# pydantic_ai_slim/pydantic_ai/_run_context.py:97-103
def get_current_run_context() -> RunContext[Any] | None:
    """Get the current run context, if one is set.

    Returns:
        The current [`RunContext`][pydantic_ai.tools.RunContext], or `None` if not in an agent run.
    """
    return _CURRENT_RUN_CONTEXT.get()

# tests/models/anthropic/test_output.py:562-585
def test_mixed_tools_native_output(
    allow_model_requests: None,
    anthropic_model: ANTHROPIC_MODEL_FIXTURE,
) -> None:
    """Mixed tools (one strict=True, one strict=None), NativeOutput → beta, only strict=True has strict field + output_format."""
    model = anthropic_model('claude-sonnet-4-5')
    hook = create_header_verification_hook(expect_beta=True, test_name='test_mixed_tools_native_output')
    model.client._client.event_hooks['request'].append(hook)  # pyright: ignore[reportPrivateUsage]

    agent = Agent(model, output_type=NativeOutput(CityInfo))

    @agent.tool_plain(strict=True)
    def lookup_country(city: str) -> str:
        return 'Japan' if city == 'Tokyo' else 'Unknown'

    @agent.tool_plain
    def get_founded_year(city: str) -> str:
        return '1457' if city == 'Tokyo' else 'Unknown'

    result = agent.run_sync('Give me complete details about Tokyo')

    assert isinstance(result.output, CityInfo)
    if errors := hook.errors:  # type: ignore[attr-defined]
        assert False, '\n'.join(sorted(errors))

# pydantic_ai_slim/pydantic_ai/toolsets/abstract.py:98-103
    async def __aenter__(self) -> Self:
        """Enter the toolset context.

        This is where you can set up network connections in a concrete implementation.
        """
        return self

# pydantic_ai_slim/pydantic_ai/toolsets/abstract.py:105-110
    async def __aexit__(self, *args: Any) -> bool | None:
        """Exit the toolset context.

        This is where you can tear down network connections in a concrete implementation.
        """
        return None

# pydantic_ai_slim/pydantic_ai/_a2a.py:200-207
    def build_message_history(self, history: list[Message]) -> list[ModelMessage]:
        model_messages: list[ModelMessage] = []
        for message in history:
            if message['role'] == 'user':
                model_messages.append(ModelRequest(parts=self._request_parts_from_a2a(message['parts'])))
            else:
                model_messages.append(ModelResponse(parts=self._response_parts_from_a2a(message['parts'])))
        return model_messages

# pydantic_evals/pydantic_evals/otel/_context_in_memory_span_exporter.py:56-72
def _context_subtree_spans() -> typing.Iterator[list[ReadableSpan] | SpanTreeRecordingError]:
    """Context manager that yields a list of spans that are collected during the context.

    The list will be empty until the context is exited.
    """
    exporter = _add_context_span_exporter()

    if isinstance(exporter, SpanTreeRecordingError):
        yield exporter
        return

    spans: list[ReadableSpan] = []
    with _set_exporter_context_id() as context_id:
        yield spans
    result = exporter.get_finished_spans(context_id)
    exporter.clear(context_id)
    spans.extend(result)

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:29-29
from ._run_context import set_current_run_context

# tests/test_thinking_part.py:109-116
def test_thinking_part_delta_applies_to_part_with_none_signature():
    thinking_part_no_sig = ThinkingPart(content='No sig content', signature=None)
    delta_to_none_sig = ThinkingPartDelta(content_delta=' extra', signature_delta='added_sig')

    result_none_sig = delta_to_none_sig.apply(thinking_part_no_sig)

    # The content is appended, and the signature is updated.
    assert result_none_sig == snapshot(ThinkingPart(content='No sig content extra', signature='added_sig'))

# pydantic_ai_slim/pydantic_ai/ui/_web/api.py:57-76
def validate_request_options(
    extra_data: ChatRequestExtra,
    model_ids: set[str],
    builtin_tool_ids: set[str],
) -> str | None:
    """Validate that requested model and tools are in the allowed lists.

    Returns an error message if validation fails, or None if valid.
    """
    if extra_data.model and extra_data.model not in model_ids:
        return f'Model "{extra_data.model}" is not in the allowed models list'

    # base model also validates this but makes sense to have an api check, since one could be a UI bug/misbehavior
    # the other would be a pydantic-ai bug
    # also as future proofing since we don't know how users will use this feature in the future
    invalid_tools = [t for t in extra_data.builtin_tools if t not in builtin_tool_ids]
    if invalid_tools:
        return f'Builtin tool(s) {invalid_tools} not in the allowed tools list'

    return None

# pydantic_ai_slim/pydantic_ai/models/function.py:200-202
    def system(self) -> str:
        """The system / model provider."""
        return self._system

# pydantic_ai_slim/pydantic_ai/models/xai.py:197-199
    def system(self) -> str:
        """The model provider."""
        return 'xai'

# pydantic_ai_slim/pydantic_ai/models/groq.py:171-173
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/test.py:157-159
    def system(self) -> str:
        """The model provider."""
        return self._system

# pydantic_ai_slim/pydantic_ai/models/huggingface.py:163-165
    def system(self) -> str:
        """The system / model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/cohere.py:151-153
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/gemini.py:165-167
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/google.py:249-251
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# tests/typed_agent.py:71-75
async def prep_wrong_type(ctx: RunContext[int], tool_def: ToolDefinition) -> ToolDefinition | None:
    if ctx.deps == 42:
        return None
    else:
        return tool_def

# pydantic_ai_slim/pydantic_ai/_griffe.py:10-10
from griffe import Docstring, DocstringSectionKind, GoogleOptions, Object as GriffeObject