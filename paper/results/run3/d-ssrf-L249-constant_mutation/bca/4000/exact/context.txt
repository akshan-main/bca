## examples/pydantic_ai_examples/flight_booking.py

class Deps:
    web_page_text: str
    req_origin: str
    req_destination: str
    req_date: datetime.date

## examples/pydantic_ai_examples/slack_lead_qualifier/agent.py

async def analyze_profile(profile: Profile) -> Analysis | None:
    result = await agent.run(profile.as_prompt())
    return result.output  ### [/analyze_profile]

## pydantic_ai_slim/pydantic_ai/_agent_graph.py

    model_response: _messages.ModelResponse

## pydantic_ai_slim/pydantic_ai/_json_schema.py

from abc import ABC, abstractmethod

## pydantic_ai_slim/pydantic_ai/_ssrf.py

    resolved_ip: str

## pydantic_ai_slim/pydantic_ai/_utils.py

def number_to_datetime(x: int | float) -> datetime:
    return _datetime_ta.validate_python(x)

## pydantic_ai_slim/pydantic_ai/models/__init__.py

def get_user_agent() -> str:
    """Get the user agent string for the HTTP client."""
    from .. import __version__

    return f'pydantic-ai/{__version__}'

## pydantic_ai_slim/pydantic_ai/models/gemini.py

class _GeminiContent(TypedDict):
    role: Literal['user', 'model']
    parts: list[_GeminiPartUnion]

def _tool_config(function_names: list[str]) -> _GeminiToolConfig:
    return _GeminiToolConfig(
        function_calling_config=_GeminiFunctionCallingConfig(mode='ANY', allowed_function_names=function_names)
    )

class _GeminiFunctionCallingConfig(TypedDict):
    mode: Literal['ANY', 'AUTO']
    allowed_function_names: list[str]

## pydantic_ai_slim/pydantic_ai/ui/vercel_ai/_models.py

class CamelBaseModel(BaseModel, ABC):
    """Base model with camelCase aliases."""

    model_config = ConfigDict(alias_generator=to_camel, populate_by_name=True, extra='forbid')

## pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py

class BaseUIPart(CamelBaseModel, ABC):
    """Abstract base class for all UI parts."""

class StepStartUIPart(BaseUIPart):
    """A step boundary part of a message."""

    type: Literal['step-start'] = 'step-start'

## tests/conftest.py

def raise_if_exception(e: Any) -> None:
    if isinstance(e, Exception):
        raise e

def disable_ssrf_protection_for_vcr():
    """Disable SSRF protection for VCR compatibility.

    VCR cassettes record requests with the original hostname. Since SSRF protection
    resolves hostnames to IPs before making requests, we need to disable the validation
    for VCR tests to match the pre-recorded cassettes.

    This fixture patches validate_and_resolve_url to return the hostname in place
    of the resolved IP, allowing the request URL to use the original hostname.
    """
    from unittest.mock import patch

    from pydantic_ai._ssrf import ResolvedUrl, extract_host_and_port

    async def mock_validate_and_resolve(url: str, allow_local: bool) -> ResolvedUrl:
        hostname, path, port, is_https = extract_host_and_port(url)
        # Return hostname in place of resolved IP - this allows VCR matching
        return ResolvedUrl(resolved_ip=hostname, hostname=hostname, port=port, is_https=is_https, path=path)

    with patch('pydantic_ai._ssrf.validate_and_resolve_url', mock_validate_and_resolve):
        yield

## tests/evals/test_dataset.py

class TaskInput(BaseModel):
    query: str

class TaskOutput(BaseModel):
    answer: str
    confidence: float = 1.0

class TaskMetadata(BaseModel):
    difficulty: str = 'easy'
    category: str = 'general'

## tests/evals/test_report_evaluators.py

def _make_report(cases: list[ReportCase]) -> EvaluationReport:
    return EvaluationReport(name='test', cases=cases)

## tests/graph/beta/test_broadcast_and_spread.py

class CounterState:
    values: list[int] = field(default_factory=list[int])

    values: list[int] = field(default_factory=list[int])

## tests/graph/beta/test_decisions.py

class DecisionState:
    path_taken: str | None = None
    value: int = 0

## tests/graph/beta/test_edge_cases.py

class EdgeCaseState:
    value: int = 0
    error_raised: bool = False

## tests/graph/beta/test_edge_labels.py

class LabelState:
    value: int = 0

## tests/graph/beta/test_graph_builder.py

class SimpleState:
    counter: int = 0
    result: str | None = None

## tests/graph/beta/test_graph_edge_cases.py

class MyState:
    value: int = 0

## tests/graph/beta/test_graph_execution.py

class ExecutionState:
    log: list[str] = field(default_factory=list[str])
    counter: int = 0

## tests/models/test_bedrock.py

def _bedrock_model_with_client_error(error: ClientError) -> BedrockConverseModel:
    """Instantiate a BedrockConverseModel wired to always raise the given error."""
    return BedrockConverseModel(
        'us.amazon.nova-micro-v1:0',
        provider=_StubBedrockProvider(_StubBedrockClient(error)),
    )

async def test_bedrock_model_max_tokens(allow_model_requests: None, bedrock_provider: BedrockProvider):
    model = BedrockConverseModel('us.amazon.nova-micro-v1:0', provider=bedrock_provider)
    agent = Agent(model=model, instructions='You are a helpful chatbot.', model_settings={'max_tokens': 5})
    result = await agent.run('What is the capital of France?')
    assert result.output == snapshot('The capital of France is')

async def test_image_url_input(
    allow_model_requests: None, bedrock_provider: BedrockProvider, disable_ssrf_protection_for_vcr: None
):
    m = BedrockConverseModel('us.amazon.nova-pro-v1:0', provider=bedrock_provider)
    agent = Agent(m, instructions='You are a helpful chatbot.')

    result = await agent.run(
        [
            'What is this vegetable?',
            ImageUrl(url='https://t3.ftcdn.net/jpg/00/85/79/92/360_F_85799278_0BBGV9OAdQDTLnKwAPBCcg1J7QtiieJY.jpg'),
        ]
    )
    assert result.output == snapshot(
        'The image shows a potato. It is oval in shape and has a yellow skin with numerous dark brown patches. These patches are known as lenticels, which are pores that allow the potato to breathe. The potato is a root vegetable that is widely cultivated and consumed around the world. It is a versatile ingredient that can be used in a variety of dishes, including mashed potatoes, fries, and potato salad.'
    )

async def test_video_url_input(
    allow_model_requests: None, bedrock_provider: BedrockProvider, disable_ssrf_protection_for_vcr: None
):
    m = BedrockConverseModel('us.amazon.nova-pro-v1:0', provider=bedrock_provider)
    agent = Agent(m, instructions='You are a helpful chatbot.')

    result = await agent.run(
        [
            'Explain me this video',
            VideoUrl(url='https://t3.ftcdn.net/jpg/00/85/79/92/small_video.mp4'),
        ]
    )
    assert result.output == snapshot(
        'The video shows a camera set up on a tripod, pointed at a scenic view of a rocky landscape under a clear sky. The camera remains stationary throughout the video, capturing the same view without any changes.'
    )

## tests/models/test_download_item.py

async def test_download_item_raises_user_error_with_unsupported_protocol(
    url: AudioUrl | DocumentUrl | ImageUrl | VideoUrl,
    protocol: str,
) -> None:
    with pytest.raises(ValueError, match=f'URL protocol "{protocol}" is not allowed'):
        _ = await download_item(url, data_format='bytes')

async def test_download_item_raises_user_error_with_youtube_url() -> None:
    with pytest.raises(UserError, match='Downloading YouTube videos is not supported.'):
        _ = await download_item(VideoUrl(url='https://youtu.be/lCdaVNyHtjU'), data_format='bytes')

async def test_download_item_audio_mpeg(disable_ssrf_protection_for_vcr: None) -> None:
    downloaded_item = await download_item(
        AudioUrl(url='https://smokeshow.helpmanual.io/4l1l1s0s6q4741012x1w/common_voice_en_537507.mp3'),
        data_format='bytes',
    )
    assert downloaded_item['data_type'] == 'audio/mpeg'
    assert downloaded_item['data'] == IsInstance(bytes)

async def test_download_item_no_content_type(disable_ssrf_protection_for_vcr: None) -> None:
    downloaded_item = await download_item(
        DocumentUrl(url='https://raw.githubusercontent.com/pydantic/pydantic-ai/refs/heads/main/docs/help.md'),
        data_format='text',
    )
    assert downloaded_item['data_type'] == 'text/markdown'
    assert downloaded_item['data'] == IsStr()

## tests/models/test_gemini.py

def gemini_response(content: _GeminiContent, finish_reason: Literal['STOP'] | None = 'STOP') -> _GeminiResponse:
    candidate = _GeminiCandidates(content=content, index=0, safety_ratings=[])
    if finish_reason:  # pragma: no branch
        candidate['finish_reason'] = finish_reason
    return _GeminiResponse(candidates=[candidate], usage_metadata=example_usage(), model_version='gemini-1.5-flash-123')

def example_usage() -> _GeminiUsageMetaData:
    return _GeminiUsageMetaData(prompt_token_count=1, candidates_token_count=2, total_token_count=3)

async def test_image_url_input(
    allow_model_requests: None, gemini_api_key: str, disable_ssrf_protection_for_vcr: None
) -> None:
    m = GeminiModel('gemini-2.0-flash-exp', provider=GoogleGLAProvider(api_key=gemini_api_key))
    agent = Agent(m)

    image_url = ImageUrl(url='https://goo.gle/instrument-img')

    result = await agent.run(['What is the name of this fruit?', image_url])
    assert result.output == snapshot("This is not a fruit; it's a pipe organ console.")

async def test_video_url_input(
    allow_model_requests: None, gemini_api_key: str, disable_ssrf_protection_for_vcr: None
) -> None:
    m = GeminiModel('gemini-2.5-flash', provider=GoogleGLAProvider(api_key=gemini_api_key))
    agent = Agent(m, instructions='You are a helpful chatbot.')

    video_url = VideoUrl(url='https://data.grepit.app/assets/tiny_video.mp4')

    result = await agent.run(['Explain me this video', video_url])
    assert result.output.strip() == snapshot(
        """\
This video is a beautiful, static shot (or appears to be a still image) of a picturesque Mediterranean scene.

Here's a breakdown:

*   **Setting:** It depicts a narrow, charming alleyway or street, likely in a coastal town or island.
*   **Architecture:** The buildings on both sides are traditional, whitewashed stucco, characteristic of Cycladic architecture often found in the Greek islands. There are minimal details on the walls, with some simple light fixtures on the left and a blue-painted window frame on the right.
*   **Cafe/Restaurant:** Along the left side of the alley, several rustic wooden tables and chairs are set up, suggesting an outdoor cafe or restaurant. On the far left wall, there are also some woven baskets hanging or placed.
*   **Pathway:** The ground is paved with a distinctive pattern of light-colored stones, adding to the quaint aesthetic.
*   **The Sea View:** The alley opens up directly to a stunning view of the sea. The water is a vibrant blue, with noticeable waves gently breaking.
*   **Horizon:** In the distance, across the sparkling water, another landmass or island can be seen under a clear, bright blue sky.
*   **Atmosphere:** The overall impression is one of serenity, beauty, and a quintessential Mediterranean vacation spot, perfect for enjoying a meal or drink with a breathtaking ocean view.

It strongly evokes places like Mykonos or Santorini in Greece, known for their iconic white buildings and narrow pathways leading to the sea.\
"""
    )

## tests/models/test_groq.py

def text_chunk(text: str, finish_reason: FinishReason | None = None) -> chat.ChatCompletionChunk:
    return chunk([ChoiceDelta(content=text, role='assistant')], finish_reason=finish_reason)

## tests/models/test_mcp_sampling.py

def fake_session(create_message: Any) -> Any:
    return FakeSession(create_message)

## tests/models/test_openai.py

def test_init():
    m = OpenAIChatModel('gpt-4o', provider=OpenAIProvider(api_key='foobar'))
    assert m.base_url == 'https://api.openai.com/v1/'
    assert m.client.api_key == 'foobar'
    assert m.model_name == 'gpt-4o'

async def test_system_prompt_role_o1_mini(allow_model_requests: None, openai_api_key: str):
    model = OpenAIChatModel('o1-mini', provider=OpenAIProvider(api_key=openai_api_key))
    agent = Agent(model=model, system_prompt='You are a helpful assistant.')

    result = await agent.run("What's the capital of France?")
    assert result.output == snapshot('The capital of France is **Paris**.')

async def test_document_url_input(
    allow_model_requests: None, openai_api_key: str, disable_ssrf_protection_for_vcr: None
):
    m = OpenAIChatModel('gpt-4o', provider=OpenAIProvider(api_key=openai_api_key))
    agent = Agent(m)

    document_url = DocumentUrl(url='https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf')

    result = await agent.run(['What is the main content on this document?', document_url])
    assert result.output == snapshot('The document contains the text "Dummy PDF file" on its single page.')

async def test_max_completion_tokens(allow_model_requests: None, model_name: str, openai_api_key: str):
    m = OpenAIChatModel(model_name, provider=OpenAIProvider(api_key=openai_api_key))
    agent = Agent(m, model_settings=ModelSettings(max_tokens=100))

    result = await agent.run('hello')
    assert result.output == IsStr()

async def test_extra_headers(allow_model_requests: None, openai_api_key: str):
    # This test doesn't do anything, it's just here to ensure that calls with `extra_headers` don't cause errors, including type.
    m = OpenAIChatModel('gpt-4o', provider=OpenAIProvider(api_key=openai_api_key))
    agent = Agent(m, model_settings=OpenAIChatModelSettings(extra_headers={'Extra-Header-Key': 'Extra-Header-Value'}))
    await agent.run('hello')

async def test_user_id(allow_model_requests: None, openai_api_key: str):
    # This test doesn't do anything, it's just here to ensure that calls with `user` don't cause errors, including type.
    # Since we use VCR, creating tests with an `httpx.Transport` is not possible.
    m = OpenAIChatModel('gpt-4o', provider=OpenAIProvider(api_key=openai_api_key))
    agent = Agent(m, model_settings=OpenAIChatModelSettings(openai_user='user_id'))
    await agent.run('hello')

def test_openai_model_profile():
    m = OpenAIChatModel('gpt-4o', provider=OpenAIProvider(api_key='foobar'))
    assert isinstance(m.profile, OpenAIModelProfile)

async def test_openai_model_cerebras_provider(allow_model_requests: None, cerebras_api_key: str):
    m = OpenAIChatModel('llama3.3-70b', provider=CerebrasProvider(api_key=cerebras_api_key))
    agent = Agent(m)

    result = await agent.run('What is the capital of France?')
    assert result.output == snapshot('The capital of France is Paris.')

async def test_openai_model_cerebras_provider_harmony(allow_model_requests: None, cerebras_api_key: str):
    m = OpenAIChatModel('gpt-oss-120b', provider=CerebrasProvider(api_key=cerebras_api_key))
    agent = Agent(m)

    result = await agent.run('What is the capital of France?')
    assert result.output == snapshot('The capital of France is **Paris**.')

## tests/models/test_outlines.py

def test_request_image_url(transformers_multimodal_model: OutlinesModel, disable_ssrf_protection_for_vcr: None) -> None:
    agent = Agent(transformers_multimodal_model)
    result = agent.run_sync(
        [
            "What's on the image?",
            ImageUrl(url='https://t3.ftcdn.net/jpg/00/85/79/92/360_F_85799278_0BBGV9OAdQDTLnKwAPBCcg1J7QtiieJY.jpg'),
        ],
        model_settings=ModelSettings(extra_body={'max_new_tokens': 100}),
    )
    assert result.all_messages() == snapshot(
        [
            ModelRequest(
                parts=[
                    UserPromptPart(
                        content=[
                            "What's on the image?",
                            ImageUrl(
                                url='https://t3.ftcdn.net/jpg/00/85/79/92/360_F_85799278_0BBGV9OAdQDTLnKwAPBCcg1J7QtiieJY.jpg'
                            ),
                        ],
                        timestamp=IsDatetime(),
                    )
                ],
                timestamp=IsDatetime(),
                run_id=IsStr(),
            ),
            ModelResponse(parts=[TextPart(content=IsStr())], timestamp=IsDatetime(), run_id=IsStr()),
        ]
    )

## tests/providers/test_google_gla.py

def test_api_key_env_var(env: TestEnv):
    env.set('GEMINI_API_KEY', 'via-env-var')
    provider = GoogleGLAProvider()
    assert 'x-goog-api-key' in dict(provider.client.headers)

## tests/providers/test_openai.py

async def test_init_with_http_client():
    async with httpx.AsyncClient() as http_client:
        provider = OpenAIProvider(http_client=http_client, api_key='foobar')
        assert provider.client._client == http_client  # type: ignore

## tests/test_dbos.py

def workflow_raises(exc_type: type[Exception], exc_message: str) -> Iterator[None]:
    """Helper for asserting that a DBOS workflow fails with the expected error."""
    with pytest.raises(Exception) as exc_info:
        yield
    assert isinstance(exc_info.value, Exception)
    assert str(exc_info.value) == exc_message

## tests/test_deps.py

class MyDeps:
    foo: int
    bar: int

## tests/test_mcp.py

def model(openai_api_key: str) -> Model:
    return OpenAIChatModel('gpt-4o', provider=OpenAIProvider(api_key=openai_api_key))

async def test_agent_with_server_not_running(agent: Agent, allow_model_requests: None):
    result = await agent.run('What is 0 degrees Celsius in Fahrenheit?')
    assert result.output == snapshot('0 degrees Celsius is 32.0 degrees Fahrenheit.')

## tests/test_prefect.py

class SimpleDeps:
    value: str
