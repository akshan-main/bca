## examples/pydantic_ai_examples/data_analyst.py

    def get(self, ref: str) -> pd.DataFrame:
        if ref not in self.output:
            raise ModelRetry(
                f'Error: {ref} is not a valid variable reference. Check the previous messages and try again.'
            )
        return self.output[ref]

## pydantic_ai_slim/pydantic_ai/_ssrf.py

def build_url_with_ip(resolved: ResolvedUrl) -> str:
    """Build a URL using a resolved IP address instead of the hostname.

    For IPv6 addresses, wraps them in brackets as required by URL syntax.
    """
    scheme = 'https' if resolved.is_https else 'http'
    default_port = 443 if resolved.is_https else 80

    # IPv6 addresses need brackets in URLs
    try:
        ip_obj = ipaddress.ip_address(resolved.resolved_ip)
        if isinstance(ip_obj, ipaddress.IPv6Address):
            host_part = f'[{resolved.resolved_ip}]'
        else:
            host_part = resolved.resolved_ip
    except ValueError:
        host_part = resolved.resolved_ip

    # Only include port if non-default
    if resolved.port != default_port:
        host_part = f'{host_part}:{resolved.port}'

    return urlunparse((scheme, host_part, resolved.path, '', '', ''))

async def safe_download(
    url: str,
    allow_local: bool = False,
    max_redirects: int = _MAX_REDIRECTS,
    timeout: int = _DEFAULT_TIMEOUT,
) -> httpx.Response:
    """Download content from a URL with SSRF protection.

    This function:
    1. Validates the URL protocol (only http/https allowed)
    2. Resolves the hostname to IP addresses
    3. Validates that no resolved IP is private (unless allow_local=True)
    4. Always blocks cloud metadata endpoints
    5. Makes the request to the resolved IP with the Host header set
    6. Manually follows redirects, validating each hop

    Args:
        url: The URL to download from.
        allow_local: If True, allows requests to private/internal IP addresses.
                    Cloud metadata endpoints are always blocked regardless.
        max_redirects: Maximum number of redirects to follow (default: 10).
        timeout: Request timeout in seconds (default: 30).

    Returns:
        The httpx.Response object.

    Raises:
        ValueError: If the URL fails SSRF validation or too many redirects occur.
        httpx.HTTPStatusError: If the response has an error status code.
    """
    current_url = url
    redirects_followed = 0

    client = cached_async_http_client(timeout=timeout)
    while True:
        # Validate and resolve the current URL
        resolved = await validate_and_resolve_url(current_url, allow_local)

        # Build URL with resolved IP
        request_url = build_url_with_ip(resolved)

        # For HTTPS, set sni_hostname so TLS uses the original hostname for SNI
        # and certificate validation, even though we're connecting to the resolved IP.
        extensions: dict[str, str] = {}
        if resolved.is_https:
            extensions['sni_hostname'] = resolved.hostname

        # Make request with Host header set to original hostname
        response = await client.get(
            request_url,
            headers={'Host': resolved.hostname},
            extensions=extensions,
            follow_redirects=False,
        )

        # Check if we need to follow a redirect
        if response.is_redirect:
            redirects_followed += 1
            if redirects_followed > max_redirects:
                raise ValueError(f'Too many redirects ({redirects_followed}). Maximum allowed: {max_redirects}')

            # Get redirect location
            location = response.headers.get('location')
            if not location:
                raise ValueError('Redirect response missing Location header')

            current_url = resolve_redirect_url(current_url, location)
            continue

        # Not a redirect, we're done
        response.raise_for_status()
        return response

## pydantic_ai_slim/pydantic_ai/mcp.py

    def _get_content(
        self, resource: mcp_types.TextResourceContents | mcp_types.BlobResourceContents
    ) -> str | messages.BinaryContent:
        if isinstance(resource, mcp_types.TextResourceContents):
            return resource.text
        elif isinstance(resource, mcp_types.BlobResourceContents):
            return messages.BinaryContent.narrow_type(
                messages.BinaryContent(
                    data=base64.b64decode(resource.blob), media_type=resource.mimeType or 'application/octet-stream'
                )
            )
        else:
            assert_never(resource)

## pydantic_ai_slim/pydantic_ai/models/bedrock.py

    def _get_tools(self, model_request_parameters: ModelRequestParameters) -> list[ToolTypeDef]:
        return [self._map_tool_definition(r) for r in model_request_parameters.tool_defs.values()]

## pydantic_ai_slim/pydantic_ai/models/mistral.py

    def _get_python_type(cls, value: dict[str, Any]) -> str:
        """Return a string representation of the Python type for a single JSON schema property.

        This function handles recursion for nested arrays/objects and `anyOf`.
        """
        # 1) Handle anyOf first, because it's a different schema structure
        if any_of := value.get('anyOf'):
            # Simplistic approach: pick the first option in anyOf
            # (In reality, you'd possibly want to merge or union types)
            return f'Optional[{cls._get_python_type(any_of[0])}]'

        # 2) If we have a top-level "type" field
        value_type = value.get('type')
        if not value_type:
            # No explicit type; fallback
            return 'Any'

        # 3) Direct simple type mapping (string, integer, float, bool, None)
        if value_type in SIMPLE_JSON_TYPE_MAPPING and value_type != 'array' and value_type != 'object':
            return SIMPLE_JSON_TYPE_MAPPING[value_type]

        # 4) Array: Recursively get the item type
        if value_type == 'array':
            items = value.get('items', {})
            return f'list[{cls._get_python_type(items)}]'

        # 5) Object: Check for additionalProperties
        if value_type == 'object':
            additional_properties = value.get('additionalProperties', {})
            if isinstance(additional_properties, bool):
                return 'bool'  # pragma: lax no cover
            additional_properties_type = additional_properties.get('type')
            if (
                additional_properties_type in SIMPLE_JSON_TYPE_MAPPING
                and additional_properties_type != 'array'
                and additional_properties_type != 'object'
            ):
                # dict[str, bool/int/float/etc...]
                return f'dict[str, {SIMPLE_JSON_TYPE_MAPPING[additional_properties_type]}]'
            elif additional_properties_type == 'array':
                array_items = additional_properties.get('items', {})
                return f'dict[str, list[{cls._get_python_type(array_items)}]]'
            elif additional_properties_type == 'object':
                # nested dictionary of unknown shape
                return 'dict[str, dict[str, Any]]'
            else:
                # If no additionalProperties type or something else, default to a generic dict
                return 'dict[str, Any]'

        # 6) Fallback
        return 'Any'

## pydantic_ai_slim/pydantic_ai/models/openrouter.py

    type: Literal['file']

## pydantic_ai_slim/pydantic_ai/providers/bedrock.py

    def get_credentials(self) -> None:  # type: ignore[reportIncompatibleMethodOverride]
        return None

## pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py

    type: Literal['file'] = 'file'

    type: Literal['dynamic-tool'] = 'dynamic-tool'

## pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py

    type: Literal['error'] = 'error'

    type: Literal['tool-output-error'] = 'tool-output-error'

## pydantic_graph/pydantic_graph/_utils.py

def get_union_args(tp: Any) -> tuple[Any, ...]:
    """Extract the arguments of a Union type if `response_type` is a union, otherwise return an empty tuple."""
    # similar to `pydantic_ai_slim/pydantic_ai/_result.py:get_union_args`
    if typing_objects.is_typealiastype(tp):
        tp = tp.__value__  # pragma: no cover

    origin = get_origin(tp)
    if is_union_origin(origin):
        return get_args(tp)
    else:
        return (tp,)

def get_parent_namespace(frame: types.FrameType | None) -> dict[str, Any] | None:
    """Attempt to get the namespace where the graph was defined.

    If the graph is defined with generics `Graph[a, b]` then another frame is inserted, and we have to skip that
    to get the correct namespace.
    """
    if frame is not None:  # pragma: no branch
        if back := frame.f_back:  # pragma: no branch
            if back.f_globals.get('__name__') == 'typing':
                # If the class calling this function is generic, explicitly parameterizing the class
                # results in a `typing._GenericAlias` instance, which proxies instantiation calls to the
                # "real" class and thus adding an extra frame to the call. To avoid pulling anything
                # from the `typing` module, use the correct frame (the one before):
                return get_parent_namespace(back)
            else:
                return back.f_locals

## pydantic_graph/pydantic_graph/graph.py

    def get_nodes(self) -> Sequence[type[BaseNode[StateT, DepsT, RunEndT]]]:
        """Get the nodes in the graph."""
        return [node_def.node for node_def in self.node_defs.values()]

## tests/mcp_server.py

async def get_log_level(ctx: Context) -> str:  # type: ignore
    """Get the current log level.

    Returns:
        The current log level.
    """
    await ctx.info('this is a log message')
    return log_level

## tests/models/mock_xai.py

def _get_example_tool_output(
    tool_type: chat_pb2.ToolCallType,
    content: ToolCallOutputType | None = None,
) -> ToolCallOutputType:
    """Return content if provided, otherwise a realistic default for the tool type."""
    if content is not None:
        return content
    if tool_type == chat_pb2.ToolCallType.TOOL_CALL_TYPE_CODE_EXECUTION_TOOL:
        return {'stdout': '4\n', 'stderr': '', 'output_files': {}, 'error': '', 'ret': ''}
    elif tool_type == chat_pb2.ToolCallType.TOOL_CALL_TYPE_WEB_SEARCH_TOOL:
        return {}  # Web search has no content currently, in future will return inline citations
    elif tool_type == chat_pb2.ToolCallType.TOOL_CALL_TYPE_MCP_TOOL:
        return [
            {
                'id': 'issue_001',
                'identifier': 'PROJ-123',
                'title': 'example-issue',
                'description': 'example-issue description',
                'status': 'Todo',
                'priority': {'value': 3, 'name': 'Medium'},
                'url': 'https://linear.app/team/issue/PROJ-123/example-issue',
            }
        ]
    else:  # pragma: no cover
        # Unknown tool type - return empty dict as fallback
        return {}

def create_code_execution_response(
    code: str,
    content: ToolCallOutputType | None = None,
    *,
    tool_call_id: str = 'code_exec_001',
    assistant_text: str,
) -> chat_types.Response:
    """Create a Response with code execution tool outputs.

    Args:
        assistant_text: Text for the final assistant message (required to match real API).

    Example:
        >>> response = create_code_execution_response(
        ...     code='2 + 2',
        ...     content={'stdout': '4\\n', 'stderr': '', 'output_files': {}, 'error': '', 'ret': ''},
        ...     assistant_text='The result is 4.',
        ... )
    """
    tool_type = chat_pb2.ToolCallType.TOOL_CALL_TYPE_CODE_EXECUTION_TOOL
    actual_content = _get_example_tool_output(tool_type, content)
    outputs = _create_builtin_tool_outputs(
        tool_name='code_execution',
        arguments={'code': code},
        content=actual_content,
        tool_call_id=tool_call_id,
        tool_type=tool_type,
        initial_status=chat_pb2.ToolCallStatus.TOOL_CALL_STATUS_COMPLETED,
    )
    # Add final assistant message (matching real API behavior)
    outputs.append(
        chat_pb2.CompletionOutput(
            index=len(outputs),
            finish_reason=sample_pb2.FinishReason.REASON_STOP,
            message=chat_pb2.CompletionMessage(
                role=chat_pb2.MessageRole.ROLE_ASSISTANT,
                content=assistant_text,
            ),
        )
    )
    return _build_response_with_outputs(response_id=f'grok-{tool_call_id}', outputs=outputs)

def create_web_search_response(
    query: str,
    content: ToolCallOutputType | None = None,
    *,
    tool_call_id: str = 'web_search_001',
    assistant_text: str,
) -> chat_types.Response:
    """Create a Response with web search tool outputs.

    Args:
        assistant_text: Text for the final assistant message (required to match real API).

    Example:
        >>> response = create_web_search_response(
        ...     query='date of Jan 1 in 2026',
        ...     content='Thursday',
        ...     assistant_text='January 1, 2026 is a Thursday.',
        ... )
    """
    tool_type = chat_pb2.ToolCallType.TOOL_CALL_TYPE_WEB_SEARCH_TOOL
    actual_content = _get_example_tool_output(tool_type, content)
    outputs = _create_builtin_tool_outputs(
        tool_name='web_search',
        arguments={'query': query},
        content=actual_content,
        tool_call_id=tool_call_id,
        tool_type=tool_type,
        initial_status=chat_pb2.ToolCallStatus.TOOL_CALL_STATUS_COMPLETED,
    )
    # Add final assistant message (matching real API behavior)
    outputs.append(
        chat_pb2.CompletionOutput(
            index=len(outputs),
            finish_reason=sample_pb2.FinishReason.REASON_STOP,
            message=chat_pb2.CompletionMessage(
                role=chat_pb2.MessageRole.ROLE_ASSISTANT,
                content=assistant_text,
            ),
        )
    )
    return _build_response_with_outputs(response_id=f'grok-{tool_call_id}', outputs=outputs)

def create_mcp_server_response(
    server_id: str,
    tool_name: str,
    tool_input: ToolCallArgumentsType | None = None,
    content: ToolCallOutputType | None = None,
    *,
    tool_call_id: str = 'mcp_001',
    assistant_text: str,
) -> chat_types.Response:
    """Create a Response with MCP server tool outputs.

    Args:
        assistant_text: Text for the final assistant message (required to match real API).

    Example:
        >>> response = create_mcp_server_response(
        ...     server_id='linear',
        ...     tool_name='list_issues',
        ...     content=[{'id': 'issue_001'}],
        ...     assistant_text='Found 1 issue.',
        ... )
    """
    full_tool_name = f'{server_id}.{tool_name}'
    tool_type = chat_pb2.ToolCallType.TOOL_CALL_TYPE_MCP_TOOL
    actual_content = _get_example_tool_output(tool_type, content)
    outputs = _create_builtin_tool_outputs(
        tool_name=full_tool_name,
        arguments=tool_input or {},
        content=actual_content,
        tool_call_id=tool_call_id,
        tool_type=tool_type,
        initial_status=chat_pb2.ToolCallStatus.TOOL_CALL_STATUS_COMPLETED,
    )
    # Add final assistant message (matching real API behavior)
    outputs.append(
        chat_pb2.CompletionOutput(
            index=len(outputs),
            finish_reason=sample_pb2.FinishReason.REASON_STOP,
            message=chat_pb2.CompletionMessage(
                role=chat_pb2.MessageRole.ROLE_ASSISTANT,
                content=assistant_text,
            ),
        )
    )
    return _build_response_with_outputs(response_id=f'grok-{tool_call_id}', outputs=outputs)

## tests/test_ssrf.py

class TestBuildUrlWithIp
    """Tests for build_url_with_ip function."""
    ...  # (skeleton: full source omitted for budget)

    def test_http_default_port(self) -> None:
        resolved = ResolvedUrl(
            resolved_ip='203.0.113.50', hostname='example.com', port=80, is_https=False, path='/path'
        )
        url = build_url_with_ip(resolved)
        assert url == 'http://203.0.113.50/path'

    def test_https_default_port(self) -> None:
        resolved = ResolvedUrl(
            resolved_ip='203.0.113.50', hostname='example.com', port=443, is_https=True, path='/path'
        )
        url = build_url_with_ip(resolved)
        assert url == 'https://203.0.113.50/path'

    def test_ipv6_address(self) -> None:
        resolved = ResolvedUrl(resolved_ip='2001:db8::1', hostname='example.com', port=443, is_https=True, path='/path')
        url = build_url_with_ip(resolved)
        assert url == 'https://[2001:db8::1]/path'
