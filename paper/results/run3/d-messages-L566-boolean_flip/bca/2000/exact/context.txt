## examples/pydantic_ai_examples/chat_app.py

    async def add_messages(self, messages: bytes):
        await self._asyncify(
            self._execute,
            'INSERT INTO messages (message_list) VALUES (?);',
            messages,
            commit=True,
        )
        await self._asyncify(self.con.commit)

    async def get_messages(self) -> list[ModelMessage]:
        c = await self._asyncify(
            self._execute, 'SELECT message_list FROM messages order by id'
        )
        rows = await self._asyncify(c.fetchall)
        messages: list[ModelMessage] = []
        for row in rows:
            messages.extend(ModelMessagesTypeAdapter.validate_json(row[0]))
        return messages

## examples/pydantic_ai_examples/weather_agent_gradio.py

def undo(chatbot, past_messages: list, undo_data: gr.UndoData):
    new_history = chatbot[: undo_data.index]
    past_messages = past_messages[: undo_data.index]
    return chatbot[undo_data.index]['content'], new_history, past_messages

## pydantic_ai_slim/pydantic_ai/models/test.py

    def _bool_gen(self) -> bool:
        """Generate a boolean from a JSON Schema boolean."""
        return bool(self.seed % 2)

## pydantic_graph/pydantic_graph/nodes.py

    def deep_copy_data(self) -> End[RunEndT]:
        """Returns a deep copy of the end of the run."""
        if self.data is None:
            return self
        else:
            end = End(copy.deepcopy(self.data))
            end.set_snapshot_id(self.get_snapshot_id())
            return end

## tests/test_vercel_ai.py

async def test_adapter_dump_messages_thinking_with_metadata():
    """Test dumping and loading messages with ThinkingPart metadata preservation."""
    original_messages = [
        ModelResponse(
            parts=[
                ThinkingPart(
                    content='Let me think about this...',
                    id='thinking_123',
                    signature='sig_abc',
                    provider_name='anthropic',
                    provider_details={'model': 'claude-3'},
                ),
                TextPart(content='Here is my answer.'),
            ]
        ),
    ]

    ui_messages = VercelAIAdapter.dump_messages(original_messages)
    ui_message_dicts = [msg.model_dump() for msg in ui_messages]

    assert ui_message_dicts == snapshot(
        [
            {
                'id': IsStr(),
                'role': 'assistant',
                'metadata': None,
                'parts': [
                    {
                        'type': 'reasoning',
                        'text': 'Let me think about this...',
                        'state': 'done',
                        'provider_metadata': {
                            'pydantic_ai': {
                                'id': 'thinking_123',
                                'signature': 'sig_abc',
                                'provider_name': 'anthropic',
                                'provider_details': {'model': 'claude-3'},
                            }
                        },
                    },
                    {'type': 'text', 'text': 'Here is my answer.', 'state': 'done', 'provider_metadata': None},
                ],
            }
        ]
    )

    # Test roundtrip - verify metadata is preserved when loading back
    reloaded_messages = VercelAIAdapter.load_messages(ui_messages)

    # Sync timestamps for comparison (ModelResponse always has timestamp)
    for orig_msg, new_msg in zip(original_messages, reloaded_messages):
        new_msg.timestamp = orig_msg.timestamp

    assert reloaded_messages == original_messages

async def test_adapter_load_messages_text_with_provider_metadata():
    """Test loading TextUIPart with provider_metadata preserves metadata on TextPart."""
    ui_messages = [
        UIMessage(
            id='msg1',
            role='assistant',
            parts=[
                TextUIPart(
                    text='Hello with metadata',
                    state='done',
                    provider_metadata={
                        'pydantic_ai': {
                            'id': 'text_123',
                            'provider_name': 'anthropic',
                            'provider_details': {'model': 'gpt-4', 'tokens': 50},
                        }
                    },
                )
            ],
        )
    ]

    messages = VercelAIAdapter.load_messages(ui_messages)
    assert messages == snapshot(
        [
            ModelResponse(
                parts=[
                    TextPart(
                        content='Hello with metadata',
                        id='text_123',
                        provider_name='anthropic',
                        provider_details={'model': 'gpt-4', 'tokens': 50},
                    )
                ],
                timestamp=IsDatetime(),
            )
        ]
    )

async def test_adapter_dump_messages_tool_error_with_provider_metadata():
    """Test dumping ToolCallPart with RetryPromptPart includes provider metadata with provider_name."""
    messages = [
        ModelRequest(parts=[UserPromptPart(content='Do task')]),
        ModelResponse(
            parts=[
                ToolCallPart(
                    tool_name='failing_tool',
                    args={'x': 1},
                    tool_call_id='tc_fail',
                    id='call_fail_id',
                    provider_name='google',
                    provider_details={'attempt': 1},
                ),
            ]
        ),
        ModelRequest(
            parts=[
                RetryPromptPart(
                    content='Tool execution failed',
                    tool_name='failing_tool',
                    tool_call_id='tc_fail',
                )
            ]
        ),
    ]

    ui_messages = VercelAIAdapter.dump_messages(messages)
    ui_message_dicts = [msg.model_dump() for msg in ui_messages]

    assert ui_message_dicts == snapshot(
        [
            {
                'id': IsStr(),
                'role': 'user',
                'metadata': None,
                'parts': [{'type': 'text', 'text': 'Do task', 'state': 'done', 'provider_metadata': None}],
            },
            {
                'id': IsStr(),
                'role': 'assistant',
                'metadata': None,
                'parts': [
                    {
                        'type': 'dynamic-tool',
                        'tool_name': 'failing_tool',
                        'tool_call_id': 'tc_fail',
                        'state': 'output-error',
                        'input': '{"x":1}',
                        'error_text': """\
Tool execution failed

Fix the errors and try again.\
""",
                        'call_provider_metadata': {
                            'pydantic_ai': {
                                'id': 'call_fail_id',
                                'provider_name': 'google',
                                'provider_details': {'attempt': 1},
                            }
                        },
                    }
                ],
            },
        ]
    )

    # Verify roundtrip
    reloaded_messages = VercelAIAdapter.load_messages(ui_messages)
    # Content will have changed for retry prompt part, so we set it back to the original value
    retry_prompt_part = reloaded_messages[2].parts[0]
    assert isinstance(retry_prompt_part, RetryPromptPart)
    assert retry_prompt_part.content == 'Tool execution failed\n\nFix the errors and try again.'
    retry_prompt_part.content = 'Tool execution failed'
    _sync_timestamps(messages, reloaded_messages)
    assert reloaded_messages == messages
