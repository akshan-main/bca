{
  "task_id": "usage-total-tokens-math",
  "method": "bm25",
  "budget": 8000,
  "query_type": "vague",
  "tokens_used": 8000,
  "symbols_selected": 122,
  "files_included": 38,
  "assembly_time_ms": 309.0,
  "llm_time_ms": 1465.3,
  "llm_input_tokens": 11558,
  "llm_output_tokens": 44,
  "tests_passed": true,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: pydantic_ai_slim/pydantic_ai/usage.py\nSEARCH:\n        return self.input_tokens - self.output_tokens\nREPLACE:\n        return self.input_tokens + self.output_tokens\n",
  "error": "",
  "test_time_ms": 1308.7,
  "failure_mode": "pass",
  "target_file_hit": true,
  "target_symbol_hit": true,
  "context_patch_overlap": 0.028,
  "patch_files_changed": 1,
  "patch_lines_changed": 1,
  "edit_distance_lines": 0,
  "entity_count_extracted": 0,
  "entity_count_mapped": 0,
  "query_identifier_density": 0.0,
  "seed_symbol_keys": [],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.total_tokens",
  "min_hops_seed_to_mutation": -1,
  "median_hops_seed_to_mutation": -1.0,
  "bca_closure_added_symbols": 0,
  "bca_closure_added_tokens": 0,
  "bca_frontier_visited": 0,
  "context_symbol_keys": [
    "pydantic_ai_slim/pydantic_ai/embeddings/__init__.py::Embedder",
    "pydantic_ai_slim/pydantic_ai/embeddings/__init__.py::Embedder.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/__init__.py::Embedder.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/__init__.py::Embedder.count_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/__init__.py::Embedder.max_input_tokens_sync",
    "pydantic_ai_slim/pydantic_ai/embeddings/__init__.py::Embedder.count_tokens_sync",
    "pydantic_ai_slim/pydantic_ai/embeddings/base.py::EmbeddingModel",
    "pydantic_ai_slim/pydantic_ai/embeddings/base.py::EmbeddingModel.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/base.py::EmbeddingModel.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/base.py::EmbeddingModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_BedrockEmbeddingHandler.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_TitanEmbeddingHandler.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_CohereEmbeddingHandler.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::BedrockEmbeddingModel",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::BedrockEmbeddingModel.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::BedrockEmbeddingModel.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/google.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/google.py::GoogleEmbeddingModel",
    "pydantic_ai_slim/pydantic_ai/embeddings/google.py::GoogleEmbeddingModel.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/google.py::GoogleEmbeddingModel.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/google.py::GoogleEmbeddingModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/openai.py::OpenAIEmbeddingModel.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/openai.py::OpenAIEmbeddingModel.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/openai.py::OpenAIEmbeddingModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/sentence_transformers.py::SentenceTransformerEmbeddingModel.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/sentence_transformers.py::SentenceTransformerEmbeddingModel.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/sentence_transformers.py::SentenceTransformerEmbeddingModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/test.py::_TOKEN_SPLIT_RE",
    "pydantic_ai_slim/pydantic_ai/embeddings/test.py::_estimate_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/test.py::TestEmbeddingModel.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/test.py::TestEmbeddingModel.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/test.py::TestEmbeddingModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py::VoyageAIEmbeddingModel",
    "pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py::VoyageAIEmbeddingModel.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py::VoyageAIEmbeddingModel.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/wrapper.py::WrapperEmbeddingModel.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/wrapper.py::WrapperEmbeddingModel.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/wrapper.py::WrapperEmbeddingModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::ModelRequestParameters",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.__init__",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.request",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.count_tokens",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::check_allow_model_requests",
    "pydantic_ai_slim/pydantic_ai/models/anthropic.py::AnthropicModelSettings",
    "pydantic_ai_slim/pydantic_ai/models/anthropic.py::AnthropicModel",
    "pydantic_ai_slim/pydantic_ai/models/anthropic.py::AnthropicModel.__init__",
    "pydantic_ai_slim/pydantic_ai/models/anthropic.py::AnthropicModel.request",
    "pydantic_ai_slim/pydantic_ai/models/anthropic.py::AnthropicModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/models/anthropic.py::AnthropicModel._messages_count_tokens",
    "pydantic_ai_slim/pydantic_ai/models/bedrock.py::BedrockModelSettings",
    "pydantic_ai_slim/pydantic_ai/models/bedrock.py::BedrockConverseModel",
    "pydantic_ai_slim/pydantic_ai/models/bedrock.py::BedrockConverseModel.__init__",
    "pydantic_ai_slim/pydantic_ai/models/bedrock.py::BedrockConverseModel.request",
    "pydantic_ai_slim/pydantic_ai/models/bedrock.py::BedrockConverseModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/models/bedrock.py::_AsyncIteratorWrapper.__init__",
    "pydantic_ai_slim/pydantic_ai/models/concurrency.py::ConcurrencyLimitedModel",
    "pydantic_ai_slim/pydantic_ai/models/concurrency.py::ConcurrencyLimitedModel.__init__",
    "pydantic_ai_slim/pydantic_ai/models/concurrency.py::ConcurrencyLimitedModel.request",
    "pydantic_ai_slim/pydantic_ai/models/concurrency.py::ConcurrencyLimitedModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/models/function.py::FunctionModel.__init__",
    "pydantic_ai_slim/pydantic_ai/models/function.py::FunctionModel.request",
    "pydantic_ai_slim/pydantic_ai/models/function.py::_estimate_string_tokens",
    "pydantic_ai_slim/pydantic_ai/models/function.py::_TOKEN_SPLIT_RE",
    "pydantic_ai_slim/pydantic_ai/models/gemini.py::GeminiModel.__init__",
    "pydantic_ai_slim/pydantic_ai/models/gemini.py::GeminiModel.request",
    "pydantic_ai_slim/pydantic_ai/models/gemini.py::_GeminiFunctionResponse.response",
    "pydantic_ai_slim/pydantic_ai/models/gemini.py::_GeminiModalityTokenCount",
    "pydantic_ai_slim/pydantic_ai/models/google.py::GoogleModelSettings",
    "pydantic_ai_slim/pydantic_ai/models/google.py::GoogleModel",
    "pydantic_ai_slim/pydantic_ai/models/google.py::GoogleModel.__init__",
    "pydantic_ai_slim/pydantic_ai/models/google.py::GoogleModel.request",
    "pydantic_ai_slim/pydantic_ai/models/google.py::GoogleModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/models/mcp_sampling.py::MCPSamplingModel.request",
    "pydantic_ai_slim/pydantic_ai/models/openrouter.py::_OpenRouterMaxPrice.request",
    "pydantic_ai_slim/pydantic_ai/models/openrouter.py::_OpenRouterError.message",
    "pydantic_ai_slim/pydantic_ai/models/openrouter.py::_OpenRouterChoice.message",
    "pydantic_ai_slim/pydantic_ai/models/openrouter.py::_OpenRouterPromptTokenDetails",
    "pydantic_ai_slim/pydantic_ai/models/openrouter.py::_OpenRouterCompletionTokenDetails",
    "pydantic_ai_slim/pydantic_ai/models/openrouter.py::OpenRouterModel.__init__",
    "pydantic_ai_slim/pydantic_ai/models/wrapper.py::WrapperModel.__init__",
    "pydantic_ai_slim/pydantic_ai/models/wrapper.py::WrapperModel.request",
    "pydantic_ai_slim/pydantic_ai/models/wrapper.py::WrapperModel.count_tokens",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModelSettings",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel.__init__",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel.request",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_map_server_side_tools_used_to_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_extract_usage",
    "pydantic_ai_slim/pydantic_ai/providers/bedrock.py::remove_bedrock_geo_prefix",
    "pydantic_ai_slim/pydantic_ai/providers/bedrock.py::BedrockProvider",
    "pydantic_ai_slim/pydantic_ai/providers/bedrock.py::BedrockProvider.__init__",
    "pydantic_ai_slim/pydantic_ai/providers/bedrock.py::_BearerTokenSession",
    "pydantic_ai_slim/pydantic_ai/providers/bedrock.py::_BearerTokenSession.__init__",
    "pydantic_ai_slim/pydantic_ai/providers/bedrock.py::_BearerTokenSession.get_auth_token",
    "pydantic_ai_slim/pydantic_ai/providers/bedrock.py::_BearerTokenSession.get_credentials",
    "pydantic_ai_slim/pydantic_ai/settings.py::ModelSettings",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.request_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.response_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.total_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.extract",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::_incr_usage_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::Usage",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.count_tokens_before_request",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.request_tokens_limit",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.response_tokens_limit",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.__init__",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.check_tokens",
    "tests/models/test_anthropic.py::MockAnthropic",
    "tests/models/test_anthropic.py::MockAnthropic.messages_",
    "tests/models/test_anthropic.py::MockAnthropic.messages",
    "tests/models/test_anthropic.py::MockAnthropic.create_mock",
    "tests/models/test_anthropic.py::MockAnthropic.messages_count_tokens",
    "tests/models/test_anthropic.py::completion_message",
    "tests/models/test_anthropic.py::test_count_tokens_connection_error",
    "tests/models/test_anthropic.py::test_usage",
    "tests/models/test_anthropic.py::test_anthropic_count_tokens_with_mock",
    "tests/models/test_anthropic.py::test_anthropic_count_tokens_with_no_messages",
    "tests/models/test_anthropic.py::test_anthropic_count_tokens_error",
    "tests/models/test_anthropic.py::test_anthropic_bedrock_count_tokens_not_supported",
    "tests/models/test_bedrock.py::_StubBedrockClient.__init__",
    "tests/models/test_bedrock.py::_StubBedrockClient.count_tokens",
    "tests/models/test_bedrock.py::_StubBedrockProvider.__init__",
    "tests/models/test_bedrock.py::_bedrock_model_with_client_error",
    "tests/models/test_bedrock.py::test_bedrock_model",
    "tests/models/test_bedrock.py::test_bedrock_count_tokens_error",
    "tests/models/test_bedrock.py::test_bedrock_count_tokens_non_http_error",
    "tests/models/test_bedrock.py::test_bedrock_model_max_tokens",
    "tests/models/test_bedrock.py::test_bedrock_cache_usage_includes_cache_tokens",
    "tests/models/test_google.py::google_provider",
    "tests/models/test_google.py::test_google_model",
    "tests/models/test_google.py::test_google_model_max_tokens",
    "tests/models/test_huggingface.py::completion_message",
    "tests/models/test_huggingface.py::test_max_completion_tokens",
    "tests/models/test_instrumented.py::MyModel",
    "tests/models/test_instrumented.py::MyModel.request",
    "tests/models/test_instrumented.py::MyModel.count_tokens",
    "tests/models/test_instrumented.py::test_instrumented_model",
    "tests/models/test_instrumented.py::test_instrumented_model_count_tokens",
    "tests/models/test_xai.py::XAI_REASONING_MODEL",
    "tests/models/test_xai.py::test_xai_usage_with_reasoning_tokens",
    "tests/test_concurrency.py::AsyncBarrier.__init__",
    "tests/test_concurrency.py::TestConcurrencyLimitedModelMethods.test_count_tokens",
    "tests/test_embeddings.py::TestOpenAI.test_max_input_tokens",
    "tests/test_embeddings.py::TestOpenAI.test_count_tokens",
    "tests/test_embeddings.py::TestCohere.test_max_input_tokens",
    "tests/test_embeddings.py::TestCohere.test_count_tokens",
    "tests/test_embeddings.py::TestVoyageAI.test_max_input_tokens",
    "tests/test_embeddings.py::TestBedrock.test_titan_v1_max_input_tokens",
    "tests/test_embeddings.py::TestBedrock.test_titan_v2_max_input_tokens",
    "tests/test_embeddings.py::TestBedrock.test_cohere_v3_max_input_tokens",
    "tests/test_embeddings.py::TestBedrock.test_cohere_v4_max_input_tokens",
    "tests/test_embeddings.py::TestBedrock.test_nova_max_input_tokens",
    "tests/test_embeddings.py::TestBedrock.test_unknown_model_max_tokens_returns_none",
    "tests/test_embeddings.py::TestBedrock.test_count_tokens_not_implemented",
    "tests/test_embeddings.py::TestGoogle.test_max_input_tokens",
    "tests/test_embeddings.py::TestGoogle.test_count_tokens",
    "tests/test_embeddings.py::TestGoogle.test_count_tokens_error",
    "tests/test_embeddings.py::TestSentenceTransformers.test_max_input_tokens",
    "tests/test_embeddings.py::TestSentenceTransformers.test_count_tokens",
    "tests/test_json_body_serializer.py::cassette_dict_base",
    "tests/test_json_body_serializer.py::test_headers_are_lowercased",
    "tests/test_usage_limits.py::test_total_token_limit"
  ],
  "mutation_symbol_lines": 3,
  "mutation_symbol_kind": "method",
  "mutation_file_symbols": 65,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 6.472262,
  "retrieval_softmax_entropy": 4.3138,
  "retrieval_softmax_tau": 41.232219,
  "retrieval_effective_candidates": 19.89,
  "retrieval_top5_ratio": 0.8708,
  "retrieval_within95_count": 1,
  "retrieval_scored_symbols": 50,
  "retrieval_top1_score": 55.491865,
  "retrieval_top5_mean_score": 48.321125,
  "retrieval_budget_utilization": 1.0,
  "retrieval_file_concentration": 0.1967,
  "repo_name": "pydantic-ai",
  "category": "usage",
  "mutation_type": "handcrafted",
  "source": "handcrafted"
}