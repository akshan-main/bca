# pydantic_ai_slim/pydantic_ai/_tool_manager.py:42-42
    default_max_retries: int = 1

# pydantic_ai_slim/pydantic_ai/tools.py:272-272
    max_retries: int | None

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_dynamic_toolset.py:30-30
    max_retries: int

# pydantic_ai_slim/pydantic_ai/mcp.py:331-331
    max_retries: int

# pydantic_ai_slim/pydantic_ai/_run_context.py:63-63
    max_retries: int = 0

# pydantic_ai_slim/pydantic_ai/output.py:115-115
    max_retries: int | None

# pydantic_ai_slim/pydantic_ai/toolsets/abstract.py:53-53
    max_retries: int

# pydantic_ai_slim/pydantic_ai/_output.py:868-868
    max_retries: int

# pydantic_ai_slim/pydantic_ai/mcp.py:863-863
    max_retries: int

# pydantic_ai_slim/pydantic_ai/mcp.py:1030-1030
    max_retries: int

# pydantic_ai_slim/pydantic_ai/toolsets/fastmcp.py:74-74
    max_retries: int

# pydantic_ai_slim/pydantic_ai/toolsets/function.py:44-44
    max_retries: int

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:165-165
    _max_tool_retries: int = dataclasses.field(repr=False)

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:164-164
    _max_result_retries: int = dataclasses.field(repr=False)

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:139-139
    max_result_retries: int

# pydantic_ai_slim/pydantic_ai/models/mcp_sampling.py:41-41
    default_max_tokens: int = 16_384

# tests/models/test_model_test.py:12-12
from annotated_types import Ge, Gt, Le, Lt, MaxLen, MinLen

# tests/test_tenacity.py:554-571
    def test_default_max_wait(self):
        """Test that default max_wait of 300 seconds is used."""
        wait_func = wait_retry_after()  # Use all defaults

        # Create HTTP status error with large Retry-After value
        request = httpx.Request('GET', 'https://example.com')
        response = Mock(spec=httpx.Response)
        response.headers = {'retry-after': '600'}  # 10 minutes
        http_error = httpx.HTTPStatusError('Rate limited', request=request, response=response)

        retry_state = Mock(spec=RetryCallState)
        retry_state.outcome = Mock()
        retry_state.outcome.failed = True
        retry_state.outcome.exception.return_value = http_error

        result = wait_func(retry_state)

        assert result == 300.0  # Capped at default max_wait

# pydantic_evals/pydantic_evals/evaluators/__init__.py:1-10
from .common import (
    Contains,
    Equals,
    EqualsExpected,
    HasMatchingSpan,
    IsInstance,
    LLMJudge,
    MaxDuration,
    OutputConfig,
)

# pydantic_ai_slim/pydantic_ai/_ssrf.py:50-50
_MAX_REDIRECTS = 10

# pydantic_evals/pydantic_evals/otel/span_tree.py:75-75
    max_depth: int

# tests/models/test_model_test.py:449-456
def test_max_items():
    json_schema = {
        'type': 'array',
        'items': {'type': 'string'},
        'maxItems': 0,
    }
    data = _JsonSchemaTestData(json_schema).generate()
    assert data == snapshot([])

# pydantic_ai_slim/pydantic_ai/_ssrf.py:50-50
_MAX_REDIRECTS = 10

# pydantic_ai_slim/pydantic_ai/builtin_tools.py:207-207
    max_uses: int | None = None

# pydantic_ai_slim/pydantic_ai/builtin_tools.py:144-144
    max_uses: int | None = None

# tests/evals/test_evaluator_common.py:179-189
async def test_max_duration():
    """Test MaxDuration evaluator."""
    # Test with float seconds
    evaluator = MaxDuration(seconds=1.0)
    assert evaluator.evaluate(MockContext(duration=0.5)) is True
    assert evaluator.evaluate(MockContext(duration=1.5)) is False

    # Test with timedelta
    evaluator = MaxDuration(seconds=timedelta(seconds=1))
    assert evaluator.evaluate(MockContext(duration=0.5)) is True
    assert evaluator.evaluate(MockContext(duration=1.5)) is False

# pydantic_evals/pydantic_evals/reporting/render_numbers.py:21-21
MULTIPLIER_DROP_FACTOR = 10  # Factor used with BASE_THRESHOLD to drop the multiplier.

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:195-202
_MAX_INPUT_TOKENS: dict[str, int] = {
    'amazon.titan-embed-text-v1': 8192,
    'amazon.titan-embed-text-v2:0': 8192,
    'cohere.embed-english-v3': 512,
    'cohere.embed-multilingual-v3': 512,
    'cohere.embed-v4:0': 128000,
    'amazon.nova-2-multimodal-embeddings-v1:0': 8192,
}

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:195-202
_MAX_INPUT_TOKENS: dict[str, int] = {
    'amazon.titan-embed-text-v1': 8192,
    'amazon.titan-embed-text-v2:0': 8192,
    'cohere.embed-english-v3': 512,
    'cohere.embed-multilingual-v3': 512,
    'cohere.embed-v4:0': 128000,
    'amazon.nova-2-multimodal-embeddings-v1:0': 8192,
}

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:195-202
_MAX_INPUT_TOKENS: dict[str, int] = {
    'amazon.titan-embed-text-v1': 8192,
    'amazon.titan-embed-text-v2:0': 8192,
    'cohere.embed-english-v3': 512,
    'cohere.embed-multilingual-v3': 512,
    'cohere.embed-v4:0': 128000,
    'amazon.nova-2-multimodal-embeddings-v1:0': 8192,
}

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:195-202
_MAX_INPUT_TOKENS: dict[str, int] = {
    'amazon.titan-embed-text-v1': 8192,
    'amazon.titan-embed-text-v2:0': 8192,
    'cohere.embed-english-v3': 512,
    'cohere.embed-multilingual-v3': 512,
    'cohere.embed-v4:0': 128000,
    'amazon.nova-2-multimodal-embeddings-v1:0': 8192,
}

# pydantic_ai_slim/pydantic_ai/settings.py:14-14
    max_tokens: int

# pydantic_evals/pydantic_evals/otel/span_tree.py:48-48
    max_duration: timedelta | float

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_utils.py:9-9
    max_attempts: int

# docs/.hooks/algolia.py:35-35
MAX_CONTENT_LENGTH = 90_000

# pydantic_ai_slim/pydantic_ai/concurrency.py:76-76
    max_queued: int | None = None

# pydantic_ai_slim/pydantic_ai/concurrency.py:75-75
    max_running: int

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:185-185
    max_tokens: int

# pydantic_evals/pydantic_evals/otel/span_tree.py:57-57
    max_child_count: int

# pydantic_ai_slim/pydantic_ai/common_tools/exa.py:94-94
    max_characters: int | None

# pydantic_ai_slim/pydantic_ai/common_tools/duckduckgo.py:47-47
    max_results: int | None

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:170-170
    max_price: _OpenRouterMaxPrice

# pydantic_ai_slim/pydantic_ai/concurrency.py:161-163
    def max_running(self) -> int:
        """Maximum concurrent operations allowed."""
        return int(self._limiter.total_tokens)

# pydantic_evals/pydantic_evals/evaluators/__init__.py:1-10
from .common import (
    Contains,
    Equals,
    EqualsExpected,
    HasMatchingSpan,
    IsInstance,
    LLMJudge,
    MaxDuration,
    OutputConfig,
)

# tests/evals/test_evaluators.py:520-541
async def test_max_duration_evaluator(test_context: EvaluatorContext[TaskInput, TaskOutput, TaskMetadata]):
    """Test the max_duration evaluator."""
    from datetime import timedelta

    # Test with duration under the maximum (using float seconds)
    evaluator = MaxDuration(seconds=0.2)  # test_context has duration=0.1
    result = evaluator.evaluate(test_context)
    assert result is True

    # Test with duration over the maximum
    evaluator = MaxDuration(seconds=0.05)
    result = evaluator.evaluate(test_context)
    assert result is False

    # Test with timedelta
    evaluator = MaxDuration(seconds=timedelta(milliseconds=200))
    result = evaluator.evaluate(test_context)
    assert result is True

    evaluator = MaxDuration(seconds=timedelta(milliseconds=50))
    result = evaluator.evaluate(test_context)
    assert result is False

# pydantic_ai_slim/pydantic_ai/builtin_tools.py:243-243
    max_content_tokens: int | None = None

# pydantic_evals/pydantic_evals/otel/span_tree.py:68-68
    max_descendant_count: int

# pydantic_ai_slim/pydantic_ai/embeddings/test.py:115-116
    async def max_input_tokens(self) -> int | None:
        return 1024

# tests/models/test_huggingface.py:775-780
async def test_max_completion_tokens(allow_model_requests: None, model_name: str, huggingface_api_key: str):
    m = HuggingFaceModel(model_name, provider=HuggingFaceProvider(provider_name='nebius', api_key=huggingface_api_key))
    agent = Agent(m, model_settings=ModelSettings(max_tokens=100))

    result = await agent.run('hello')
    assert result.output == IsStr()

# tests/models/test_huggingface.py:775-780
async def test_max_completion_tokens(allow_model_requests: None, model_name: str, huggingface_api_key: str):
    m = HuggingFaceModel(model_name, provider=HuggingFaceProvider(provider_name='nebius', api_key=huggingface_api_key))
    agent = Agent(m, model_settings=ModelSettings(max_tokens=100))

    result = await agent.run('hello')
    assert result.output == IsStr()

# pydantic_evals/pydantic_evals/reporting/render_numbers.py:19-19
MULTIPLIER_ONE_DECIMAL_THRESHOLD = 100  # If |multiplier| is below this, use one decimal; otherwise, use none.

# pydantic_ai_slim/pydantic_ai/embeddings/cohere.py:204-205
    async def max_input_tokens(self) -> int | None:
        return _MAX_INPUT_TOKENS.get(self.model_name)

# pydantic_ai_slim/pydantic_ai/embeddings/google.py:192-193
    async def max_input_tokens(self) -> int | None:
        return _MAX_INPUT_TOKENS.get(self._model_name)

# pydantic_ai_slim/pydantic_ai/embeddings/openai.py:150-155
    async def max_input_tokens(self) -> int | None:
        if self.system != 'openai':
            return None

        # https://platform.openai.com/docs/guides/embeddings#embedding-models
        return 8192

# tests/test_embeddings.py:161-163
    async def test_max_input_tokens(self, embedder: Embedder):
        max_input_tokens = await embedder.max_input_tokens()
        assert max_input_tokens == snapshot(8192)

# tests/test_embeddings.py:366-370
    async def test_max_input_tokens(self, co_api_key: str):
        model = CohereEmbeddingModel('embed-v4.0', provider=CohereProvider(api_key=co_api_key))
        embedder = Embedder(model)
        max_input_tokens = await embedder.max_input_tokens()
        assert max_input_tokens == snapshot(128000)

# tests/test_embeddings.py:1261-1263
    async def test_max_input_tokens(self, embedder: Embedder):
        max_input_tokens = await embedder.max_input_tokens()
        assert max_input_tokens == snapshot(2048)

# pydantic_ai_slim/pydantic_ai/embeddings/wrapper.py:48-49
    async def max_input_tokens(self) -> int | None:
        return await self.wrapped.max_input_tokens()

# pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py:183-184
    async def max_input_tokens(self) -> int | None:
        return _MAX_INPUT_TOKENS.get(self.model_name)

# tests/test_embeddings.py:480-484
    async def test_max_input_tokens(self, voyage_api_key: str):
        model = VoyageAIEmbeddingModel('voyage-3.5', provider=VoyageAIProvider(api_key=voyage_api_key))
        embedder = Embedder(model)
        max_input_tokens = await embedder.max_input_tokens()
        assert max_input_tokens == snapshot(32000)

# tests/models/test_google.py:685-689
async def test_google_model_max_tokens(allow_model_requests: None, google_provider: GoogleProvider):
    model = GoogleModel('gemini-1.5-flash', provider=google_provider)
    agent = Agent(model=model, instructions='You are a helpful chatbot.', model_settings={'max_tokens': 5})
    result = await agent.run('What is the capital of France?')
    assert result.output == snapshot('The capital of France is')

# pydantic_ai_slim/pydantic_ai/embeddings/cohere.py:63-63
    cohere_max_tokens: int

# pydantic_ai_slim/pydantic_ai/models/gemini.py:629-629
    max_output_tokens: int

# tests/models/test_bedrock.py:549-553
async def test_bedrock_model_max_tokens(allow_model_requests: None, bedrock_provider: BedrockProvider):
    model = BedrockConverseModel('us.amazon.nova-micro-v1:0', provider=bedrock_provider)
    agent = Agent(model=model, instructions='You are a helpful chatbot.', model_settings={'max_tokens': 5})
    result = await agent.run('What is the capital of France?')
    assert result.output == snapshot('The capital of France is')

# pydantic_ai_slim/pydantic_ai/embeddings/__init__.py:360-362
    def max_input_tokens_sync(self) -> int | None:
        """Synchronous version of [`max_input_tokens()`][pydantic_ai.embeddings.Embedder.max_input_tokens]."""
        return _utils.get_event_loop().run_until_complete(self.max_input_tokens())

# tests/test_tenacity.py:540-552
    def test_default_fallback_strategy(self):
        """Test that default fallback strategy is used when none is provided."""
        wait_func = wait_retry_after(max_wait=300)

        # Create a retry state with no exception to trigger fallback
        retry_state = Mock(spec=RetryCallState)
        retry_state.outcome = None
        retry_state.attempt_number = 1

        # Should use default exponential backoff, exact value depends on retry state
        result = wait_func(retry_state)

        assert result == 1  # first backoff

# tests/test_embeddings.py:1034-1038
    async def test_nova_max_input_tokens(self, bedrock_provider: BedrockProvider):
        model = BedrockEmbeddingModel('amazon.nova-2-multimodal-embeddings-v1:0', provider=bedrock_provider)
        embedder = Embedder(model)
        max_input_tokens = await embedder.max_input_tokens()
        assert max_input_tokens == snapshot(8192)

# tests/test_embeddings.py:762-779
    async def test_cohere_v4_with_max_tokens(self, bedrock_provider: BedrockProvider):
        """Test Cohere V4 with max_tokens setting."""

        model = BedrockEmbeddingModel('cohere.embed-v4:0', provider=bedrock_provider)
        embedder = Embedder(model, settings=BedrockEmbeddingSettings(bedrock_cohere_max_tokens=256))
        result = await embedder.embed_query('Test max tokens setting')
        assert result == snapshot(
            EmbeddingResult(
                embeddings=IsList(IsList(IsFloat(), length=1536), length=1),
                inputs=['Test max tokens setting'],
                input_type='query',
                model_name='cohere.embed-v4:0',
                provider_name='bedrock',
                timestamp=IsDatetime(),
                usage=RequestUsage(input_tokens=4),
                provider_response_id=IsStr(),
            )
        )

# pydantic_ai_slim/pydantic_ai/embeddings/sentence_transformers.py:159-161
    async def max_input_tokens(self) -> int | None:
        model = await self._get_model()
        return model.get_max_seq_length()

# tests/test_embeddings.py:1409-1411
    async def test_max_input_tokens(self, embedder: Embedder):
        max_input_tokens = await embedder.max_input_tokens()
        assert max_input_tokens == snapshot(512)

# tests/models/test_gemini.py:1436-1448
async def test_gemini_drop_exclusive_maximum(allow_model_requests: None, gemini_api_key: str) -> None:
    m = GeminiModel('gemini-2.0-flash', provider=GoogleGLAProvider(api_key=gemini_api_key))
    agent = Agent(m)

    @agent.tool_plain
    async def get_chinese_zodiac(age: Annotated[int, Field(gt=18)]) -> str:
        return 'Dragon'

    result = await agent.run('I want to know my chinese zodiac. I am 20 years old.')
    assert result.output == snapshot('Your Chinese zodiac is Dragon.\n')

    result = await agent.run('I want to know my chinese zodiac. I am 17 years old.')
    assert result.output == snapshot('I am sorry, I cannot fulfill this request. The age must be greater than 18.')

# tests/profiles/test_google.py:146-154
def test_removes_exclusive_min_max():
    """exclusiveMinimum and exclusiveMaximum should be removed."""
    schema = {'type': 'integer', 'exclusiveMinimum': 0, 'exclusiveMaximum': 100}
    transformer = GoogleJsonSchemaTransformer(schema)
    transformed = transformer.walk()

    assert 'exclusiveMinimum' not in transformed
    assert 'exclusiveMaximum' not in transformed
    assert transformed == snapshot({'type': 'integer'})

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:661-663
    async def max_input_tokens(self) -> int | None:
        """Get the maximum number of tokens that can be input to the model."""
        return _MAX_INPUT_TOKENS.get(self._handler.model_name, None)

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:183-183
    bedrock_max_concurrency: int

# tests/test_embeddings.py:1010-1014
    async def test_titan_v1_max_input_tokens(self, bedrock_provider: BedrockProvider):
        model = BedrockEmbeddingModel('amazon.titan-embed-text-v1', provider=bedrock_provider)
        embedder = Embedder(model)
        max_input_tokens = await embedder.max_input_tokens()
        assert max_input_tokens == snapshot(8192)

# tests/test_embeddings.py:1016-1020
    async def test_titan_v2_max_input_tokens(self, bedrock_provider: BedrockProvider):
        model = BedrockEmbeddingModel('amazon.titan-embed-text-v2:0', provider=bedrock_provider)
        embedder = Embedder(model)
        max_input_tokens = await embedder.max_input_tokens()
        assert max_input_tokens == snapshot(8192)

# pydantic_ai_slim/pydantic_ai/embeddings/__init__.py:317-324
    async def max_input_tokens(self) -> int | None:
        """Get the maximum number of tokens the model can accept as input.

        Returns:
            The maximum token count, or `None` if the limit is unknown for this model.
        """
        model = self._get_model()
        return await model.max_input_tokens()

# examples/pydantic_ai_examples/evals/models.py:13-13
    max_timestamp_with_offset: AwareDatetime

# tests/test_embeddings.py:1022-1026
    async def test_cohere_v3_max_input_tokens(self, bedrock_provider: BedrockProvider):
        model = BedrockEmbeddingModel('cohere.embed-english-v3', provider=bedrock_provider)
        embedder = Embedder(model)
        max_input_tokens = await embedder.max_input_tokens()
        assert max_input_tokens == snapshot(512)

# tests/test_embeddings.py:1028-1032
    async def test_cohere_v4_max_input_tokens(self, bedrock_provider: BedrockProvider):
        model = BedrockEmbeddingModel('cohere.embed-v4:0', provider=bedrock_provider)
        embedder = Embedder(model)
        max_input_tokens = await embedder.max_input_tokens()
        assert max_input_tokens == snapshot(128000)

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:118-118
    bedrock_cohere_max_tokens: int

# pydantic_evals/pydantic_evals/evaluators/common.py:154-154
    seconds: float | timedelta

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:48-55
class _OpenRouterMaxPrice(TypedDict, total=False):
    """The object specifying the maximum price you want to pay for this request. USD price per million tokens, for prompt and completion."""

    prompt: int
    completion: int
    image: int
    audio: int
    request: int

# pydantic_ai_slim/pydantic_ai/embeddings/base.py:95-101
    async def max_input_tokens(self) -> int | None:
        """Get the maximum number of tokens that can be input to the model.

        Returns:
            The maximum token count, or `None` if unknown.
        """
        return None  # pragma: no cover

# pydantic_evals/pydantic_evals/evaluators/common.py:156-161
    def evaluate(self, ctx: EvaluatorContext[object, object, object]) -> bool:
        duration = timedelta(seconds=ctx.duration)
        seconds = self.seconds
        if not isinstance(seconds, timedelta):
            seconds = timedelta(seconds=seconds)
        return duration <= seconds

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:53-53
    image: int

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:54-54
    audio: int

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:51-51
    prompt: int

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:55-55
    request: int

# tests/test_tenacity.py:422-441
    def test_retry_after_seconds_respects_max_wait(self):
        """Test that max_wait is respected for seconds format."""
        fallback = Mock()
        wait_func = wait_retry_after(fallback_strategy=fallback, max_wait=60)

        # Create HTTP status error with Retry-After > max_wait
        request = httpx.Request('GET', 'https://example.com')
        response = Mock(spec=httpx.Response)
        response.headers = {'retry-after': '120'}
        http_error = httpx.HTTPStatusError('Rate limited', request=request, response=response)

        retry_state = Mock(spec=RetryCallState)
        retry_state.outcome = Mock()
        retry_state.outcome.failed = True
        retry_state.outcome.exception.return_value = http_error

        result = wait_func(retry_state)

        assert result == 60.0  # Capped at max_wait
        fallback.assert_not_called()

# tests/test_tenacity.py:494-517
    def test_retry_after_http_date_respects_max_wait(self):
        """Test that max_wait is respected for HTTP date format."""
        fallback = Mock()
        wait_func = wait_retry_after(fallback_strategy=fallback, max_wait=60)

        # Create a future date (120 seconds from now, > max_wait)
        future_time = datetime.now(timezone.utc).timestamp() + 120
        http_date = formatdate(future_time, usegmt=True)

        # Create HTTP status error with Retry-After in HTTP date format
        request = httpx.Request('GET', 'https://example.com')
        response = Mock(spec=httpx.Response)
        response.headers = {'retry-after': http_date}
        http_error = httpx.HTTPStatusError('Rate limited', request=request, response=response)

        retry_state = Mock(spec=RetryCallState)
        retry_state.outcome = Mock()
        retry_state.outcome.failed = True
        retry_state.outcome.exception.return_value = http_error

        result = wait_func(retry_state)

        assert result == 60.0  # Capped at max_wait
        fallback.assert_not_called()

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:52-52
    completion: int

# tests/test_embeddings.py:1082-1085
    async def test_unknown_model_max_tokens_returns_none(self, bedrock_provider: BedrockProvider):
        """Test that unknown models with valid prefixes return None for max_input_tokens."""
        model = BedrockEmbeddingModel('amazon.titan-embed-text-v99:0', provider=bedrock_provider)
        assert await model.max_input_tokens() is None

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# pydantic_ai_slim/pydantic_ai/mcp.py:241-241
    tools_list_changed: bool = False