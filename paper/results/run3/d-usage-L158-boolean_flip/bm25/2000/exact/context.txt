# pydantic_ai_slim/pydantic_ai/usage.py:200-200
    details: dict[str, int] = dataclasses.field(default_factory=dict[str, int])

# pydantic_ai_slim/pydantic_ai/usage.py:46-50
    details: Annotated[
        dict[str, int],
        # `details` can not be `None` any longer, but we still want to support deserializing model responses stored in a DB before this was changed
        BeforeValidator(lambda d: d or {}),
    ] = dataclasses.field(default_factory=dict[str, int])

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:443-443
    cost_details: _OpenRouterCostDetails | None = None

# pydantic_ai_slim/pydantic_ai/models/gemini.py:905-907
    candidates_tokens_details: NotRequired[
        Annotated[list[_GeminiModalityTokenCount], pydantic.Field(alias='candidatesTokensDetails')]
    ]

# examples/pydantic_ai_examples/flight_booking.py:28-35
class FlightDetails(BaseModel):
    """Details of the most suitable flight."""

    flight_number: str
    price: int
    origin: str = Field(description='Three-letter airport code')
    destination: str = Field(description='Three-letter airport code')
    date: datetime.date

# tests/test_agent.py:15-15
from pydantic_core import ErrorDetails, to_json

# tests/test_agent.py:15-15
from pydantic_core import ErrorDetails, to_json

# tests/test_agent.py:15-15
from pydantic_core import ErrorDetails, to_json

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:447-447
    prompt_tokens_details: _OpenRouterPromptTokenDetails | None = None  # type: ignore[reportIncompatibleVariableOverride]

# pydantic_ai_slim/pydantic_ai/messages.py:927-927
error_details_ta = pydantic.TypeAdapter(list[pydantic_core.ErrorDetails], config=pydantic.ConfigDict(defer_build=True))

# pydantic_ai_slim/pydantic_ai/models/gemini.py:902-904
    cache_tokens_details: NotRequired[
        Annotated[list[_GeminiModalityTokenCount], pydantic.Field(alias='cacheTokensDetails')]
    ]

# pydantic_ai_slim/pydantic_ai/models/gemini.py:899-901
    prompt_tokens_details: NotRequired[
        Annotated[list[_GeminiModalityTokenCount], pydantic.Field(alias='promptTokensDetails')]
    ]

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:449-449
    completion_tokens_details: _OpenRouterCompletionTokenDetails | None = None  # type: ignore[reportIncompatibleVariableOverride]

# pydantic_ai_slim/pydantic_ai/_parts_manager.py:21-34
from pydantic_ai.messages import (
    BuiltinToolCallPart,
    ModelResponsePart,
    ModelResponseStreamEvent,
    PartDeltaEvent,
    PartStartEvent,
    ProviderDetailsDelta,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolCallPartDelta,
)

# pydantic_ai_slim/pydantic_ai/_parts_manager.py:21-34
from pydantic_ai.messages import (
    BuiltinToolCallPart,
    ModelResponsePart,
    ModelResponseStreamEvent,
    PartDeltaEvent,
    PartStartEvent,
    ProviderDetailsDelta,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolCallPartDelta,
)

# pydantic_ai_slim/pydantic_ai/_parts_manager.py:21-34
from pydantic_ai.messages import (
    BuiltinToolCallPart,
    ModelResponsePart,
    ModelResponseStreamEvent,
    PartDeltaEvent,
    PartStartEvent,
    ProviderDetailsDelta,
    TextPart,
    TextPartDelta,
    ThinkingPart,
    ThinkingPartDelta,
    ToolCallPart,
    ToolCallPartDelta,
)

# pydantic_ai_slim/pydantic_ai/messages.py:1081-1081
    provider_details: dict[str, Any] | None = None

# pydantic_ai_slim/pydantic_ai/messages.py:1171-1171
    provider_details: dict[str, Any] | None = None

# pydantic_ai_slim/pydantic_ai/messages.py:1533-1534
    def vendor_details(self) -> dict[str, Any] | None:
        return self.provider_details

# pydantic_ai_slim/pydantic_ai/models/openai.py:2825-2836
def _map_provider_details(
    choice: chat_completion_chunk.Choice | chat_completion.Choice,
) -> dict[str, Any] | None:
    provider_details: dict[str, Any] = {}

    # Add logprobs to vendor_details if available
    if choice.logprobs is not None and choice.logprobs.content:
        provider_details['logprobs'] = _map_logprobs(choice.logprobs.content)
    if raw_finish_reason := choice.finish_reason:
        provider_details['finish_reason'] = raw_finish_reason

    return provider_details or None

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:417-420
class _OpenRouterCostDetails:
    """OpenRouter specific cost details."""

    upstream_inference_cost: float | None = None

# pydantic_ai_slim/pydantic_ai/messages.py:1133-1133
    provider_details: dict[str, Any] | None = None

# pydantic_ai_slim/pydantic_ai/messages.py:1327-1331
    provider_details: Annotated[
        dict[str, Any] | None,
        # `vendor_details` is deprecated, but we still want to support deserializing model responses stored in a DB before the name was changed
        pydantic.Field(validation_alias=pydantic.AliasChoices('provider_details', 'vendor_details')),
    ] = None

# pydantic_ai_slim/pydantic_ai/messages.py:1573-1573
    provider_details: dict[str, Any] | None = None

# tests/models/test_openrouter.py:347-378
async def test_openrouter_with_provider_details_but_no_parent_details(openrouter_api_key: str) -> None:
    from typing import Any

    class TestOpenRouterModel(OpenRouterModel):
        def _process_provider_details(self, response: ChatCompletion) -> dict[str, Any] | None:
            from pydantic_ai.models.openrouter import (
                _map_openrouter_provider_details,  # pyright: ignore[reportPrivateUsage]
                _OpenRouterChatCompletion,  # pyright: ignore[reportPrivateUsage]
            )

            assert isinstance(response, _OpenRouterChatCompletion)
            openrouter_details = _map_openrouter_provider_details(response)
            return openrouter_details or None

    provider = OpenRouterProvider(api_key=openrouter_api_key)
    model = TestOpenRouterModel('google/gemini-2.0-flash-exp:free', provider=provider)

    choice = Choice.model_construct(
        index=0, message={'role': 'assistant', 'content': 'test'}, finish_reason='stop', native_finish_reason='stop'
    )
    response = ChatCompletion.model_construct(
        id='test', choices=[choice], created=1704067200, object='chat.completion', model='test', provider='TestProvider'
    )
    result = model._process_response(response)  # type: ignore[reportPrivateUsage]

    assert result.provider_details == snapshot(
        {
            'downstream_provider': 'TestProvider',
            'finish_reason': 'stop',
            'timestamp': datetime.datetime(2024, 1, 1, 0, 0, tzinfo=datetime.timezone.utc),
        }
    )

# pydantic_ai_slim/pydantic_ai/embeddings/result.py:79-79
    provider_details: dict[str, Any] | None = None

# pydantic_ai_slim/pydantic_ai/messages.py:1223-1223
    provider_details: dict[str, Any] | None = None

# pydantic_ai_slim/pydantic_ai/models/__init__.py:928-928
    provider_details: dict[str, Any] | None = field(default=None, init=False)

# pydantic_ai_slim/pydantic_ai/messages.py:1628-1628
    provider_details: ProviderDetailsDelta = None

# pydantic_ai_slim/pydantic_ai/messages.py:1743-1743
    provider_details: dict[str, Any] | None = None

# pydantic_ai_slim/pydantic_ai/models/gemini.py:908-910
    tool_use_prompt_tokens_details: NotRequired[
        Annotated[list[_GeminiModalityTokenCount], pydantic.Field(alias='toolUsePromptTokensDetails')]
    ]

# pydantic_ai_slim/pydantic_ai/messages.py:917-917
    provider_details: dict[str, Any] | None = None

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:613-613
    reasoning_details: list[_OpenRouterReasoningDetail] | None = None

# tests/models/test_mistral.py:82-83
    def get_server_details(self) -> tuple[str, ...]:
        return ('https://api.mistral.ai',)

# tests/models/test_xai.py:3246-3261
async def test_xai_usage_without_details(allow_model_requests: None):
    """Test that xAI model handles usage without reasoning_tokens or cached tokens."""
    mock_usage = create_usage(prompt_tokens=20, completion_tokens=10)
    response = create_response(
        content='Simple answer',
        usage=mock_usage,
    )
    mock_client = MockXai.create_mock([response])
    m = XaiModel(XAI_REASONING_MODEL, provider=XaiProvider(xai_client=mock_client))
    agent = Agent(m)

    result = await agent.run('Simple question')
    assert result.output == 'Simple answer'

    # Verify usage without details (empty dict when no additional usage info)
    assert result.usage() == snapshot(RunUsage(input_tokens=20, output_tokens=10, requests=1))

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:390-390
    reasoning_details: list[_OpenRouterReasoningDetail] | None = None

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:468-487
def _map_openrouter_provider_details(
    response: _OpenRouterChatCompletion | _OpenRouterChatCompletionChunk,
) -> dict[str, Any]:
    provider_details: dict[str, Any] = {}

    provider_details['downstream_provider'] = response.provider
    if native_finish_reason := response.choices[0].native_finish_reason:
        provider_details['finish_reason'] = native_finish_reason

    if usage := response.usage:
        if cost := usage.cost:
            provider_details['cost'] = cost

        if cost_details := usage.cost_details:
            provider_details['upstream_inference_cost'] = cost_details.upstream_inference_cost

        if (is_byok := usage.is_byok) is not None:
            provider_details['is_byok'] = is_byok

    return provider_details

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:569-574
    def _process_provider_details(self, response: chat.ChatCompletion) -> dict[str, Any] | None:
        assert isinstance(response, _OpenRouterChatCompletion)

        provider_details = super()._process_provider_details(response) or {}
        provider_details.update(_map_openrouter_provider_details(response))
        return provider_details or None

# tests/models/test_openrouter.py:487-507
async def test_openrouter_no_openrouter_details(openrouter_api_key: str) -> None:
    """Test _process_provider_details when _map_openrouter_provider_details returns empty dict."""
    from unittest.mock import patch

    provider = OpenRouterProvider(api_key=openrouter_api_key)
    model = OpenRouterModel('google/gemini-2.0-flash-exp:free', provider=provider)

    choice = Choice.model_construct(
        index=0, message={'role': 'assistant', 'content': 'test'}, finish_reason='stop', native_finish_reason='stop'
    )
    response = ChatCompletion.model_construct(
        id='test', choices=[choice], created=1704067200, object='chat.completion', model='test', provider='TestProvider'
    )

    with patch('pydantic_ai.models.openrouter._map_openrouter_provider_details', return_value={}):
        result = model._process_response(response)  # type: ignore[reportPrivateUsage]

    # With empty openrouter_details, we should still get the parent's provider_details (timestamp + finish_reason)
    assert result.provider_details == snapshot(
        {'finish_reason': 'stop', 'timestamp': datetime.datetime(2024, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)}
    )

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:687-692
    def _map_provider_details(self, chunk: chat.ChatCompletionChunk) -> dict[str, Any] | None:
        assert isinstance(chunk, _OpenRouterChatCompletionChunk)

        provider_details = super()._map_provider_details(chunk) or {}
        provider_details.update(_map_openrouter_provider_details(chunk))
        return provider_details or None

# examples/pydantic_ai_examples/flight_booking.py:35-35
    date: datetime.date

# examples/pydantic_ai_examples/flight_booking.py:32-32
    price: int

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:578-578
        reasoning_details: list[dict[str, Any]] = field(default_factory=list[dict[str, Any]])

# examples/pydantic_ai_examples/flight_booking.py:33-33
    origin: str = Field(description='Three-letter airport code')

# pydantic_ai_slim/pydantic_ai/models/openai.py:2314-2319
    def _map_provider_details(self, chunk: ChatCompletionChunk) -> dict[str, Any] | None:
        """Hook that generates the provider details from chunk content.

        This method may be overridden by subclasses of `OpenAIStreamResponse` to customize the provider details.
        """
        return _map_provider_details(chunk.choices[0])

# examples/pydantic_ai_examples/flight_booking.py:34-34
    destination: str = Field(description='Three-letter airport code')

# examples/pydantic_ai_examples/flight_booking.py:31-31
    flight_number: str

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:429-429
    video_tokens: int | None = None