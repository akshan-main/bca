## pydantic_ai_slim/pydantic_ai/__init__.py

from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

## pydantic_ai_slim/pydantic_ai/_function_schema.py

    json_schema: ObjectJsonSchema

## pydantic_ai_slim/pydantic_ai/_output.py

    async def get_tools(self, ctx: RunContext[AgentDepsT]) -> dict[str, ToolsetTool[AgentDepsT]]:
        return {
            tool_def.name: ToolsetTool(
                toolset=self,
                tool_def=tool_def,
                max_retries=self.max_retries,
                args_validator=self.processors[tool_def.name].validator,
            )
            for tool_def in self._tool_defs
        }

## pydantic_ai_slim/pydantic_ai/agent/wrapper.py

    def toolsets(self) -> Sequence[AbstractToolset[AgentDepsT]]:
        return self.wrapped.toolsets

## pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_agent.py

    def toolsets(self) -> Sequence[AbstractToolset[AgentDepsT]]:
        with self._dbos_overrides():
            return super().toolsets

## pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_mcp.py

    async def get_tools(self, ctx: RunContext[AgentDepsT]) -> dict[str, ToolsetTool[AgentDepsT]]:
        tool_defs = await self._dbos_wrapped_get_tools_step(ctx)
        return {name: self.tool_for_tool_def(tool_def) for name, tool_def in tool_defs.items()}

## pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_agent.py

    def toolsets(self) -> Sequence[AbstractToolset[AgentDepsT]]:
        with self._prefect_overrides():
            return super().toolsets

## pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_agent.py

    def toolsets(self) -> Sequence[AbstractToolset[AgentDepsT]]:
        with self._temporal_overrides(force=True):
            return super().toolsets

## pydantic_ai_slim/pydantic_ai/output.py

    json_schema: ObjectJsonSchema

## pydantic_ai_slim/pydantic_ai/toolsets/_dynamic.py

    async def get_tools(self, ctx: RunContext[AgentDepsT]) -> dict[str, ToolsetTool[AgentDepsT]]:
        if self._toolset is None or (self.per_run_step and ctx.run_step != self._run_step):
            if self._toolset is not None:
                await self._toolset.__aexit__()

            toolset = self.toolset_func(ctx)
            if inspect.isawaitable(toolset):
                toolset = await toolset

            if toolset is not None:
                await toolset.__aenter__()

            self._toolset = toolset
            self._run_step = ctx.run_step

        if self._toolset is None:
            return {}

        return await self._toolset.get_tools(ctx)

## pydantic_ai_slim/pydantic_ai/toolsets/fastmcp.py

    async def get_tools(self, ctx: RunContext[AgentDepsT]) -> dict[str, ToolsetTool[AgentDepsT]]:
        async with self:
            return {
                mcp_tool.name: self.tool_for_tool_def(
                    ToolDefinition(
                        name=mcp_tool.name,
                        description=mcp_tool.description,
                        parameters_json_schema=mcp_tool.inputSchema,
                        metadata={
                            'meta': mcp_tool.meta,
                            'annotations': mcp_tool.annotations.model_dump() if mcp_tool.annotations else None,
                            'output_schema': mcp_tool.outputSchema or None,
                        },
                    )
                )
                for mcp_tool in await self.client.list_tools()
            }

## pydantic_ai_slim/pydantic_ai/toolsets/filtered.py

    async def get_tools(self, ctx: RunContext[AgentDepsT]) -> dict[str, ToolsetTool[AgentDepsT]]:
        return {
            name: tool for name, tool in (await super().get_tools(ctx)).items() if self.filter_func(ctx, tool.tool_def)
        }

## pydantic_ai_slim/pydantic_ai/toolsets/prepared.py

class PreparedToolset(WrapperToolset[AgentDepsT]):
    """A toolset that prepares the tools it contains using a prepare function that takes the agent context and the original tool definitions.

    See [toolset docs](../toolsets.md#preparing-tool-definitions) for more information.
    """

    prepare_func: ToolsPrepareFunc[AgentDepsT]

    async def get_tools(self, ctx: RunContext[AgentDepsT]) -> dict[str, ToolsetTool[AgentDepsT]]:
        original_tools = await super().get_tools(ctx)
        original_tool_defs = [tool.tool_def for tool in original_tools.values()]
        prepared_tool_defs_by_name = {
            tool_def.name: tool_def for tool_def in (await self.prepare_func(ctx, original_tool_defs) or [])
        }

        if len(prepared_tool_defs_by_name.keys() - original_tools.keys()) > 0:
            raise UserError(
                'Prepare function cannot add or rename tools. Use `FunctionToolset.add_function()` or `RenamedToolset` instead.'
            )

        return {
            name: replace(original_tools[name], tool_def=tool_def)
            for name, tool_def in prepared_tool_defs_by_name.items()
        }

    async def get_tools(self, ctx: RunContext[AgentDepsT]) -> dict[str, ToolsetTool[AgentDepsT]]:
        original_tools = await super().get_tools(ctx)
        original_tool_defs = [tool.tool_def for tool in original_tools.values()]
        prepared_tool_defs_by_name = {
            tool_def.name: tool_def for tool_def in (await self.prepare_func(ctx, original_tool_defs) or [])
        }

        if len(prepared_tool_defs_by_name.keys() - original_tools.keys()) > 0:
            raise UserError(
                'Prepare function cannot add or rename tools. Use `FunctionToolset.add_function()` or `RenamedToolset` instead.'
            )

        return {
            name: replace(original_tools[name], tool_def=tool_def)
            for name, tool_def in prepared_tool_defs_by_name.items()
        }

## pydantic_ai_slim/pydantic_ai/ui/__init__.py

from ._adapter import StateDeps, StateHandler, UIAdapter

## pydantic_ai_slim/pydantic_ai/ui/ag_ui/_adapter.py

class _AGUIFrontendToolset(ExternalToolset[AgentDepsT]):
    """Toolset for AG-UI frontend tools."""

    def __init__(self, tools: list[AGUITool]):
        """Initialize the toolset with AG-UI tools.

        Args:
            tools: List of AG-UI tool definitions.
        """
        super().__init__(
            [
                ToolDefinition(
                    name=tool.name,
                    description=tool.description,
                    parameters_json_schema=tool.parameters,
                )
                for tool in tools
            ]
        )

    @property
    def label(self) -> str:
        """Return the label for this toolset."""
        return 'the AG-UI frontend tools'  # pragma: no cover

    def toolset(self) -> AbstractToolset[AgentDepsT] | None:
        """Toolset representing frontend tools from the AG-UI run input."""
        if self.run_input.tools:
            return _AGUIFrontendToolset[AgentDepsT](self.run_input.tools)
        return None

## pydantic_graph/pydantic_graph/beta/mermaid.py

def _topological_sort(
    nodes: list[MermaidNode], edges: list[MermaidEdge]
) -> tuple[list[MermaidNode], list[MermaidEdge]]:
    """Sort nodes and edges in a logical topological order.

    Uses BFS from the start node to assign depths, then sorts:
    - Nodes by their distance from start
    - Edges by the distance of their source and target nodes
    """
    # Build adjacency list for BFS
    adjacency: dict[str, list[str]] = defaultdict(list)
    for edge in edges:
        adjacency[edge.start_id].append(edge.end_id)

    # BFS to assign depth to each node (distance from start)
    depths: dict[str, int] = {}
    queue: list[tuple[str, int]] = [(StartNode.id, 0)]
    depths[StartNode.id] = 0

    while queue:
        node_id, depth = queue.pop(0)
        for next_id in adjacency[node_id]:
            if next_id not in depths:  # pragma: no branch
                depths[next_id] = depth + 1
                queue.append((next_id, depth + 1))

    # Sort nodes by depth (distance from start), then by id for stability
    # Nodes not reachable from start get infinity depth (sorted to end)
    sorted_nodes = sorted(nodes, key=lambda n: (depths.get(n.id, float('inf')), n.id))

    # Sort edges by source depth, then target depth
    # This ensures edges closer to start come first, edges closer to end come last
    sorted_edges = sorted(
        edges,
        key=lambda e: (
            depths.get(e.start_id, float('inf')),
            depths.get(e.end_id, float('inf')),
            e.start_id,
            e.end_id,
        ),
    )

    return sorted_nodes, sorted_edges

## tests/evals/test_otel.py

async def test_span_query_logical_combinations():
    """Test logical combinations (AND/OR) in SpanQuery."""

    with context_subtree() as tree:
        with logfire.span('root1', level='0'):
            with logfire.span('child1', level='1', category='important'):
                pass
            with logfire.span('child2', level='1', category='normal'):
                pass
            with logfire.span('special', level='1', category='important', priority='high'):
                pass
    assert isinstance(tree, SpanTree)

    # Test AND logic
    and_query: SpanQuery = {'and_': [{'name_contains': '1'}, {'has_attributes': {'level': '1'}}]}
    matched_nodes = list(tree.find(and_query))
    assert len(matched_nodes) == 1, matched_nodes
    assert all(node.name in ['child1'] for node in matched_nodes)

    # Test OR logic
    or_query: SpanQuery = {'or_': [{'name_contains': '2'}, {'has_attributes': {'level': '0'}}]}
    matched_nodes = list(tree.find(or_query))
    assert len(matched_nodes) == 2
    assert any(node.name == 'child2' for node in matched_nodes)
    assert any(node.attributes.get('level') == '0' for node in matched_nodes)

    # Test complex combination (AND + OR)
    complex_query: SpanQuery = {
        'and_': [
            {'has_attributes': {'level': '1'}},
            {'or_': [{'has_attributes': {'category': 'important'}}, {'name_equals': 'child2'}]},
        ]
    }
    matched_nodes = list(tree.find(complex_query))
    assert len(matched_nodes) == 3  # child1, child2, special
    matched_names = [node.name for node in matched_nodes]
    assert set(matched_names) == {'child1', 'child2', 'special'}

## tests/test_fastmcp.py

    async def test_context_manager_no_enter(
        self, fastmcp_client: Client[FastMCPTransport], run_context: RunContext[None]
    ):
        """Test no enter/exit cycle."""
        toolset = FastMCPToolset(fastmcp_client)

        # Test that we can get tools when the context is not active
        tools = await toolset.get_tools(run_context)
        assert len(tools) > 0
        assert 'test_tool' in tools

## tests/test_mcp.py

async def test_stdio_server(run_context: RunContext[int]):
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        tools = [tool.tool_def for tool in (await server.get_tools(run_context)).values()]
        assert len(tools) == snapshot(20)
        assert tools[0].name == 'celsius_to_fahrenheit'
        assert isinstance(tools[0].description, str)
        assert tools[0].description.startswith('Convert Celsius to Fahrenheit.')

        # Test calling the temperature conversion tool
        result = await server.direct_call_tool('celsius_to_fahrenheit', {'celsius': 0})
        assert result == snapshot(32.0)

async def test_stdio_server_with_tool_prefix(run_context: RunContext[int]):
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'], tool_prefix='foo')
    async with server:
        tools = await server.get_tools(run_context)
        assert all(name.startswith('foo_') for name in tools.keys())

        result = await server.call_tool(
            'foo_celsius_to_fahrenheit', {'celsius': 0}, run_context, tools['foo_celsius_to_fahrenheit']
        )
        assert result == snapshot(32.0)

async def test_stdio_server_with_cwd(run_context: RunContext[int]):
    test_dir = Path(__file__).parent
    server = MCPServerStdio('python', ['mcp_server.py'], cwd=test_dir)
    async with server:
        tools = await server.get_tools(run_context)
        assert len(tools) == snapshot(20)

async def test_tool_metadata_extraction():
    """Test that MCP tool metadata is properly extracted into ToolDefinition."""

    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        ctx = RunContext(deps=None, model=TestModel(), usage=RunUsage())
        tools = [tool.tool_def for tool in (await server.get_tools(ctx)).values()]
        # find `celsius_to_fahrenheit`
        celsius_to_fahrenheit = next(tool for tool in tools if tool.name == 'celsius_to_fahrenheit')
        assert celsius_to_fahrenheit.metadata is not None
        assert celsius_to_fahrenheit.metadata.get('annotations') is not None
        assert celsius_to_fahrenheit.metadata.get('annotations', {}).get('title', None) == 'Celsius to Fahrenheit'
        assert celsius_to_fahrenheit.metadata.get('output_schema') is not None
        assert celsius_to_fahrenheit.metadata.get('output_schema', {}).get('type', None) == 'object'

## tests/test_prefect.py

def conditions(city: str) -> str:
    # Simplified version without RunContext
    return "It's raining"

## tests/test_toolsets.py

async def test_visit_and_replace():
    toolset1 = FunctionToolset(id='toolset1')
    toolset2 = FunctionToolset(id='toolset2')

    run_ctx = build_run_context(None)

    active_dynamic_toolset = DynamicToolset(toolset_func=lambda ctx: toolset2)
    await active_dynamic_toolset.get_tools(run_ctx)
    assert active_dynamic_toolset._toolset is not None  # pyright: ignore[reportPrivateUsage]
    assert active_dynamic_toolset._toolset is toolset2  # pyright: ignore[reportPrivateUsage]

    inactive_dynamic_toolset = DynamicToolset(toolset_func=lambda ctx: FunctionToolset())

    toolset = CombinedToolset(
        [
            WrapperToolset(toolset1),
            active_dynamic_toolset,
            inactive_dynamic_toolset,
        ]
    )
    visited_toolset = toolset.visit_and_replace(lambda toolset: WrapperToolset(toolset))

    expected_dynamic = DynamicToolset(
        toolset_func=active_dynamic_toolset.toolset_func,
        per_run_step=active_dynamic_toolset.per_run_step,
        id=active_dynamic_toolset._id,  # pyright: ignore[reportPrivateUsage]
    )
    expected_dynamic._toolset = WrapperToolset(toolset2)  # pyright: ignore[reportPrivateUsage]
    expected_dynamic._run_step = active_dynamic_toolset._run_step  # pyright: ignore[reportPrivateUsage]

    assert visited_toolset == CombinedToolset(
        [
            WrapperToolset(WrapperToolset(toolset1)),
            expected_dynamic,
            WrapperToolset(inactive_dynamic_toolset),
        ]
    )

async def test_dynamic_toolset_empty():
    def no_toolset_func(ctx: RunContext[None]) -> None:
        return None

    toolset = DynamicToolset[None](toolset_func=no_toolset_func)

    run_context = build_run_context(None)

    tools = await toolset.get_tools(run_context)

    assert tools == {}

    async with toolset:
        assert toolset._toolset is None  # pyright: ignore[reportPrivateUsage]

        tools = await toolset.get_tools(run_context)

        assert tools == {}

        assert toolset._toolset is None  # pyright: ignore[reportPrivateUsage]

## tests/test_ui.py

class DummyUIAdapter(UIAdapter[DummyUIRunInput, ModelMessage, str, AgentDepsT, OutputDataT]):
    @classmethod
    def build_run_input(cls, body: bytes) -> DummyUIRunInput:
        return DummyUIRunInput.model_validate_json(body)

    @classmethod
    def dump_messages(cls, messages: Sequence[ModelMessage]) -> list[ModelMessage]:
        return list(messages)

    @classmethod
    def load_messages(cls, messages: Sequence[ModelMessage]) -> list[ModelMessage]:
        return list(messages)

    def build_event_stream(self) -> UIEventStream[DummyUIRunInput, str, AgentDepsT, OutputDataT]:
        return DummyUIEventStream[AgentDepsT, OutputDataT](self.run_input, accept=self.accept)

    @cached_property
    def messages(self) -> list[ModelMessage]:
        return self.load_messages(self.run_input.messages)

    @cached_property
    def state(self) -> dict[str, Any] | None:
        return self.run_input.state

    @cached_property
    def toolset(self) -> AbstractToolset[AgentDepsT] | None:
        return ExternalToolset(self.run_input.tool_defs) if self.run_input.tool_defs else None

    def toolset(self) -> AbstractToolset[AgentDepsT] | None:
        return ExternalToolset(self.run_input.tool_defs) if self.run_input.tool_defs else None
