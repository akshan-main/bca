{
  "task_id": "usage-check-tokens-output-inverted",
  "method": "vector",
  "budget": 2000,
  "query_type": "vague",
  "tokens_used": 2000,
  "symbols_selected": 20,
  "files_included": 17,
  "assembly_time_ms": 155.6,
  "llm_time_ms": 8054.3,
  "llm_input_tokens": 2818,
  "llm_output_tokens": 271,
  "tests_passed": false,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: pydantic_ai_slim/pydantic_ai/agent/abstract.py\nSEARCH:\n        async def _consume_stream():\n            async with self.run_stream(\n                user_prompt,\n                output_type=output_type,\n                message_history=message_history,\n                deferred_tool_results=deferred_tool_results,\n                model=model,\n                deps=deps,\n                model_settings=model_settings,\n                usage_limits=usage_limits,\n                usage=usage,\n                metadata=metadata,\n                infer_name=infer_name,\n                toolsets=toolsets,\n                builtin_tools=builtin_tools,\n                event_stream_handler=event_stream_handler,\n            ) as stream_result:\n                yield stream_result\nREPLACE:\n        async def _consume_stream():\n            async with self.run_stream(\n                user_prompt,\n                output_type=output_type,\n                message_history=message_history,\n                deferred_tool_results=deferred_tool_results,\n                model=model,\n                deps=deps,\n                model_settings=model_settings,\n                usage_limits=usage_limits,\n                usage=usage,\n                metadata=metadata,\n                infer_name=infer_name,\n                toolsets=toolsets,\n                builtin_tools=builtin_tools,\n                event_stream_handler=event_stream_handler,\n                output_tokens_limit=output_tokens_limit,  # Add this line\n            ) as stream_result:\n                yield stream_result\n",
  "error": "",
  "test_time_ms": 1324.5,
  "failure_mode": "test_fail",
  "target_file_hit": true,
  "target_symbol_hit": true,
  "context_patch_overlap": 0.059,
  "patch_files_changed": 1,
  "patch_lines_changed": 19,
  "edit_distance_lines": -1,
  "entity_count_extracted": 1,
  "entity_count_mapped": 1,
  "query_identifier_density": 0.0625,
  "seed_symbol_keys": [
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.output_tokens_limit"
  ],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.check_tokens",
  "min_hops_seed_to_mutation": 2,
  "median_hops_seed_to_mutation": 2.0,
  "bca_closure_added_symbols": 0,
  "bca_closure_added_tokens": 0,
  "bca_frontier_visited": 0,
  "context_symbol_keys": [
    "examples/pydantic_ai_examples/ag_ui/api/agentic_chat.py::agent",
    "examples/pydantic_ai_examples/ag_ui/api/agentic_generative_ui.py::agent",
    "examples/pydantic_ai_examples/ag_ui/api/agentic_generative_ui.py::create_plan",
    "examples/pydantic_ai_examples/ag_ui/api/agentic_generative_ui.py::update_plan_step",
    "examples/pydantic_ai_examples/ag_ui/api/human_in_the_loop.py::agent",
    "examples/pydantic_ai_examples/data_analyst.py::AnalystAgentDeps.output",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::RunOutputDataT",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::EventStreamHandler",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::AgentMetadata",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::AbstractAgent",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::AbstractAgent.run",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::AbstractAgent.run_stream",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::AbstractAgent.run_stream_sync",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::AbstractAgent.iter",
    "pydantic_ai_slim/pydantic_ai/output.py::OutputDataT",
    "pydantic_ai_slim/pydantic_ai/output.py::OutputTypeOrFunction",
    "pydantic_ai_slim/pydantic_ai/output.py::ToolOutput.output",
    "pydantic_ai_slim/pydantic_ai/output.py::OutputSpec",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync",
    "pydantic_ai_slim/pydantic_ai/result.py::FinalResult.output",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResult.output",
    "pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py::ToolOutputAvailablePart.output",
    "pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py::DynamicToolOutputAvailablePart.output",
    "pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py::ToolOutputAvailableChunk.output",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::Usage",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits",
    "pydantic_evals/pydantic_evals/evaluators/common.py::Equals.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/common.py::EqualsExpected.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/common.py::_truncated_repr",
    "pydantic_evals/pydantic_evals/evaluators/common.py::Contains",
    "pydantic_evals/pydantic_evals/evaluators/common.py::Contains.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/common.py::IsInstance.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/common.py::MaxDuration.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/common.py::LLMJudge.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/common.py::HasMatchingSpan.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/context.py::OutputT",
    "pydantic_evals/pydantic_evals/evaluators/context.py::EvaluatorContext",
    "pydantic_evals/pydantic_evals/evaluators/context.py::EvaluatorContext.output",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::OutputT",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::ReportCase.output",
    "pydantic_graph/pydantic_graph/beta/graph.py::DepsT",
    "pydantic_graph/pydantic_graph/beta/graph.py::OutputT",
    "pydantic_graph/pydantic_graph/beta/graph.py::EndMarker",
    "pydantic_graph/pydantic_graph/beta/graph.py::GraphRun.output",
    "pydantic_graph/pydantic_graph/graph.py::GraphRunResult.output"
  ],
  "mutation_symbol_lines": 15,
  "mutation_symbol_kind": "method",
  "mutation_file_symbols": 65,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.001765,
  "retrieval_softmax_entropy": 4.3007,
  "retrieval_softmax_tau": 0.286858,
  "retrieval_effective_candidates": 19.71,
  "retrieval_top5_ratio": 0.9872,
  "retrieval_within95_count": 6,
  "retrieval_scored_symbols": 50,
  "retrieval_top1_score": 0.310457,
  "retrieval_top5_mean_score": 0.306484,
  "retrieval_budget_utilization": 1.0,
  "retrieval_file_concentration": 0.1,
  "repo_name": "pydantic-ai",
  "category": "usage",
  "mutation_type": "handcrafted",
  "source": "handcrafted"
}