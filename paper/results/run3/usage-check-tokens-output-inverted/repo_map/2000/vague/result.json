{
  "task_id": "usage-check-tokens-output-inverted",
  "method": "repo_map",
  "budget": 2000,
  "query_type": "vague",
  "tokens_used": 2000,
  "symbols_selected": 5,
  "files_included": 4,
  "assembly_time_ms": 54.6,
  "llm_time_ms": 4408.2,
  "llm_input_tokens": 2288,
  "llm_output_tokens": 159,
  "tests_passed": false,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: pydantic_ai_slim/pydantic_ai/agent/abstract.py\nSEARCH:\n        raise NotImplementedError\nREPLACE:\n        if self.usage_limits and self.usage_limits.output_tokens_limit is not None:\n            if self.usage_limits.output_tokens_limit <= 0:\n                raise ValueError(\"Output tokens limit must be greater than zero.\")\n            # Implement logic to enforce output token limit here\n        yield\n\nFILE: pydantic_ai_slim/pydantic_ai/_cli/__init__.py\nSEARCH:\n            result = await agent.run(prompt, message_history=messages, deps=deps)\nREPLACE:\n            result = await agent.run(prompt, message_history=messages, deps=deps, usage_limits=usage_limits)\n",
  "error": "",
  "test_time_ms": 1327.5,
  "failure_mode": "test_fail",
  "target_file_hit": true,
  "target_symbol_hit": true,
  "context_patch_overlap": 0.5,
  "patch_files_changed": 2,
  "patch_lines_changed": 6,
  "edit_distance_lines": -1,
  "entity_count_extracted": 1,
  "entity_count_mapped": 1,
  "query_identifier_density": 0.0625,
  "seed_symbol_keys": [
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.output_tokens_limit"
  ],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.check_tokens",
  "min_hops_seed_to_mutation": 2,
  "median_hops_seed_to_mutation": 2.0,
  "bca_closure_added_symbols": 0,
  "bca_closure_added_tokens": 0,
  "bca_frontier_visited": 0,
  "context_symbol_keys": [
    "examples/pydantic_ai_examples/data_analyst.py::AnalystAgentDeps.store",
    "pydantic_ai_slim/pydantic_ai/_cli/__init__.py::ask_agent",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::RunOutputDataT",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::Instructions",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::AgentMetadata",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::AbstractAgent",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::AbstractAgent.toolsets",
    "pydantic_ai_slim/pydantic_ai/agent/abstract.py::AbstractAgent.iter",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::Usage",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits"
  ],
  "mutation_symbol_lines": 15,
  "mutation_symbol_kind": "method",
  "mutation_file_symbols": 65,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.0,
  "retrieval_softmax_entropy": 0.0,
  "retrieval_softmax_tau": 0.0,
  "retrieval_effective_candidates": 0.0,
  "retrieval_top5_ratio": 0.0,
  "retrieval_within95_count": 0,
  "retrieval_scored_symbols": 0,
  "retrieval_top1_score": 0.0,
  "retrieval_top5_mean_score": 0.0,
  "retrieval_budget_utilization": 1.0,
  "retrieval_file_concentration": 0.4,
  "repo_name": "pydantic-ai",
  "category": "usage",
  "mutation_type": "handcrafted",
  "source": "handcrafted"
}