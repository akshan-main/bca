```
FILE: pydantic_ai_slim/pydantic_ai/agent/__init__.py
SEARCH:
    def run_stream(  # noqa: C901
        self,
        user_prompt: str | Sequence[_messages.UserContent] | None = None,
        *,
        output_type: OutputSpec[RunOutputDataT] | None = None,
        message_history: Sequence[_messages.ModelMessage] | None = None,
        deferred_tool_results: DeferredToolResults | None = None,
        model: models.Model | models.KnownModelName | str | None = None,
        instructions: Instructions[AgentDepsT] = None,
        deps: AgentDepsT = None,
        model_settings: ModelSettings | None = None,
        usage_limits: _usage.UsageLimits | None = None,
        usage: _usage.RunUsage | None = None,
        metadata: AgentMetadata[AgentDepsT] | None = None,
        infer_name: bool = True,
        toolsets: Sequence[AbstractToolset[AgentDepsT]] | None = None,
        builtin_tools: Sequence[AbstractBuiltinTool | BuiltinToolFunc[AgentDepsT]] | None = None,
        event_stream_handler: EventStreamHandler[AgentDepsT] | None = None,
    ) -> AsyncIterator[result.StreamedRunResult[AgentDepsT, Any]]:
        """Run the agent with a user prompt in async streaming mode.
        ...
        """
        ...
        if usage_limits is not None and usage_limits.output_tokens_limit is not None:
            # Check if the output exceeds the limit
            if self.output_schema and self.output_schema.output_tokens > usage_limits.output_tokens_limit:
                raise exceptions.AgentRunError('Output token limit exceeded')  # pragma: no cover
        ...
```

```
FILE: pydantic_ai_slim/pydantic_ai/agent/__init__.py
SEARCH:
        if not isinstance(next_node, _agent_graph.AgentNode):
SEARCH:
        if not isinstance(next_node, _agent_graph.AgentNode) or (usage_limits is not None and usage_limits.output_tokens_limit is not None and self.output_schema.output_tokens > usage_limits.output_tokens_limit):
```