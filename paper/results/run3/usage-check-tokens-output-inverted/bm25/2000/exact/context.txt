# pydantic_ai_slim/pydantic_ai/usage.py:266-266
    output_tokens_limit: int | None = None

# tests/test_usage_limits.py:394-455
async def test_parallel_tool_calls_limit_enforced():
    """Parallel tool calls must not exceed the limit and should raise immediately."""
    executed_tools: list[str] = []

    model_call_count = 0

    def test_model_function(messages: list[ModelMessage], info: AgentInfo) -> ModelResponse:
        nonlocal model_call_count
        model_call_count += 1

        if model_call_count == 1:
            # First response: 5 parallel tool calls (within limit)
            return ModelResponse(
                parts=[
                    ToolCallPart('tool_a', {}, 'call_1'),
                    ToolCallPart('tool_b', {}, 'call_2'),
                    ToolCallPart('tool_c', {}, 'call_3'),
                    ToolCallPart('tool_a', {}, 'call_4'),
                    ToolCallPart('tool_b', {}, 'call_5'),
                ]
            )
        else:
            assert model_call_count == 2
            # Second response: 3 parallel tool calls (would exceed limit of 6)
            return ModelResponse(
                parts=[
                    ToolCallPart('tool_c', {}, 'call_6'),
                    ToolCallPart('tool_a', {}, 'call_7'),
                    ToolCallPart('tool_b', {}, 'call_8'),
                ]
            )

    test_model = FunctionModel(test_model_function)
    agent = Agent(test_model)

    @agent.tool_plain
    async def tool_a() -> str:
        await asyncio.sleep(0.01)
        executed_tools.append('a')
        return 'result a'

    @agent.tool_plain
    async def tool_b() -> str:
        await asyncio.sleep(0.01)
        executed_tools.append('b')
        return 'result b'

    @agent.tool_plain
    async def tool_c() -> str:
        await asyncio.sleep(0.01)
        executed_tools.append('c')
        return 'result c'

    # Run with tool call limit of 6; expecting an error when trying to execute 3 more tools
    with pytest.raises(
        UsageLimitExceeded,
        match=re.escape('The next tool call(s) would exceed the tool_calls_limit of 6 (tool_calls=8).'),
    ):
        await agent.run('Use tools', usage_limits=UsageLimits(tool_calls_limit=6))

    # Only the first batch of 5 tools should have executed
    assert len(executed_tools) == 5

# pydantic_ai_slim/pydantic_ai/usage.py:384-398
    def check_tokens(self, usage: RunUsage) -> None:
        """Raises a `UsageLimitExceeded` exception if the usage exceeds any of the token limits."""
        input_tokens = usage.input_tokens
        if self.input_tokens_limit is not None and input_tokens > self.input_tokens_limit:
            raise UsageLimitExceeded(f'Exceeded the input_tokens_limit of {self.input_tokens_limit} ({input_tokens=})')

        output_tokens = usage.output_tokens
        if self.output_tokens_limit is None and output_tokens > self.output_tokens_limit:
            raise UsageLimitExceeded(
                f'Exceeded the output_tokens_limit of {self.output_tokens_limit} ({output_tokens=})'
            )

        total_tokens = usage.total_tokens
        if self.total_tokens_limit is not None and total_tokens > self.total_tokens_limit:
            raise UsageLimitExceeded(f'Exceeded the total_tokens_limit of {self.total_tokens_limit} ({total_tokens=})')

# pydantic_ai_slim/pydantic_ai/concurrency.py:276-295
def normalize_to_limiter(
    limit: AnyConcurrencyLimit,
    *,
    name: str | None = None,
) -> AbstractConcurrencyLimiter | None:
    """Normalize a concurrency limit configuration to an AbstractConcurrencyLimiter.

    Args:
        limit: The concurrency limit configuration.
        name: Optional name for the limiter if one is created.

    Returns:
        An AbstractConcurrencyLimiter if limit is not None, otherwise None.
    """
    if limit is None:
        return None
    elif isinstance(limit, AbstractConcurrencyLimiter):
        return limit
    else:
        return ConcurrencyLimiter.from_limit(limit, name=name)

# tests/test_concurrency.py:461-464
    async def test_limiter_without_name(self):
        """Test that limiter name is None by default."""
        limiter = ConcurrencyLimiter(max_running=5)
        assert limiter.name is None

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# tests/mcp_server.py:164-165
async def get_none():
    return None

# tests/profiles/test_anthropic.py:191-209
def test_strict_none_simple_schema():
    """With strict=None, simple schemas are not transformed (only title/$schema removed)."""

    class Person(BaseModel):
        name: str
        age: int

    transformer = AnthropicJsonSchemaTransformer(Person.model_json_schema(), strict=None)
    transformed = transformer.walk()

    assert transformer.is_strict_compatible is False
    # No additionalProperties added, title removed
    assert transformed == snapshot(
        {
            'type': 'object',
            'properties': {'name': {'type': 'string'}, 'age': {'type': 'integer'}},
            'required': ['name', 'age'],
        }
    )

# tests/test_concurrency.py:509-539
    async def test_unnamed_limiter_waiting_uses_source_in_span_name(self, capfire: CaptureLogfire):
        """Test that waiting without a limiter name uses source for span name."""
        limiter = ConcurrencyLimiter(max_running=1)  # No name
        hold = anyio.Event()

        async def holder():
            async with get_concurrency_context(limiter, 'model:gpt-4'):
                await hold.wait()

        async def waiter():
            async with get_concurrency_context(limiter, 'model:gpt-4'):
                pass

        async with anyio.create_task_group() as tg:
            tg.start_soon(holder)
            await anyio.sleep(0.01)

            tg.start_soon(waiter)
            await anyio.sleep(0.01)

            hold.set()

        # Verify span uses source in name when limiter has no name
        spans = capfire.exporter.exported_spans_as_dict()
        assert len(spans) == 1
        span = spans[0]
        assert span['name'] == 'waiting for model:gpt-4 concurrency'
        attrs = span['attributes']
        assert attrs['source'] == 'model:gpt-4'
        assert 'limiter_name' not in attrs  # Should not be present when name is None
        assert attrs['max_running'] == 1

# tests/profiles/test_openai.py:28-28
    supports_reasoning_effort_none: bool = False

# tests/profiles/test_anthropic.py:167-188
def test_strict_none_preserves_schema():
    """With strict=None (default), schemas are not transformed (only title/$schema removed)."""

    class User(BaseModel):
        username: Annotated[str, Field(min_length=3)]
        age: int

    transformer = AnthropicJsonSchemaTransformer(User.model_json_schema(), strict=None)
    transformed = transformer.walk()

    assert transformer.is_strict_compatible is False
    # Constraints preserved, title removed
    assert transformed == snapshot(
        {
            'type': 'object',
            'properties': {
                'username': {'minLength': 3, 'type': 'string'},
                'age': {'type': 'integer'},
            },
            'required': ['username', 'age'],
        }
    )

# pydantic_ai_slim/pydantic_ai/format_prompt.py:84-84
    none_str: str

# tests/test_tools.py:2665-2675
def test_tool_timeout_default_none():
    """Test that timeout defaults to None when not specified."""
    agent = Agent(TestModel())

    @agent.tool_plain
    def tool_without_timeout() -> str:
        return 'done'  # pragma: no cover

    tool = agent._function_toolset.tools['tool_without_timeout']
    assert tool.timeout is None
    assert tool.tool_def.timeout is None

# tests/typed_deps.py:53-54
async def my_prepare_none(ctx: RunContext, tool_defn: ToolDefinition) -> None:
    pass