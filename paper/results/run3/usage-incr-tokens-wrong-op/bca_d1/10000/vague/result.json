{
  "task_id": "usage-incr-tokens-wrong-op",
  "method": "bca_d1",
  "budget": 10000,
  "query_type": "vague",
  "tokens_used": 9498,
  "symbols_selected": 30,
  "files_included": 14,
  "assembly_time_ms": 717.5,
  "llm_time_ms": 5514.0,
  "llm_input_tokens": 8370,
  "llm_output_tokens": 169,
  "tests_passed": false,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: pydantic_ai_slim/pydantic_ai/models/__init__.py\nSEARCH:\n        return self._usage\nREPLACE:\n        return RequestUsage(input_tokens=self._usage.input_tokens, output_tokens=self._usage.output_tokens)\n\nFILE: pydantic_ai_slim/pydantic_ai/result.py\nSEARCH:\n        return self._initial_run_ctx_usage + self._raw_stream_response.usage()\nREPLACE:\n        return self._initial_run_ctx_usage + self._raw_stream_response.usage() if self._raw_stream_response else self._initial_run_ctx_usage\n\nFILE: pydantic_ai_slim/pydantic_ai/run.py\nSEARCH:\n        return self._graph_run.state.usage\nREPLACE:\n        return self._graph_run.state.usage if self._graph_run.state else RunUsage()\n",
  "error": "",
  "test_time_ms": 1501.2,
  "failure_mode": "test_fail",
  "target_file_hit": true,
  "target_symbol_hit": true,
  "context_patch_overlap": 0.214,
  "patch_files_changed": 3,
  "patch_lines_changed": 3,
  "edit_distance_lines": -1,
  "entity_count_extracted": 0,
  "entity_count_mapped": 0,
  "query_identifier_density": 0.0,
  "seed_symbol_keys": [],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/usage.py::_incr_usage_tokens",
  "min_hops_seed_to_mutation": -1,
  "median_hops_seed_to_mutation": -1.0,
  "bca_closure_added_symbols": 4,
  "bca_closure_added_tokens": 4106,
  "bca_frontier_visited": 20,
  "context_symbol_keys": [
    "pydantic_ai_slim/pydantic_ai/_run_context.py::RunContext.model",
    "pydantic_ai_slim/pydantic_ai/_run_context.py::RunContext.usage",
    "pydantic_ai_slim/pydantic_ai/_run_context.py::RunContext.__repr__",
    "pydantic_ai_slim/pydantic_ai/direct.py::model_request",
    "pydantic_ai_slim/pydantic_ai/direct.py::StreamedResponseSync.__repr__",
    "pydantic_ai_slim/pydantic_ai/direct.py::StreamedResponseSync.response",
    "pydantic_ai_slim/pydantic_ai/direct.py::StreamedResponseSync.usage",
    "pydantic_ai_slim/pydantic_ai/direct.py::StreamedResponseSync.model_name",
    "pydantic_ai_slim/pydantic_ai/direct.py::StreamedResponseSync.timestamp",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.__init__",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse._get_event_iterator",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.usage",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.model_name",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.provider_name",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.provider_url",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.timestamp",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectModel.__init__",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectModel.request",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_BedrockEmbeddingHandler.model_name",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_BedrockEmbeddingHandler.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_TitanEmbeddingHandler.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_CohereEmbeddingHandler.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::BedrockEmbeddingModel.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::BedrockEmbeddingModel.model_name",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::BedrockEmbeddingModel.system",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModelName",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel.model_name",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel.system",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::_map_usage",
    "pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py::VoyageAIEmbeddingModel.__init__",
    "pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py::VoyageAIEmbeddingModel.model_name",
    "pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py::VoyageAIEmbeddingModel.system",
    "pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py::_map_usage",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::ModelRequestParameters.__repr__",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.__init__",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.request",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.model_name",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.system",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse._get_event_iterator",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.usage",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.model_name",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.provider_name",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.provider_url",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.timestamp",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModelSettings",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel.__init__",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel.model_name",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel.system",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel.request",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel._process_response",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel._map_usage",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesModel.__init__",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesModel.model_name",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesModel.system",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesModel.request",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesModel._process_response",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIStreamedResponse._get_event_iterator",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIStreamedResponse._map_usage",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIStreamedResponse.model_name",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIStreamedResponse.provider_name",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIStreamedResponse.provider_url",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIStreamedResponse.timestamp",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesStreamedResponse._get_event_iterator",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesStreamedResponse._map_usage",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesStreamedResponse.model_name",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesStreamedResponse.provider_name",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesStreamedResponse.provider_url",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesStreamedResponse.timestamp",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::_map_logprobs",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::_map_usage",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_FINISH_REASON_MAP",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_FINISH_REASON_PROTO_MAP",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel.__init__",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel.model_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel.system",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel.request",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel._process_response",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse.system",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse.provider_url",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse._update_response_state",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse._collect_reasoning_events",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse._handle_server_side_tool_call",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse._get_event_iterator",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse.model_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse.provider_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse.timestamp",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_get_builtin_tool_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_map_server_side_tools_used_to_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_extract_usage",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_get_tool_result_content",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_parse_tool_args",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_build_mcp_tool_call_args",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_create_tool_call_part",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_map_logprobs",
    "pydantic_ai_slim/pydantic_ai/result.py::AgentStream.response",
    "pydantic_ai_slim/pydantic_ai/result.py::AgentStream.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::AgentStream.timestamp",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.__init__",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.response",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.timestamp",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.__init__",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.response",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.timestamp",
    "pydantic_ai_slim/pydantic_ai/result.py::FinalResult.__repr__",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRun.usage",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRun.__repr__",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResult.response",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResult.usage",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResult.timestamp",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResultEvent.__repr__",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.request_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.response_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.total_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.opentelemetry_attributes",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.__repr__",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.has_values",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.requests",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.incr",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.__add__",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.extract",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage.requests",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage.incr",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage.__add__",
    "pydantic_ai_slim/pydantic_ai/usage.py::_incr_usage_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::Usage",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.request_tokens_limit",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.response_tokens_limit",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.__init__",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.has_token_limits",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.check_before_request",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.check_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.check_before_tool_call",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.__repr__",
    "tests/models/test_openai.py::FinishReason",
    "tests/models/test_openai.py::chunk",
    "tests/models/test_openai.py::chunk_with_usage",
    "tests/models/test_openai.py::test_stream_with_continuous_usage_stats",
    "tests/test_mcp.py::mcp_server",
    "tests/test_mcp.py::model",
    "tests/test_mcp.py::agent",
    "tests/test_mcp.py::run_context"
  ],
  "mutation_symbol_lines": 18,
  "mutation_symbol_kind": "function",
  "mutation_file_symbols": 65,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.008,
  "retrieval_softmax_entropy": 4.2546,
  "retrieval_softmax_tau": 0.528,
  "retrieval_effective_candidates": 19.09,
  "retrieval_top5_ratio": 0.914,
  "retrieval_within95_count": 2,
  "retrieval_scored_symbols": 30,
  "retrieval_top1_score": 0.923,
  "retrieval_top5_mean_score": 0.8436,
  "retrieval_budget_utilization": 0.9498,
  "retrieval_file_concentration": 0.0,
  "repo_name": "pydantic-ai",
  "category": "usage",
  "mutation_type": "handcrafted",
  "source": "handcrafted"
}