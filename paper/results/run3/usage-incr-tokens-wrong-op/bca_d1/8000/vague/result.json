{
  "task_id": "usage-incr-tokens-wrong-op",
  "method": "bca_d1",
  "budget": 8000,
  "query_type": "vague",
  "tokens_used": 7547,
  "symbols_selected": 24,
  "files_included": 11,
  "assembly_time_ms": 232.0,
  "llm_time_ms": 3181.5,
  "llm_input_tokens": 6664,
  "llm_output_tokens": 124,
  "tests_passed": false,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: pydantic_ai_slim/pydantic_ai/result.py\nSEARCH:\n        return self._initial_run_ctx_usage + self._raw_stream_response.usage()\nREPLACE:\n        return self._initial_run_ctx_usage + self._raw_stream_response.usage() if self._raw_stream_response else self._initial_run_ctx_usage\n\nFILE: pydantic_ai_slim/pydantic_ai/run.py\nSEARCH:\n        return self._graph_run.state.usage\nREPLACE:\n        return self._graph_run.state.usage if self._graph_run.state else RunUsage()\n",
  "error": "",
  "test_time_ms": 1488.6,
  "failure_mode": "test_fail",
  "target_file_hit": true,
  "target_symbol_hit": true,
  "context_patch_overlap": 0.182,
  "patch_files_changed": 2,
  "patch_lines_changed": 2,
  "edit_distance_lines": -1,
  "entity_count_extracted": 0,
  "entity_count_mapped": 0,
  "query_identifier_density": 0.0,
  "seed_symbol_keys": [],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/usage.py::_incr_usage_tokens",
  "min_hops_seed_to_mutation": -1,
  "median_hops_seed_to_mutation": -1.0,
  "bca_closure_added_symbols": 4,
  "bca_closure_added_tokens": 4106,
  "bca_frontier_visited": 20,
  "context_symbol_keys": [
    "pydantic_ai_slim/pydantic_ai/direct.py::model_request",
    "pydantic_ai_slim/pydantic_ai/direct.py::StreamedResponseSync.__repr__",
    "pydantic_ai_slim/pydantic_ai/direct.py::StreamedResponseSync.response",
    "pydantic_ai_slim/pydantic_ai/direct.py::StreamedResponseSync.usage",
    "pydantic_ai_slim/pydantic_ai/direct.py::StreamedResponseSync.model_name",
    "pydantic_ai_slim/pydantic_ai/direct.py::StreamedResponseSync.timestamp",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse._get_event_iterator",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.usage",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.model_name",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.provider_name",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.provider_url",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.timestamp",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectModel.request",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_BedrockEmbeddingHandler.model_name",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::BedrockEmbeddingModel.model_name",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::BedrockEmbeddingModel.system",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModelName",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel.model_name",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel.system",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::ModelRequestParameters.__repr__",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.request",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.model_name",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.system",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse._get_event_iterator",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.usage",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.model_name",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.provider_name",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.provider_url",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.timestamp",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_FINISH_REASON_MAP",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_FINISH_REASON_PROTO_MAP",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel.model_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel.system",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel.request",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel._process_response",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse.system",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse.provider_url",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse._update_response_state",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse._collect_reasoning_events",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse._handle_server_side_tool_call",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse._get_event_iterator",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse.model_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse.provider_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse.timestamp",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_get_builtin_tool_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_map_server_side_tools_used_to_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_extract_usage",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_get_tool_result_content",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_parse_tool_args",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_build_mcp_tool_call_args",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_create_tool_call_part",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_map_logprobs",
    "pydantic_ai_slim/pydantic_ai/result.py::AgentStream.response",
    "pydantic_ai_slim/pydantic_ai/result.py::AgentStream.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::AgentStream.timestamp",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.response",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.timestamp",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.response",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.timestamp",
    "pydantic_ai_slim/pydantic_ai/result.py::FinalResult.__repr__",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRun.usage",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRun.__repr__",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResult.response",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResult.usage",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResult.timestamp",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResultEvent.__repr__",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.request_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.response_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.total_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.opentelemetry_attributes",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.__repr__",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.has_values",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.requests",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.incr",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.__add__",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.extract",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage.requests",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage.incr",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage.__add__",
    "pydantic_ai_slim/pydantic_ai/usage.py::_incr_usage_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::Usage",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.__repr__",
    "tests/models/test_openai.py::FinishReason",
    "tests/models/test_openai.py::chunk",
    "tests/models/test_openai.py::chunk_with_usage",
    "tests/models/test_openai.py::test_stream_with_continuous_usage_stats",
    "tests/test_mcp.py::mcp_server",
    "tests/test_mcp.py::model",
    "tests/test_mcp.py::agent"
  ],
  "mutation_symbol_lines": 18,
  "mutation_symbol_kind": "function",
  "mutation_file_symbols": 65,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.008,
  "retrieval_softmax_entropy": 4.2312,
  "retrieval_softmax_tau": 0.528,
  "retrieval_effective_candidates": 18.78,
  "retrieval_top5_ratio": 0.914,
  "retrieval_within95_count": 2,
  "retrieval_scored_symbols": 24,
  "retrieval_top1_score": 0.923,
  "retrieval_top5_mean_score": 0.8436,
  "retrieval_budget_utilization": 0.9434,
  "retrieval_file_concentration": 0.0,
  "repo_name": "pydantic-ai",
  "category": "usage",
  "mutation_type": "handcrafted",
  "source": "handcrafted"
}