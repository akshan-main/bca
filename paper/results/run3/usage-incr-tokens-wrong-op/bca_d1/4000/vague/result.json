{
  "task_id": "usage-incr-tokens-wrong-op",
  "method": "bca_d1",
  "budget": 4000,
  "query_type": "vague",
  "tokens_used": 3799,
  "symbols_selected": 27,
  "files_included": 12,
  "assembly_time_ms": 727.8,
  "llm_time_ms": 1119.5,
  "llm_input_tokens": 3797,
  "llm_output_tokens": 46,
  "tests_passed": true,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: pydantic_ai_slim/pydantic_ai/usage.py\nSEARCH:\n    slf.input_tokens -= incr_usage.input_tokens\nREPLACE:\n    slf.input_tokens += incr_usage.input_tokens\n",
  "error": "",
  "test_time_ms": 1372.0,
  "failure_mode": "pass",
  "target_file_hit": true,
  "target_symbol_hit": true,
  "context_patch_overlap": 0.083,
  "patch_files_changed": 1,
  "patch_lines_changed": 1,
  "edit_distance_lines": 0,
  "entity_count_extracted": 0,
  "entity_count_mapped": 0,
  "query_identifier_density": 0.0,
  "seed_symbol_keys": [],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/usage.py::_incr_usage_tokens",
  "min_hops_seed_to_mutation": -1,
  "median_hops_seed_to_mutation": -1.0,
  "bca_closure_added_symbols": 0,
  "bca_closure_added_tokens": 0,
  "bca_frontier_visited": 20,
  "context_symbol_keys": [
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.usage",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModelName",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::_map_usage",
    "pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py::_map_usage",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.usage",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModelSettings",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel._process_response",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel._map_usage",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesModel._process_response",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIStreamedResponse._map_usage",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesStreamedResponse._map_usage",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::_map_logprobs",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::_map_usage",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_FINISH_REASON_MAP",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_FINISH_REASON_PROTO_MAP",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel._process_response",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiStreamedResponse._update_response_state",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_map_server_side_tools_used_to_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_extract_usage",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_get_tool_result_content",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_create_tool_call_part",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_map_logprobs",
    "pydantic_ai_slim/pydantic_ai/result.py::AgentStream.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.usage",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRun.usage",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResult.usage",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.total_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.__add__",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.extract",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage.__add__",
    "pydantic_ai_slim/pydantic_ai/usage.py::_incr_usage_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::Usage",
    "tests/models/test_openai.py::FinishReason",
    "tests/models/test_openai.py::chunk",
    "tests/models/test_openai.py::chunk_with_usage",
    "tests/models/test_openai.py::test_stream_with_continuous_usage_stats",
    "tests/test_mcp.py::mcp_server",
    "tests/test_mcp.py::model",
    "tests/test_mcp.py::agent"
  ],
  "mutation_symbol_lines": 18,
  "mutation_symbol_kind": "function",
  "mutation_file_symbols": 65,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.008,
  "retrieval_softmax_entropy": 4.2581,
  "retrieval_softmax_tau": 0.528,
  "retrieval_effective_candidates": 19.13,
  "retrieval_top5_ratio": 0.914,
  "retrieval_within95_count": 2,
  "retrieval_scored_symbols": 27,
  "retrieval_top1_score": 0.923,
  "retrieval_top5_mean_score": 0.8436,
  "retrieval_budget_utilization": 0.9497,
  "retrieval_file_concentration": 0.0,
  "repo_name": "pydantic-ai",
  "category": "usage",
  "mutation_type": "handcrafted",
  "source": "handcrafted"
}