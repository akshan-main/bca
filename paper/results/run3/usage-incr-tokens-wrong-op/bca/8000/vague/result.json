{
  "task_id": "usage-incr-tokens-wrong-op",
  "method": "bca",
  "budget": 8000,
  "query_type": "vague",
  "tokens_used": 8000,
  "symbols_selected": 76,
  "files_included": 29,
  "assembly_time_ms": 272.0,
  "llm_time_ms": 3291.6,
  "llm_input_tokens": 8296,
  "llm_output_tokens": 178,
  "tests_passed": false,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: pydantic_ai_slim/pydantic_ai/usage.py\nSEARCH:\n    input_tokens: int = 0\nREPLACE:\n    input_tokens: int = 0  # Ensure this is initialized correctly to avoid negative counts\n\nFILE: pydantic_ai_slim/pydantic_ai/result.py\nSEARCH:\n        return self._initial_run_ctx_usage + self._raw_stream_response.usage()\nREPLACE:\n        return self._initial_run_ctx_usage + self._raw_stream_response.usage() if self._raw_stream_response else self._initial_run_ctx_usage\n\nFILE: pydantic_ai_slim/pydantic_ai/run.py\nSEARCH:\n        return self._graph_run.state.usage\nREPLACE:\n        return self._graph_run.state.usage if self._graph_run.state else RunUsage()\n",
  "error": "",
  "test_time_ms": 1685.6,
  "failure_mode": "test_fail",
  "target_file_hit": true,
  "target_symbol_hit": false,
  "context_patch_overlap": 0.103,
  "patch_files_changed": 3,
  "patch_lines_changed": 3,
  "edit_distance_lines": 49,
  "entity_count_extracted": 0,
  "entity_count_mapped": 0,
  "query_identifier_density": 0.0,
  "seed_symbol_keys": [],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/usage.py::_incr_usage_tokens",
  "min_hops_seed_to_mutation": -1,
  "median_hops_seed_to_mutation": -1.0,
  "bca_closure_added_symbols": 0,
  "bca_closure_added_tokens": 0,
  "bca_frontier_visited": 937,
  "context_symbol_keys": [
    "examples/pydantic_ai_examples/chat_app.py::agent",
    "examples/pydantic_ai_examples/chat_app.py::THIS_DIR",
    "examples/pydantic_ai_examples/chat_app.py::index",
    "examples/pydantic_ai_examples/chat_app.py::main_ts",
    "examples/pydantic_ai_examples/chat_app.py::get_db",
    "examples/pydantic_ai_examples/chat_app.py::get_chat",
    "examples/pydantic_ai_examples/chat_app.py::to_chat_message",
    "examples/pydantic_ai_examples/chat_app.py::Database",
    "examples/pydantic_ai_examples/data_analyst.py::AnalystAgentDeps",
    "examples/pydantic_ai_examples/data_analyst.py::display",
    "pydantic_ai_slim/pydantic_ai/_agent_graph.py::GraphAgentState.usage",
    "pydantic_ai_slim/pydantic_ai/_agent_graph.py::GraphAgentDeps.model",
    "pydantic_ai_slim/pydantic_ai/_agent_graph.py::_RunMessages",
    "pydantic_ai_slim/pydantic_ai/_agent_graph.py::_messages_ctx_var",
    "pydantic_ai_slim/pydantic_ai/_agent_graph.py::get_captured_run_messages",
    "pydantic_ai_slim/pydantic_ai/_run_context.py::RunContext",
    "pydantic_ai_slim/pydantic_ai/_run_context.py::RunContext.model",
    "pydantic_ai_slim/pydantic_ai/_run_context.py::RunContext.usage",
    "pydantic_ai_slim/pydantic_ai/_run_context.py::_CURRENT_RUN_CONTEXT",
    "pydantic_ai_slim/pydantic_ai/_run_context.py::get_current_run_context",
    "pydantic_ai_slim/pydantic_ai/_utils.py::_disable_threads",
    "pydantic_ai_slim/pydantic_ai/_utils.py::disable_threads",
    "pydantic_ai_slim/pydantic_ai/_utils.py::run_in_executor",
    "pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py::PrefectStreamedResponse.usage",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModelName",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.request",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.request_stream",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.usage",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::ALLOW_MODEL_REQUESTS",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::check_allow_model_requests",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_map_server_side_tools_used_to_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_extract_usage",
    "pydantic_ai_slim/pydantic_ai/result.py::AgentStream.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.usage",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRun.usage",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResult.usage",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.total_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.extract",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::Usage",
    "pydantic_graph/pydantic_graph/beta/graph_builder.py::_replace_placeholder_node_ids",
    "pydantic_graph/pydantic_graph/beta/graph_builder.py::_build_placeholder_node_id_remapping",
    "pydantic_graph/pydantic_graph/beta/graph_builder.py::_update_node_with_id_remapping",
    "pydantic_graph/pydantic_graph/beta/graph_builder.py::_update_path_with_id_remapping",
    "pydantic_graph/pydantic_graph/beta/paths.py::PathItem",
    "pydantic_graph/pydantic_graph/beta/paths.py::Path",
    "tests/models/mock_xai.py::_get_proto_finish_reason",
    "tests/models/mock_xai.py::MockXai",
    "tests/models/mock_xai.py::MockXai.index",
    "tests/models/mock_xai.py::MockXai.create_mock",
    "tests/models/mock_xai.py::MockXai.create_mock_stream",
    "tests/models/mock_xai.py::MockChatInstance.index",
    "tests/models/mock_xai.py::get_grok_text_chunk",
    "tests/models/test_bedrock.py::test_bedrock_model",
    "tests/models/test_bedrock.py::test_bedrock_model_stream",
    "tests/models/test_bedrock.py::test_image_as_binary_content_input",
    "tests/models/test_bedrock.py::test_document_url_input",
    "tests/models/test_bedrock.py::test_text_document_url_input",
    "tests/models/test_gemini.py::AsyncByteStreamList",
    "tests/models/test_gemini.py::GetGeminiClient",
    "tests/models/test_gemini.py::get_gemini_client",
    "tests/models/test_gemini.py::example_usage",
    "tests/models/test_gemini.py::test_stream_text",
    "tests/models/test_gemini.py::test_stream_text_no_data",
    "tests/models/test_gemini.py::test_image_as_binary_content_input",
    "tests/models/test_gemini.py::test_document_url_input",
    "tests/models/test_huggingface.py::MockHuggingFace",
    "tests/models/test_huggingface.py::MockHuggingFace.index",
    "tests/models/test_huggingface.py::MockHuggingFace.model",
    "tests/models/test_huggingface.py::MockHuggingFace.create_stream_mock",
    "tests/models/test_huggingface.py::get_mock_chat_completion_kwargs",
    "tests/models/test_huggingface.py::completion_message",
    "tests/models/test_huggingface.py::test_stream_completion",
    "tests/models/test_huggingface.py::FinishReason",
    "tests/models/test_huggingface.py::chunk",
    "tests/models/test_huggingface.py::text_chunk",
    "tests/models/test_huggingface.py::test_stream_text",
    "tests/models/test_huggingface.py::test_no_delta",
    "tests/models/test_huggingface.py::test_image_as_binary_content_input",
    "tests/models/test_huggingface.py::test_model_status_error",
    "tests/models/test_huggingface.py::test_max_completion_tokens",
    "tests/models/test_model_function.py::hello",
    "tests/models/test_model_function.py::test_init",
    "tests/models/test_model_function.py::stream_text_function",
    "tests/models/test_model_function.py::test_stream_text",
    "tests/models/test_model_function.py::stream_text_function_empty",
    "tests/models/test_model_function.py::test_return_empty",
    "tests/models/test_openai.py::test_init",
    "tests/models/test_openai.py::FinishReason",
    "tests/models/test_openai.py::chunk",
    "tests/models/test_openai.py::text_chunk",
    "tests/models/test_openai.py::test_stream_text",
    "tests/models/test_openai.py::test_no_delta",
    "tests/models/test_openai.py::none_delta_chunk",
    "tests/models/test_openai.py::test_none_delta",
    "tests/models/test_openai.py::test_system_prompt_role",
    "tests/models/test_openai.py::test_system_prompt_role_o1_mini",
    "tests/models/test_openai.py::test_openai_pass_custom_system_prompt_role",
    "tests/models/test_openai.py::test_document_url_input",
    "tests/models/test_openai.py::test_document_url_input_response_api",
    "tests/models/test_openai.py::test_image_as_binary_content_input",
    "tests/models/test_openai.py::test_document_as_binary_content_input",
    "tests/models/test_openai.py::test_text_document_url_input",
    "tests/models/test_openai.py::test_text_document_as_binary_content_input",
    "tests/models/test_openai.py::test_model_status_error",
    "tests/models/test_openai.py::test_responses_model_connection_error",
    "tests/models/test_openai.py::test_max_completion_tokens",
    "tests/models/test_openai.py::test_extra_headers",
    "tests/models/test_openai.py::test_openai_store_false",
    "tests/models/test_openai.py::test_openai_store_true",
    "tests/models/test_openai.py::test_user_id",
    "tests/models/test_openai.py::test_openai_model_without_system_prompt",
    "tests/models/test_openai.py::test_openai_web_search_tool_model_not_supported",
    "tests/models/test_openai.py::test_openai_web_search_tool",
    "tests/models/test_openai.py::test_reasoning_model_with_temperature",
    "tests/models/test_openai.py::test_openai_model_profile",
    "tests/models/test_openai.py::test_text_response",
    "tests/models/test_openai.py::test_openai_model_settings_temperature_ignored_on_gpt_5",
    "tests/models/test_openai.py::test_openai_model_cerebras_provider",
    "tests/models/test_openai.py::test_openai_model_cerebras_provider_qwen_3_coder",
    "tests/models/test_openai.py::test_openai_model_cerebras_provider_harmony",
    "tests/models/test_openai.py::test_deprecated_openai_model",
    "tests/models/test_openai.py::chunk_with_usage",
    "tests/models/test_xai.py::XAI_NON_REASONING_MODEL",
    "tests/models/test_xai.py::test_xai_stream_text",
    "tests/models/test_xai.py::test_xai_stream_empty_response_raises",
    "tests/providers/test_gateway.py::gateway_api_key",
    "tests/providers/test_gateway.py::test_gateway_provider",
    "tests/providers/test_gateway.py::test_gateway_provider_with_openai",
    "tests/providers/test_heroku.py::test_heroku_model_provider_claude_3_7_sonnet",
    "tests/test_builtin_tools.py::test_builtin_tools_not_supported_web_search",
    "tests/test_builtin_tools.py::test_builtin_tools_not_supported_web_search_stream",
    "tests/test_builtin_tools.py::test_builtin_tools_not_supported_code_execution",
    "tests/test_builtin_tools.py::test_builtin_tools_not_supported_code_execution_stream",
    "tests/test_direct.py::test_model_request",
    "tests/test_direct.py::test_model_request_stream_sync",
    "tests/test_direct.py::test_model_request_stream",
    "tests/test_direct.py::test_model_request_stream_sync_intermediate_get",
    "tests/test_mcp.py::mcp_server",
    "tests/test_mcp.py::model",
    "tests/test_mcp.py::agent",
    "tests/test_mcp.py::run_context",
    "tests/test_mcp.py::test_tool_metadata_extraction",
    "tests/test_ui_web.py::test_chat_app_health_endpoint",
    "tests/test_ui_web.py::test_chat_app_index_file_not_found",
    "tests/test_usage_limits.py::test_usage_unknown_provider"
  ],
  "mutation_symbol_lines": 18,
  "mutation_symbol_kind": "function",
  "mutation_file_symbols": 65,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.008,
  "retrieval_softmax_entropy": 4.2517,
  "retrieval_softmax_tau": 0.508,
  "retrieval_effective_candidates": 19.05,
  "retrieval_top5_ratio": 0.8719,
  "retrieval_within95_count": 2,
  "retrieval_scored_symbols": 50,
  "retrieval_top1_score": 0.923,
  "retrieval_top5_mean_score": 0.8048,
  "retrieval_budget_utilization": 1.0,
  "retrieval_file_concentration": 0.0,
  "repo_name": "pydantic-ai",
  "category": "usage",
  "mutation_type": "handcrafted",
  "source": "handcrafted"
}