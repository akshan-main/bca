{
  "task_id": "usage-incr-tokens-wrong-op",
  "method": "bm25",
  "budget": 10000,
  "query_type": "vague",
  "tokens_used": 10000,
  "symbols_selected": 120,
  "files_included": 59,
  "assembly_time_ms": 293.0,
  "llm_time_ms": 3004.1,
  "llm_input_tokens": 10226,
  "llm_output_tokens": 47,
  "tests_passed": true,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: pydantic_ai_slim/pydantic_ai/usage.py\nSEARCH:\n    slf.input_tokens -= incr_usage.input_tokens\nREPLACE:\n    slf.input_tokens += incr_usage.input_tokens\n",
  "error": "",
  "test_time_ms": 1351.5,
  "failure_mode": "pass",
  "target_file_hit": true,
  "target_symbol_hit": true,
  "context_patch_overlap": 0.037,
  "patch_files_changed": 1,
  "patch_lines_changed": 1,
  "edit_distance_lines": 0,
  "entity_count_extracted": 0,
  "entity_count_mapped": 0,
  "query_identifier_density": 0.0,
  "seed_symbol_keys": [],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/usage.py::_incr_usage_tokens",
  "min_hops_seed_to_mutation": -1,
  "median_hops_seed_to_mutation": -1.0,
  "bca_closure_added_symbols": 0,
  "bca_closure_added_tokens": 0,
  "bca_frontier_visited": 0,
  "context_symbol_keys": [
    "examples/pydantic_ai_examples/flight_booking.py::usage_limits",
    "pydantic_ai_slim/pydantic_ai/_agent_graph.py::GraphAgentState.usage",
    "pydantic_ai_slim/pydantic_ai/_agent_graph.py::ModelRequestNode.request",
    "pydantic_ai_slim/pydantic_ai/direct.py::model_request",
    "pydantic_ai_slim/pydantic_ai/direct.py::StreamedResponseSync.response",
    "pydantic_ai_slim/pydantic_ai/direct.py::StreamedResponseSync.usage",
    "pydantic_ai_slim/pydantic_ai/embeddings/__init__.py::Embedder.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/base.py::EmbeddingModel",
    "pydantic_ai_slim/pydantic_ai/embeddings/base.py::EmbeddingModel.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py::BedrockEmbeddingModel.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::_MAX_INPUT_TOKENS",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::CohereEmbeddingModel.max_input_tokens",
    "pydantic_ai_slim/pydantic_ai/embeddings/cohere.py::_map_usage",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::Model.request",
    "pydantic_ai_slim/pydantic_ai/models/__init__.py::StreamedResponse.usage",
    "pydantic_ai_slim/pydantic_ai/models/anthropic.py::AnthropicModel.request",
    "pydantic_ai_slim/pydantic_ai/models/anthropic.py::_map_usage",
    "pydantic_ai_slim/pydantic_ai/models/function.py::FunctionModel.request",
    "pydantic_ai_slim/pydantic_ai/models/function.py::_estimate_usage",
    "pydantic_ai_slim/pydantic_ai/models/function.py::_estimate_string_tokens",
    "pydantic_ai_slim/pydantic_ai/models/gemini.py::GeminiModel.request",
    "pydantic_ai_slim/pydantic_ai/models/gemini.py::_GeminiFunctionResponse.response",
    "pydantic_ai_slim/pydantic_ai/models/gemini.py::_GeminiModalityTokenCount",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModelSettings",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel.request",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel._map_usage",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIChatModel._get_stream_options",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesModel.request",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIStreamedResponse._map_usage",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::OpenAIResponsesStreamedResponse._map_usage",
    "pydantic_ai_slim/pydantic_ai/models/openai.py::_map_usage",
    "pydantic_ai_slim/pydantic_ai/models/openrouter.py::_OpenRouterMaxPrice.request",
    "pydantic_ai_slim/pydantic_ai/models/openrouter.py::_OpenRouterPromptTokenDetails",
    "pydantic_ai_slim/pydantic_ai/models/openrouter.py::_OpenRouterChatCompletion.usage",
    "pydantic_ai_slim/pydantic_ai/models/openrouter.py::_OpenRouterChatCompletionChunk.usage",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModelSettings",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::XaiModel.request",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_map_server_side_tools_used_to_name",
    "pydantic_ai_slim/pydantic_ai/models/xai.py::_extract_usage",
    "pydantic_ai_slim/pydantic_ai/result.py::AgentStream",
    "pydantic_ai_slim/pydantic_ai/result.py::AgentStream.response",
    "pydantic_ai_slim/pydantic_ai/result.py::AgentStream.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.response",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResult.usage",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.response",
    "pydantic_ai_slim/pydantic_ai/result.py::StreamedRunResultSync.usage",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRun",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRun.usage",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResult",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResult.response",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResult.usage",
    "pydantic_ai_slim/pydantic_ai/run.py::AgentRunResultEvent",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.request_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.response_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.total_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.opentelemetry_attributes",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.incr",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.__add__",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage.extract",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage.incr",
    "pydantic_ai_slim/pydantic_ai/usage.py::RunUsage.__add__",
    "pydantic_ai_slim/pydantic_ai/usage.py::_incr_usage_tokens",
    "pydantic_ai_slim/pydantic_ai/usage.py::Usage",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.request_tokens_limit",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.response_tokens_limit",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageLimits.check_tokens",
    "tests/models/mock_xai.py::_get_proto_finish_reason",
    "tests/models/mock_xai.py::_build_response_with_outputs",
    "tests/models/mock_xai.py::MockXai",
    "tests/models/mock_xai.py::MockXai.create_mock",
    "tests/models/mock_xai.py::create_response",
    "tests/models/mock_xai.py::create_response_without_usage",
    "tests/models/mock_xai.py::create_usage",
    "tests/models/test_anthropic.py::test_usage",
    "tests/models/test_bedrock.py::test_bedrock_cache_usage_includes_cache_tokens",
    "tests/models/test_openai.py::FinishReason",
    "tests/models/test_openai.py::chunk",
    "tests/models/test_openai.py::chunk_with_usage",
    "tests/models/test_openai.py::test_stream_with_continuous_usage_stats",
    "tests/models/test_xai.py::XAI_REASONING_MODEL",
    "tests/models/test_xai.py::test_xai_usage_with_reasoning_tokens",
    "tests/models/test_xai.py::test_xai_usage_without_details",
    "tests/test_embeddings.py::TestOpenAI.test_response_with_no_usage",
    "tests/test_temporal.py::client",
    "tests/test_temporal.py::model",
    "tests/test_temporal.py::simple_temporal_agent",
    "tests/test_temporal.py::SimpleAgentWorkflow",
    "tests/test_temporal.py::Response",
    "tests/test_temporal.py::SimpleAgentWorkflowWithRunSync",
    "tests/test_temporal.py::SimpleAgentWorkflowWithRunStream",
    "tests/test_temporal.py::SimpleAgentWorkflowWithRunStreamEvents",
    "tests/test_temporal.py::model_settings",
    "tests/test_usage_limits.py::test_multi_agent_usage_no_incr",
    "tests/test_usage_limits.py::test_multi_agent_usage_sync"
  ],
  "mutation_symbol_lines": 18,
  "mutation_symbol_kind": "function",
  "mutation_file_symbols": 65,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.749791,
  "retrieval_softmax_entropy": 4.3144,
  "retrieval_softmax_tau": 27.630478,
  "retrieval_effective_candidates": 19.9,
  "retrieval_top5_ratio": 0.9608,
  "retrieval_within95_count": 4,
  "retrieval_scored_symbols": 50,
  "retrieval_top1_score": 31.926114,
  "retrieval_top5_mean_score": 30.67616,
  "retrieval_budget_utilization": 1.0,
  "retrieval_file_concentration": 0.2417,
  "repo_name": "pydantic-ai",
  "category": "usage",
  "mutation_type": "handcrafted",
  "source": "handcrafted"
}