# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_ai_slim/pydantic_ai/_output.py:18-18
from . import _function_schema, _utils, messages as _messages

# pydantic_graph/pydantic_graph/persistence/file.py:14-14
from .. import _utils as _graph_utils, exceptions

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# tests/test_validation_context.py:22-27
class Value(BaseModel):
    x: int

    @field_validator('x')
    def increment_value(cls, value: int, info: ValidationInfo):
        return value + (info.context or 0)

# pydantic_ai_slim/pydantic_ai/_utils.py:150-153
class Unset:
    """A singleton to represent an unset value."""

    pass

# pydantic_ai_slim/pydantic_ai/_utils.py:143-143
    value: T

# pydantic_ai_slim/pydantic_ai/_utils.py:143-143
    value: T

# tests/test_validation_context.py:26-27
    def increment_value(cls, value: int, info: ValidationInfo):
        return value + (info.context or 0)

# pydantic_ai_slim/pydantic_ai/messages.py:21-21
from opentelemetry.util.types import AnyValue

# pydantic_evals/pydantic_evals/evaluators/common.py:32-32
    value: Any

# pydantic_evals/pydantic_evals/reporting/__init__.py:707-711
    def render_value(self, name: str | None, v: Any) -> str:
        result = self._get_value_str(v)
        if name:
            result = f'{name}: {result}'
        return result

# pydantic_ai_slim/pydantic_ai/_otel_messages.py:10-10
from pydantic import JsonValue

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:15-15
JSONValue = Any

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/request_types.py:15-15
JSONValue = Any

# tests/graph/beta/test_graph_edge_cases.py:20-20
    value: int = 0

# tests/graph/beta/test_graph_edge_cases.py:20-20
    value: int = 0

# pydantic_ai_slim/pydantic_ai/_utils.py:150-153
class Unset:
    """A singleton to represent an unset value."""

    pass

# pydantic_evals/pydantic_evals/evaluators/common.py:73-73
    value: Any

# tests/test_ag_ui.py:158-158
    value: int = 0

# pydantic_graph/pydantic_graph/beta/graph.py:86-87
    def value(self) -> OutputT:
        return self._value

# pydantic_evals/pydantic_evals/reporting/__init__.py:736-742
    def _get_value_str(self, value: Any) -> str:
        if value is None:
            return MISSING_VALUE_STR
        if isinstance(self.value_formatter, str):
            return self.value_formatter.format(value)
        else:
            return self.value_formatter(value)

# tests/graph/beta/test_edge_labels.py:17-17
    value: int = 0

# tests/test_agent.py:3308-3308
    value: str

# tests/test_prefect.py:1195-1195
    value: str

# tests/test_agent.py:3308-3308
    value: str

# pydantic_evals/pydantic_evals/reporting/__init__.py:693-693
    value_formatter: str | Callable[[Any], str] = '{}'

# examples/pydantic_ai_examples/ag_ui/api/agentic_generative_ui.py:42-45
    value: Any = Field(
        default=None,
        description='The value to apply (for add, replace operations)',
    )

# pydantic_graph/pydantic_graph/beta/graph.py:78-78
    _value: OutputT

# tests/graph/beta/test_joins_and_reducers.py:24-24
    value: int = 0

# pydantic_evals/pydantic_evals/reporting/analyses.py:65-65
    value: float | int

# tests/test_temporal.py:2579-2579
    values: list[int] = field(default_factory=list[int])

# pydantic_evals/pydantic_evals/reporting/__init__.py:685-685
    value_formatter: str | Callable[[Any], str]

# tests/graph/beta/test_decisions.py:20-20
    value: int = 0

# tests/graph/beta/test_edge_cases.py:19-19
    value: int = 0

# tests/test_agent.py:114-114
    value: T

# tests/graph/beta/test_broadcast_and_spread.py:17-17
    values: list[int] = field(default_factory=list[int])

# pydantic_evals/pydantic_evals/evaluators/evaluator.py:44-44
    value: EvaluationScalar

# pydantic_evals/pydantic_evals/evaluators/evaluator.py:73-73
    value: EvaluationScalarT

# pydantic_ai_slim/pydantic_ai/embeddings/instrumented.py:11-11
from opentelemetry.util.types import AttributeValue

# pydantic_ai_slim/pydantic_ai/embeddings/instrumented.py:11-11
from opentelemetry.util.types import AttributeValue

# pydantic_ai_slim/pydantic_ai/embeddings/instrumented.py:11-11
from opentelemetry.util.types import AttributeValue

# pydantic_evals/pydantic_evals/reporting/__init__.py:692-742
class _ValueRenderer:
    value_formatter: str | Callable[[Any], str] = '{}'
    diff_checker: Callable[[Any, Any], bool] | None = lambda x, y: x != y
    diff_formatter: Callable[[Any, Any], str | None] | None = None
    diff_style: str = 'magenta'

    @staticmethod
    def from_config(config: RenderValueConfig) -> _ValueRenderer:
        return _ValueRenderer(
            value_formatter=config.get('value_formatter', '{}'),
            diff_checker=config.get('diff_checker', lambda x, y: x != y),
            diff_formatter=config.get('diff_formatter'),
            diff_style=config.get('diff_style', 'magenta'),
        )

    def render_value(self, name: str | None, v: Any) -> str:
        result = self._get_value_str(v)
        if name:
            result = f'{name}: {result}'
        return result

    def render_diff(self, name: str | None, old: Any | None, new: Any | None) -> str:
        old_str = self._get_value_str(old) or MISSING_VALUE_STR
        new_str = self._get_value_str(new) or MISSING_VALUE_STR
        if old_str == new_str:
            result = old_str
        else:
            result = f'{old_str} → {new_str}'

            has_diff = self.diff_checker and self.diff_checker(old, new)
            if has_diff:  # pragma: no branch
                # If there is a diff, make the name bold and compute the diff_str
                name = name and f'[bold]{name}[/]'
                diff_str = self.diff_formatter and self.diff_formatter(old, new)
                if diff_str:  # pragma: no cover
                    result += f' ({diff_str})'
                result = f'[{self.diff_style}]{result}[/]'

        # Add the name
        if name:
            result = f'{name}: {result}'

        return result

    def _get_value_str(self, value: Any) -> str:
        if value is None:
            return MISSING_VALUE_STR
        if isinstance(self.value_formatter, str):
            return self.value_formatter.format(value)
        else:
            return self.value_formatter(value)

# pydantic_evals/pydantic_evals/reporting/render_numbers.py:14-14
VALUE_SIG_FIGS = 3  # Significant figures for the default number formatting.

# examples/pydantic_ai_examples/evals/agent.py:12-20
class TimeRangeDeps:
    """Dependencies for the time range inference agent.

    While we could just get the current time using datetime.now() directly in the tools or system prompt, passing it
    via deps makes it easier to use a repeatable value during testing. While there are packages like `time-machine`
    that can do this for you, that kind of monkey-patching approach can become unwieldy as things get more complex.
    """

    now: datetime = field(default_factory=lambda: datetime.now().astimezone())

# pydantic_ai_slim/pydantic_ai/models/test.py:45-45
    value: str | None

# pydantic_ai_slim/pydantic_ai/models/test.py:52-52
    value: dict[str, Any] | None

# pydantic_ai_slim/pydantic_ai/_utils.py:342-344
    async def is_exhausted(self) -> bool:
        """Returns True if the stream is exhausted, False otherwise."""
        return isinstance(await self.peek(), Unset)

# pydantic_ai_slim/pydantic_ai/_utils.py:30-30
from pydantic.json_schema import JsonSchemaValue

# pydantic_ai_slim/pydantic_ai/_utils.py:30-30
from pydantic.json_schema import JsonSchemaValue

# pydantic_ai_slim/pydantic_ai/_utils.py:30-30
from pydantic.json_schema import JsonSchemaValue

# pydantic_ai_slim/pydantic_ai/_utils.py:30-30
from pydantic.json_schema import JsonSchemaValue

# pydantic_ai_slim/pydantic_ai/_utils.py:30-30
from pydantic.json_schema import JsonSchemaValue

# pydantic_ai_slim/pydantic_ai/_utils.py:30-30
from pydantic.json_schema import JsonSchemaValue

# pydantic_graph/pydantic_graph/beta/join.py:141-147
class ReduceFirstValue(Generic[T]):
    """A reducer that returns the first value it encounters, and cancels all other tasks."""

    def __call__(self, ctx: ReducerContext[object, object], current: T, inputs: T) -> T:
        """The reducer function."""
        ctx.cancel_sibling_tasks()
        return inputs

# pydantic_graph/pydantic_graph/beta/join.py:141-147
class ReduceFirstValue(Generic[T]):
    """A reducer that returns the first value it encounters, and cancels all other tasks."""

    def __call__(self, ctx: ReducerContext[object, object], current: T, inputs: T) -> T:
        """The reducer function."""
        ctx.cancel_sibling_tasks()
        return inputs

# pydantic_graph/pydantic_graph/beta/join.py:141-147
class ReduceFirstValue(Generic[T]):
    """A reducer that returns the first value it encounters, and cancels all other tasks."""

    def __call__(self, ctx: ReducerContext[object, object], current: T, inputs: T) -> T:
        """The reducer function."""
        ctx.cancel_sibling_tasks()
        return inputs

# pydantic_evals/pydantic_evals/reporting/__init__.py:59-59
MISSING_VALUE_STR = '[i]<missing>[/i]'

# pydantic_ai_slim/pydantic_ai/messages.py:690-690
    return_value: ToolReturnContent

# pydantic_ai_slim/pydantic_ai/_cli/__init__.py:14-14
from typing_inspection.introspection import get_literal_values

# tests/test_format_as_xml.py:601-603
def test_invalid_value():
    with pytest.raises(TypeError, match='Unsupported type'):
        format_as_xml(object())

# pydantic_evals/pydantic_evals/otel/_context_in_memory_span_exporter.py:9-9
from weakref import WeakValueDictionary

# pydantic_ai_slim/pydantic_ai/usage.py:99-101
    def has_values(self) -> bool:
        """Whether any values are set and non-zero."""
        return any(dataclasses.asdict(self).values())

# pydantic_evals/pydantic_evals/reporting/__init__.py:817-821
    def render_value(self, name: str | None, v: float | int) -> str:
        result = self._get_value_str(v)
        if name:
            result = f'{name}: {result}'
        return result

# tests/test_validation_context.py:23-23
    x: int

# pydantic_ai_slim/pydantic_ai/format_prompt.py:135-155
    def _set_scalar_text(self, element: ElementTree.Element, value: Any) -> bool:
        """Set element.text for scalar types. Return True if handled, False otherwise."""
        if value is None:
            element.text = self.none_str
        elif isinstance(value, str):
            element.text = value
        elif isinstance(value, bytes | bytearray):
            element.text = value.decode(errors='ignore')
        elif isinstance(value, bool | int | float | Enum):
            element.text = str(value)
        elif isinstance(value, date | time):
            element.text = value.isoformat()
        elif isinstance(value, timedelta):
            element.text = str(value)
        elif isinstance(value, Decimal):
            element.text = str(value)
        elif isinstance(value, UUID):
            element.text = str(value)
        else:
            return False
        return True

# pydantic_evals/pydantic_evals/reporting/__init__.py:917-917
    def render_value(self, name: str | None, v: T_contra) -> str: ...  # pragma: no branch

# pydantic_evals/pydantic_evals/reporting/__init__.py:923-923
_DEFAULT_VALUE_CONFIG = RenderValueConfig()

# pydantic_evals/pydantic_evals/reporting/__init__.py:884-890
    def _get_value_str(self, value: float | int | None) -> str:
        if value is None:
            return MISSING_VALUE_STR
        if isinstance(self.value_formatter, str):
            return self.value_formatter.format(value)
        else:
            return self.value_formatter(value)

# pydantic_ai_slim/pydantic_ai/_utils.py:159-160
def is_set(t_or_unset: T | Unset) -> TypeGuard[T]:
    return t_or_unset is not UNSET

# pydantic_evals/pydantic_evals/reporting/__init__.py:810-810
    value_formatter: str | Callable[[float | int], str]

# tests/models/test_openai.py:1624-1636
async def test_openai_store_false(allow_model_requests: None):
    """Test that openai_store=False is correctly passed to the OpenAI API."""
    c = completion_message(ChatCompletionMessage(content='hello', role='assistant'))
    mock_client = MockOpenAI.create_mock(c)
    m = OpenAIChatModel('gpt-4o', provider=OpenAIProvider(openai_client=mock_client))
    agent = Agent(m, model_settings=OpenAIChatModelSettings(openai_store=False))

    result = await agent.run('test')
    assert result.output == 'hello'

    # Verify the store parameter was passed to the mock
    kwargs = get_mock_chat_completion_kwargs(mock_client)[0]
    assert kwargs.get('store') is False

# tests/test_format_as_xml.py:611-617
def test_parse_invalid_value():
    class Invalid(BaseModel):
        name: str = Field(default='Alice', title='Name')
        bad: Any = object()

    with pytest.raises(TypeError, match='Unsupported type'):
        format_as_xml(Invalid(), include_field_info='once')

# tests/evals/test_multi_run.py:140-148
async def test_repeat_invalid_value():
    """repeat < 1 should raise ValueError."""

    async def task(inputs: str) -> str:
        return inputs  # pragma: no cover

    dataset = Dataset(cases=[Case(inputs='hello')])
    with pytest.raises(ValueError, match='repeat must be >= 1'):
        await dataset.evaluate(task, name='test', progress=False, repeat=0)

# pydantic_evals/pydantic_evals/reporting/__init__.py:751-751
    value_formatter: str | Callable[[float | int], str]

# tests/models/anthropic/test_output.py:465-483
def test_strict_false_tool_no_output(
    allow_model_requests: None,
    anthropic_model: ANTHROPIC_MODEL_FIXTURE,
) -> None:
    """Tool with strict=False, no output_type → no beta header."""
    model = anthropic_model('claude-sonnet-4-5')
    hook = create_header_verification_hook(expect_beta=False, test_name='test_strict_false_tool_no_output')
    model.client._client.event_hooks['request'].append(hook)  # pyright: ignore[reportPrivateUsage]

    agent = Agent(model)

    @agent.tool_plain(strict=False)
    def calculate_distance(city_a: str, city_b: str) -> str:
        return f'Distance from {city_a} to {city_b}: 504 km'

    agent.run_sync('How far is Madrid from Lisbon?')

    if errors := hook.errors:  # type: ignore[attr-defined]
        assert False, '\n'.join(sorted(errors))

# pydantic_ai_slim/pydantic_ai/run.py:316-316
    _traceparent_value: str | None = dataclasses.field(repr=False, compare=False, default=None)