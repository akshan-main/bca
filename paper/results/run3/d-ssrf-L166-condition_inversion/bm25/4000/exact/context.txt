# pydantic_ai_slim/pydantic_ai/_ssrf.py:61-61
    hostname: str

# pydantic_ai_slim/pydantic_ai/_ssrf.py:100-127
async def resolve_hostname(hostname: str) -> list[str]:
    """Resolve a hostname to its IP addresses using DNS.

    Uses run_in_executor to run DNS resolution in a thread pool to avoid blocking.

    Returns:
        List of IP address strings, preserving DNS order with duplicates removed.

    Raises:
        ValueError: If DNS resolution fails.
    """
    try:
        # getaddrinfo returns list of (family, type, proto, canonname, sockaddr)
        # sockaddr is (ip, port) for IPv4 or (ip, port, flowinfo, scope_id) for IPv6
        results = await run_in_executor(socket.getaddrinfo, hostname, None, socket.AF_UNSPEC, socket.SOCK_STREAM)
        # Extract unique IP addresses, preserving order (first IP is typically preferred)
        seen: set[str] = set()
        ips: list[str] = []
        for result in results:
            ip = str(result[4][0])
            if ip not in seen:
                seen.add(ip)
                ips.append(ip)
        if not ips:
            raise ValueError(f'DNS resolution failed for hostname: {hostname}')  # pragma: no cover
        return ips
    except socket.gaierror as e:
        raise ValueError(f'DNS resolution failed for hostname "{hostname}": {e}') from e

# tests/test_ssrf.py:301-320
class TestResolveHostname:
    """Tests for resolve_hostname function."""

    async def test_resolve_success(self) -> None:
        """Test that hostname resolution returns IP addresses."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            mock_executor.return_value = [
                (2, 1, 6, '', ('93.184.215.14', 0)),
                (2, 1, 6, '', ('93.184.215.14', 0)),  # Duplicate should be removed
            ]
            ips = await resolve_hostname('example.com')
            assert ips == ['93.184.215.14']

    async def test_resolve_failure(self) -> None:
        """Test that DNS resolution failure raises ValueError."""
        import socket

        with patch('pydantic_ai._ssrf.run_in_executor', side_effect=socket.gaierror('DNS lookup failed')):
            with pytest.raises(ValueError, match='DNS resolution failed for hostname'):
                await resolve_hostname('nonexistent.invalid')

# tests/conftest.py:674-694
def disable_ssrf_protection_for_vcr():
    """Disable SSRF protection for VCR compatibility.

    VCR cassettes record requests with the original hostname. Since SSRF protection
    resolves hostnames to IPs before making requests, we need to disable the validation
    for VCR tests to match the pre-recorded cassettes.

    This fixture patches validate_and_resolve_url to return the hostname in place
    of the resolved IP, allowing the request URL to use the original hostname.
    """
    from unittest.mock import patch

    from pydantic_ai._ssrf import ResolvedUrl, extract_host_and_port

    async def mock_validate_and_resolve(url: str, allow_local: bool) -> ResolvedUrl:
        hostname, path, port, is_https = extract_host_and_port(url)
        # Return hostname in place of resolved IP - this allows VCR matching
        return ResolvedUrl(resolved_ip=hostname, hostname=hostname, port=port, is_https=is_https, path=path)

    with patch('pydantic_ai._ssrf.validate_and_resolve_url', mock_validate_and_resolve):
        yield

# tests/test_ssrf.py:227-229
    def test_invalid_url_no_hostname(self) -> None:
        with pytest.raises(ValueError, match='Invalid URL: no hostname found'):
            extract_host_and_port('http://')

# tests/test_ssrf.py:678-684
    async def test_hostname_resolving_to_private_ip_blocked(self) -> None:
        """Test that a hostname resolving to a private IP is blocked."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            # Attacker's DNS returns private IP
            mock_executor.return_value = [(2, 1, 6, '', ('127.0.0.1', 0))]
            with pytest.raises(ValueError, match='Access to private/internal IP address'):
                await validate_and_resolve_url('http://attacker.com/path', allow_local=False)

# tests/test_ssrf.py:304-312
    async def test_resolve_success(self) -> None:
        """Test that hostname resolution returns IP addresses."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            mock_executor.return_value = [
                (2, 1, 6, '', ('93.184.215.14', 0)),
                (2, 1, 6, '', ('93.184.215.14', 0)),  # Duplicate should be removed
            ]
            ips = await resolve_hostname('example.com')
            assert ips == ['93.184.215.14']

# tests/test_ssrf.py:686-692
    async def test_hostname_resolving_to_cloud_metadata_blocked(self) -> None:
        """Test that a hostname resolving to cloud metadata IP is blocked."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            # Attacker's DNS returns cloud metadata IP
            mock_executor.return_value = [(2, 1, 6, '', ('169.254.169.254', 0))]
            with pytest.raises(ValueError, match='Access to cloud metadata service'):
                await validate_and_resolve_url('http://attacker.com/path', allow_local=True)

# pydantic_graph/pydantic_graph/beta/decision.py:88-124
class DecisionBranch(Generic[SourceT]):
    """Represents a single branch within a decision node.

    Each branch defines the conditions under which it should be taken
    and the path to follow when those conditions are met.

    Note: with the current design, it is actually _critical_ that this class is invariant in SourceT for the sake
    of type-checking that inputs to a Decision are actually handled. See the `# type: ignore` comment in
    `tests.graph.beta.test_graph_edge_cases.test_decision_no_matching_branch` for an example of how this works.
    """

    source: TypeOrTypeExpression[SourceT]
    """The expected type of data for this branch.

    This is necessary for exhaustiveness-checking when handling the inputs to a decision node."""

    matches: Callable[[Any], bool] | None
    """An optional predicate function used to determine whether input data matches this branch.

    If `None`, default logic is used which attempts to check the value for type-compatibility with the `source` type:
    * If `source` is `Any` or `object`, the branch will always match
    * If `source` is a `Literal` type, this branch will match if the value is one of the parametrizing literal values
    * If `source` is any other type, the value will be checked for matching using `isinstance`

    Inputs are tested against each branch of a decision node in order, and the path of the first matching branch is
    used to handle the input value.
    """

    path: Path
    """The execution path to follow when an input value matches this branch of a decision node.

    This can include transforming, mapping, and broadcasting the output before sending to the next node or nodes.

    The path can also include position-aware labels which are used when generating mermaid diagrams."""

    destinations: list[AnyDestinationNode]
    """The destination nodes that can be referenced by DestinationMarker in the path."""

# tests/test_dbos.py:976-980
def conditions(ctx: RunContext, city: str) -> str:
    if ctx.run_step % 2 == 0:
        return "It's sunny"  # pragma: lax no cover
    else:
        return "It's raining"

# tests/test_dbos.py:976-980
def conditions(ctx: RunContext, city: str) -> str:
    if ctx.run_step % 2 == 0:
        return "It's sunny"  # pragma: lax no cover
    else:
        return "It's raining"

# pydantic_graph/pydantic_graph/beta/decision.py:41-80
class Decision(Generic[StateT, DepsT, HandledT]):
    """Decision node for conditional branching in graph execution.

    A Decision node evaluates conditions and routes execution to different
    branches based on the input data type or custom matching logic.
    """

    id: NodeID
    """Unique identifier for this decision node."""

    branches: list[DecisionBranch[Any]]
    """List of branches that can be taken from this decision."""

    note: str | None
    """Optional documentation note for this decision."""

    def branch(self, branch: DecisionBranch[T]) -> Decision[StateT, DepsT, HandledT | T]:
        """Add a new branch to this decision.

        Args:
            branch: The branch to add to this decision.

        Returns:
            A new Decision with the additional branch.
        """
        return Decision(id=self.id, branches=self.branches + [branch], note=self.note)

    def _force_handled_contravariant(self, inputs: HandledT) -> Never:  # pragma: no cover
        """Forces this type to be contravariant in the HandledT type variable.

        This is an implementation detail of how we can type-check that all possible input types have
        been exhaustively covered.

        Args:
            inputs: Input data of handled types.

        Raises:
            RuntimeError: Always, as this method should never be executed.
        """
        raise RuntimeError('This method should never be called, it is just defined for typing purposes.')

# pydantic_ai_slim/pydantic_ai/models/fallback.py:152-158
def _default_fallback_condition_factory(exceptions: tuple[type[Exception], ...]) -> Callable[[Exception], bool]:
    """Create a default fallback condition for the given exceptions."""

    def fallback_condition(exception: Exception) -> bool:
        return isinstance(exception, exceptions)

    return fallback_condition

# tests/models/test_xai.py:1589-1599
async def test_xai_binary_content_unknown_media_type_raises(allow_model_requests: None):
    """Cover the unsupported BinaryContent media type branch."""
    response = create_response(content='ok', usage=create_usage(prompt_tokens=1, completion_tokens=1))
    mock_client = MockXai.create_mock([response])
    m = XaiModel(XAI_NON_REASONING_MODEL, provider=XaiProvider(xai_client=mock_client))
    agent = Agent(m)

    # Neither image/*, audio/*, nor a known document type => should fail during prompt mapping.
    bc = BinaryContent(b'123', media_type='video/mp4')
    with pytest.raises(RuntimeError, match='Unsupported binary content type: video/mp4'):
        await agent.run(['hello', bc])

# pydantic_graph/pydantic_graph/beta/decision.py:57-66
    def branch(self, branch: DecisionBranch[T]) -> Decision[StateT, DepsT, HandledT | T]:
        """Add a new branch to this decision.

        Args:
            branch: The branch to add to this decision.

        Returns:
            A new Decision with the additional branch.
        """
        return Decision(id=self.id, branches=self.branches + [branch], note=self.note)

# pydantic_evals/pydantic_evals/otel/span_tree.py:244-366
    def _matches_query(self, query: SpanQuery) -> bool:  # noqa: C901
        """Check if the span matches the query conditions."""
        # Logical combinations
        if or_ := query.get('or_'):
            if len(query) > 1:
                raise ValueError("Cannot combine 'or_' conditions with other conditions at the same level")
            return any(self._matches_query(q) for q in or_)
        if not_ := query.get('not_'):
            if self._matches_query(not_):
                return False
        if and_ := query.get('and_'):
            results = [self._matches_query(q) for q in and_]
            if not all(results):
                return False
        # At this point, all existing ANDs and no existing ORs have passed, so it comes down to this condition

        # Name conditions
        if (name_equals := query.get('name_equals')) and self.name != name_equals:
            return False
        if (name_contains := query.get('name_contains')) and name_contains not in self.name:
            return False
        if (name_matches_regex := query.get('name_matches_regex')) and not re.match(name_matches_regex, self.name):
            return False

        # Attribute conditions
        if (has_attributes := query.get('has_attributes')) and not all(
            self.attributes.get(key) == value for key, value in has_attributes.items()
        ):
            return False
        if (has_attributes_keys := query.get('has_attribute_keys')) and not all(
            key in self.attributes for key in has_attributes_keys
        ):
            return False

        # Timing conditions
        if (min_duration := query.get('min_duration')) is not None:
            if not isinstance(min_duration, timedelta):
                min_duration = timedelta(seconds=min_duration)
            if self.duration < min_duration:
                return False
        if (max_duration := query.get('max_duration')) is not None:
            if not isinstance(max_duration, timedelta):
                max_duration = timedelta(seconds=max_duration)
            if self.duration > max_duration:
                return False

        # Children conditions
        if (min_child_count := query.get('min_child_count')) and len(self.children) < min_child_count:
            return False
        if (max_child_count := query.get('max_child_count')) and len(self.children) > max_child_count:
            return False
        if (some_child_has := query.get('some_child_has')) and not any(
            child._matches_query(some_child_has) for child in self.children
        ):
            return False
        if (all_children_have := query.get('all_children_have')) and not all(
            child._matches_query(all_children_have) for child in self.children
        ):
            return False
        if (no_child_has := query.get('no_child_has')) and any(
            child._matches_query(no_child_has) for child in self.children
        ):
            return False

        # Descendant conditions
        # The following local functions with cache decorators are used to avoid repeatedly evaluating these properties
        @cache
        def descendants():
            return self.descendants

        @cache
        def pruned_descendants():
            stop_recursing_when = query.get('stop_recursing_when')
            return (
                self._filter_descendants(lambda _: True, stop_recursing_when) if stop_recursing_when else descendants()
            )

        if (min_descendant_count := query.get('min_descendant_count')) and len(descendants()) < min_descendant_count:
            return False
        if (max_descendant_count := query.get('max_descendant_count')) and len(descendants()) > max_descendant_count:
            return False
        if (some_descendant_has := query.get('some_descendant_has')) and not any(
            descendant._matches_query(some_descendant_has) for descendant in pruned_descendants()
        ):
            return False
        if (all_descendants_have := query.get('all_descendants_have')) and not all(
            descendant._matches_query(all_descendants_have) for descendant in pruned_descendants()
        ):
            return False
        if (no_descendant_has := query.get('no_descendant_has')) and any(
            descendant._matches_query(no_descendant_has) for descendant in pruned_descendants()
        ):
            return False

        # Ancestor conditions
        # The following local functions with cache decorators are used to avoid repeatedly evaluating these properties
        @cache
        def ancestors():
            return self.ancestors

        @cache
        def pruned_ancestors():
            stop_recursing_when = query.get('stop_recursing_when')
            return self._filter_ancestors(lambda _: True, stop_recursing_when) if stop_recursing_when else ancestors()

        if (min_depth := query.get('min_depth')) and len(ancestors()) < min_depth:
            return False
        if (max_depth := query.get('max_depth')) and len(ancestors()) > max_depth:
            return False
        if (some_ancestor_has := query.get('some_ancestor_has')) and not any(
            ancestor._matches_query(some_ancestor_has) for ancestor in pruned_ancestors()
        ):
            return False
        if (all_ancestors_have := query.get('all_ancestors_have')) and not all(
            ancestor._matches_query(all_ancestors_have) for ancestor in pruned_ancestors()
        ):
            return False
        if (no_ancestor_has := query.get('no_ancestor_has')) and any(
            ancestor._matches_query(no_ancestor_has) for ancestor in pruned_ancestors()
        ):
            return False

        return True

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# tests/graph/test_file_persistence.py:21-21
from ..conftest import IsFloat, IsNow

# pydantic_evals/pydantic_evals/otel/span_tree.py:237-242
    def matches(self, query: SpanQuery | SpanPredicate) -> bool:
        """Check if the span node matches the query conditions or predicate."""
        if callable(query):
            return query(self)

        return self._matches_query(query)

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:22-22
from pydantic_ai._utils import dataclasses_no_defaults_repr, get_union_args, is_async_callable, now_utc, run_in_executor

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:22-22
from pydantic_ai._utils import dataclasses_no_defaults_repr, get_union_args, is_async_callable, now_utc, run_in_executor

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:22-22
from pydantic_ai._utils import dataclasses_no_defaults_repr, get_union_args, is_async_callable, now_utc, run_in_executor

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:22-22
from pydantic_ai._utils import dataclasses_no_defaults_repr, get_union_args, is_async_callable, now_utc, run_in_executor

# pydantic_ai_slim/pydantic_ai/embeddings/result.py:8-8
from pydantic_ai._utils import now_utc as _now_utc

# pydantic_ai_slim/pydantic_ai/embeddings/result.py:8-8
from pydantic_ai._utils import now_utc as _now_utc

# pydantic_ai_slim/pydantic_ai/embeddings/result.py:8-8
from pydantic_ai._utils import now_utc as _now_utc

# pydantic_ai_slim/pydantic_ai/embeddings/result.py:8-8
from pydantic_ai._utils import now_utc as _now_utc

# tests/test_dbos.py:987-988
def now_func() -> datetime:
    return datetime.now()

# tests/test_dbos.py:987-988
def now_func() -> datetime:
    return datetime.now()

# pydantic_ai_slim/pydantic_ai/_ssrf.py:182-204
def build_url_with_ip(resolved: ResolvedUrl) -> str:
    """Build a URL using a resolved IP address instead of the hostname.

    For IPv6 addresses, wraps them in brackets as required by URL syntax.
    """
    scheme = 'https' if resolved.is_https else 'http'
    default_port = 443 if resolved.is_https else 80

    # IPv6 addresses need brackets in URLs
    try:
        ip_obj = ipaddress.ip_address(resolved.resolved_ip)
        if isinstance(ip_obj, ipaddress.IPv6Address):
            host_part = f'[{resolved.resolved_ip}]'
        else:
            host_part = resolved.resolved_ip
    except ValueError:
        host_part = resolved.resolved_ip

    # Only include port if non-default
    if resolved.port != default_port:
        host_part = f'{host_part}:{resolved.port}'

    return urlunparse((scheme, host_part, resolved.path, '', '', ''))

# examples/pydantic_ai_examples/evals/agent.py:20-20
    now: datetime = field(default_factory=lambda: datetime.now().astimezone())

# examples/pydantic_ai_examples/evals/models.py:57-57
    now: AwareDatetime

# tests/models/test_fallback.py:571-577
async def test_fallback_condition_tuple() -> None:
    potato_model = FunctionModel(potato_exception_response)
    fallback_model = FallbackModel(potato_model, success_model, fallback_on=(PotatoException, ModelHTTPError))
    agent = Agent(model=fallback_model)

    response = await agent.run('hello')
    assert response.output == 'success'

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName

# examples/pydantic_ai_examples/stream_markdown.py:19-19
from pydantic_ai.models import KnownModelName