# pydantic_ai_slim/pydantic_ai/builtin_tools.py:412-412
    allowed_tools: list[str] | None = None

# pydantic_ai_slim/pydantic_ai/_output.py:219-219
    allows_deferred_tools: bool = False

# tests/models/test_openai.py:1696-1697
class MyExtrasDc(BaseModel, extra='allow'):
    foo: str

# pydantic_ai_slim/pydantic_ai/ui/_web/api.py:48-54
class ChatRequestExtra(BaseModel, extra='ignore', alias_generator=to_camel):
    """Extra data extracted from chat request."""

    model: str | None = None
    """Model ID selected by the user, e.g. 'openai:gpt-5'. Maps to JSON field 'model'."""
    builtin_tools: list[str] = []
    """Tool IDs selected by the user, e.g. ['web_search', 'code_execution']. Maps to JSON field 'builtinTools'."""

# pydantic_ai_slim/pydantic_ai/_function_schema.py:15-15
from pydantic._internal import _decorators, _generate_schema, _typing_extra

# pydantic_ai_slim/pydantic_ai/_function_schema.py:15-15
from pydantic._internal import _decorators, _generate_schema, _typing_extra

# tests/models/test_openai.py:1713-1714
class MyExtrasModel(BaseModel, extra='allow'):
    pass

# examples/pydantic_ai_examples/flight_booking.py:62-66
extraction_agent = Agent(
    'openai:gpt-5.2',
    output_type=list[FlightDetails],
    system_prompt='Extract all the flight details from the given text.',
)

# pydantic_ai_slim/pydantic_ai/ui/_web/api.py:53-53
    builtin_tools: list[str] = []

# pydantic_ai_slim/pydantic_ai/settings.py:173-173
    extra_body: object

# tests/models/test_anthropic.py:1588-1597
async def test_extra_headers(allow_model_requests: None, anthropic_api_key: str):
    # This test doesn't do anything, it's just here to ensure that calls with `extra_headers` don't cause errors, including type.
    m = AnthropicModel('claude-haiku-4-5', provider=AnthropicProvider(api_key=anthropic_api_key))
    agent = Agent(
        m,
        model_settings=AnthropicModelSettings(
            anthropic_metadata={'user_id': '123'}, extra_headers={'Extra-Header-Key': 'Extra-Header-Value'}
        ),
    )
    await agent.run('hello')

# tests/models/test_anthropic.py:1588-1597
async def test_extra_headers(allow_model_requests: None, anthropic_api_key: str):
    # This test doesn't do anything, it's just here to ensure that calls with `extra_headers` don't cause errors, including type.
    m = AnthropicModel('claude-haiku-4-5', provider=AnthropicProvider(api_key=anthropic_api_key))
    agent = Agent(
        m,
        model_settings=AnthropicModelSettings(
            anthropic_metadata={'user_id': '123'}, extra_headers={'Extra-Header-Key': 'Extra-Header-Value'}
        ),
    )
    await agent.run('hello')

# tests/models/test_anthropic.py:1588-1597
async def test_extra_headers(allow_model_requests: None, anthropic_api_key: str):
    # This test doesn't do anything, it's just here to ensure that calls with `extra_headers` don't cause errors, including type.
    m = AnthropicModel('claude-haiku-4-5', provider=AnthropicProvider(api_key=anthropic_api_key))
    agent = Agent(
        m,
        model_settings=AnthropicModelSettings(
            anthropic_metadata={'user_id': '123'}, extra_headers={'Extra-Header-Key': 'Extra-Header-Value'}
        ),
    )
    await agent.run('hello')

# pydantic_ai_slim/pydantic_ai/embeddings/settings.py:60-60
    extra_body: object

# docs/.hooks/snippets.py:17-17
    extra_attrs: dict[str, str] | None = None

# pydantic_ai_slim/pydantic_ai/settings.py:162-162
    extra_headers: dict[str, str]

# pydantic_evals/pydantic_evals/evaluators/report_common.py:62-84
    def _extract(
        case: ReportCase[Any, Any, Any],
        from_: Literal['expected_output', 'output', 'metadata', 'labels'],
        key: str | None,
    ) -> str | None:
        if from_ == 'expected_output':
            return str(case.expected_output) if case.expected_output is not None else None
        elif from_ == 'output':
            return str(case.output) if case.output is not None else None
        elif from_ == 'metadata':
            if key is not None:
                if isinstance(case.metadata, dict):
                    metadata_dict = cast(dict[str, Any], case.metadata)  # pyright: ignore[reportUnknownMemberType]
                    val = metadata_dict.get(key)
                    return str(val) if val is not None else None
                return None  # key requested but metadata isn't a dict â€” skip this case
            return str(case.metadata) if case.metadata is not None else None
        elif from_ == 'labels':
            if key is None:
                raise ValueError("'key' is required when from_='labels'")
            label_result = case.labels.get(key)
            return label_result.value if label_result else None
        assert_never(from_)

# pydantic_ai_slim/pydantic_ai/_ssrf.py:151-179
def extract_host_and_port(url: str) -> tuple[str, str, int, bool]:
    """Extract hostname, path, port, and protocol info from a URL.

    Returns:
        Tuple of (hostname, path_with_query, port, is_https)

    Raises:
        ValueError: If the URL is malformed or uses an unsupported protocol.
    """
    # Validate protocol first, before trying to extract hostname
    _, is_https = validate_url_protocol(url)

    parsed = urlparse(url)
    hostname = parsed.hostname

    if not hostname:
        raise ValueError(f'Invalid URL: no hostname found in "{url}"')

    default_port = 443 if is_https else 80
    port = parsed.port or default_port

    # Reconstruct path with query string
    path = parsed.path or '/'
    if parsed.query:
        path = f'{path}?{parsed.query}'
    if parsed.fragment:
        path = f'{path}#{parsed.fragment}'

    return hostname, path, port, is_https

# pydantic_ai_slim/pydantic_ai/format_prompt.py:96-96
    _is_info_extracted: bool = False

# pydantic_ai_slim/pydantic_ai/embeddings/settings.py:51-51
    extra_headers: dict[str, str]

# pydantic_ai_slim/pydantic_ai/format_prompt.py:223-224
    def _extract_attributes(cls, info: FieldInfo | ComputedFieldInfo) -> dict[str, str]:
        return {attr: str(value) for attr in cls._FIELD_ATTRIBUTES if (value := getattr(info, attr, None)) is not None}

# tests/test_ssrf.py:182-229
class TestExtractHostAndPort:
    """Tests for extract_host_and_port function."""

    def test_basic_http_url(self) -> None:
        hostname, path, port, is_https = extract_host_and_port('http://example.com/path')
        assert hostname == 'example.com'
        assert path == '/path'
        assert port == 80
        assert is_https is False

    def test_basic_https_url(self) -> None:
        hostname, path, port, is_https = extract_host_and_port('https://example.com/path')
        assert hostname == 'example.com'
        assert path == '/path'
        assert port == 443
        assert is_https is True

    def test_custom_port(self) -> None:
        hostname, path, port, is_https = extract_host_and_port('http://example.com:8080/path')
        assert hostname == 'example.com'
        assert path == '/path'
        assert port == 8080
        assert is_https is False

    def test_path_with_query_string(self) -> None:
        hostname, path, port, is_https = extract_host_and_port('https://example.com/path?query=value')
        assert hostname == 'example.com'
        assert path == '/path?query=value'
        assert port == 443
        assert is_https is True

    def test_path_with_fragment(self) -> None:
        hostname, path, port, is_https = extract_host_and_port('https://example.com/path#fragment')
        assert hostname == 'example.com'
        assert path == '/path#fragment'
        assert port == 443
        assert is_https is True

    def test_empty_path(self) -> None:
        hostname, path, port, is_https = extract_host_and_port('https://example.com')
        assert hostname == 'example.com'
        assert path == '/'
        assert port == 443
        assert is_https is True

    def test_invalid_url_no_hostname(self) -> None:
        with pytest.raises(ValueError, match='Invalid URL: no hostname found'):
            extract_host_and_port('http://')

# tests/json_body_serializer.py:66-74
ALLOWED_HEADERS = {
    # required by huggingface_hub.file_download used by test_embeddings.py::TestSentenceTransformers
    'x-repo-commit',
    'x-linked-size',
    'x-linked-etag',
    # required for test_google_model_file_search_tool
    'x-goog-upload-url',
    'x-goog-upload-status',
}

# pydantic_ai_slim/pydantic_ai/models/__init__.py:1083-1095
def override_allow_model_requests(allow_model_requests: bool) -> Iterator[None]:
    """Context manager to temporarily override [`ALLOW_MODEL_REQUESTS`][pydantic_ai.models.ALLOW_MODEL_REQUESTS].

    Args:
        allow_model_requests: Whether to allow model requests within the context.
    """
    global ALLOW_MODEL_REQUESTS
    old_value = ALLOW_MODEL_REQUESTS
    ALLOW_MODEL_REQUESTS = allow_model_requests  # pyright: ignore[reportConstantRedefinition]
    try:
        yield
    finally:
        ALLOW_MODEL_REQUESTS = old_value  # pyright: ignore[reportConstantRedefinition]

# tests/models/test_openai.py:1765-1766
def tool_with_model_with_extras(x: MyExtrasModel) -> str:
    return f'{x}'  # pragma: no cover

# examples/pydantic_ai_examples/flight_booking.py:70-75
async def extract_flights(ctx: RunContext[Deps]) -> list[FlightDetails]:
    """Get details of all flights."""
    # we pass the usage to the search agent so requests within this agent are counted
    result = await extraction_agent.run(ctx.deps.web_page_text, usage=ctx.usage)
    logfire.info('found {flight_count} flights', flight_count=len(result.output))
    return result.output

# pydantic_ai_slim/pydantic_ai/_output.py:227-228
    def allows_text(self) -> bool:
        return self.text_processor is not None

# tests/models/test_openai.py:1697-1697
    foo: str

# tests/test_ssrf.py:344-349
    async def test_private_ip_allowed_with_allow_local(self) -> None:
        """Test that private IPs are allowed with allow_local=True."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            mock_executor.return_value = [(2, 1, 6, '', ('192.168.1.1', 0))]
            resolved = await validate_and_resolve_url('http://internal.local/path', allow_local=True)
            assert resolved.resolved_ip == '192.168.1.1'

# pydantic_ai_slim/pydantic_ai/_output.py:220-220
    allows_image: bool = False

# pydantic_ai_slim/pydantic_ai/mcp.py:325-325
    allow_sampling: bool

# tests/models/test_openai.py:1749-1750
def tool_with_dataclass_with_extras(x: MyExtrasDc) -> str:
    return f'{x}'  # pragma: no cover

# pydantic_ai_slim/pydantic_ai/models/__init__.py:1058-1058
ALLOW_MODEL_REQUESTS = True

# tests/conftest.py:177-179
def allow_model_requests():
    with pydantic_ai.models.override_allow_model_requests(True):
        yield

# docs/.hooks/test_snippets.py:636-649
def test_inject_snippets_extra_attrs():
    """Test snippet injection with extra attributes."""
    content = "print('test')"

    with tempfile.TemporaryDirectory() as temp_dir:
        docs_dir = Path(temp_dir)
        target_file = docs_dir / 'test.py'
        target_file.write_text(content, encoding='utf-8')

        markdown = '```snippet {path="test.py" custom="value" another="attr"}'

        result = inject_snippets(markdown, docs_dir)

    assert result == snapshot('```snippet {path="test.py" custom="value" another="attr"}')

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_utils.py:7-7
    retries_allowed: bool

# pydantic_ai_slim/pydantic_ai/builtin_tools.py:215-215
    allowed_domains: list[str] | None = None

# pydantic_ai_slim/pydantic_ai/mcp.py:861-861
    allow_sampling: bool

# pydantic_ai_slim/pydantic_ai/mcp.py:1028-1028
    allow_sampling: bool

# pydantic_ai_slim/pydantic_ai/builtin_tools.py:131-131
    allowed_domains: list[str] | None = None

# pydantic_ai_slim/pydantic_ai/models/function.py:225-225
    allow_text_output: bool

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:431-436
    def model(self, value: models.Model | models.KnownModelName | str | None) -> None:
        """Set the default model configured for this agent.

        We allow `str` here since the actual list of allowed models changes frequently.
        """
        self._model = value

# docs/.hooks/test_snippets.py:56-68
def test_parse_snippet_directive_extra_attrs():
    """Test parsing with extra attributes."""
    line = '```snippet {path="test.py" custom="value" another="attr"}'
    result = parse_snippet_directive(line)
    assert result == snapshot(
        SnippetDirective(
            path='test.py',
            title=None,
            fragment=None,
            highlight=None,
            extra_attrs={'another': 'attr', 'custom': 'value'},
        )
    )

# tests/test_usage_limits.py:329-360
async def test_output_tool_allowed_at_limit() -> None:
    """Test that output tools can be called even when at the tool_calls_limit."""

    class MyOutput(BaseModel):
        result: str

    def call_output_after_regular(messages: list[ModelMessage], info: AgentInfo) -> ModelResponse:
        if len(messages) == 1:
            return ModelResponse(
                parts=[
                    ToolCallPart('regular_tool', {'x': 'test'}, 'call_1'),
                ],
                usage=RequestUsage(input_tokens=10, output_tokens=5),
            )
        else:
            return ModelResponse(
                parts=[
                    ToolCallPart('final_result', {'result': 'success'}, 'call_2'),
                ],
                usage=RequestUsage(input_tokens=10, output_tokens=5),
            )

    test_agent = Agent(FunctionModel(call_output_after_regular), output_type=ToolOutput(MyOutput))

    @test_agent.tool_plain
    async def regular_tool(x: str) -> str:
        return f'{x}-processed'

    result = await test_agent.run('test', usage_limits=UsageLimits(tool_calls_limit=1))

    assert result.output.result == 'success'
    assert result.usage() == snapshot(RunUsage(requests=2, input_tokens=20, output_tokens=10, tool_calls=1))

# tests/json_body_serializer.py:60-65
ALLOWED_HEADER_PREFIXES = {
    # required by huggingface_hub.file_download used by test_embeddings.py::TestSentenceTransformers
    'x-xet-',
    # required for Bedrock embeddings to preserve token count headers
    'x-amzn-bedrock-',
}

# docs/.hooks/test_snippets.py:247-296
def test_extract_fragment_content_specific_section():
    """Test extracting specific section."""
    content = """line 1
### [section1]
content 1
content 2
### [/section1]
line 6"""

    with temp_text_file(content) as temp_path:
        parsed = parse_file_sections(temp_path)

    assert parsed.render([], []) == snapshot(
        RenderedSnippet(
            content="""\
line 1
content 1
content 2
line 6\
""",
            highlights=[],
            original_range=LineRange(start_line=0, end_line=6),
        )
    )

    assert parsed.render(['section1'], []) == snapshot(
        RenderedSnippet(
            content="""\
content 1
content 2

...\
""",
            highlights=[],
            original_range=LineRange(start_line=2, end_line=4),
        )
    )

    assert parsed.render([], ['section1']) == snapshot(
        RenderedSnippet(
            content="""\
line 1
content 1
content 2
line 6\
""",
            highlights=[LineRange(start_line=1, end_line=3)],
            original_range=LineRange(start_line=0, end_line=6),
        )
    )

# tests/test_mcp.py:1564-1577
async def test_tool_metadata_extraction():
    """Test that MCP tool metadata is properly extracted into ToolDefinition."""

    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        ctx = RunContext(deps=None, model=TestModel(), usage=RunUsage())
        tools = [tool.tool_def for tool in (await server.get_tools(ctx)).values()]
        # find `celsius_to_fahrenheit`
        celsius_to_fahrenheit = next(tool for tool in tools if tool.name == 'celsius_to_fahrenheit')
        assert celsius_to_fahrenheit.metadata is not None
        assert celsius_to_fahrenheit.metadata.get('annotations') is not None
        assert celsius_to_fahrenheit.metadata.get('annotations', {}).get('title', None) == 'Celsius to Fahrenheit'
        assert celsius_to_fahrenheit.metadata.get('output_schema') is not None
        assert celsius_to_fahrenheit.metadata.get('output_schema', {}).get('type', None) == 'object'

# pydantic_ai_slim/pydantic_ai/models/__init__.py:1069-1079
def check_allow_model_requests() -> None:
    """Check if model requests are allowed.

    If you're defining your own models that have costs or latency associated with their use, you should call this in
    [`Model.request`][pydantic_ai.models.Model.request] and [`Model.request_stream`][pydantic_ai.models.Model.request_stream].

    Raises:
        RuntimeError: If model requests are not allowed.
    """
    if not ALLOW_MODEL_REQUESTS:
        raise RuntimeError('Model requests are not allowed, since ALLOW_MODEL_REQUESTS is False')

# pydantic_ai_slim/pydantic_ai/models/__init__.py:1069-1079
def check_allow_model_requests() -> None:
    """Check if model requests are allowed.

    If you're defining your own models that have costs or latency associated with their use, you should call this in
    [`Model.request`][pydantic_ai.models.Model.request] and [`Model.request_stream`][pydantic_ai.models.Model.request_stream].

    Raises:
        RuntimeError: If model requests are not allowed.
    """
    if not ALLOW_MODEL_REQUESTS:
        raise RuntimeError('Model requests are not allowed, since ALLOW_MODEL_REQUESTS is False')

# pydantic_ai_slim/pydantic_ai/models/__init__.py:1069-1079
def check_allow_model_requests() -> None:
    """Check if model requests are allowed.

    If you're defining your own models that have costs or latency associated with their use, you should call this in
    [`Model.request`][pydantic_ai.models.Model.request] and [`Model.request_stream`][pydantic_ai.models.Model.request_stream].

    Raises:
        RuntimeError: If model requests are not allowed.
    """
    if not ALLOW_MODEL_REQUESTS:
        raise RuntimeError('Model requests are not allowed, since ALLOW_MODEL_REQUESTS is False')

# pydantic_ai_slim/pydantic_ai/models/__init__.py:1069-1079
def check_allow_model_requests() -> None:
    """Check if model requests are allowed.

    If you're defining your own models that have costs or latency associated with their use, you should call this in
    [`Model.request`][pydantic_ai.models.Model.request] and [`Model.request_stream`][pydantic_ai.models.Model.request_stream].

    Raises:
        RuntimeError: If model requests are not allowed.
    """
    if not ALLOW_MODEL_REQUESTS:
        raise RuntimeError('Model requests are not allowed, since ALLOW_MODEL_REQUESTS is False')

# pydantic_ai_slim/pydantic_ai/models/__init__.py:1069-1079
def check_allow_model_requests() -> None:
    """Check if model requests are allowed.

    If you're defining your own models that have costs or latency associated with their use, you should call this in
    [`Model.request`][pydantic_ai.models.Model.request] and [`Model.request_stream`][pydantic_ai.models.Model.request_stream].

    Raises:
        RuntimeError: If model requests are not allowed.
    """
    if not ALLOW_MODEL_REQUESTS:
        raise RuntimeError('Model requests are not allowed, since ALLOW_MODEL_REQUESTS is False')

# pydantic_ai_slim/pydantic_ai/models/__init__.py:1069-1079
def check_allow_model_requests() -> None:
    """Check if model requests are allowed.

    If you're defining your own models that have costs or latency associated with their use, you should call this in
    [`Model.request`][pydantic_ai.models.Model.request] and [`Model.request_stream`][pydantic_ai.models.Model.request_stream].

    Raises:
        RuntimeError: If model requests are not allowed.
    """
    if not ALLOW_MODEL_REQUESTS:
        raise RuntimeError('Model requests are not allowed, since ALLOW_MODEL_REQUESTS is False')

# pydantic_ai_slim/pydantic_ai/models/__init__.py:1069-1079
def check_allow_model_requests() -> None:
    """Check if model requests are allowed.

    If you're defining your own models that have costs or latency associated with their use, you should call this in
    [`Model.request`][pydantic_ai.models.Model.request] and [`Model.request_stream`][pydantic_ai.models.Model.request_stream].

    Raises:
        RuntimeError: If model requests are not allowed.
    """
    if not ALLOW_MODEL_REQUESTS:
        raise RuntimeError('Model requests are not allowed, since ALLOW_MODEL_REQUESTS is False')

# pydantic_ai_slim/pydantic_ai/models/__init__.py:1069-1079
def check_allow_model_requests() -> None:
    """Check if model requests are allowed.

    If you're defining your own models that have costs or latency associated with their use, you should call this in
    [`Model.request`][pydantic_ai.models.Model.request] and [`Model.request_stream`][pydantic_ai.models.Model.request_stream].

    Raises:
        RuntimeError: If model requests are not allowed.
    """
    if not ALLOW_MODEL_REQUESTS:
        raise RuntimeError('Model requests are not allowed, since ALLOW_MODEL_REQUESTS is False')

# pydantic_ai_slim/pydantic_ai/models/__init__.py:1069-1079
def check_allow_model_requests() -> None:
    """Check if model requests are allowed.

    If you're defining your own models that have costs or latency associated with their use, you should call this in
    [`Model.request`][pydantic_ai.models.Model.request] and [`Model.request_stream`][pydantic_ai.models.Model.request_stream].

    Raises:
        RuntimeError: If model requests are not allowed.
    """
    if not ALLOW_MODEL_REQUESTS:
        raise RuntimeError('Model requests are not allowed, since ALLOW_MODEL_REQUESTS is False')

# pydantic_ai_slim/pydantic_ai/ui/_web/api.py:51-51
    model: str | None = None

# pydantic_ai_slim/pydantic_ai/models/openrouter.py:146-146
    allow_fallbacks: bool

# pydantic_ai_slim/pydantic_ai/models/__init__.py:609-609
    allow_text_output: bool = True

# pydantic_ai_slim/pydantic_ai/mcp.py:241-241
    tools_list_changed: bool = False

# pydantic_ai_slim/pydantic_ai/models/__init__.py:610-610
    allow_image_output: bool = False

# tests/test_ssrf.py:326-335
    async def test_public_ip_allowed(self) -> None:
        """Test that public IPs are allowed."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            mock_executor.return_value = [(2, 1, 6, '', ('93.184.215.14', 0))]
            resolved = await validate_and_resolve_url('https://example.com/path', allow_local=False)
            assert resolved.resolved_ip == '93.184.215.14'
            assert resolved.hostname == 'example.com'
            assert resolved.port == 443
            assert resolved.is_https is True
            assert resolved.path == '/path'

# tests/test_ssrf.py:86-87
    def test_public_ips_allowed(self, ip: str) -> None:
        assert is_private_ip(ip) is False

# tests/test_ssrf.py:160-163
    def test_allowed_protocols(self, url: str) -> None:
        scheme, is_https = validate_url_protocol(url)
        assert scheme in ('http', 'https')
        assert is_https == (scheme == 'https')

# pydantic_ai_slim/pydantic_ai/models/gemini.py:845-845
    allowed_function_names: list[str]

# tests/conftest.py:51-51
pydantic_ai.models.ALLOW_MODEL_REQUESTS = False

# tests/test_usage_limits.py:3-3
import operator

# examples/pydantic_ai_examples/flight_booking.py:109-110
class Failed(BaseModel):
    """Unable to extract a seat selection."""

# pydantic_ai_slim/pydantic_ai/toolsets/abstract.py:113-115
    async def get_tools(self, ctx: RunContext[AgentDepsT]) -> dict[str, ToolsetTool[AgentDepsT]]:
        """The tools that are available in this toolset."""
        raise NotImplementedError()