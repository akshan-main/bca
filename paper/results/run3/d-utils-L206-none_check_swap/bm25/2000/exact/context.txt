# tests/typed_agent.py:11-11
from typing_extensions import assert_type

# tests/typed_agent.py:11-11
from typing_extensions import assert_type

# tests/typed_agent.py:11-11
from typing_extensions import assert_type

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_ai_slim/pydantic_ai/_a2a.py:12-12
from typing_extensions import assert_never

# pydantic_evals/pydantic_evals/evaluators/common.py:199-199
    assertion: OutputConfig | Literal[False] = field(default_factory=lambda: OutputConfig(include_reason=True))

# pydantic_evals/pydantic_evals/reporting/__init__.py:88-88
    assertions: dict[str, EvaluationResult[bool]]

# tests/evals/test_reporting.py:46-52
def sample_assertion(mock_evaluator: Evaluator[TaskInput, TaskOutput, TaskMetadata]) -> EvaluationResult[bool]:
    return EvaluationResult(
        name='MockEvaluator',
        value=True,
        reason=None,
        source=mock_evaluator.as_spec(),
    )

# pydantic_evals/pydantic_evals/reporting/__init__.py:171-171
    assertions: float | None

# pydantic_ai_slim/pydantic_ai/_utils.py:140-143
class Some(Generic[T]):
    """Analogous to Rust's `Option::Some` type."""

    value: T

# tests/conftest.py:21-21
from _pytest.assertion.rewrite import AssertionRewritingHook

# pydantic_evals/pydantic_evals/evaluators/report_common.py:93-93
    positive_key: str | None = None

# pydantic_evals/pydantic_evals/evaluators/report_common.py:92-92
    positive_from: Literal['expected_output', 'assertions', 'labels']

# pydantic_evals/pydantic_evals/evaluators/report_common.py:149-162
    def _get_positive(self, case: ReportCase[Any, Any, Any]) -> bool | None:
        if self.positive_from == 'expected_output':
            return bool(case.expected_output) if case.expected_output is not None else None
        elif self.positive_from == 'assertions':
            if self.positive_key is None:
                raise ValueError("'positive_key' is required when positive_from='assertions'")
            assertion = case.assertions.get(self.positive_key)
            return assertion.value if assertion else None
        elif self.positive_from == 'labels':
            if self.positive_key is None:
                raise ValueError("'positive_key' is required when positive_from='labels'")
            label = case.labels.get(self.positive_key)
            return bool(label.value) if label else None
        assert_never(self.positive_from)

# pydantic_evals/pydantic_evals/reporting/__init__.py:946-946
    include_assertions: bool

# pydantic_evals/pydantic_evals/reporting/__init__.py:1277-1290
    def _render_assertions(
        self,
        assertions: list[EvaluationResult[bool]],
    ) -> str:
        if not assertions:
            return EMPTY_CELL_STR
        lines: list[str] = []
        for a in assertions:
            line = '[green]✔[/]' if a.value else '[red]✗[/]'
            if self.include_reasons:
                line = f'{a.name}: {line}\n'
                line = f'{line}  Reason: {a.reason}\n\n' if a.reason else line
            lines.append(line)
        return ''.join(lines)

# pydantic_evals/pydantic_evals/reporting/__init__.py:1392-1393
    def include_assertions(self, report: EvaluationReport, baseline: EvaluationReport | None = None):
        return any(case.assertions for case in self._all_cases(report, baseline))

# tests/test_usage_limits.py:258-284
def test_add_usages_with_none_detail_value():
    """Test that None values in details are skipped when incrementing usage."""
    usage = RunUsage(
        requests=1,
        input_tokens=10,
        output_tokens=20,
        details={'reasoning_tokens': 5},
    )

    # Create a usage with None in details (simulating model response with missing detail)
    incr_usage = RunUsage(
        requests=1,
        input_tokens=5,
        output_tokens=10,
    )
    # Manually set a None value in details to simulate edge case from model responses
    incr_usage.details = {'reasoning_tokens': None, 'other_tokens': 10}  # type: ignore[dict-item]

    result = usage + incr_usage
    assert result == snapshot(
        RunUsage(
            requests=2,
            input_tokens=15,
            output_tokens=30,
            details={'reasoning_tokens': 5, 'other_tokens': 10},
        )
    )

# pydantic_evals/pydantic_evals/reporting/__init__.py:1303-1311
    def _render_assertions_diff(
        assertions: list[EvaluationResult[bool]], new_assertions: list[EvaluationResult[bool]]
    ) -> str:
        if not assertions and not new_assertions:  # pragma: no cover
            return EMPTY_CELL_STR

        old = ''.join(['[green]✔[/]' if a.value else '[red]✗[/]' for a in assertions])
        new = ''.join(['[green]✔[/]' if a.value else '[red]✗[/]' for a in new_assertions])
        return old if old == new else f'{old} → {new}'

# tests/graph/beta/test_edge_cases.py:60-80
async def test_step_with_zero_value():
    """Test handling of zero values (ensure they're not confused with None/falsy)."""
    g = GraphBuilder(state_type=EdgeCaseState, output_type=int)

    @g.step
    async def return_zero(ctx: StepContext[EdgeCaseState, None, None]) -> int:
        return 0

    @g.step
    async def process_zero(ctx: StepContext[EdgeCaseState, None, int]) -> int:
        return ctx.inputs + 1

    g.add(
        g.edge_from(g.start_node).to(return_zero),
        g.edge_from(return_zero).to(process_zero),
        g.edge_from(process_zero).to(g.end_node),
    )

    graph = g.build()
    result = await graph.run(state=EdgeCaseState())
    assert result == 1

# pydantic_evals/pydantic_evals/reporting/__init__.py:1293-1300
    def _render_aggregate_assertions(
        assertions: float | None,
    ) -> str:
        return (
            default_render_percentage(assertions) + ' [green]✔[/]'
            if assertions is not None
            else EMPTY_AGGREGATE_CELL_STR
        )

# tests/test_tools.py:2665-2675
def test_tool_timeout_default_none():
    """Test that timeout defaults to None when not specified."""
    agent = Agent(TestModel())

    @agent.tool_plain
    def tool_without_timeout() -> str:
        return 'done'  # pragma: no cover

    tool = agent._function_toolset.tools['tool_without_timeout']
    assert tool.timeout is None
    assert tool.tool_def.timeout is None

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType

# tests/mcp_server.py:164-165
async def get_none():
    return None

# pydantic_ai_slim/pydantic_ai/_utils.py:150-153
class Unset:
    """A singleton to represent an unset value."""

    pass

# tests/test_parts_manager.py:649-666
def test_handle_thinking_delta_provider_details_callback_from_none():
    """Test callback when existing provider_details is None."""
    manager = ModelResponsePartsManager()

    # Create initial part without provider_details
    list(manager.handle_thinking_delta(vendor_part_id='t', content='initial'))

    # Update using callback that handles None
    def add_details(existing: dict[str, Any] | None) -> dict[str, Any]:
        details = dict(existing or {})
        details['new_key'] = 'new_value'
        return details

    list(manager.handle_thinking_delta(vendor_part_id='t', content=' more', provider_details=add_details))

    assert manager.get_parts() == snapshot(
        [ThinkingPart(content='initial more', provider_details={'new_key': 'new_value'})]
    )

# pydantic_ai_slim/pydantic_ai/format_prompt.py:84-84
    none_str: str

# tests/typed_deps.py:53-54
async def my_prepare_none(ctx: RunContext, tool_defn: ToolDefinition) -> None:
    pass