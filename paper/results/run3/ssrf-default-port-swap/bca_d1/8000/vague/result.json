{
  "task_id": "ssrf-default-port-swap",
  "method": "bca_d1",
  "budget": 8000,
  "query_type": "vague",
  "tokens_used": 7999,
  "symbols_selected": 41,
  "files_included": 12,
  "assembly_time_ms": 204.2,
  "llm_time_ms": 3850.0,
  "llm_input_tokens": 7514,
  "llm_output_tokens": 70,
  "tests_passed": false,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: tests/models/test_google.py\nSEARCH:\n    model = GoogleModel('gemini-1.5-flash', provider=GoogleProvider(api_key='test-key'))\nREPLACE:\n    model = GoogleModel('gemini-1.5-flash', provider=GoogleProvider(api_key='test-key', port=443))\n",
  "error": "",
  "test_time_ms": 1303.1,
  "failure_mode": "test_fail",
  "target_file_hit": false,
  "target_symbol_hit": false,
  "context_patch_overlap": 0.083,
  "patch_files_changed": 1,
  "patch_lines_changed": 1,
  "edit_distance_lines": -1,
  "entity_count_extracted": 0,
  "entity_count_mapped": 0,
  "query_identifier_density": 0.0,
  "seed_symbol_keys": [],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/_ssrf.py::extract_host_and_port",
  "min_hops_seed_to_mutation": -1,
  "median_hops_seed_to_mutation": -1.0,
  "bca_closure_added_symbols": 2,
  "bca_closure_added_tokens": 181,
  "bca_frontier_visited": 45,
  "context_symbol_keys": [
    "examples/pydantic_ai_examples/evals/custom_evaluators.py::ValidateTimeRange",
    "examples/pydantic_ai_examples/evals/custom_evaluators.py::ValidateTimeRange.evaluate",
    "examples/pydantic_ai_examples/evals/custom_evaluators.py::UserMessageIsConcise.evaluate",
    "examples/pydantic_ai_examples/evals/custom_evaluators.py::AgentCalledTool.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/report_evaluator.py::InputsT",
    "pydantic_evals/pydantic_evals/evaluators/report_evaluator.py::OutputT",
    "pydantic_evals/pydantic_evals/evaluators/report_evaluator.py::MetadataT",
    "pydantic_evals/pydantic_evals/evaluators/report_evaluator.py::ReportEvaluatorContext",
    "pydantic_evals/pydantic_evals/evaluators/report_evaluator.py::ReportEvaluator",
    "pydantic_evals/pydantic_evals/evaluators/report_evaluator.py::ReportEvaluator.evaluate",
    "pydantic_evals/pydantic_evals/otel/_context_in_memory_span_exporter.py::_EXPORTER_CONTEXT_ID",
    "pydantic_evals/pydantic_evals/otel/_context_in_memory_span_exporter.py::_ContextInMemorySpanExporter",
    "pydantic_evals/pydantic_evals/otel/_context_in_memory_span_exporter.py::_ContextInMemorySpanExporter.__init__",
    "pydantic_evals/pydantic_evals/otel/_context_in_memory_span_exporter.py::_ContextInMemorySpanExporter.clear",
    "pydantic_evals/pydantic_evals/otel/_context_in_memory_span_exporter.py::_ContextInMemorySpanExporter.get_finished_spans",
    "pydantic_evals/pydantic_evals/otel/_context_in_memory_span_exporter.py::_ContextInMemorySpanExporter.export",
    "pydantic_evals/pydantic_evals/otel/_context_in_memory_span_exporter.py::_ContextInMemorySpanExporter.shutdown",
    "pydantic_evals/pydantic_evals/otel/_context_in_memory_span_exporter.py::_ContextInMemorySpanExporter.force_flush",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::InputsT",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::OutputT",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::MetadataT",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::ReportCase",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::EvaluationReport",
    "tests/evals/test_report_evaluators.py::_make_report_case",
    "tests/evals/test_report_evaluators.py::_make_report",
    "tests/evals/test_report_evaluators.py::test_confusion_matrix_evaluator_from_expected_output_and_output",
    "tests/evals/test_report_evaluators.py::test_confusion_matrix_evaluator_from_labels",
    "tests/evals/test_report_evaluators.py::test_confusion_matrix_evaluator_from_metadata",
    "tests/evals/test_report_evaluators.py::test_confusion_matrix_evaluator_skips_none",
    "tests/evals/test_report_evaluators.py::test_confusion_matrix_labels_requires_key",
    "tests/evals/test_report_evaluators.py::test_precision_recall_evaluator_basic",
    "tests/evals/test_report_evaluators.py::test_precision_recall_evaluator_from_metrics",
    "tests/evals/test_report_evaluators.py::test_precision_recall_evaluator_empty",
    "tests/evals/test_report_evaluators.py::test_precision_recall_assertions_requires_key",
    "tests/evals/test_report_evaluators.py::test_precision_recall_labels_requires_key",
    "tests/evals/test_report_evaluators.py::test_custom_report_evaluator",
    "tests/evals/test_report_evaluators.py::test_report_rendering_includes_analyses",
    "tests/evals/test_report_evaluators.py::test_report_rendering_include_analyses_false",
    "tests/evals/test_report_evaluators.py::test_report_rendering_include_evaluator_failures_false",
    "tests/evals/test_report_evaluators.py::test_confusion_matrix_evaluator_metadata_non_dict",
    "tests/evals/test_report_evaluators.py::test_confusion_matrix_evaluator_metadata_key_with_non_dict",
    "tests/evals/test_report_evaluators.py::test_precision_recall_evaluator_skips_missing_scores",
    "tests/evals/test_report_evaluators.py::test_precision_recall_evaluator_positive_from_expected_output",
    "tests/evals/test_report_evaluators.py::test_precision_recall_evaluator_positive_from_labels",
    "tests/evals/test_report_evaluators.py::test_async_report_evaluator",
    "tests/evals/test_report_evaluators.py::test_report_rendering_with_failures",
    "tests/evals/test_report_evaluators.py::test_report_rendering_scalar_without_unit",
    "tests/evals/test_report_evaluators.py::test_report_rendering_precision_recall",
    "tests/evals/test_report_evaluators.py::test_report_rendering_table_result",
    "tests/evals/test_report_evaluators.py::test_report_evaluator_exception_during_evaluate",
    "tests/evals/test_reporting.py::sample_report_case",
    "tests/evals/test_reporting.py::sample_report",
    "tests/evals/test_reports.py::sample_report_case",
    "tests/evals/test_reports.py::sample_report",
    "tests/evals/test_reports.py::test_report_init",
    "tests/models/test_bedrock.py::_StubBedrockClient.__init__",
    "tests/models/test_bedrock.py::_StubBedrockProvider.__init__",
    "tests/models/test_bedrock.py::test_bedrock_cache_skipped_for_unsupported_models",
    "tests/models/test_fallback.py::failure_model",
    "tests/models/test_fallback.py::test_all_failed",
    "tests/models/test_fallback.py::failure_model_stream",
    "tests/models/test_fallback.py::test_all_failed_streaming",
    "tests/models/test_google.py::test_http_video_url_downloads_on_google_gla",
    "tests/models/test_groq.py::chunk",
    "tests/models/test_groq.py::test_tool_use_failed_error",
    "tests/models/test_groq.py::test_tool_use_failed_error_streaming"
  ],
  "mutation_symbol_lines": 29,
  "mutation_symbol_kind": "function",
  "mutation_file_symbols": 29,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.073,
  "retrieval_softmax_entropy": 4.2649,
  "retrieval_softmax_tau": 0.605,
  "retrieval_effective_candidates": 19.23,
  "retrieval_top5_ratio": 0.8782,
  "retrieval_within95_count": 1,
  "retrieval_scored_symbols": 41,
  "retrieval_top1_score": 1.082,
  "retrieval_top5_mean_score": 0.9502,
  "retrieval_budget_utilization": 0.9999,
  "retrieval_file_concentration": 0.0,
  "repo_name": "pydantic-ai",
  "category": "ssrf",
  "mutation_type": "handcrafted",
  "source": "handcrafted"
}