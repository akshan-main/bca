# tests/test_ssrf.py:344-349
    async def test_private_ip_allowed_with_allow_local(self) -> None:
        """Test that private IPs are allowed with allow_local=True."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            mock_executor.return_value = [(2, 1, 6, '', ('192.168.1.1', 0))]
            resolved = await validate_and_resolve_url('http://internal.local/path', allow_local=True)
            assert resolved.resolved_ip == '192.168.1.1'

# tests/test_ssrf.py:351-356
    async def test_cloud_metadata_always_blocked(self) -> None:
        """Test that cloud metadata IPs are always blocked, even with allow_local=True."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            mock_executor.return_value = [(2, 1, 6, '', ('169.254.169.254', 0))]
            with pytest.raises(ValueError, match='Access to cloud metadata service'):
                await validate_and_resolve_url('http://metadata.google.internal/path', allow_local=True)

# tests/test_ssrf.py:372-375
    async def test_literal_private_ip_blocked(self) -> None:
        """Test that literal private IPs in URLs are blocked."""
        with pytest.raises(ValueError, match='Access to private/internal IP address'):
            await validate_and_resolve_url('http://192.168.1.1/path', allow_local=False)

# tests/test_ssrf.py:337-342
    async def test_private_ip_blocked_by_default(self) -> None:
        """Test that private IPs are blocked by default."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            mock_executor.return_value = [(2, 1, 6, '', ('192.168.1.1', 0))]
            with pytest.raises(ValueError, match='Access to private/internal IP address'):
                await validate_and_resolve_url('http://internal.local/path', allow_local=False)

# tests/test_ssrf.py:86-87
    def test_public_ips_allowed(self, ip: str) -> None:
        assert is_private_ip(ip) is False

# tests/test_ssrf.py:461-482
    async def test_redirect_to_private_ip_blocked(self) -> None:
        """Test that redirects to private IPs are blocked."""
        redirect_response = AsyncMock()
        redirect_response.is_redirect = True
        redirect_response.headers = {'location': 'http://internal.local/file.txt'}

        with (
            patch('pydantic_ai._ssrf.run_in_executor') as mock_executor,
            patch('pydantic_ai._ssrf.cached_async_http_client') as mock_client_fn,
        ):
            # First call for example.com (public), second for internal.local (private)
            mock_executor.side_effect = [
                [(2, 1, 6, '', ('93.184.215.14', 0))],
                [(2, 1, 6, '', ('192.168.1.1', 0))],
            ]

            mock_client = AsyncMock()
            mock_client.get.return_value = redirect_response
            mock_client_fn.return_value = mock_client

            with pytest.raises(ValueError, match='Access to private/internal IP address'):
                await safe_download('https://example.com/file.txt')

# tests/test_ssrf.py:358-363
    async def test_alibaba_cloud_metadata_always_blocked(self) -> None:
        """Test that Alibaba Cloud metadata IP is always blocked, even with allow_local=True."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            mock_executor.return_value = [(2, 1, 6, '', ('100.100.100.200', 0))]
            with pytest.raises(ValueError, match='Access to cloud metadata service'):
                await validate_and_resolve_url('http://metadata.aliyun.internal/path', allow_local=True)

# pydantic_ai_slim/pydantic_ai/_ssrf.py:74-79
def is_cloud_metadata_ip(ip_str: str) -> bool:
    """Check if an IP address is a cloud metadata endpoint.

    These are always blocked for security reasons, even with allow_local=True.
    """
    return ip_str in _CLOUD_METADATA_IPS

# tests/test_ssrf.py:694-703
    async def test_multiple_ips_with_any_private_blocked(self) -> None:
        """Test that if any IP in the resolution is private, request is blocked."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            # DNS returns multiple IPs, one of which is private
            mock_executor.return_value = [
                (2, 1, 6, '', ('8.8.8.8', 0)),  # Public
                (10, 1, 6, '', ('::1', 0)),  # Private IPv6 loopback
            ]
            with pytest.raises(ValueError, match='Access to private/internal IP address'):
                await validate_and_resolve_url('http://attacker.com/path', allow_local=False)

# tests/test_ssrf.py:583-603
    async def test_protocol_relative_redirect_to_private_blocked(self) -> None:
        """Test that protocol-relative redirects to private IPs are blocked."""
        redirect_response = AsyncMock()
        redirect_response.is_redirect = True
        redirect_response.headers = {'location': '//internal.local/file.txt'}

        with (
            patch('pydantic_ai._ssrf.run_in_executor') as mock_executor,
            patch('pydantic_ai._ssrf.cached_async_http_client') as mock_client_fn,
        ):
            mock_executor.side_effect = [
                [(2, 1, 6, '', ('93.184.215.14', 0))],
                [(2, 1, 6, '', ('192.168.1.1', 0))],
            ]

            mock_client = AsyncMock()
            mock_client.get.return_value = redirect_response
            mock_client_fn.return_value = mock_client

            with pytest.raises(ValueError, match='Access to private/internal IP address'):
                await safe_download('https://example.com/file.txt')

# tests/test_ssrf.py:326-335
    async def test_public_ip_allowed(self) -> None:
        """Test that public IPs are allowed."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            mock_executor.return_value = [(2, 1, 6, '', ('93.184.215.14', 0))]
            resolved = await validate_and_resolve_url('https://example.com/path', allow_local=False)
            assert resolved.resolved_ip == '93.184.215.14'
            assert resolved.hostname == 'example.com'
            assert resolved.port == 443
            assert resolved.is_https is True
            assert resolved.path == '/path'

# tests/test_ssrf.py:70-71
    def test_private_ips_detected(self, ip: str) -> None:
        assert is_private_ip(ip) is True

# tests/test_ssrf.py:388-392
    async def test_6to4_address_blocked(self) -> None:
        """Test that 6to4 addresses (which can embed private IPv4) are blocked."""
        # 2002:c0a8:0101::1 embeds 192.168.1.1
        with pytest.raises(ValueError, match='Access to private/internal IP address'):
            await validate_and_resolve_url('http://[2002:c0a8:0101::1]/path', allow_local=False)

# tests/test_ssrf.py:377-386
    async def test_any_private_ip_blocks_request(self) -> None:
        """Test that if any resolved IP is private, the request is blocked."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            # Return both public and private IPs
            mock_executor.return_value = [
                (2, 1, 6, '', ('93.184.215.14', 0)),
                (2, 1, 6, '', ('192.168.1.1', 0)),
            ]
            with pytest.raises(ValueError, match='Access to private/internal IP address'):
                await validate_and_resolve_url('http://example.com/path', allow_local=False)

# tests/test_ssrf.py:678-684
    async def test_hostname_resolving_to_private_ip_blocked(self) -> None:
        """Test that a hostname resolving to a private IP is blocked."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            # Attacker's DNS returns private IP
            mock_executor.return_value = [(2, 1, 6, '', ('127.0.0.1', 0))]
            with pytest.raises(ValueError, match='Access to private/internal IP address'):
                await validate_and_resolve_url('http://attacker.com/path', allow_local=False)

# tests/graph/beta/test_parent_forks.py:117-133
def test_parent_fork_no_forks():
    """Test parent fork identification when there are no forks."""
    join_id = 'J'
    nodes = {'start', 'A', 'B', 'J', 'end'}
    start_ids = {'start'}
    fork_ids = set[str]()
    edges = {
        'start': ['A'],
        'A': ['B'],
        'B': ['J'],
        'J': ['end'],
    }

    finder = ParentForkFinder(nodes, start_ids, fork_ids, edges)
    parent_fork = finder.find_parent_fork(join_id)

    assert parent_fork is None

# tests/test_mcp.py:2289-2301
async def test_tools_no_caching_when_disabled() -> None:
    """Test that list_tools() does not cache when cache_tools=False."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'], cache_tools=False)
    async with server:
        # First call - should not populate cache
        tools1 = await server.list_tools()
        assert len(tools1) > 0
        assert server._cached_tools is None  # pyright: ignore[reportPrivateUsage]

        # Second call - cache should still be None
        tools2 = await server.list_tools()
        assert tools2 == tools1
        assert server._cached_tools is None  # pyright: ignore[reportPrivateUsage]

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:14-14
from typing import TYPE_CHECKING, Any, Generic, Literal, TypeGuard, cast

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:14-14
from typing import TYPE_CHECKING, Any, Generic, Literal, TypeGuard, cast

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:14-14
from typing import TYPE_CHECKING, Any, Generic, Literal, TypeGuard, cast

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:14-14
from typing import TYPE_CHECKING, Any, Generic, Literal, TypeGuard, cast

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:14-14
from typing import TYPE_CHECKING, Any, Generic, Literal, TypeGuard, cast

# tests/graph/beta/test_parent_forks.py:33-53
def test_parent_fork_with_cycle():
    """Test parent fork identification when there's a cycle bypassing the fork."""
    join_id = 'J'
    nodes = {'start', 'F', 'A', 'B', 'C', 'J', 'end'}
    start_ids = {'start'}
    fork_ids = {'F'}
    # C creates a cycle back to A, bypassing F
    edges = {
        'start': ['F'],
        'F': ['A', 'B'],
        'A': ['J'],
        'B': ['J'],
        'J': ['C'],
        'C': ['A'],  # Cycle that bypasses F
    }

    finder = ParentForkFinder(nodes, start_ids, fork_ids, edges)
    parent_fork = finder.find_parent_fork(join_id)

    # Should return None because J sits on a cycle avoiding F
    assert parent_fork is None

# pydantic_ai_slim/pydantic_ai/_ssrf.py:207-254
async def validate_and_resolve_url(url: str, allow_local: bool) -> ResolvedUrl:
    """Validate URL and resolve hostname to IP addresses.

    Performs protocol validation, DNS resolution, and IP validation.

    Args:
        url: The URL to validate.
        allow_local: Whether to allow private/internal IP addresses.

    Returns:
        ResolvedUrl with all the information needed to make the request.

    Raises:
        ValueError: If the URL fails validation.
    """
    hostname, path, port, is_https = extract_host_and_port(url)

    # Check if hostname is already an IP address
    try:
        # Handle IPv6 addresses in brackets
        ip_str = hostname.strip('[]')
        ipaddress.ip_address(ip_str)
        ips = [ip_str]
    except ValueError:
        # It's a hostname, resolve it
        ips = await resolve_hostname(hostname)

    # Validate all resolved IPs
    for ip in ips:
        # Cloud metadata IPs are always blocked
        if is_cloud_metadata_ip(ip):
            raise ValueError(f'Access to cloud metadata service ({ip}) is blocked for security reasons.')

        # Private IPs are blocked unless allow_local is True
        if allow_local and is_private_ip(ip):
            raise ValueError(
                f'Access to private/internal IP address ({ip}) is blocked. '
                f'Use force_download="allow-local" to allow local network access.'
            )

    # Use the first resolved IP
    return ResolvedUrl(
        resolved_ip=ips[0],
        hostname=hostname,
        port=port,
        is_https=is_https,
        path=path,
    )

# tests/test_mcp.py:2339-2352
async def test_resources_no_caching_when_disabled() -> None:
    """Test that list_resources() does not cache when cache_resources=False."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'], cache_resources=False)
    async with server:
        assert server.capabilities.resources

        # First call - should not populate cache
        resources1 = await server.list_resources()
        assert server._cached_resources is None  # pyright: ignore[reportPrivateUsage]

        # Second call - cache should still be None
        resources2 = await server.list_resources()
        assert resources2 == resources1
        assert server._cached_resources is None  # pyright: ignore[reportPrivateUsage]

# tests/test_usage_limits.py:329-360
async def test_output_tool_allowed_at_limit() -> None:
    """Test that output tools can be called even when at the tool_calls_limit."""

    class MyOutput(BaseModel):
        result: str

    def call_output_after_regular(messages: list[ModelMessage], info: AgentInfo) -> ModelResponse:
        if len(messages) == 1:
            return ModelResponse(
                parts=[
                    ToolCallPart('regular_tool', {'x': 'test'}, 'call_1'),
                ],
                usage=RequestUsage(input_tokens=10, output_tokens=5),
            )
        else:
            return ModelResponse(
                parts=[
                    ToolCallPart('final_result', {'result': 'success'}, 'call_2'),
                ],
                usage=RequestUsage(input_tokens=10, output_tokens=5),
            )

    test_agent = Agent(FunctionModel(call_output_after_regular), output_type=ToolOutput(MyOutput))

    @test_agent.tool_plain
    async def regular_tool(x: str) -> str:
        return f'{x}-processed'

    result = await test_agent.run('test', usage_limits=UsageLimits(tool_calls_limit=1))

    assert result.output.result == 'success'
    assert result.usage() == snapshot(RunUsage(requests=2, input_tokens=20, output_tokens=10, tool_calls=1))

# pydantic_ai_slim/pydantic_ai/_utils.py:286-294
def guard_tool_call_id(
    t: _messages.ToolCallPart
    | _messages.ToolReturnPart
    | _messages.RetryPromptPart
    | _messages.BuiltinToolCallPart
    | _messages.BuiltinToolReturnPart,
) -> str:
    """Type guard that either returns the tool call id or generates a new one if it's None."""
    return t.tool_call_id or generate_tool_call_id()

# pydantic_ai_slim/pydantic_ai/_ssrf.py:297-368
async def safe_download(
    url: str,
    allow_local: bool = False,
    max_redirects: int = _MAX_REDIRECTS,
    timeout: int = _DEFAULT_TIMEOUT,
) -> httpx.Response:
    """Download content from a URL with SSRF protection.

    This function:
    1. Validates the URL protocol (only http/https allowed)
    2. Resolves the hostname to IP addresses
    3. Validates that no resolved IP is private (unless allow_local=True)
    4. Always blocks cloud metadata endpoints
    5. Makes the request to the resolved IP with the Host header set
    6. Manually follows redirects, validating each hop

    Args:
        url: The URL to download from.
        allow_local: If True, allows requests to private/internal IP addresses.
                    Cloud metadata endpoints are always blocked regardless.
        max_redirects: Maximum number of redirects to follow (default: 10).
        timeout: Request timeout in seconds (default: 30).

    Returns:
        The httpx.Response object.

    Raises:
        ValueError: If the URL fails SSRF validation or too many redirects occur.
        httpx.HTTPStatusError: If the response has an error status code.
    """
    current_url = url
    redirects_followed = 0

    client = cached_async_http_client(timeout=timeout)
    while True:
        # Validate and resolve the current URL
        resolved = await validate_and_resolve_url(current_url, allow_local)

        # Build URL with resolved IP
        request_url = build_url_with_ip(resolved)

        # For HTTPS, set sni_hostname so TLS uses the original hostname for SNI
        # and certificate validation, even though we're connecting to the resolved IP.
        extensions: dict[str, str] = {}
        if resolved.is_https:
            extensions['sni_hostname'] = resolved.hostname

        # Make request with Host header set to original hostname
        response = await client.get(
            request_url,
            headers={'Host': resolved.hostname},
            extensions=extensions,
            follow_redirects=False,
        )

        # Check if we need to follow a redirect
        if response.is_redirect:
            redirects_followed += 1
            if redirects_followed > max_redirects:
                raise ValueError(f'Too many redirects ({redirects_followed}). Maximum allowed: {max_redirects}')

            # Get redirect location
            location = response.headers.get('location')
            if not location:
                raise ValueError('Redirect response missing Location header')

            current_url = resolve_redirect_url(current_url, location)
            continue

        # Not a redirect, we're done
        response.raise_for_status()
        return response

# tests/test_tools.py:2784-2814
async def test_tool_cancelled_when_agent_cancelled(is_stream: bool):
    """Test that tools are cancelled when agent is cancelled."""
    import asyncio

    agent = Agent(TestModel())
    is_called = asyncio.Event()
    is_cancelled = asyncio.Event()

    @agent.tool_plain
    async def tool() -> None:
        is_called.set()

        try:
            await asyncio.sleep(1.0)

        except asyncio.CancelledError:
            is_cancelled.set()
            raise

    async def run_agent() -> None:
        if not is_stream:
            await agent.run('call tool')

        else:
            async for _ in agent.run_stream_events('call tool'):
                pass

    task = asyncio.create_task(run_agent())
    await asyncio.wait_for(is_called.wait(), timeout=1.0)
    task.cancel()
    await asyncio.wait_for(is_cancelled.wait(), timeout=1.0)

# tests/test_agent.py:4623-4706
def test_dynamic_false_no_reevaluate():
    """When dynamic is false (default), the system prompt is not reevaluated
    i.e: SystemPromptPart(
            content="A",       <--- Remains the same when `message_history` is passed.
    )
    """
    agent = Agent('test', system_prompt='Foobar')

    dynamic_value = 'A'

    @agent.system_prompt
    async def func() -> str:
        return dynamic_value

    res = agent.run_sync('Hello')

    assert res.all_messages() == snapshot(
        [
            ModelRequest(
                parts=[
                    SystemPromptPart(content='Foobar', timestamp=IsNow(tz=timezone.utc)),
                    SystemPromptPart(content=dynamic_value, timestamp=IsNow(tz=timezone.utc)),
                    UserPromptPart(content='Hello', timestamp=IsNow(tz=timezone.utc)),
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='request',
            ),
            ModelResponse(
                parts=[TextPart(content='success (no tool calls)')],
                usage=RequestUsage(input_tokens=53, output_tokens=4),
                model_name='test',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='response',
            ),
        ]
    )

    dynamic_value = 'B'

    res_two = agent.run_sync('World', message_history=res.all_messages())

    assert res_two.all_messages() == snapshot(
        [
            ModelRequest(
                parts=[
                    SystemPromptPart(content='Foobar', timestamp=IsNow(tz=timezone.utc)),
                    SystemPromptPart(
                        content='A',  # Remains the same
                        timestamp=IsNow(tz=timezone.utc),
                    ),
                    UserPromptPart(content='Hello', timestamp=IsNow(tz=timezone.utc)),
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='request',
            ),
            ModelResponse(
                parts=[TextPart(content='success (no tool calls)')],
                usage=RequestUsage(input_tokens=53, output_tokens=4),
                model_name='test',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='response',
            ),
            ModelRequest(
                parts=[UserPromptPart(content='World', timestamp=IsNow(tz=timezone.utc), part_kind='user-prompt')],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='request',
            ),
            ModelResponse(
                parts=[TextPart(content='success (no tool calls)')],
                usage=RequestUsage(input_tokens=54, output_tokens=8),
                model_name='test',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='response',
            ),
        ]
    )

    assert res_two.new_messages() == res_two.all_messages()[-2:]

# tests/test_mcp.py:2375-2392
async def test_cache_cleared_on_connection_close() -> None:
    """Test that caches are cleared when the connection is closed."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])

    # First connection
    async with server:
        await server.list_tools()
        assert server._cached_tools is not None  # pyright: ignore[reportPrivateUsage]

    # After exiting, cache should be cleared by __aexit__
    assert server._cached_tools is None  # pyright: ignore[reportPrivateUsage]

    # Reconnect and verify cache starts empty
    async with server:
        assert server._cached_tools is None  # pyright: ignore[reportPrivateUsage]
        # Fetch again to populate
        await server.list_tools()
        assert server._cached_tools is not None  # pyright: ignore[reportPrivateUsage]

# pydantic_ai_slim/pydantic_ai/models/anthropic.py:15-15
from .._utils import guard_tool_call_id as _guard_tool_call_id

# pydantic_ai_slim/pydantic_ai/models/anthropic.py:15-15
from .._utils import guard_tool_call_id as _guard_tool_call_id

# pydantic_ai_slim/pydantic_ai/models/anthropic.py:15-15
from .._utils import guard_tool_call_id as _guard_tool_call_id

# pydantic_ai_slim/pydantic_ai/models/anthropic.py:15-15
from .._utils import guard_tool_call_id as _guard_tool_call_id

# pydantic_ai_slim/pydantic_ai/models/anthropic.py:15-15
from .._utils import guard_tool_call_id as _guard_tool_call_id

# tests/profiles/test_google.py:59-65
def test_const_false_boolean_infers_type():
    """When converting const to enum, type should be inferred for False boolean."""
    schema = {'const': False}
    transformer = GoogleJsonSchemaTransformer(schema)
    transformed = transformer.walk()

    assert transformed == snapshot({'enum': [False], 'type': 'boolean'})

# pydantic_evals/pydantic_evals/otel/span_tree.py:63-63
    stop_recursing_when: SpanQuery

# tests/graph/beta/test_node_and_step.py:32-48
def test_is_source_type_guard():
    """Test is_source type guard function."""

    # Test with StartNode
    start = StartNode[int]()
    assert is_source(start)

    # Test with Step
    async def my_step(ctx: StepContext[Any, Any, Any]):
        return 42  # pragma: no cover

    step = Step[None, None, None, int](id=NodeID('test'), call=my_step)
    assert is_source(step)

    # Test with EndNode (should be False)
    end = EndNode[int]()
    assert not is_source(end)

# pydantic_ai_slim/pydantic_ai/format_prompt.py:135-155
    def _set_scalar_text(self, element: ElementTree.Element, value: Any) -> bool:
        """Set element.text for scalar types. Return True if handled, False otherwise."""
        if value is None:
            element.text = self.none_str
        elif isinstance(value, str):
            element.text = value
        elif isinstance(value, bytes | bytearray):
            element.text = value.decode(errors='ignore')
        elif isinstance(value, bool | int | float | Enum):
            element.text = str(value)
        elif isinstance(value, date | time):
            element.text = value.isoformat()
        elif isinstance(value, timedelta):
            element.text = str(value)
        elif isinstance(value, Decimal):
            element.text = str(value)
        elif isinstance(value, UUID):
            element.text = str(value)
        else:
            return False
        return True

# tests/models/test_anthropic.py:5276-5302
async def test_anthropic_web_fetch_tool_domain_filtering():
    """Test that blocked_domains work and are mutually exclusive with allowed_domains."""
    from pydantic_ai.models.anthropic import AnthropicModel
    from pydantic_ai.providers.anthropic import AnthropicProvider

    # Create a model instance
    m = AnthropicModel('claude-sonnet-4-0', provider=AnthropicProvider(api_key='test-key'))

    # Test with blocked_domains
    web_fetch_tool = WebFetchTool(blocked_domains=['private.example.com', 'internal.example.com'])

    model_request_parameters = ModelRequestParameters(
        function_tools=[],
        builtin_tools=[web_fetch_tool],
        output_tools=[],
    )

    # Get tools from model
    tools, _, _ = m._add_builtin_tools([], model_request_parameters)  # pyright: ignore[reportPrivateUsage]

    # Find the web_fetch tool
    web_fetch_tool_param = next((t for t in tools if t.get('name') == 'web_fetch'), None)
    assert web_fetch_tool_param is not None

    # Verify blocked_domains is passed correctly
    assert web_fetch_tool_param.get('blocked_domains') == ['private.example.com', 'internal.example.com']
    assert web_fetch_tool_param.get('allowed_domains') is None

# pydantic_ai_slim/pydantic_ai/_ssrf.py:42-48
_CLOUD_METADATA_IPS: frozenset[str] = frozenset(
    {
        '169.254.169.254',  # AWS, GCP, Azure metadata endpoint
        'fd00:ec2::254',  # AWS EC2 IPv6 metadata endpoint
        '100.100.100.200',  # Alibaba Cloud metadata endpoint
    }
)

# pydantic_graph/pydantic_graph/beta/graph.py:32-32
from pydantic_graph.beta.parent_forks import ParentFork

# tests/graph/beta/test_node_and_step.py:51-70
def test_is_destination_type_guard():
    """Test is_destination type guard function."""
    # Test with EndNode
    end = EndNode[int]()
    assert is_destination(end)

    # Test with Step
    async def my_step(ctx: StepContext[Any, Any, Any]):
        return 42  # pragma: no cover

    step = Step[None, None, None, int](id=NodeID('test'), call=my_step)
    assert is_destination(step)

    # Test with Decision
    decision = Decision[None, None, int](id=NodeID('test_decision'), branches=[], note=None)
    assert is_destination(decision)

    # Test with StartNode (should be False)
    start = StartNode[int]()
    assert not is_destination(start)

# tests/graph/beta/test_graph_edge_cases.py:80-100
async def test_get_parent_fork_missing():
    """Test that get_parent_fork raises RuntimeError when join has no parent fork."""
    from pydantic_graph.beta.id_types import JoinID, NodeID

    g = GraphBuilder(state_type=MyState, output_type=int)

    @g.step
    async def simple_step(ctx: StepContext[MyState, None, None]) -> int:
        return 42  # pragma: no cover

    g.add(
        g.edge_from(g.start_node).to(simple_step),
        g.edge_from(simple_step).to(g.end_node),
    )

    graph = g.build()

    # Try to get a parent fork for a non-existent join
    fake_join_id = JoinID(NodeID('fake_join'))
    with pytest.raises(RuntimeError, match='not a join node'):
        graph.get_parent_fork(fake_join_id)

# tests/test_ssrf.py:394-399
    async def test_cgnat_range_blocked(self) -> None:
        """Test that CGNAT range (100.64.0.0/10) is blocked."""
        with patch('pydantic_ai._ssrf.run_in_executor') as mock_executor:
            mock_executor.return_value = [(2, 1, 6, '', ('100.64.0.1', 0))]
            with pytest.raises(ValueError, match='Access to private/internal IP address'):
                await validate_and_resolve_url('http://cgnat-host.internal/path', allow_local=False)

# pydantic_ai_slim/pydantic_ai/_utils.py:342-344
    async def is_exhausted(self) -> bool:
        """Returns True if the stream is exhausted, False otherwise."""
        return isinstance(await self.peek(), Unset)

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:239-246
    def prepare_request(
        self,
        texts: list[str],
        input_type: EmbedInputType,
        settings: BedrockEmbeddingSettings,
    ) -> dict[str, Any]:
        """Prepare the request body for the embedding model."""
        raise NotImplementedError

# pydantic_ai_slim/pydantic_ai/models/bedrock.py:169-219
def _insert_cache_point_before_trailing_documents(
    content: list[Any],
    *,
    raise_if_cannot_insert: bool = False,
) -> bool:
    """Insert a cache point before trailing document/video content.

    AWS rejects cache points that directly follow documents and videos (but not images).
    This function finds the start of the trailing contiguous group of documents/videos
    and inserts a cache point before it.

    Args:
        content: The content list to modify in place.
        raise_if_cannot_insert: If True, raises UserError when cache point cannot be inserted
            (e.g., when the message contains only documents/videos). If False, silently skips.

    Returns:
        True if a cache point was inserted, False otherwise.

    Raises:
        UserError: If raise_if_cannot_insert is True and the cache point cannot be placed.
    """
    multimodal_keys = ['document', 'video']
    # Find where the trailing contiguous group of documents/videos starts
    trailing_start: int | None = None
    for i in range(len(content) - 1, -1, -1):
        if any(key in content[i] for key in multimodal_keys):
            trailing_start = i
        else:
            break

    if trailing_start is not None and trailing_start > 0:
        # Skip if there's already a cache point at the insertion position
        prev_block = content[trailing_start - 1]
        if isinstance(prev_block, dict) and 'cachePoint' in prev_block:
            return False
        content.insert(trailing_start, {'cachePoint': {'type': 'default'}})
        return True
    elif trailing_start is None:
        # No trailing document/video content, append cache point at the end
        content.append({'cachePoint': {'type': 'default'}})
        return True
    else:
        # trailing_start == 0, can't insert at start
        if raise_if_cannot_insert:
            raise UserError(
                'CachePoint cannot be placed when the user message contains only a document or video, '
                'due to Bedrock API restrictions. '
                'Add text content before or after your document or video to enable caching.'
            )
        return False

# pydantic_ai_slim/pydantic_ai/models/gemini.py:967-967
    blocked: NotRequired[bool]

# pydantic_ai_slim/pydantic_ai/models/bedrock.py:231-231
    bedrock_guardrail_config: GuardrailConfigurationTypeDef

# pydantic_graph/pydantic_graph/persistence/__init__.py:208-213
    def should_set_types(self) -> bool:
        """Whether types need to be set.

        Implementations should override this method to return `True` when types have not been set if they are needed.
        """
        return False

# tests/models/test_bedrock.py:575-588
async def test_bedrock_model_guardrail_config(allow_model_requests: None, bedrock_provider: BedrockProvider):
    model = BedrockConverseModel('us.amazon.nova-micro-v1:0', provider=bedrock_provider)
    model_settings = BedrockModelSettings(
        bedrock_guardrail_config={
            'guardrailIdentifier': 'xbgw7g293v7o',
            'guardrailVersion': 'DRAFT',
            'trace': 'enabled',
        }
    )
    agent = Agent(model=model, instructions='You are a helpful chatbot.', model_settings=model_settings)
    result = await agent.run('What is the capital of France?')
    assert result.output == snapshot(
        "The capital of France is Paris. Paris is not only the capital city but also the most populous city in France, serving as the center of French government, culture, and commerce. It's known for its historical and cultural landmarks such as the Eiffel Tower, the Louvre Museum, Notre-Dame Cathedral, and many charming neighborhoods like Montmartre."
    )

# tests/models/test_openai.py:3640-3654
async def test_openai_gpt_5_2_temperature_warns_when_reasoning_enabled(allow_model_requests: None):
    """GPT-5.2 warns and filters temperature when reasoning_effort is set."""
    c = completion_message(ChatCompletionMessage(content='Paris.', role='assistant'))
    mock_client = MockOpenAI.create_mock(c)
    m = OpenAIChatModel('gpt-5.2', provider=OpenAIProvider(openai_client=mock_client))
    agent = Agent(m)

    with pytest.warns(UserWarning, match='Sampling parameters.*temperature.*not supported when reasoning is enabled'):
        await agent.run(
            'What is the capital of France?',
            model_settings=OpenAIChatModelSettings(temperature=0.5, openai_reasoning_effort='medium'),
        )

    # Verify temperature was NOT passed to the API (filtered out)
    assert 'temperature' not in get_mock_chat_completion_kwargs(mock_client)[0]

# pydantic_ai_slim/pydantic_ai/_ssrf.py:82-97
def is_private_ip(ip_str: str) -> bool:
    """Check if an IP address is in a private/internal range.

    Handles both IPv4 and IPv6 addresses, including IPv4-mapped IPv6 addresses.
    """
    try:
        ip = ipaddress.ip_address(ip_str)

        # Handle IPv4-mapped IPv6 addresses (e.g., ::ffff:192.168.1.1)
        if isinstance(ip, ipaddress.IPv6Address) and ip.ipv4_mapped:
            ip = ip.ipv4_mapped

        return any(ip in network for network in _PRIVATE_NETWORKS)
    except ValueError:
        # Invalid IP address, treat as potentially dangerous
        return True

# tests/graph/beta/test_parent_forks.py:136-154
def test_parent_fork_unreachable_join():
    """Test parent fork identification when join is unreachable from start."""
    join_id = 'J'
    nodes = {'start', 'F', 'A', 'B', 'J', 'end'}
    start_ids = {'start'}
    fork_ids = {'F'}
    # J is not reachable from start
    edges = {
        'start': ['end'],
        'F': ['A', 'B'],
        'A': ['J'],
        'B': ['J'],
    }

    finder = ParentForkFinder(nodes, start_ids, fork_ids, edges)
    parent_fork = finder.find_parent_fork(join_id)

    # Should return None or a parent fork with no intermediate nodes
    assert parent_fork is None or len(parent_fork.intermediate_nodes) == 0

# pydantic_ai_slim/pydantic_ai/_ssrf.py:82-97
def is_private_ip(ip_str: str) -> bool:
    """Check if an IP address is in a private/internal range.

    Handles both IPv4 and IPv6 addresses, including IPv4-mapped IPv6 addresses.
    """
    try:
        ip = ipaddress.ip_address(ip_str)

        # Handle IPv4-mapped IPv6 addresses (e.g., ::ffff:192.168.1.1)
        if isinstance(ip, ipaddress.IPv6Address) and ip.ipv4_mapped:
            ip = ip.ipv4_mapped

        return any(ip in network for network in _PRIVATE_NETWORKS)
    except ValueError:
        # Invalid IP address, treat as potentially dangerous
        return True

# tests/graph/beta/test_paths.py:30-33
async def test_path_last_fork_with_no_forks():
    """Test Path.last_fork property when there are no forks."""
    path = Path(items=[LabelMarker('test'), DestinationMarker(NodeID('dest'))])
    assert path.last_fork is None

# pydantic_ai_slim/pydantic_ai/builtin_tools.py:225-225
    blocked_domains: list[str] | None = None

# pydantic_ai_slim/pydantic_ai/builtin_tools.py:119-119
    blocked_domains: list[str] | None = None