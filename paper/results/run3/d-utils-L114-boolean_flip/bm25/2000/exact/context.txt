# pydantic_ai_slim/pydantic_ai/toolsets/prefixed.py:24-33
    async def get_tools(self, ctx: RunContext[AgentDepsT]) -> dict[str, ToolsetTool[AgentDepsT]]:
        return {
            new_name: replace(
                tool,
                toolset=self,
                tool_def=replace(tool.tool_def, name=new_name),
            )
            for name, tool in (await super().get_tools(ctx)).items()
            if (new_name := f'{self.prefix}_{name}')
        }

# pydantic_evals/pydantic_evals/dataset.py:81-81
_YAML_SCHEMA_LINE_PREFIX = '# yaml-language-server: $schema='

# pydantic_ai_slim/pydantic_ai/toolsets/prefixed.py:18-18
    prefix: str

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:462-466
_HANDLER_PREFIXES: dict[str, type[_BedrockEmbeddingHandler]] = {
    'amazon.titan-embed': _TitanEmbeddingHandler,
    'cohere.embed': _CohereEmbeddingHandler,
    'amazon.nova': _NovaEmbeddingHandler,
}

# pydantic_ai_slim/pydantic_ai/output.py:7-7
from pydantic import GetCoreSchemaHandler, GetJsonSchemaHandler

# pydantic_ai_slim/pydantic_ai/output.py:7-7
from pydantic import GetCoreSchemaHandler, GetJsonSchemaHandler

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_model.py:44-45
    def get(self) -> ModelResponse:
        return self.response

# pydantic_ai_slim/pydantic_ai/mcp.py:292-292
    tool_prefix: str | None

# tests/test_tools.py:120-125
async def get_json_schema(_messages: list[ModelMessage], info: AgentInfo) -> ModelResponse:
    if len(info.function_tools) == 1:
        r = info.function_tools[0]
        return ModelResponse(parts=[TextPart(pydantic_core.to_json(r).decode())])
    else:
        return ModelResponse(parts=[TextPart(pydantic_core.to_json(info.function_tools).decode())])

# tests/models/test_model_test.py:439-446
def test_prefix_unique():
    json_schema = {
        'type': 'array',
        'uniqueItems': True,
        'prefixItems': [{'type': 'string'}, {'type': 'string'}],
    }
    data = _JsonSchemaTestData(json_schema).generate()
    assert data == snapshot(['a', 'b'])

# pydantic_ai_slim/pydantic_ai/mcp.py:855-855
    tool_prefix: str | None

# pydantic_ai_slim/pydantic_ai/mcp.py:1022-1022
    tool_prefix: str | None

# pydantic_ai_slim/pydantic_ai/providers/bedrock.py:72-72
BEDROCK_GEO_PREFIXES: tuple[str, ...] = ('us', 'eu', 'apac', 'jp', 'au', 'ca', 'global', 'us-gov')

# examples/pydantic_ai_examples/ag_ui/api/shared_state.py:32-32
    VEGETARIAN = 'Vegetarian'

# tests/json_body_serializer.py:60-65
ALLOWED_HEADER_PREFIXES = {
    # required by huggingface_hub.file_download used by test_embeddings.py::TestSentenceTransformers
    'x-xet-',
    # required for Bedrock embeddings to preserve token count headers
    'x-amzn-bedrock-',
}

# tests/json_body_serializer.py:58-58
FILTERED_HEADER_PREFIXES = ['anthropic-', 'cf-', 'x-']

# pydantic_evals/pydantic_evals/dataset.py:897-924
def _get_relative_path_reference(target: Path, source: Path, _prefix: str = '') -> Path:  # pragma: no cover
    """Get a relative path reference from source to target.

    Recursively resolve a relative path to target from source, adding '..' as needed.
    This is useful for creating a relative path reference from a source file to a target file.

    Args:
        target: The target path to reference.
        source: The source path to reference from.
        _prefix: Internal prefix used during recursion.

    Returns:
        A Path object representing the relative path from source to target.

    Example:
        If source is '/a/b/c.py' and target is '/a/d/e.py', the relative path reference
        would be '../../d/e.py'.
    """
    # Recursively resolve a relative path to target from source, adding '..' as needed.
    # This is useful for creating a relative path reference from a source file to a target file.
    # For example, if source is '/a/b/c.py' and target is '/a/d/e.py', the relative path reference
    # would be '../../d/e.py'.
    if not target.is_absolute():
        target = target.resolve()
    try:
        return Path(f'{_prefix}{Path(target).relative_to(source)}')
    except ValueError:
        return _get_relative_path_reference(target, source.parent, _prefix=f'{_prefix}../')

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:16-16
from pydantic_ai.providers.bedrock import remove_bedrock_geo_prefix

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:16-16
from pydantic_ai.providers.bedrock import remove_bedrock_geo_prefix

# pydantic_ai_slim/pydantic_ai/_utils.py:449-489
def merge_json_schema_defs(schemas: list[dict[str, Any]]) -> tuple[list[dict[str, Any]], dict[str, dict[str, Any]]]:
    """Merges the `$defs` from different JSON schemas into a single deduplicated `$defs`, handling name collisions of `$defs` that are not the same, and rewrites `$ref`s to point to the new `$defs`.

    Returns a tuple of the rewritten schemas and a dictionary of the new `$defs`.
    """
    all_defs: dict[str, dict[str, Any]] = {}
    rewritten_schemas: list[dict[str, Any]] = []

    for schema in schemas:
        if '$defs' not in schema:
            rewritten_schemas.append(schema)
            continue

        schema = schema.copy()
        defs = schema.pop('$defs', None)
        schema_name_mapping: dict[str, str] = {}

        # Process definitions and build mapping
        for name, def_schema in defs.items():
            if name not in all_defs:
                all_defs[name] = def_schema
                schema_name_mapping[name] = name
            elif def_schema != all_defs[name]:
                new_name = name
                if title := schema.get('title'):
                    new_name = f'{title}_{name}'

                i = 1
                original_new_name = new_name
                new_name = f'{new_name}_{i}'
                while new_name in all_defs:
                    i += 1
                    new_name = f'{original_new_name}_{i}'

                all_defs[new_name] = def_schema
                schema_name_mapping[name] = new_name

        _update_mapped_json_schema_refs(schema, schema_name_mapping)
        rewritten_schemas.append(schema)

    return rewritten_schemas, all_defs

# examples/pydantic_ai_examples/ag_ui/api/shared_state.py:30-30
    BUDGET_FRIENDLY = 'Budget-Friendly'

# pydantic_ai_slim/pydantic_ai/ui/ag_ui/_event_stream.py:68-68
BUILTIN_TOOL_CALL_ID_PREFIX: Final[str] = 'pyd_ai_builtin'

# pydantic_graph/pydantic_graph/beta/id_types.py:68-68
_NODE_ID_PLACEHOLDER_PREFIX = '__placeholder__'