# pydantic_ai_slim/pydantic_ai/messages.py:4-4
import hashlib

# pydantic_ai_slim/pydantic_ai/messages.py:4-4
import hashlib

# pydantic_ai_slim/pydantic_ai/messages.py:4-4
import hashlib

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:26-27
    def encode(self, sdk_version: int) -> str:
        return self.model_dump_json(by_alias=True, exclude_none=True)

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:256-257
    def encode(self, sdk_version: int) -> str:
        return '[DONE]'

# tests/test_temporal.py:3066-3069
    async def encode(
        self, payloads: Sequence[temporalio.api.common.v1.Payload]
    ) -> list[temporalio.api.common.v1.Payload]:  # pragma: no cover
        return list(payloads)

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:97-99
    def encode(self, sdk_version: int) -> str:
        exclude = {'provider_metadata'} if sdk_version < 6 else None
        return self.model_dump_json(by_alias=True, exclude_none=True, exclude=exclude)

# pydantic_ai_slim/pydantic_ai/ui/ag_ui/_event_stream.py:87-88
    def encode_event(self, event: BaseEvent) -> str:
        return self._event_encoder.encode(event)

# tests/test_ui.py:119-120
    def encode_event(self, event: str) -> str:
        return event

# pydantic_ai_slim/pydantic_ai/ui/ag_ui/_event_stream.py:80-81
    def _event_encoder(self) -> EventEncoder:
        return EventEncoder(accept=self.accept or SSE_CONTENT_TYPE)

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/_event_stream.py:90-91
    def encode_event(self, event: BaseChunk) -> str:
        return f'data: {event.encode(self.sdk_version)}\n\n'

# pydantic_ai_slim/pydantic_ai/ui/_event_stream.py:101-103
    def encode_event(self, event: EventT) -> str:
        """Encode a protocol-specific event as a string."""
        raise NotImplementedError

# tests/test_ui_web.py:521-526
def test_agent_to_web_with_html_source():
    """Test that Agent.to_web() accepts html_source parameter."""
    agent = Agent('test')
    app = agent.to_web(html_source='https://custom-cdn.example.com/ui/index.html')

    assert isinstance(app, Starlette)

# pydantic_ai_slim/pydantic_ai/ui/_event_stream.py:105-108
    async def encode_stream(self, stream: AsyncIterator[EventT]) -> AsyncIterator[str]:
        """Encode a stream of protocol-specific events as strings according to the `Accept` header value."""
        async for event in stream:
            yield self.encode_event(event)

# tests/test_cli.py:752-769
def test_clai_web_with_html_source(mocker: MockerFixture, env: TestEnv):
    """Test web command with --html-source flag."""
    env.set('OPENAI_API_KEY', 'test')
    mock_run_web = mocker.patch('pydantic_ai._cli.web.run_web_command', return_value=0)

    custom_url = 'https://internal.company.com/pydantic-ai-ui/index.html'
    assert cli(['web', '-m', 'openai:gpt-5', '--html-source', custom_url], prog_name='clai') == 0

    mock_run_web.assert_called_once_with(
        agent_path=None,
        host='127.0.0.1',
        port=7932,
        models=['openai:gpt-5'],
        tools=[],
        instructions=None,
        default_model='openai:gpt-5',
        html_source=custom_url,
    )

# pydantic_ai_slim/pydantic_ai/ui/_adapter.py:191-197
    def encode_stream(self, stream: AsyncIterator[EventT]) -> AsyncIterator[str]:
        """Encode a stream of protocol-specific events as strings according to the `Accept` header value.

        Args:
            stream: The stream of protocol-specific events to encode.
        """
        return self.build_event_stream().encode_stream(stream)

# tests/test_ui_web.py:575-583
def test_chat_app_index_file_not_found(tmp_path: Path):
    """Test that index endpoint raises FileNotFoundError for non-existent html_source file."""
    agent = Agent('test')
    nonexistent_file = tmp_path / 'nonexistent-ui.html'
    app = create_web_app(agent, html_source=str(nonexistent_file))

    with TestClient(app, raise_server_exceptions=True) as client:
        with pytest.raises(FileNotFoundError, match='Local UI file not found'):
            client.get('/')

# pydantic_ai_slim/pydantic_ai/messages.py:574-576
    def base64(self) -> str:
        """Return the binary data as a base64-encoded string. Default encoding is UTF-8."""
        return base64.b64encode(self.data).decode()

# tests/test_ui_web.py:566-572
async def test_get_ui_html_source_instance_not_found(monkeypatch: pytest.MonkeyPatch, tmp_path: Path):
    """Test that _get_ui_html raises FileNotFoundError for missing Path instances."""
    # Try to use a non-existent Path instance
    nonexistent_path = tmp_path / 'nonexistent-ui.html'

    with pytest.raises(FileNotFoundError, match='Local UI file not found'):
        await app_module._get_ui_html(html_source=nonexistent_path)  # pyright: ignore[reportPrivateUsage]

# examples/pydantic_ai_examples/weather_agent_gradio.py:8-8
from pydantic_ai import ToolCallPart, ToolReturnPart

# examples/pydantic_ai_examples/ag_ui/__init__.py:27-27
app = FastAPI(title='Pydantic AI AG-UI server')

# examples/pydantic_ai_examples/ag_ui/__init__.py:27-27
app = FastAPI(title='Pydantic AI AG-UI server')

# examples/pydantic_ai_examples/ag_ui/__init__.py:27-27
app = FastAPI(title='Pydantic AI AG-UI server')

# examples/pydantic_ai_examples/ag_ui/__init__.py:27-27
app = FastAPI(title='Pydantic AI AG-UI server')

# examples/pydantic_ai_examples/ag_ui/__init__.py:27-27
app = FastAPI(title='Pydantic AI AG-UI server')

# examples/pydantic_ai_examples/ag_ui/__init__.py:27-27
app = FastAPI(title='Pydantic AI AG-UI server')

# examples/pydantic_ai_examples/ag_ui/__init__.py:27-27
app = FastAPI(title='Pydantic AI AG-UI server')

# examples/pydantic_ai_examples/ag_ui/__init__.py:27-27
app = FastAPI(title='Pydantic AI AG-UI server')

# examples/pydantic_ai_examples/ag_ui/__init__.py:27-27
app = FastAPI(title='Pydantic AI AG-UI server')

# examples/pydantic_ai_examples/ag_ui/__init__.py:27-27
app = FastAPI(title='Pydantic AI AG-UI server')

# pydantic_ai_slim/pydantic_ai/toolsets/wrapper.py:45-46
    def apply(self, visitor: Callable[[AbstractToolset[AgentDepsT]], None]) -> None:
        self.wrapped.apply(visitor)

# pydantic_ai_slim/pydantic_ai/ui/_web/app.py:50-107
async def _get_ui_html(html_source: str | Path | None = None) -> bytes:
    """Get UI HTML content from the specified source or default CDN.

    When html_source is provided, it is used directly.
    When html_source is None, fetches from the default CDN.

    Args:
        html_source: Path or URL for the chat UI HTML. Can be:
            - None: Uses the default CDN (cached locally)
            - A Path instance: Reads from the local file
            - A URL (http:// or https://): Fetches from the URL
            - A file path string: Reads from the local file
    """
    # Use default CDN with caching
    if html_source is None:
        cache_dir = _get_cache_dir()
        cache_file = cache_dir / f'{CHAT_UI_VERSION}.html'

        if cache_file.exists():
            return cache_file.read_bytes()

        async with httpx.AsyncClient() as client:
            response = await client.get(DEFAULT_HTML_URL)
            response.raise_for_status()
            content = response.content

        cache_file.write_bytes(content)
        return content

    # Handle Path instances
    if isinstance(html_source, Path):
        html_source = html_source.expanduser()
        if html_source.is_file():
            return html_source.read_bytes()
        raise FileNotFoundError(f'Local UI file not found: {html_source}')

    # Handle URLs with filesystem caching
    if html_source.startswith(('http://', 'https://')):
        cache_dir = _get_cache_dir()
        url_hash = hashlib.sha256(html_source.encode()).hexdigest()[:17]
        cache_file = cache_dir / f'url_{url_hash}.html'

        if cache_file.exists():
            return cache_file.read_bytes()

        async with httpx.AsyncClient() as client:
            response = await client.get(html_source)
            response.raise_for_status()
            content = response.content

        cache_file.write_bytes(content)
        return content

    # Handle local file paths (strings)
    local_path = Path(html_source).expanduser()
    if local_path.is_file():
        return local_path.read_bytes()
    raise FileNotFoundError(f'Local UI file not found: {html_source}')

# pydantic_ai_slim/pydantic_ai/models/wrapper.py:24-24
    wrapped: Model

# pydantic_ai_slim/pydantic_ai/toolsets/wrapper.py:20-20
    wrapped: AbstractToolset[AgentDepsT]

# pydantic_ai_slim/pydantic_ai/messages.py:1804-1846
    def _apply_to_delta(self, delta: ToolCallPartDelta) -> ToolCallPart | BuiltinToolCallPart | ToolCallPartDelta:
        """Internal helper to apply this delta to another delta."""
        if self.tool_name_delta:
            # Append incremental text to the existing tool_name_delta
            updated_tool_name_delta = (delta.tool_name_delta or '') + self.tool_name_delta
            delta = replace(delta, tool_name_delta=updated_tool_name_delta)

        if isinstance(self.args_delta, str):
            if isinstance(delta.args_delta, dict):
                raise UnexpectedModelBehavior(
                    f'Cannot apply JSON deltas to non-JSON tool arguments ({delta=}, {self=})'
                )
            updated_args_delta = (delta.args_delta or '') + self.args_delta
            delta = replace(delta, args_delta=updated_args_delta)
        elif isinstance(self.args_delta, dict):
            if isinstance(delta.args_delta, str):
                raise UnexpectedModelBehavior(
                    f'Cannot apply dict deltas to non-dict tool arguments ({delta=}, {self=})'
                )
            updated_args_delta = {**(delta.args_delta or {}), **self.args_delta}
            delta = replace(delta, args_delta=updated_args_delta)

        if self.tool_call_id:
            delta = replace(delta, tool_call_id=self.tool_call_id)

        if self.provider_name:
            delta = replace(delta, provider_name=self.provider_name)

        if self.provider_details:
            merged_provider_details = {**(delta.provider_details or {}), **self.provider_details}
            delta = replace(delta, provider_details=merged_provider_details)

        # If we now have enough data to create a full ToolCallPart, do so
        if delta.tool_name_delta is not None:
            return ToolCallPart(
                delta.tool_name_delta,
                delta.args_delta,
                delta.tool_call_id or _generate_tool_call_id(),
                provider_name=delta.provider_name,
                provider_details=delta.provider_details,
            )

        return delta

# examples/pydantic_ai_examples/ag_ui/api/agentic_chat.py:9-9
from pydantic_ai.ui.ag_ui.app import AGUIApp

# examples/pydantic_ai_examples/ag_ui/api/agentic_chat.py:9-9
from pydantic_ai.ui.ag_ui.app import AGUIApp

# examples/pydantic_ai_examples/ag_ui/api/agentic_chat.py:9-9
from pydantic_ai.ui.ag_ui.app import AGUIApp

# examples/pydantic_ai_examples/ag_ui/api/agentic_chat.py:9-9
from pydantic_ai.ui.ag_ui.app import AGUIApp

# examples/pydantic_ai_examples/ag_ui/api/agentic_chat.py:9-9
from pydantic_ai.ui.ag_ui.app import AGUIApp

# examples/pydantic_ai_examples/ag_ui/api/agentic_chat.py:9-9
from pydantic_ai.ui.ag_ui.app import AGUIApp

# examples/pydantic_ai_examples/slack_lead_qualifier/modal.py:36-41
def web_app():
    setup_logfire()

    from .app import app as _app

    return _app  ### [/web_app]

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/agent/abstract.py:6-6
from collections.abc import AsyncIterable, AsyncIterator, Awaitable, Callable, Iterator, Mapping, Sequence

# pydantic_ai_slim/pydantic_ai/embeddings/wrapper.py:27-27
    wrapped: EmbeddingModel

# pydantic_ai_slim/pydantic_ai/mcp.py:241-241
    tools_list_changed: bool = False

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:160-160
    approval_id: str

# pydantic_ai_slim/pydantic_ai/__init__.py:114-114
from .tools import DeferredToolRequests, DeferredToolResults, RunContext, Tool, ToolApproved, ToolDefinition, ToolDenied

# pydantic_ai_slim/pydantic_ai/__init__.py:114-114
from .tools import DeferredToolRequests, DeferredToolResults, RunContext, Tool, ToolApproved, ToolDefinition, ToolDenied

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:71-71
from .wrapper import WrapperAgent

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:71-71
from .wrapper import WrapperAgent

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:17-17
from pydantic_ai.models.wrapper import WrapperModel

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:71-71
from .wrapper import WrapperAgent

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:17-17
from pydantic_ai.models.wrapper import WrapperModel

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:71-71
from .wrapper import WrapperAgent

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:17-17
from pydantic_ai.models.wrapper import WrapperModel

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:17-17
from pydantic_ai.models.wrapper import WrapperModel

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:17-17
from pydantic_ai.models.wrapper import WrapperModel

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:17-17
from pydantic_ai.models.wrapper import WrapperModel

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:71-71
from .wrapper import WrapperAgent

# pydantic_ai_slim/pydantic_ai/__init__.py:114-114
from .tools import DeferredToolRequests, DeferredToolResults, RunContext, Tool, ToolApproved, ToolDefinition, ToolDenied

# pydantic_ai_slim/pydantic_ai/__init__.py:114-114
from .tools import DeferredToolRequests, DeferredToolResults, RunContext, Tool, ToolApproved, ToolDefinition, ToolDenied

# pydantic_ai_slim/pydantic_ai/toolsets/_dynamic.py:101-105
    def apply(self, visitor: Callable[[AbstractToolset[AgentDepsT]], None]) -> None:
        if self._toolset is None:
            super().apply(visitor)
        else:
            self._toolset.apply(visitor)

# pydantic_ai_slim/pydantic_ai/_function_schema.py:16-16
from pydantic._internal._config import ConfigWrapper

# pydantic_ai_slim/pydantic_ai/toolsets/combined.py:92-94
    def apply(self, visitor: Callable[[AbstractToolset[AgentDepsT]], None]) -> None:
        for toolset in self.toolsets:
            toolset.apply(visitor)

# pydantic_ai_slim/pydantic_ai/mcp.py:229-229
    prompts_list_changed: bool = False

# docs/.hooks/algolia.py:30-30
ALGOLIA_APP_ID = 'KPPUDTIAVX'

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/_cli/web.py:7-7
from pydantic_ai.ui._web import create_web_app

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/_cli/web.py:7-7
from pydantic_ai.ui._web import create_web_app

# pydantic_ai_slim/pydantic_ai/ui/_web/api.py:79-180
def create_api_app(
    agent: Agent[AgentDepsT, OutputDataT],
    models: ModelsParam = None,
    builtin_tools: Sequence[AbstractBuiltinTool] | None = None,
    deps: AgentDepsT = None,
    model_settings: ModelSettings | None = None,
    instructions: str | None = None,
) -> Starlette:
    """Create API app for the web chat UI.

    Args:
        agent: Agent instance.
        models: Models to make available in the UI. Can be:
            - A sequence of model names/instances (e.g., `['openai:gpt-5', Model(...)]`)
            - A dict mapping display labels to model names/instances
            If not provided, the UI will have no model options.
        builtin_tools: Optional list of additional builtin tools to make available in the UI.
            Tools already configured on the agent are always included but won't appear as options.
        deps: Optional dependencies to use for all requests.
        model_settings: Optional settings to use for all model requests.
        instructions: Optional extra instructions to pass to each agent run.

    Returns:
        A Starlette application with the API endpoints.
    """
    # Build model ID â†’ original reference mapping and ModelInfo list for frontend
    model_id_to_ref: dict[str, Model | str] = {}
    model_infos: list[ModelInfo] = []

    # Filter out builtin_tools that are already configured on the agent (they're always included)
    agent_tool_ids = {t.unique_id for t in agent._builtin_tools if isinstance(t, AbstractBuiltinTool)}  # pyright: ignore[reportPrivateUsage]
    ui_builtin_tools = [t for t in (builtin_tools or []) if t.unique_id not in agent_tool_ids]

    # Build combined models: agent's model first (if exists), then provided models
    all_models: list[tuple[str | None, Model | str]] = []
    if agent.model is not None:
        all_models.append((None, agent.model))
    items = list(models.items()) if isinstance(models, Mapping) else [(None, m) for m in (models or [])]
    all_models.extend(items)

    seen_model_ids: set[str] = set()
    for label, model_ref in all_models:
        model = infer_model(model_ref)
        # Use original string if provided to preserve openai-chat: vs openai-responses: distinction
        model_id = model_ref if isinstance(model_ref, str) else f'{model.system}:{model.model_name}'
        if model_id in seen_model_ids:
            continue
        seen_model_ids.add(model_id)
        display_name = label or model.label
        model_supported_tools = model.profile.supported_builtin_tools
        supported_tool_ids = [t.unique_id for t in ui_builtin_tools if type(t) in model_supported_tools]

        model_id_to_ref[model_id] = model_ref
        model_infos.append(ModelInfo(id=model_id, name=display_name, builtin_tools=supported_tool_ids))

    model_ids = set(model_id_to_ref.keys())
    allowed_tool_ids = {tool.unique_id for tool in ui_builtin_tools}

    async def options_chat(request: Request) -> Response:
        """Handle CORS preflight requests."""
        return Response()

    async def configure_frontend(request: Request) -> Response:
        """Endpoint to configure the frontend with available models and tools."""
        config = ConfigureFrontend(
            models=model_infos,
            builtin_tools=[BuiltinToolInfo(id=tool.unique_id, name=tool.label) for tool in ui_builtin_tools],
        )
        return JSONResponse(config.model_dump(by_alias=True))

    async def health(request: Request) -> Response:
        """Health check endpoint."""
        return JSONResponse({'ok': True})

    async def post_chat(request: Request) -> Response:
        """Handle chat requests via Vercel AI Adapter."""
        adapter = await VercelAIAdapter[AgentDepsT, OutputDataT].from_request(request, agent=agent)
        extra_data = ChatRequestExtra.model_validate(adapter.run_input.__pydantic_extra__)

        if error := validate_request_options(extra_data, model_ids, allowed_tool_ids):
            return JSONResponse({'error': error}, status_code=400)

        model_ref = model_id_to_ref.get(extra_data.model) if extra_data.model else None
        request_builtin_tools = [tool for tool in ui_builtin_tools if tool.unique_id in extra_data.builtin_tools]
        streaming_response = await VercelAIAdapter[AgentDepsT, OutputDataT].dispatch_request(
            request,
            agent=agent,
            model=model_ref,
            builtin_tools=request_builtin_tools,
            deps=deps,
            model_settings=model_settings,
            instructions=instructions,
        )
        return streaming_response

    routes = [
        Route('/chat', options_chat, methods=['OPTIONS']),
        Route('/chat', post_chat, methods=['POST']),
        Route('/configure', configure_frontend, methods=['GET']),
        Route('/health', health, methods=['GET']),
    ]
    return Starlette(routes=routes)

# tests/test_ag_ui.py:7-7
from collections.abc import AsyncIterator, MutableMapping

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# tests/test_ag_ui.py:7-7
from collections.abc import AsyncIterator, MutableMapping

# tests/test_ag_ui.py:7-7
from collections.abc import AsyncIterator, MutableMapping

# pydantic_ai_slim/pydantic_ai/_agent_graph.py:22-22
from pydantic_ai._utils import dataclasses_no_defaults_repr, get_union_args, is_async_callable, now_utc, run_in_executor

# pydantic_ai_slim/pydantic_ai/mcp.py:235-235
    resources_list_changed: bool = False

# tests/test_mcp.py:1678-1723
def test_map_from_pai_messages_with_binary_content():
    """Test that map_from_pai_messages correctly converts image and audio content to MCP format.

    Note: `data` in this case are base64-encoded bytes (e.g., base64.b64encode(b'raw')).
    map_from_pai_messages decodes this to get the base64 string for MCP.
    """

    message = ModelRequest(
        parts=[
            UserPromptPart(content='text message'),
            UserPromptPart(content=[BinaryContent(data=b'raw_image_bytes', media_type='image/png')]),
            # TODO uncomment when audio content is supported
            # UserPromptPart(content=[BinaryContent(data=b'raw_audio_bytes', media_type='audio/wav'), 'text after audio']),
        ]
    )
    system_prompt, sampling_msgs = map_from_pai_messages([message])
    assert system_prompt == ''
    assert [m.model_dump(by_alias=True) for m in sampling_msgs] == snapshot(
        [
            {
                'role': 'user',
                'content': {'type': 'text', 'text': 'text message', 'annotations': None, '_meta': None},
                '_meta': None,
            },
            {
                'role': 'user',
                'content': {
                    'type': 'image',
                    'data': 'cmF3X2ltYWdlX2J5dGVz',
                    'mimeType': 'image/png',
                    'annotations': None,
                    '_meta': None,
                },
                '_meta': None,
            },
        ]
    )

    # Unsupported content type raises NotImplementedError
    message_with_video = ModelRequest(
        parts=[UserPromptPart(content=[BinaryContent(data=b'raw_video_bytes', media_type='video/mp4')])]
    )
    with pytest.raises(
        NotImplementedError, match="Unsupported content type: <class 'pydantic_ai.messages.BinaryContent'>"
    ):
        map_from_pai_messages([message_with_video])

# pydantic_ai_slim/pydantic_ai/messages.py:1848-1876
    def _apply_to_part(self, part: ToolCallPart | BuiltinToolCallPart) -> ToolCallPart | BuiltinToolCallPart:
        """Internal helper to apply this delta directly to a `ToolCallPart` or `BuiltinToolCallPart`."""
        if self.tool_name_delta:
            # Append incremental text to the existing tool_name
            tool_name = part.tool_name + self.tool_name_delta
            part = replace(part, tool_name=tool_name)

        if isinstance(self.args_delta, str):
            if isinstance(part.args, dict):
                raise UnexpectedModelBehavior(f'Cannot apply JSON deltas to non-JSON tool arguments ({part=}, {self=})')
            updated_json = (part.args or '') + self.args_delta
            part = replace(part, args=updated_json)
        elif isinstance(self.args_delta, dict):
            if isinstance(part.args, str):
                raise UnexpectedModelBehavior(f'Cannot apply dict deltas to non-dict tool arguments ({part=}, {self=})')
            updated_dict = {**(part.args or {}), **self.args_delta}
            part = replace(part, args=updated_dict)

        if self.tool_call_id:
            part = replace(part, tool_call_id=self.tool_call_id)

        if self.provider_name:
            part = replace(part, provider_name=self.provider_name)

        if self.provider_details:
            merged_provider_details = {**(part.provider_details or {}), **self.provider_details}
            part = replace(part, provider_details=merged_provider_details)

        return part

# examples/pydantic_ai_examples/ag_ui/__init__.py:18-25
from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

# examples/pydantic_ai_examples/ag_ui/__init__.py:18-25
from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

# examples/pydantic_ai_examples/ag_ui/__init__.py:18-25
from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

# examples/pydantic_ai_examples/ag_ui/__init__.py:18-25
from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# pydantic_ai_slim/pydantic_ai/__init__.py:35-48
from .exceptions import (
    AgentRunError,
    ApprovalRequired,
    CallDeferred,
    ConcurrencyLimitExceeded,
    FallbackExceptionGroup,
    IncompleteToolCall,
    ModelAPIError,
    ModelHTTPError,
    ModelRetry,
    UnexpectedModelBehavior,
    UsageLimitExceeded,
    UserError,
)

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/_toolset.py:38-40
class _ApprovalRequired:
    metadata: dict[str, Any] | None = None
    kind: Literal['approval_required'] = 'approval_required'

# tests/models/test_cohere.py:66-68
class MockClientWrapper:
    def get_base_url(self) -> str:
        return 'https://api.cohere.com'

# pydantic_graph/pydantic_graph/persistence/file.py:169-177
async def _file_append_check(file: Path, content: bytes) -> bool:
    path = anyio.Path(file)
    if await path.exists():
        return False

    async with await anyio.open_file(path, mode='ab') as f:
        await f.write(content + b'\n')

    return (await path.read_bytes()).startswith(content)

# pydantic_graph/pydantic_graph/beta/join.py:106-109
def reduce_list_append(current: list[T], inputs: T) -> list[T]:
    """A reducer that appends to a list."""
    current.append(inputs)
    return current

# pydantic_graph/pydantic_graph/beta/join.py:106-109
def reduce_list_append(current: list[T], inputs: T) -> list[T]:
    """A reducer that appends to a list."""
    current.append(inputs)
    return current

# pydantic_graph/pydantic_graph/beta/join.py:106-109
def reduce_list_append(current: list[T], inputs: T) -> list[T]:
    """A reducer that appends to a list."""
    current.append(inputs)
    return current

# pydantic_graph/pydantic_graph/beta/join.py:106-109
def reduce_list_append(current: list[T], inputs: T) -> list[T]:
    """A reducer that appends to a list."""
    current.append(inputs)
    return current

# pydantic_graph/pydantic_graph/beta/join.py:106-109
def reduce_list_append(current: list[T], inputs: T) -> list[T]:
    """A reducer that appends to a list."""
    current.append(inputs)
    return current

# pydantic_graph/pydantic_graph/beta/join.py:106-109
def reduce_list_append(current: list[T], inputs: T) -> list[T]:
    """A reducer that appends to a list."""
    current.append(inputs)
    return current

# pydantic_graph/pydantic_graph/beta/join.py:106-109
def reduce_list_append(current: list[T], inputs: T) -> list[T]:
    """A reducer that appends to a list."""
    current.append(inputs)
    return current

# pydantic_graph/pydantic_graph/beta/join.py:106-109
def reduce_list_append(current: list[T], inputs: T) -> list[T]:
    """A reducer that appends to a list."""
    current.append(inputs)
    return current

# pydantic_graph/pydantic_graph/beta/join.py:106-109
def reduce_list_append(current: list[T], inputs: T) -> list[T]:
    """A reducer that appends to a list."""
    current.append(inputs)
    return current

# tests/test_agent.py:6475-6520
async def test_wrapper_agent():
    async def event_stream_handler(ctx: RunContext[None], events: AsyncIterable[AgentStreamEvent]):
        pass  # pragma: no cover

    foo_toolset = FunctionToolset()

    @foo_toolset.tool
    def foo() -> str:
        return 'Hello from foo'  # pragma: no cover

    test_model = TestModel()
    agent = Agent(test_model, toolsets=[foo_toolset], output_type=Foo, event_stream_handler=event_stream_handler)
    wrapper_agent = WrapperAgent(agent)
    assert wrapper_agent.toolsets == agent.toolsets
    assert wrapper_agent.model == agent.model
    assert wrapper_agent.name == agent.name
    wrapper_agent.name = 'wrapped'
    assert wrapper_agent.name == 'wrapped'
    assert wrapper_agent.output_type == agent.output_type
    assert wrapper_agent.event_stream_handler == agent.event_stream_handler
    assert wrapper_agent.output_json_schema() == snapshot(
        {
            'type': 'object',
            'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'string'}},
            'title': 'Foo',
            'required': ['a', 'b'],
        }
    )
    assert wrapper_agent.output_json_schema(output_type=str) == snapshot({'type': 'string'})

    bar_toolset = FunctionToolset()

    @bar_toolset.tool
    def bar() -> str:
        return 'Hello from bar'

    with wrapper_agent.override(toolsets=[bar_toolset]):
        async with wrapper_agent:
            async with wrapper_agent.iter(user_prompt='Hello') as run:
                async for _ in run:
                    pass

    assert run.result is not None
    assert run.result.output == snapshot(Foo(a=0, b='a'))
    assert test_model.last_model_request_parameters is not None
    assert [t.name for t in test_model.last_model_request_parameters.function_tools] == snapshot(['bar'])

# pydantic_graph/pydantic_graph/beta/join.py:106-109
def reduce_list_append(current: list[T], inputs: T) -> list[T]:
    """A reducer that appends to a list."""
    current.append(inputs)
    return current

# pydantic_ai_slim/pydantic_ai/toolsets/approval_required.py:22-24
    approval_required_func: Callable[[RunContext[AgentDepsT], ToolDefinition, dict[str, Any]], bool] = (
        lambda ctx, tool_def, tool_args: True
    )

# docs/.hooks/snippets.py:65-65
    lines_mapping: dict[int, int]

# pydantic_ai_slim/pydantic_ai/format_prompt.py:174-185
    def _mapping_to_xml(
        self,
        element: ElementTree.Element,
        mapping: Mapping[Any, Any],
        path: str = '',
    ) -> None:
        for key, value in mapping.items():
            if isinstance(key, int):
                key = str(key)
            elif not isinstance(key, str):
                raise TypeError(f'Unsupported key type for XML formatting: {type(key)}, only str and int are allowed')
            element.append(self._to_xml(value=value, path=f'{path}.{key}' if path else key, tag=key))

# pydantic_graph/pydantic_graph/beta/join.py:106-109
def reduce_list_append(current: list[T], inputs: T) -> list[T]:
    """A reducer that appends to a list."""
    current.append(inputs)
    return current

# pydantic_ai_slim/pydantic_ai/tools.py:227-229
    approvals: dict[str, bool | DeferredToolApprovalResult] = field(
        default_factory=dict[str, bool | DeferredToolApprovalResult]
    )

# tests/graph/beta/test_util.py:23-29
def test_some_wrapper():
    """Test Some wrapper for Maybe pattern."""
    value = Some(42)
    assert value.value == 42

    none_value = Some(None)
    assert none_value.value is None

# pydantic_ai_slim/pydantic_ai/tools.py:161-161
    approvals: list[ToolCallPart] = field(default_factory=list[ToolCallPart])

# pydantic_ai_slim/pydantic_ai/tools.py:280-280
    requires_approval: bool

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/response_types.py:156-161
class ToolApprovalRequestChunk(BaseChunk):
    """Tool approval request chunk for human-in-the-loop approval."""

    type: Literal['tool-approval-request'] = 'tool-approval-request'
    approval_id: str
    tool_call_id: str

# pydantic_ai_slim/pydantic_ai/ui/_event_stream.py:92-98
    def content_type(self) -> str:
        """Get the content type for the event stream, compatible with the `Accept` header value.

        By default, this returns the Server-Sent Events content type (`text/event-stream`).
        If a subclass supports other types as well, it should consider `self.accept` in [`encode_event()`][pydantic_ai.ui.UIEventStream.encode_event] and return the resulting content type.
        """
        return SSE_CONTENT_TYPE

# examples/pydantic_ai_examples/ag_ui/__init__.py:18-25
from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

# examples/pydantic_ai_examples/ag_ui/__init__.py:18-25
from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

# pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_function_toolset.py:10-10
from ._toolset import PrefectWrapperToolset

# pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_function_toolset.py:10-10
from ._toolset import PrefectWrapperToolset

# pydantic_ai_slim/pydantic_ai/embeddings/__init__.py:20-20
from .wrapper import WrapperEmbeddingModel

# pydantic_ai_slim/pydantic_ai/embeddings/__init__.py:20-20
from .wrapper import WrapperEmbeddingModel

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/__init__.py:19-19
from ._toolset import TemporalWrapperToolset

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/__init__.py:19-19
from ._toolset import TemporalWrapperToolset

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/__init__.py:19-19
from ._toolset import TemporalWrapperToolset

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/__init__.py:19-19
from ._toolset import TemporalWrapperToolset

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/__init__.py:19-19
from ._toolset import TemporalWrapperToolset

# pydantic_ai_slim/pydantic_ai/durable_exec/temporal/__init__.py:19-19
from ._toolset import TemporalWrapperToolset

# pydantic_graph/pydantic_graph/persistence/file.py:138-145
    async def _append_save(self, snapshot: Snapshot[StateT, RunEndT], *, lock: bool = True) -> None:
        assert self._snapshots_type_adapter is not None, 'snapshots type adapter must be set'
        async with AsyncExitStack() as stack:
            if lock:
                await stack.enter_async_context(self._lock())
            snapshots = await self.load_all()
            snapshots.append(snapshot)
            await self._save(snapshots)

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# pydantic_ai_slim/pydantic_ai/models/mistral.py:748-756
VALID_JSON_TYPE_MAPPING: dict[str, Any] = {
    'string': str,
    'integer': int,
    'number': float,
    'boolean': bool,
    'array': list,
    'object': dict,
    'null': type(None),
}

# pydantic_ai_slim/pydantic_ai/__init__.py:115-128
from .toolsets import (
    AbstractToolset,
    ApprovalRequiredToolset,
    CombinedToolset,
    ExternalToolset,
    FilteredToolset,
    FunctionToolset,
    PrefixedToolset,
    PreparedToolset,
    RenamedToolset,
    ToolsetFunc,
    ToolsetTool,
    WrapperToolset,
)

# tests/test_agent.py:6595-6790
async def test_hitl_tool_approval():
    def model_function(messages: list[ModelMessage], info: AgentInfo) -> ModelResponse:
        if len(messages) == 1:
            return ModelResponse(
                parts=[
                    ToolCallPart(
                        tool_name='create_file',
                        args={'path': 'new_file.py', 'content': 'print("Hello, world!")'},
                        tool_call_id='create_file',
                    ),
                    ToolCallPart(
                        tool_name='delete_file', args={'path': 'ok_to_delete.py'}, tool_call_id='ok_to_delete'
                    ),
                    ToolCallPart(
                        tool_name='delete_file', args={'path': 'never_delete.py'}, tool_call_id='never_delete'
                    ),
                ]
            )
        else:
            return ModelResponse(parts=[TextPart('Done!')])

    model = FunctionModel(model_function)

    agent = Agent(model, output_type=[str, DeferredToolRequests])

    @agent.tool_plain(requires_approval=True)
    def delete_file(path: str) -> str:
        return f'File {path!r} deleted'

    @agent.tool_plain
    def create_file(path: str, content: str) -> str:
        return f'File {path!r} created with content: {content}'

    result = await agent.run('Create new_file.py and delete ok_to_delete.py and never_delete.py')
    messages = result.all_messages()
    assert messages == snapshot(
        [
            ModelRequest(
                parts=[
                    UserPromptPart(
                        content='Create new_file.py and delete ok_to_delete.py and never_delete.py',
                        timestamp=IsDatetime(),
                    )
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelResponse(
                parts=[
                    ToolCallPart(
                        tool_name='create_file',
                        args={'path': 'new_file.py', 'content': 'print("Hello, world!")'},
                        tool_call_id='create_file',
                    ),
                    ToolCallPart(
                        tool_name='delete_file', args={'path': 'ok_to_delete.py'}, tool_call_id='ok_to_delete'
                    ),
                    ToolCallPart(
                        tool_name='delete_file', args={'path': 'never_delete.py'}, tool_call_id='never_delete'
                    ),
                ],
                usage=RequestUsage(input_tokens=60, output_tokens=23),
                model_name='function:model_function:',
                timestamp=IsDatetime(),
                run_id=IsStr(),
            ),
            ModelRequest(
                parts=[
                    ToolReturnPart(
                        tool_name='create_file',
                        content='File \'new_file.py\' created with content: print("Hello, world!")',
                        tool_call_id='create_file',
                        timestamp=IsDatetime(),
                    )
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
        ]
    )
    assert result.output == snapshot(
        DeferredToolRequests(
            approvals=[
                ToolCallPart(tool_name='delete_file', args={'path': 'ok_to_delete.py'}, tool_call_id='ok_to_delete'),
                ToolCallPart(tool_name='delete_file', args={'path': 'never_delete.py'}, tool_call_id='never_delete'),
            ]
        )
    )

    result = await agent.run(
        message_history=messages,
        deferred_tool_results=DeferredToolResults(
            approvals={'ok_to_delete': True, 'never_delete': ToolDenied('File cannot be deleted')},
        ),
    )
    assert result.all_messages() == snapshot(
        [
            ModelRequest(
                parts=[
                    UserPromptPart(
                        content='Create new_file.py and delete ok_to_delete.py and never_delete.py',
                        timestamp=IsDatetime(),
                    )
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelResponse(
                parts=[
                    ToolCallPart(
                        tool_name='create_file',
                        args={'path': 'new_file.py', 'content': 'print("Hello, world!")'},
                        tool_call_id='create_file',
                    ),
                    ToolCallPart(
                        tool_name='delete_file', args={'path': 'ok_to_delete.py'}, tool_call_id='ok_to_delete'
                    ),
                    ToolCallPart(
                        tool_name='delete_file', args={'path': 'never_delete.py'}, tool_call_id='never_delete'
                    ),
                ],
                usage=RequestUsage(input_tokens=60, output_tokens=23),
                model_name='function:model_function:',
                timestamp=IsDatetime(),
                run_id=IsStr(),
            ),
            ModelRequest(
                parts=[
                    ToolReturnPart(
                        tool_name='create_file',
                        content='File \'new_file.py\' created with content: print("Hello, world!")',
                        tool_call_id='create_file',
                        timestamp=IsDatetime(),
                    )
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelRequest(
                parts=[
                    ToolReturnPart(
                        tool_name='delete_file',
                        content="File 'ok_to_delete.py' deleted",
                        tool_call_id='ok_to_delete',
                        timestamp=IsDatetime(),
                    ),
                    ToolReturnPart(
                        tool_name='delete_file',
                        content='File cannot be deleted',
                        tool_call_id='never_delete',
                        timestamp=IsDatetime(),
                    ),
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelResponse(
                parts=[TextPart(content='Done!')],
                usage=RequestUsage(input_tokens=78, output_tokens=24),
                model_name='function:model_function:',
                timestamp=IsDatetime(),
                run_id=IsStr(),
            ),
        ]
    )
    assert result.output == snapshot('Done!')

    assert result.new_messages() == snapshot(
        [
            ModelRequest(
                parts=[
                    ToolReturnPart(
                        tool_name='delete_file',
                        content="File 'ok_to_delete.py' deleted",
                        tool_call_id='ok_to_delete',
                        timestamp=IsDatetime(),
                    ),
                    ToolReturnPart(
                        tool_name='delete_file',
                        content='File cannot be deleted',
                        tool_call_id='never_delete',
                        timestamp=IsDatetime(),
                    ),
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
            ),
            ModelResponse(
                parts=[TextPart(content='Done!')],
                usage=RequestUsage(input_tokens=78, output_tokens=24),
                model_name='function:model_function:',
                timestamp=IsDatetime(),
                run_id=IsStr(),
            ),
        ]
    )

# pydantic_ai_slim/pydantic_ai/durable_exec/prefect/_function_toolset.py:10-10
from ._toolset import PrefectWrapperToolset

# pydantic_ai_slim/pydantic_ai/_run_context.py:71-71
    tool_call_approved: bool = False

# pydantic_ai_slim/pydantic_ai/models/mistral.py:758-765
SIMPLE_JSON_TYPE_MAPPING = {
    'string': 'str',
    'integer': 'int',
    'number': 'float',
    'boolean': 'bool',
    'array': 'list',
    'null': 'None',
}

# tests/models/test_cohere.py:75-75
    _client_wrapper: MockClientWrapper = None  # type: ignore

# examples/pydantic_ai_examples/ag_ui/__init__.py:18-25
from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

# examples/pydantic_ai_examples/ag_ui/__init__.py:18-25
from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

# pydantic_ai_slim/pydantic_ai/tools.py:203-203
DeferredToolApprovalResult: TypeAlias = Annotated[ToolApproved | ToolDenied, Discriminator('kind')]

# pydantic_ai_slim/pydantic_ai/models/xai.py:144-157
_XAI_MODEL_SETTINGS_MAPPING: dict[str, str] = {
    'temperature': 'temperature',
    'top_p': 'top_p',
    'max_tokens': 'max_tokens',
    'stop_sequences': 'stop',
    'parallel_tool_calls': 'parallel_tool_calls',
    'presence_penalty': 'presence_penalty',
    'frequency_penalty': 'frequency_penalty',
    'xai_logprobs': 'logprobs',
    'xai_top_logprobs': 'top_logprobs',
    'xai_user': 'user',
    'xai_store_messages': 'store_messages',
    'xai_previous_response_id': 'previous_response_id',
}

# pydantic_evals/pydantic_evals/_utils.py:49-75
def get_unwrapped_function_name(func: Callable[..., Any]) -> str:
    """Get the name of a function, unwrapping partials and decorators.

    Args:
        func: The function to get the name of.

    Returns:
        The name of the function.

    Raises:
        AttributeError: If the function doesn't have a __name__ attribute and isn't a method.
    """

    def _unwrap(f: Callable[..., Any]) -> Callable[..., Any]:
        """Unwraps f, also unwrapping partials, for the sake of getting f's name."""
        if isinstance(f, partial):
            return _unwrap(f.func)
        return inspect.unwrap(f)

    try:
        return _unwrap(func).__name__
    except AttributeError as e:
        # Handle instances of types with `__call__` as a method
        if inspect.ismethod(getattr(func, '__call__', None)):
            return f'{type(func).__qualname__}.__call__'
        else:
            raise e

# tests/test_mcp.py:2395-2402
async def test_server_capabilities_list_changed_fields() -> None:
    """Test that ServerCapabilities correctly parses listChanged fields."""
    server = MCPServerStdio('python', ['-m', 'tests.mcp_server'])
    async with server:
        caps = server.capabilities
        assert isinstance(caps.prompts_list_changed, bool)
        assert isinstance(caps.tools_list_changed, bool)
        assert isinstance(caps.resources_list_changed, bool)

# examples/pydantic_ai_examples/ag_ui/__init__.py:18-25
from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

# examples/pydantic_ai_examples/ag_ui/__init__.py:18-25
from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

# examples/pydantic_ai_examples/ag_ui/__init__.py:18-25
from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

# examples/pydantic_ai_examples/ag_ui/__init__.py:18-25
from .api import (
    agentic_chat_app,
    agentic_generative_ui_app,
    human_in_the_loop_app,
    predictive_state_updates_app,
    shared_state_app,
    tool_based_generative_ui_app,
)

# pydantic_evals/pydantic_evals/evaluators/llm_as_a_judge.py:56-70
async def judge_output(
    output: Any,
    rubric: str,
    model: models.Model | models.KnownModelName | str | None = None,
    model_settings: ModelSettings | None = None,
) -> GradingOutput:
    """Judge the output of a model based on a rubric.

    If the model is not specified, a default model is used. The default model starts as 'openai:gpt-5.2',
    but this can be changed using the `set_default_judge_model` function.
    """
    user_prompt = _build_prompt(output=output, rubric=rubric)
    return (
        await _judge_output_agent.run(user_prompt, model=model or _default_model, model_settings=model_settings)
    ).output

# pydantic_ai_slim/pydantic_ai/tools.py:174-174
    kind: Literal['tool-approved'] = 'tool-approved'