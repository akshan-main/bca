# tests/test_dbos.py:976-980
def conditions(ctx: RunContext, city: str) -> str:
    if ctx.run_step % 2 == 0:
        return "It's sunny"  # pragma: lax no cover
    else:
        return "It's raining"

# tests/test_dbos.py:976-980
def conditions(ctx: RunContext, city: str) -> str:
    if ctx.run_step % 2 == 0:
        return "It's sunny"  # pragma: lax no cover
    else:
        return "It's raining"

# pydantic_ai_slim/pydantic_ai/models/fallback.py:152-158
def _default_fallback_condition_factory(exceptions: tuple[type[Exception], ...]) -> Callable[[Exception], bool]:
    """Create a default fallback condition for the given exceptions."""

    def fallback_condition(exception: Exception) -> bool:
        return isinstance(exception, exceptions)

    return fallback_condition

# tests/models/test_fallback.py:571-577
async def test_fallback_condition_tuple() -> None:
    potato_model = FunctionModel(potato_exception_response)
    fallback_model = FallbackModel(potato_model, success_model, fallback_on=(PotatoException, ModelHTTPError))
    agent = Agent(model=fallback_model)

    response = await agent.run('hello')
    assert response.output == 'success'

# pydantic_evals/pydantic_evals/otel/span_tree.py:244-366
    def _matches_query(self, query: SpanQuery) -> bool:  # noqa: C901
        """Check if the span matches the query conditions."""
        # Logical combinations
        if or_ := query.get('or_'):
            if len(query) > 1:
                raise ValueError("Cannot combine 'or_' conditions with other conditions at the same level")
            return any(self._matches_query(q) for q in or_)
        if not_ := query.get('not_'):
            if self._matches_query(not_):
                return False
        if and_ := query.get('and_'):
            results = [self._matches_query(q) for q in and_]
            if not all(results):
                return False
        # At this point, all existing ANDs and no existing ORs have passed, so it comes down to this condition

        # Name conditions
        if (name_equals := query.get('name_equals')) and self.name != name_equals:
            return False
        if (name_contains := query.get('name_contains')) and name_contains not in self.name:
            return False
        if (name_matches_regex := query.get('name_matches_regex')) and not re.match(name_matches_regex, self.name):
            return False

        # Attribute conditions
        if (has_attributes := query.get('has_attributes')) and not all(
            self.attributes.get(key) == value for key, value in has_attributes.items()
        ):
            return False
        if (has_attributes_keys := query.get('has_attribute_keys')) and not all(
            key in self.attributes for key in has_attributes_keys
        ):
            return False

        # Timing conditions
        if (min_duration := query.get('min_duration')) is not None:
            if not isinstance(min_duration, timedelta):
                min_duration = timedelta(seconds=min_duration)
            if self.duration < min_duration:
                return False
        if (max_duration := query.get('max_duration')) is not None:
            if not isinstance(max_duration, timedelta):
                max_duration = timedelta(seconds=max_duration)
            if self.duration > max_duration:
                return False

        # Children conditions
        if (min_child_count := query.get('min_child_count')) and len(self.children) < min_child_count:
            return False
        if (max_child_count := query.get('max_child_count')) and len(self.children) > max_child_count:
            return False
        if (some_child_has := query.get('some_child_has')) and not any(
            child._matches_query(some_child_has) for child in self.children
        ):
            return False
        if (all_children_have := query.get('all_children_have')) and not all(
            child._matches_query(all_children_have) for child in self.children
        ):
            return False
        if (no_child_has := query.get('no_child_has')) and any(
            child._matches_query(no_child_has) for child in self.children
        ):
            return False

        # Descendant conditions
        # The following local functions with cache decorators are used to avoid repeatedly evaluating these properties
        @cache
        def descendants():
            return self.descendants

        @cache
        def pruned_descendants():
            stop_recursing_when = query.get('stop_recursing_when')
            return (
                self._filter_descendants(lambda _: True, stop_recursing_when) if stop_recursing_when else descendants()
            )

        if (min_descendant_count := query.get('min_descendant_count')) and len(descendants()) < min_descendant_count:
            return False
        if (max_descendant_count := query.get('max_descendant_count')) and len(descendants()) > max_descendant_count:
            return False
        if (some_descendant_has := query.get('some_descendant_has')) and not any(
            descendant._matches_query(some_descendant_has) for descendant in pruned_descendants()
        ):
            return False
        if (all_descendants_have := query.get('all_descendants_have')) and not all(
            descendant._matches_query(all_descendants_have) for descendant in pruned_descendants()
        ):
            return False
        if (no_descendant_has := query.get('no_descendant_has')) and any(
            descendant._matches_query(no_descendant_has) for descendant in pruned_descendants()
        ):
            return False

        # Ancestor conditions
        # The following local functions with cache decorators are used to avoid repeatedly evaluating these properties
        @cache
        def ancestors():
            return self.ancestors

        @cache
        def pruned_ancestors():
            stop_recursing_when = query.get('stop_recursing_when')
            return self._filter_ancestors(lambda _: True, stop_recursing_when) if stop_recursing_when else ancestors()

        if (min_depth := query.get('min_depth')) and len(ancestors()) < min_depth:
            return False
        if (max_depth := query.get('max_depth')) and len(ancestors()) > max_depth:
            return False
        if (some_ancestor_has := query.get('some_ancestor_has')) and not any(
            ancestor._matches_query(some_ancestor_has) for ancestor in pruned_ancestors()
        ):
            return False
        if (all_ancestors_have := query.get('all_ancestors_have')) and not all(
            ancestor._matches_query(all_ancestors_have) for ancestor in pruned_ancestors()
        ):
            return False
        if (no_ancestor_has := query.get('no_ancestor_has')) and any(
            ancestor._matches_query(no_ancestor_has) for ancestor in pruned_ancestors()
        ):
            return False

        return True

# tests/models/test_fallback.py:554-561
async def test_fallback_condition_override() -> None:
    def should_fallback(exc: Exception) -> bool:
        return False

    fallback_model = FallbackModel(failure_model, success_model, fallback_on=should_fallback)
    agent = Agent(model=fallback_model)
    with pytest.raises(ModelHTTPError):
        await agent.run('hello')

# tests/evals/test_otel.py:628-671
async def test_span_query_timing_conditions():
    """Test timing-related conditions in SpanQuery."""
    from datetime import timedelta

    with context_subtree() as tree:
        with logfire.span('fast_operation'):
            pass

        with logfire.span('medium_operation'):
            logfire.info('add a wait')

        with logfire.span('slow_operation'):
            logfire.info('add a wait')
            logfire.info('add a wait')
    assert isinstance(tree, SpanTree)

    durations = sorted([node.duration for node in tree if node.duration > timedelta(seconds=0)])
    fast_threshold = (durations[0] + durations[1]) / 2
    medium_threshold = (durations[1] + durations[2]) / 2

    # Test min_duration
    min_duration_query: SpanQuery = {'min_duration': fast_threshold}
    matched_nodes = list(tree.find(min_duration_query))
    assert len(matched_nodes) == 2
    assert 'fast_operation' not in [node.name for node in matched_nodes]

    # Test max_duration
    max_duration_queries: list[SpanQuery] = [
        {'min_duration': 0.001, 'max_duration': medium_threshold},
        {'min_duration': 0.001, 'max_duration': medium_threshold.seconds},
    ]
    for max_duration_query in max_duration_queries:
        matched_nodes = list(tree.find(max_duration_query))
        assert len(matched_nodes) == 2
        assert 'slow_operation' not in [node.name for node in matched_nodes]

    # Test min and max duration together using timedelta
    duration_range_query: SpanQuery = {
        'min_duration': fast_threshold,
        'max_duration': medium_threshold,
    }
    matched_node = tree.first(duration_range_query)
    assert matched_node is not None
    assert matched_node.name == 'medium_operation'

# pydantic_evals/pydantic_evals/otel/span_tree.py:237-242
    def matches(self, query: SpanQuery | SpanPredicate) -> bool:
        """Check if the span node matches the query conditions or predicate."""
        if callable(query):
            return query(self)

        return self._matches_query(query)

# tests/evals/test_otel.py:674-710
async def test_span_query_descendant_conditions():
    """Test descendant-related conditions in SpanQuery."""

    with context_subtree() as tree:
        with logfire.span('parent1'):
            with logfire.span('child1', type='important'):
                pass
            with logfire.span('child2', type='normal'):
                pass

        with logfire.span('parent2'):
            with logfire.span('child3', type='normal'):
                pass
            with logfire.span('child4', type='normal'):
                pass
    assert isinstance(tree, SpanTree)

    # Test some_child_has condition
    some_child_query: SpanQuery = {'some_child_has': {'has_attributes': {'type': 'important'}}}
    matched_node = tree.first(some_child_query)
    assert matched_node is not None
    assert matched_node.name == 'parent1'

    # Test all_children_have condition
    all_children_query: SpanQuery = {'all_children_have': {'has_attributes': {'type': 'normal'}}, 'min_child_count': 1}
    matched_node = tree.first(all_children_query)
    assert matched_node is not None
    assert matched_node.name == 'parent2'
    # A couple more tests for coverage reasons:
    assert tree.first({'all_children_have': {'has_attributes': {'type': 'unusual'}}, 'min_child_count': 1}) is None
    assert not matched_node.matches({'no_child_has': {'has_attributes': {'type': 'normal'}}})

    # Test no_child_has condition
    no_child_query: SpanQuery = {'no_child_has': {'has_attributes': {'type': 'important'}}, 'min_child_count': 1}
    matched_node = tree.first(no_child_query)
    assert matched_node is not None
    assert matched_node.name == 'parent2'

# tests/graph/beta/test_v1_v2_integration.py:215-276
async def test_v1_node_conditional_return():
    """Test v1 nodes with conditional returns creating implicit decisions."""

    @dataclass
    class RouterNode(BaseNode[IntegrationState, None, str]):
        value: int

        async def run(self, ctx: GraphRunContext[IntegrationState, None]) -> PathA | PathB:
            if self.value < 10:
                return PathA()
            else:
                return PathB()

    @dataclass
    class PathA(BaseNode[IntegrationState, None, str]):
        async def run(self, ctx: GraphRunContext[IntegrationState, None]) -> End[str]:
            return End('Path A')

    @dataclass
    class PathB(BaseNode[IntegrationState, None, str]):
        async def run(self, ctx: GraphRunContext[IntegrationState, None]) -> End[str]:
            return End('Path B')

    g = GraphBuilder(state_type=IntegrationState, input_type=int, output_type=str)

    @g.step
    async def create_router(ctx: StepContext[IntegrationState, None, int]) -> RouterNode:
        return RouterNode(ctx.inputs)

    g.add(
        g.node(RouterNode),
        g.node(PathA),
        g.node(PathB),
        g.edge_from(g.start_node).to(create_router),
    )

    graph = g.build()

    assert str(graph) == snapshot("""\
stateDiagram-v2
  create_router
  RouterNode
  state decision <<choice>>
  PathA
  PathB

  [*] --> create_router
  create_router --> RouterNode
  RouterNode --> decision
  decision --> PathA
  decision --> PathB
  PathA --> [*]
  PathB --> [*]\
""")

    # Test path A
    result_a = await graph.run(state=IntegrationState(), inputs=5)
    assert result_a == 'Path A'

    # Test path B
    result_b = await graph.run(state=IntegrationState(), inputs=15)
    assert result_b == 'Path B'

# pydantic_graph/pydantic_graph/beta/decision.py:41-80
class Decision(Generic[StateT, DepsT, HandledT]):
    """Decision node for conditional branching in graph execution.

    A Decision node evaluates conditions and routes execution to different
    branches based on the input data type or custom matching logic.
    """

    id: NodeID
    """Unique identifier for this decision node."""

    branches: list[DecisionBranch[Any]]
    """List of branches that can be taken from this decision."""

    note: str | None
    """Optional documentation note for this decision."""

    def branch(self, branch: DecisionBranch[T]) -> Decision[StateT, DepsT, HandledT | T]:
        """Add a new branch to this decision.

        Args:
            branch: The branch to add to this decision.

        Returns:
            A new Decision with the additional branch.
        """
        return Decision(id=self.id, branches=self.branches + [branch], note=self.note)

    def _force_handled_contravariant(self, inputs: HandledT) -> Never:  # pragma: no cover
        """Forces this type to be contravariant in the HandledT type variable.

        This is an implementation detail of how we can type-check that all possible input types have
        been exhaustively covered.

        Args:
            inputs: Input data of handled types.

        Raises:
            RuntimeError: Always, as this method should never be executed.
        """
        raise RuntimeError('This method should never be called, it is just defined for typing purposes.')

# tests/test_concurrency.py:125-174
    async def test_backpressure_race_condition(self):
        """Test that max_queued is enforced atomically under concurrent load.

        This test verifies the fix for a race condition where multiple tasks could
        simultaneously pass the max_queued check before any of them actually started
        waiting on the limiter.
        """
        limiter = ConcurrencyLimiter(max_running=1, max_queued=1)
        hold = anyio.Event()
        started = anyio.Event()

        async def holder():
            async with get_concurrency_context(limiter, 'holder'):
                started.set()
                await hold.wait()

        # Now launch multiple tasks simultaneously that all try to queue.
        # With max_queued=1, exactly one should succeed in queuing.
        num_concurrent = 5
        results: list[str] = []
        barrier = AsyncBarrier(num_concurrent)

        async def try_acquire(idx: int):
            # Use barrier to ensure all tasks try to acquire at the same time
            await barrier.wait()
            try:
                async with get_concurrency_context(limiter, f'task-{idx}'):
                    results.append(f'acquired-{idx}')
            except ConcurrencyLimitExceeded:
                results.append(f'rejected-{idx}')

        async with anyio.create_task_group() as tg:
            # Fill the running slot and wait for it to be held
            tg.start_soon(holder)
            await started.wait()

            # Launch all tasks simultaneously
            for i in range(num_concurrent):
                tg.start_soon(try_acquire, i)
            await anyio.sleep(0.1)  # Give tasks time to hit the barrier and try to acquire

            # Release the holder
            hold.set()

        # Verify: exactly one task should have been allowed to queue and acquire
        # The rest should have been rejected
        acquired = [r for r in results if r.startswith('acquired-')]
        rejected = [r for r in results if r.startswith('rejected-')]
        assert len(acquired) == 1, f'Expected exactly 1 acquired, got {len(acquired)}: {acquired}'
        assert len(rejected) == num_concurrent - 1, f'Expected {num_concurrent - 1} rejected, got {len(rejected)}'

# pydantic_graph/pydantic_graph/beta/mermaid.py:166-208
def _topological_sort(
    nodes: list[MermaidNode], edges: list[MermaidEdge]
) -> tuple[list[MermaidNode], list[MermaidEdge]]:
    """Sort nodes and edges in a logical topological order.

    Uses BFS from the start node to assign depths, then sorts:
    - Nodes by their distance from start
    - Edges by the distance of their source and target nodes
    """
    # Build adjacency list for BFS
    adjacency: dict[str, list[str]] = defaultdict(list)
    for edge in edges:
        adjacency[edge.start_id].append(edge.end_id)

    # BFS to assign depth to each node (distance from start)
    depths: dict[str, int] = {}
    queue: list[tuple[str, int]] = [(StartNode.id, 0)]
    depths[StartNode.id] = 0

    while queue:
        node_id, depth = queue.pop(0)
        for next_id in adjacency[node_id]:
            if next_id not in depths:  # pragma: no branch
                depths[next_id] = depth + 1
                queue.append((next_id, depth + 1))

    # Sort nodes by depth (distance from start), then by id for stability
    # Nodes not reachable from start get infinity depth (sorted to end)
    sorted_nodes = sorted(nodes, key=lambda n: (depths.get(n.id, float('inf')), n.id))

    # Sort edges by source depth, then target depth
    # This ensures edges closer to start come first, edges closer to end come last
    sorted_edges = sorted(
        edges,
        key=lambda e: (
            depths.get(e.start_id, float('inf')),
            depths.get(e.end_id, float('inf')),
            e.start_id,
            e.end_id,
        ),
    )

    return sorted_nodes, sorted_edges

# tests/test_agent.py:4623-4706
def test_dynamic_false_no_reevaluate():
    """When dynamic is false (default), the system prompt is not reevaluated
    i.e: SystemPromptPart(
            content="A",       <--- Remains the same when `message_history` is passed.
    )
    """
    agent = Agent('test', system_prompt='Foobar')

    dynamic_value = 'A'

    @agent.system_prompt
    async def func() -> str:
        return dynamic_value

    res = agent.run_sync('Hello')

    assert res.all_messages() == snapshot(
        [
            ModelRequest(
                parts=[
                    SystemPromptPart(content='Foobar', timestamp=IsNow(tz=timezone.utc)),
                    SystemPromptPart(content=dynamic_value, timestamp=IsNow(tz=timezone.utc)),
                    UserPromptPart(content='Hello', timestamp=IsNow(tz=timezone.utc)),
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='request',
            ),
            ModelResponse(
                parts=[TextPart(content='success (no tool calls)')],
                usage=RequestUsage(input_tokens=53, output_tokens=4),
                model_name='test',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='response',
            ),
        ]
    )

    dynamic_value = 'B'

    res_two = agent.run_sync('World', message_history=res.all_messages())

    assert res_two.all_messages() == snapshot(
        [
            ModelRequest(
                parts=[
                    SystemPromptPart(content='Foobar', timestamp=IsNow(tz=timezone.utc)),
                    SystemPromptPart(
                        content='A',  # Remains the same
                        timestamp=IsNow(tz=timezone.utc),
                    ),
                    UserPromptPart(content='Hello', timestamp=IsNow(tz=timezone.utc)),
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='request',
            ),
            ModelResponse(
                parts=[TextPart(content='success (no tool calls)')],
                usage=RequestUsage(input_tokens=53, output_tokens=4),
                model_name='test',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='response',
            ),
            ModelRequest(
                parts=[UserPromptPart(content='World', timestamp=IsNow(tz=timezone.utc), part_kind='user-prompt')],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='request',
            ),
            ModelResponse(
                parts=[TextPart(content='success (no tool calls)')],
                usage=RequestUsage(input_tokens=54, output_tokens=8),
                model_name='test',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='response',
            ),
        ]
    )

    assert res_two.new_messages() == res_two.all_messages()[-2:]

# tests/evals/test_otel.py:713-751
async def test_span_query_complex_hierarchical_conditions():
    """Test complex hierarchical queries with nested structures."""

    with context_subtree() as tree:
        with logfire.span('app', service='web'):
            with logfire.span('request', method='GET', path='/api/v1/users'):
                with logfire.span('db_query', table='users'):
                    pass
                with logfire.span('cache_lookup', cache='redis'):
                    pass
            with logfire.span('request', method='POST', path='/api/v1/users'):
                with logfire.span('db_query', table='users'):
                    pass
                with logfire.span('notification', channel='email'):
                    pass
    assert isinstance(tree, SpanTree)

    # Find the app span that has a POST request with a notification child
    complex_query: SpanQuery = {
        'name_equals': 'app',
        'some_child_has': {
            'name_equals': 'request',
            'has_attributes': {'method': 'POST'},
            'some_child_has': {'name_equals': 'notification'},
        },
    }

    matched_node = tree.first(complex_query)
    assert matched_node is not None
    assert matched_node.name == 'app'

    # Find request spans with both db_query and another operation
    request_with_db_and_other: SpanQuery = {
        'name_equals': 'request',
        'some_child_has': {'not_': {'name_equals': 'db_query'}},
    }

    matched_nodes = list(tree.find(request_with_db_and_other))
    assert len(matched_nodes) == 2  # Both requests have db_query and another operation

# tests/test_agent.py:4709-4797
def test_dynamic_true_reevaluate_system_prompt():
    """When dynamic is true, the system prompt is reevaluated
    i.e: SystemPromptPart(
            content="B",       <--- Updated value
    )
    """
    agent = Agent('test', system_prompt='Foobar')

    dynamic_value = 'A'

    @agent.system_prompt(dynamic=True)
    async def func():
        return dynamic_value

    res = agent.run_sync('Hello')

    assert res.all_messages() == snapshot(
        [
            ModelRequest(
                parts=[
                    SystemPromptPart(content='Foobar', timestamp=IsNow(tz=timezone.utc)),
                    SystemPromptPart(
                        content=dynamic_value,
                        dynamic_ref=func.__qualname__,
                        timestamp=IsNow(tz=timezone.utc),
                    ),
                    UserPromptPart(content='Hello', timestamp=IsNow(tz=timezone.utc)),
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='request',
            ),
            ModelResponse(
                parts=[TextPart(content='success (no tool calls)')],
                usage=RequestUsage(input_tokens=53, output_tokens=4),
                model_name='test',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='response',
            ),
        ]
    )

    dynamic_value = 'B'

    res_two = agent.run_sync('World', message_history=res.all_messages())

    assert res_two.all_messages() == snapshot(
        [
            ModelRequest(
                parts=[
                    SystemPromptPart(content='Foobar', timestamp=IsNow(tz=timezone.utc)),
                    SystemPromptPart(
                        content='B',
                        dynamic_ref=func.__qualname__,
                        timestamp=IsNow(tz=timezone.utc),
                    ),
                    UserPromptPart(content='Hello', timestamp=IsNow(tz=timezone.utc)),
                ],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='request',
            ),
            ModelResponse(
                parts=[TextPart(content='success (no tool calls)')],
                usage=RequestUsage(input_tokens=53, output_tokens=4),
                model_name='test',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='response',
            ),
            ModelRequest(
                parts=[UserPromptPart(content='World', timestamp=IsNow(tz=timezone.utc), part_kind='user-prompt')],
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='request',
            ),
            ModelResponse(
                parts=[TextPart(content='success (no tool calls)')],
                usage=RequestUsage(input_tokens=54, output_tokens=8),
                model_name='test',
                timestamp=IsNow(tz=timezone.utc),
                run_id=IsStr(),
                kind='response',
            ),
        ]
    )

    assert res_two.new_messages() == res_two.all_messages()[-2:]

# pydantic_ai_slim/pydantic_ai/_utils.py:342-344
    async def is_exhausted(self) -> bool:
        """Returns True if the stream is exhausted, False otherwise."""
        return isinstance(await self.peek(), Unset)

# pydantic_ai_slim/pydantic_ai/models/xai.py:197-199
    def system(self) -> str:
        """The model provider."""
        return 'xai'

# tests/test_tools.py:429-438
async def google_style_docstring_no_body(
    foo: int, bar: Annotated[str, Field(description='from fields')]
) -> str:  # pragma: no cover
    """
    Args:
        foo: The foo thing.
        bar: The bar thing.
    """

    return f'{foo} {bar}'

# pydantic_ai_slim/pydantic_ai/models/groq.py:171-173
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/test.py:157-159
    def system(self) -> str:
        """The model provider."""
        return self._system

# pydantic_ai_slim/pydantic_ai/models/function.py:200-202
    def system(self) -> str:
        """The system / model provider."""
        return self._system

# pydantic_ai_slim/pydantic_ai/models/cohere.py:151-153
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/gemini.py:165-167
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/google.py:249-251
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/mistral.py:177-179
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/huggingface.py:163-165
    def system(self) -> str:
        """The system / model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/agent/__init__.py:71-71
from .wrapper import WrapperAgent

# pydantic_ai_slim/pydantic_ai/durable_exec/dbos/_model.py:17-17
from pydantic_ai.models.wrapper import WrapperModel

# pydantic_ai_slim/pydantic_ai/models/anthropic.py:292-294
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# tests/typed_agent.py:79-80
def wrong_tool_prepare(ctx: RunContext[MyDeps], x: int, y: str) -> str:
    return f'{ctx.deps.foo} {x} {y}'