{
  "task_id": "tool-retry-error-format",
  "method": "bca_d5",
  "budget": 2000,
  "query_type": "vague",
  "tokens_used": 1998,
  "symbols_selected": 11,
  "files_included": 10,
  "assembly_time_ms": 122.8,
  "llm_time_ms": 3852.6,
  "llm_input_tokens": 2087,
  "llm_output_tokens": 171,
  "tests_passed": false,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: tests/evals/test_dataset.py\nSEARCH:\n    assert str(exc_info.value) == snapshot(\n        \"Could not infer format for filename 'test_cases.abc'. Use the `fmt` argument to specify the format.\"\n    )\nREPLACE:\n    assert str(exc_info.value) == snapshot(\n        \"Could not infer format for filename 'test_cases.abc'. Use the `fmt` argument to specify the format.\"\n    )\n\nFILE: tests/models/test_instrumented.py\nSEARCH:\n            'body': 'Unable to serialize: error!',\nREPLACE:\n            'body': 'Unable to serialize: error!',\n\nFILE: tests/models/test_google.py\nSEARCH:\n    assert exc_info.value.status_code == expected_status\nREPLACE:\n    assert exc_info.value.status_code == expected_status\n",
  "error": "",
  "test_time_ms": 1566.3,
  "failure_mode": "test_fail",
  "target_file_hit": false,
  "target_symbol_hit": false,
  "context_patch_overlap": 0.3,
  "patch_files_changed": 3,
  "patch_lines_changed": 5,
  "edit_distance_lines": -1,
  "entity_count_extracted": 1,
  "entity_count_mapped": 7,
  "query_identifier_density": 0.0,
  "seed_symbol_keys": [
    "tests/models/test_openrouter.py::test_openrouter_errors_raised",
    "tests/evals/test_evaluators.py::test_import_errors",
    "tests/evals/test_dataset.py::test_serialization_errors",
    "tests/test_agent.py::test_capture_run_messages_with_user_exception_does_not_contain_internal_errors",
    "tests/test_agent.py::test_run_with_deferred_tool_results_errors",
    "tests/models/test_instrumented.py::test_messages_to_otel_events_serialization_errors",
    "tests/models/test_google.py::test_google_api_errors_are_handled"
  ],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/exceptions.py::ToolRetryError._format_error_details",
  "min_hops_seed_to_mutation": 4,
  "median_hops_seed_to_mutation": 4.0,
  "bca_closure_added_symbols": 0,
  "bca_closure_added_tokens": 0,
  "bca_frontier_visited": 4852,
  "context_symbol_keys": [
    "pydantic_ai_slim/pydantic_ai/ui/_adapter.py::UIAdapter.messages",
    "pydantic_ai_slim/pydantic_ai/ui/vercel_ai/_adapter.py::VercelAIAdapter.messages",
    "tests/evals/test_dataset.py::TaskInput",
    "tests/evals/test_dataset.py::TaskOutput",
    "tests/evals/test_dataset.py::TaskMetadata",
    "tests/evals/test_dataset.py::test_serialization_errors",
    "tests/models/test_anthropic.py::MockAnthropic.messages",
    "tests/models/test_google.py::google_provider",
    "tests/models/test_google.py::test_google_api_errors_are_handled",
    "tests/models/test_instrumented.py::test_messages_to_otel_events_serialization_errors",
    "tests/models/test_openrouter.py::test_openrouter_errors_raised",
    "tests/test_agent.py::test_capture_run_messages_with_user_exception_does_not_contain_internal_errors",
    "tests/test_agent.py::test_run_with_deferred_tool_results_errors",
    "tests/test_ui.py::DummyUIRunInput.messages",
    "tests/test_ui.py::DummyUIAdapter.messages"
  ],
  "mutation_symbol_lines": 17,
  "mutation_symbol_kind": "method",
  "mutation_file_symbols": 45,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.02,
  "retrieval_softmax_entropy": 3.4134,
  "retrieval_softmax_tau": 0.899,
  "retrieval_effective_candidates": 10.65,
  "retrieval_top5_ratio": 0.9147,
  "retrieval_within95_count": 2,
  "retrieval_scored_symbols": 11,
  "retrieval_top1_score": 1.079,
  "retrieval_top5_mean_score": 0.987,
  "retrieval_budget_utilization": 0.999,
  "retrieval_file_concentration": 0.0,
  "repo_name": "pydantic-ai",
  "category": "exceptions",
  "mutation_type": "handcrafted",
  "source": "handcrafted"
}