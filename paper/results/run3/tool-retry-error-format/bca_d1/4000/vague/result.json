{
  "task_id": "tool-retry-error-format",
  "method": "bca_d1",
  "budget": 4000,
  "query_type": "vague",
  "tokens_used": 3896,
  "symbols_selected": 20,
  "files_included": 14,
  "assembly_time_ms": 77.2,
  "llm_time_ms": 2492.5,
  "llm_input_tokens": 3718,
  "llm_output_tokens": 62,
  "tests_passed": false,
  "test_output": "yncio_default_fixture_loop_scope\" is unset.\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: \"function\", \"class\", \"module\", \"package\", \"session\"\n\n  warnings.warn(PytestDeprecationWarning(_DEFAULT_FIXTURE_LOOP_SCOPE_UNSET))",
  "patch": "FILE: pydantic_evals/pydantic_evals/dataset.py\nSEARCH:\n            ValidationError: If the file cannot be parsed as a valid dataset.\nREPLACE:\n            ValidationError: If the file cannot be parsed as a valid dataset or if there is a validation error.\n",
  "error": "",
  "test_time_ms": 1388.6,
  "failure_mode": "test_fail",
  "target_file_hit": false,
  "target_symbol_hit": false,
  "context_patch_overlap": 0.071,
  "patch_files_changed": 1,
  "patch_lines_changed": 1,
  "edit_distance_lines": -1,
  "entity_count_extracted": 1,
  "entity_count_mapped": 7,
  "query_identifier_density": 0.0,
  "seed_symbol_keys": [
    "tests/models/test_openrouter.py::test_openrouter_errors_raised",
    "tests/evals/test_evaluators.py::test_import_errors",
    "tests/evals/test_dataset.py::test_serialization_errors",
    "tests/test_agent.py::test_capture_run_messages_with_user_exception_does_not_contain_internal_errors",
    "tests/test_agent.py::test_run_with_deferred_tool_results_errors",
    "tests/models/test_instrumented.py::test_messages_to_otel_events_serialization_errors",
    "tests/models/test_google.py::test_google_api_errors_are_handled"
  ],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/exceptions.py::ToolRetryError._format_error_details",
  "min_hops_seed_to_mutation": 4,
  "median_hops_seed_to_mutation": 4.0,
  "bca_closure_added_symbols": 2,
  "bca_closure_added_tokens": 126,
  "bca_frontier_visited": 21,
  "context_symbol_keys": [
    "examples/pydantic_ai_examples/question_graph.py::ask_agent",
    "examples/pydantic_ai_examples/question_graph.py::QuestionState",
    "examples/pydantic_ai_examples/question_graph.py::Answer",
    "examples/pydantic_ai_examples/question_graph.py::question_graph",
    "pydantic_ai_slim/pydantic_ai/models/instrumented.py::InstrumentationSettings",
    "pydantic_ai_slim/pydantic_ai/models/instrumented.py::InstrumentationSettings.messages_to_otel_events",
    "pydantic_ai_slim/pydantic_ai/models/instrumented.py::InstrumentationSettings.messages_to_otel_messages",
    "pydantic_ai_slim/pydantic_ai/models/instrumented.py::InstrumentedModel",
    "pydantic_ai_slim/pydantic_ai/models/instrumented.py::InstrumentedModel.event_to_dict",
    "pydantic_ai_slim/pydantic_ai/models/instrumented.py::InstrumentedModel.serialize_any",
    "pydantic_ai_slim/pydantic_ai/ui/_adapter.py::UIAdapter.messages",
    "pydantic_ai_slim/pydantic_ai/ui/vercel_ai/_adapter.py::VercelAIAdapter.messages",
    "pydantic_evals/pydantic_evals/dataset.py::InputsT",
    "pydantic_evals/pydantic_evals/dataset.py::OutputT",
    "pydantic_evals/pydantic_evals/dataset.py::MetadataT",
    "pydantic_evals/pydantic_evals/dataset.py::Dataset",
    "pydantic_evals/pydantic_evals/dataset.py::Dataset.from_file",
    "tests/evals/test_dataset.py::TaskInput",
    "tests/evals/test_dataset.py::TaskOutput",
    "tests/evals/test_dataset.py::TaskMetadata",
    "tests/evals/test_dataset.py::test_serialization_errors",
    "tests/evals/test_evaluators.py::TaskInput",
    "tests/evals/test_evaluators.py::TaskOutput",
    "tests/evals/test_evaluators.py::TaskMetadata",
    "tests/evals/test_evaluators.py::test_import_errors",
    "tests/models/test_anthropic.py::MockAnthropic.messages_",
    "tests/models/test_anthropic.py::MockAnthropic.messages",
    "tests/models/test_google.py::google_provider",
    "tests/models/test_google.py::test_google_api_errors_are_handled",
    "tests/models/test_instrumented.py::test_messages_to_otel_events_serialization_errors",
    "tests/models/test_openrouter.py::test_openrouter_errors_raised",
    "tests/test_agent.py::test_capture_run_messages_with_user_exception_does_not_contain_internal_errors",
    "tests/test_agent.py::test_run_with_deferred_tool_results_errors",
    "tests/test_ui.py::DummyUIRunInput.messages",
    "tests/test_ui.py::DummyUIAdapter.messages"
  ],
  "mutation_symbol_lines": 17,
  "mutation_symbol_kind": "method",
  "mutation_file_symbols": 45,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.02,
  "retrieval_softmax_entropy": 4.2776,
  "retrieval_softmax_tau": 0.782,
  "retrieval_effective_candidates": 19.4,
  "retrieval_top5_ratio": 0.9147,
  "retrieval_within95_count": 2,
  "retrieval_scored_symbols": 20,
  "retrieval_top1_score": 1.079,
  "retrieval_top5_mean_score": 0.987,
  "retrieval_budget_utilization": 0.974,
  "retrieval_file_concentration": 0.0,
  "repo_name": "pydantic-ai",
  "category": "exceptions",
  "mutation_type": "handcrafted",
  "source": "handcrafted"
}