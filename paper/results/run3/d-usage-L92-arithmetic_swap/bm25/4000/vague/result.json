{
  "task_id": "d-usage-L92-arithmetic_swap",
  "method": "bm25",
  "budget": 4000,
  "query_type": "vague",
  "tokens_used": 4000,
  "symbols_selected": 32,
  "files_included": 19,
  "assembly_time_ms": 175.8,
  "llm_time_ms": 1581.8,
  "llm_input_tokens": 3678,
  "llm_output_tokens": 88,
  "tests_passed": false,
  "test_output": "search text not found in pydantic_evals/pydantic_evals/reporting/render_numbers.py",
  "patch": "FILE: pydantic_evals/pydantic_evals/reporting/render_numbers.py\nSEARCH:\nimport math\nREPLACE:\nimport math\nfrom decimal import Decimal\n\nFILE: pydantic_evals/pydantic_evals/reporting/render_numbers.py\nSEARCH:\n    return round(value, 2)\nREPLACE:\n    return float(Decimal(value).quantize(Decimal('0.00')))\n",
  "error": "",
  "test_time_ms": 1.0,
  "failure_mode": "patch_apply_fail",
  "target_file_hit": true,
  "target_symbol_hit": false,
  "context_patch_overlap": 0.048,
  "patch_files_changed": 1,
  "patch_lines_changed": 3,
  "edit_distance_lines": -1,
  "entity_count_extracted": 0,
  "entity_count_mapped": 0,
  "query_identifier_density": 0.0,
  "seed_symbol_keys": [],
  "mutation_symbol_key": "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.opentelemetry_attributes",
  "min_hops_seed_to_mutation": -1,
  "median_hops_seed_to_mutation": -1.0,
  "bca_closure_added_symbols": 0,
  "bca_closure_added_tokens": 0,
  "bca_frontier_visited": 0,
  "context_symbol_keys": [
    "examples/pydantic_ai_examples/ag_ui/api/shared_state.py::agent",
    "pydantic_ai_slim/pydantic_ai/agent/__init__.py::Agent",
    "pydantic_ai_slim/pydantic_ai/agent/__init__.py::Agent.output_validator",
    "pydantic_ai_slim/pydantic_ai/models/instrumented.py::ANY_ADAPTER",
    "pydantic_ai_slim/pydantic_ai/models/instrumented.py::InstrumentationSettings",
    "pydantic_ai_slim/pydantic_ai/models/instrumented.py::GEN_AI_REQUEST_MODEL_ATTRIBUTE",
    "pydantic_ai_slim/pydantic_ai/models/instrumented.py::CostCalculationFailedWarning",
    "pydantic_ai_slim/pydantic_ai/usage.py::UsageBase.has_values",
    "pydantic_ai_slim/pydantic_ai/usage.py::RequestUsage",
    "pydantic_ai_slim/pydantic_ai/usage.py::Usage",
    "pydantic_evals/pydantic_evals/dataset.py::OutputT",
    "pydantic_evals/pydantic_evals/dataset.py::Case",
    "pydantic_evals/pydantic_evals/dataset.py::Dataset",
    "pydantic_evals/pydantic_evals/dataset.py::Dataset.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/common.py::Equals",
    "pydantic_evals/pydantic_evals/evaluators/common.py::Equals.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/common.py::EqualsExpected",
    "pydantic_evals/pydantic_evals/evaluators/common.py::EqualsExpected.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/common.py::Contains",
    "pydantic_evals/pydantic_evals/evaluators/common.py::Contains.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/common.py::IsInstance",
    "pydantic_evals/pydantic_evals/evaluators/common.py::IsInstance.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/common.py::MaxDuration",
    "pydantic_evals/pydantic_evals/evaluators/common.py::MaxDuration.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/common.py::OutputConfig",
    "pydantic_evals/pydantic_evals/evaluators/common.py::LLMJudge",
    "pydantic_evals/pydantic_evals/evaluators/common.py::LLMJudge.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/common.py::HasMatchingSpan",
    "pydantic_evals/pydantic_evals/evaluators/common.py::HasMatchingSpan.evaluate",
    "pydantic_evals/pydantic_evals/evaluators/context.py::OutputT",
    "pydantic_evals/pydantic_evals/evaluators/context.py::EvaluatorContext",
    "pydantic_evals/pydantic_evals/evaluators/context.py::EvaluatorContext.output",
    "pydantic_evals/pydantic_evals/evaluators/llm_as_a_judge.py::GradingOutput",
    "pydantic_evals/pydantic_evals/evaluators/llm_as_a_judge.py::judge_output",
    "pydantic_evals/pydantic_evals/evaluators/llm_as_a_judge.py::judge_input_output",
    "pydantic_evals/pydantic_evals/evaluators/llm_as_a_judge.py::_judge_input_output_expected_agent",
    "pydantic_evals/pydantic_evals/evaluators/llm_as_a_judge.py::judge_input_output_expected",
    "pydantic_evals/pydantic_evals/evaluators/llm_as_a_judge.py::_judge_output_expected_agent",
    "pydantic_evals/pydantic_evals/evaluators/llm_as_a_judge.py::judge_output_expected",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::OutputT",
    "pydantic_evals/pydantic_evals/reporting/__init__.py::ReportCase.output",
    "tests/evals/test_dataset.py::TaskInput",
    "tests/evals/test_dataset.py::TaskOutput",
    "tests/evals/test_dataset.py::TaskMetadata",
    "tests/evals/test_dataset.py::example_dataset",
    "tests/evals/test_dataset.py::test_dataset_evaluate_with_no_expected_output",
    "tests/evals/test_evaluators.py::TaskInput",
    "tests/evals/test_evaluators.py::TaskOutput",
    "tests/evals/test_evaluators.py::TaskMetadata",
    "tests/evals/test_evaluators.py::test_evaluator_with_null_values",
    "tests/evals/test_llm_as_a_judge.py::test_judge_input_output_expected_mock",
    "tests/evals/test_llm_as_a_judge.py::test_judge_output_expected_mock",
    "tests/graph/test_mermaid.py::graph1",
    "tests/graph/test_mermaid.py::Spam",
    "tests/graph/test_mermaid.py::test_mermaid_highlight",
    "tests/graph/test_mermaid.py::test_mermaid_highlight_wrong",
    "tests/graph/test_mermaid.py::test_wrong_return_type",
    "tests/models/test_outlines.py::vllm_model_offline",
    "tests/models/test_outlines.py::test_output_type",
    "tests/test_agent.py::test_output_type_handoff_to_agent",
    "tests/typed_agent.py::MyDeps",
    "tests/typed_agent.py::typed_agent",
    "tests/typed_agent.py::prep_wrong_type",
    "tests/typed_agent.py::wrong_tool_prepare",
    "tests/typed_agent.py::output_validator_wrong",
    "tests/typed_agent.py::run_sync",
    "tests/typed_agent.py::result",
    "tests/typed_graph.py::MyState",
    "tests/typed_graph.py::MyDeps",
    "tests/typed_graph.py::run_persistence_wrong"
  ],
  "mutation_symbol_lines": 26,
  "mutation_symbol_kind": "method",
  "mutation_file_symbols": 65,
  "graph_node_count": 18010,
  "retrieval_top1_top2_gap": 0.608395,
  "retrieval_softmax_entropy": 4.3156,
  "retrieval_softmax_tau": 17.5033,
  "retrieval_effective_candidates": 19.91,
  "retrieval_top5_ratio": 0.9312,
  "retrieval_within95_count": 2,
  "retrieval_scored_symbols": 50,
  "retrieval_top1_score": 21.35588,
  "retrieval_top5_mean_score": 19.887352,
  "retrieval_budget_utilization": 1.0,
  "retrieval_file_concentration": 0.1562,
  "repo_name": "pydantic-ai",
  "category": "usage",
  "mutation_type": "arithmetic_swap",
  "source": "discovered"
}