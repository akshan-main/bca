# pydantic_ai_slim/pydantic_ai/mcp.py:19-19
from anyio.streams.memory import MemoryObjectReceiveStream, MemoryObjectSendStream

# pydantic_ai_slim/pydantic_ai/mcp.py:19-19
from anyio.streams.memory import MemoryObjectReceiveStream, MemoryObjectSendStream

# pydantic_graph/pydantic_graph/beta/graph.py:555-555
    iter_stream_sender: MemoryObjectSendStream[_GraphTaskResult] = field(init=False)

# tests/test_streaming.py:2452-2454
def test_streamed_run_result_metadata_none_without_run_or_stream() -> None:
    streamed = StreamedRunResult(all_messages=[], new_message_index=0, stream_response=None, on_complete=None)
    assert streamed.metadata is None

# pydantic_ai_slim/pydantic_ai/_utils.py:318-340
    async def peek(self) -> T | Unset:
        """Returns the next item that would be yielded without consuming it.

        Returns None if the stream is exhausted.
        """
        if self._exhausted:
            return UNSET

        # If we already have a buffered item, just return it.
        if not isinstance(self._buffer, Unset):
            return self._buffer

        # Otherwise, we need to fetch the next item from the underlying iterator.
        if self._source_iter is None:
            self._source_iter = aiter(self._source)

        try:
            self._buffer = await anext(self._source_iter)
        except StopAsyncIteration:
            self._exhausted = True
            return UNSET

        return self._buffer

# tests/models/test_download_item.py:48-56
async def test_download_item_application_octet_stream(disable_ssrf_protection_for_vcr: None) -> None:
    downloaded_item = await download_item(
        VideoUrl(
            url='https://raw.githubusercontent.com/pydantic/pydantic-ai/refs/heads/main/tests/assets/small_video.mp4'
        ),
        data_format='bytes',
    )
    assert downloaded_item['data_type'] == 'video/mp4'
    assert downloaded_item['data'] == IsInstance(bytes)

# pydantic_evals/pydantic_evals/otel/span_tree.py:178-182
    def first_descendant(
        self, predicate: SpanQuery | SpanPredicate, stop_recursing_when: SpanQuery | SpanPredicate | None = None
    ) -> SpanNode | None:
        """DFS: Return the first descendant (in DFS order) that satisfies the given predicate, or `None` if none match."""
        return next(self._filter_descendants(predicate, stop_recursing_when), None)

# pydantic_evals/pydantic_evals/reporting/__init__.py:707-711
    def render_value(self, name: str | None, v: Any) -> str:
        result = self._get_value_str(v)
        if name:
            result = f'{name}: {result}'
        return result

# tests/test_ag_ui.py:244-262
async def test_agui_adapter_state_none() -> None:
    """Ensure adapter exposes `None` state when no frontend state provided."""
    agent = Agent(
        model=FunctionModel(stream_function=simple_stream),
    )

    run_input = RunAgentInput(
        thread_id=uuid_str(),
        run_id=uuid_str(),
        messages=[],
        state=None,
        context=[],
        tools=[],
        forwarded_props=None,
    )

    adapter = AGUIAdapter(agent=agent, run_input=run_input, accept=None)

    assert adapter.state is None

# pydantic_evals/pydantic_evals/reporting/__init__.py:694-694
    diff_checker: Callable[[Any, Any], bool] | None = lambda x, y: x != y

# pydantic_ai_slim/pydantic_ai/ui/ag_ui/_event_stream.py:141-143
    async def handle_text_end(self, part: TextPart, followed_by_text: bool = False) -> AsyncIterator[BaseEvent]:
        if not followed_by_text:
            yield TextMessageEndEvent(message_id=self.message_id)

# pydantic_evals/pydantic_evals/reporting/__init__.py:686-686
    diff_checker: Callable[[Any, Any], bool] | None

# pydantic_ai_slim/pydantic_ai/_utils.py:305-372
class PeekableAsyncStream(Generic[T]):
    """Wraps an async iterable of type T and allows peeking at the *next* item without consuming it.

    We only buffer one item at a time (the next item). Once that item is yielded, it is discarded.
    This is a single-pass stream.
    """

    def __init__(self, source: AsyncIterable[T]):
        self._source = source
        self._source_iter: AsyncIterator[T] | None = None
        self._buffer: T | Unset = UNSET
        self._exhausted = False

    async def peek(self) -> T | Unset:
        """Returns the next item that would be yielded without consuming it.

        Returns None if the stream is exhausted.
        """
        if self._exhausted:
            return UNSET

        # If we already have a buffered item, just return it.
        if not isinstance(self._buffer, Unset):
            return self._buffer

        # Otherwise, we need to fetch the next item from the underlying iterator.
        if self._source_iter is None:
            self._source_iter = aiter(self._source)

        try:
            self._buffer = await anext(self._source_iter)
        except StopAsyncIteration:
            self._exhausted = True
            return UNSET

        return self._buffer

    async def is_exhausted(self) -> bool:
        """Returns True if the stream is exhausted, False otherwise."""
        return isinstance(await self.peek(), Unset)

    def __aiter__(self) -> AsyncIterator[T]:
        # For a single-pass iteration, we can return self as the iterator.
        return self

    async def __anext__(self) -> T:
        """Yields the buffered item if present, otherwise fetches the next item from the underlying source.

        Raises StopAsyncIteration if the stream is exhausted.
        """
        if self._exhausted:
            raise StopAsyncIteration

        # If we have a buffered item, yield it.
        if not isinstance(self._buffer, Unset):
            item = self._buffer
            self._buffer = UNSET
            return item

        # Otherwise, fetch the next item from the source.
        if self._source_iter is None:
            self._source_iter = aiter(self._source)

        try:
            return await anext(self._source_iter)
        except StopAsyncIteration:
            self._exhausted = True
            raise

# tests/test_ui.py:137-140
    async def handle_part_end(self, event: PartEndEvent) -> AsyncIterator[str]:
        # yield f'[/{event.part.part_kind}]'
        async for e in super().handle_part_end(event):
            yield e

# tests/test_ui.py:148-149
    async def handle_text_end(self, part: TextPart, followed_by_text: bool = False) -> AsyncIterator[str]:
        yield f'</text followed_by_text={followed_by_text!r}>'

# tests/test_streaming.py:2446-2449
def test_streamed_run_result_metadata_none_without_sources() -> None:
    run_result = _make_run_result(metadata=None)
    streamed = StreamedRunResult(all_messages=[], new_message_index=0, run_result=run_result)
    assert streamed.metadata is None

# pydantic_evals/pydantic_evals/reporting/__init__.py:817-821
    def render_value(self, name: str | None, v: float | int) -> str:
        result = self._get_value_str(v)
        if name:
            result = f'{name}: {result}'
        return result

# tests/test_temporal.py:1849-1856
class DirectStreamWorkflow:
    @workflow.run
    async def run(self, prompt: str) -> str:
        messages: list[ModelMessage] = [ModelRequest.user_text_prompt(prompt)]
        async with model_request_stream(complex_temporal_agent.model, messages) as stream:
            async for _ in stream:
                pass
        return 'done'  # pragma: no cover

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/_event_stream.py:140-145
    async def handle_text_end(self, part: TextPart, followed_by_text: bool = False) -> AsyncIterator[BaseChunk]:
        if not followed_by_text:
            provider_metadata = dump_provider_metadata(
                id=part.id, provider_name=part.provider_name, provider_details=part.provider_details
            )
            yield TextEndChunk(id=self.message_id, provider_metadata=provider_metadata)

# pydantic_ai_slim/pydantic_ai/_utils.py:350-372
    async def __anext__(self) -> T:
        """Yields the buffered item if present, otherwise fetches the next item from the underlying source.

        Raises StopAsyncIteration if the stream is exhausted.
        """
        if self._exhausted:
            raise StopAsyncIteration

        # If we have a buffered item, yield it.
        if not isinstance(self._buffer, Unset):
            item = self._buffer
            self._buffer = UNSET
            return item

        # Otherwise, fetch the next item from the source.
        if self._source_iter is None:
            self._source_iter = aiter(self._source)

        try:
            return await anext(self._source_iter)
        except StopAsyncIteration:
            self._exhausted = True
            raise

# pydantic_evals/pydantic_evals/reporting/__init__.py:917-917
    def render_value(self, name: str | None, v: T_contra) -> str: ...  # pragma: no branch

# pydantic_graph/pydantic_graph/persistence/file.py:169-177
async def _file_append_check(file: Path, content: bytes) -> bool:
    path = anyio.Path(file)
    if await path.exists():
        return False

    async with await anyio.open_file(path, mode='ab') as f:
        await f.write(content + b'\n')

    return (await path.read_bytes()).startswith(content)

# pydantic_evals/pydantic_evals/reporting/__init__.py:692-742
class _ValueRenderer:
    value_formatter: str | Callable[[Any], str] = '{}'
    diff_checker: Callable[[Any, Any], bool] | None = lambda x, y: x != y
    diff_formatter: Callable[[Any, Any], str | None] | None = None
    diff_style: str = 'magenta'

    @staticmethod
    def from_config(config: RenderValueConfig) -> _ValueRenderer:
        return _ValueRenderer(
            value_formatter=config.get('value_formatter', '{}'),
            diff_checker=config.get('diff_checker', lambda x, y: x != y),
            diff_formatter=config.get('diff_formatter'),
            diff_style=config.get('diff_style', 'magenta'),
        )

    def render_value(self, name: str | None, v: Any) -> str:
        result = self._get_value_str(v)
        if name:
            result = f'{name}: {result}'
        return result

    def render_diff(self, name: str | None, old: Any | None, new: Any | None) -> str:
        old_str = self._get_value_str(old) or MISSING_VALUE_STR
        new_str = self._get_value_str(new) or MISSING_VALUE_STR
        if old_str == new_str:
            result = old_str
        else:
            result = f'{old_str} → {new_str}'

            has_diff = self.diff_checker and self.diff_checker(old, new)
            if has_diff:  # pragma: no branch
                # If there is a diff, make the name bold and compute the diff_str
                name = name and f'[bold]{name}[/]'
                diff_str = self.diff_formatter and self.diff_formatter(old, new)
                if diff_str:  # pragma: no cover
                    result += f' ({diff_str})'
                result = f'[{self.diff_style}]{result}[/]'

        # Add the name
        if name:
            result = f'{name}: {result}'

        return result

    def _get_value_str(self, value: Any) -> str:
        if value is None:
            return MISSING_VALUE_STR
        if isinstance(self.value_formatter, str):
            return self.value_formatter.format(value)
        else:
            return self.value_formatter(value)

# tests/graph/beta/test_mermaid_rendering.py:176-197
async def test_render_with_direction():
    """Test rendering with explicit direction"""
    g = GraphBuilder(state_type=SimpleState, output_type=int)

    @g.step
    async def step(ctx: StepContext[SimpleState, None, None]) -> int:
        return 1  # pragma: no cover

    g.add(
        g.edge_from(g.start_node).to(step),
        g.edge_from(step).transform(lambda ctx: ctx.inputs * 2).to(g.end_node),
    )

    graph = g.build()

    # Test left-to-right direction
    mermaid_lr = graph.render(direction='LR')
    assert 'direction LR' in mermaid_lr

    # Test right-to-left direction
    mermaid_rl = graph.render(direction='RL')
    assert 'direction RL' in mermaid_rl

# pydantic_ai_slim/pydantic_ai/ui/ag_ui/_event_stream.py:166-174
    async def handle_thinking_end(
        self, part: ThinkingPart, followed_by_thinking: bool = False
    ) -> AsyncIterator[BaseEvent]:
        if self._thinking_text:
            yield ThinkingTextMessageEndEvent(type=EventType.THINKING_TEXT_MESSAGE_END)
            self._thinking_text = False

        if not followed_by_thinking:
            yield ThinkingEndEvent(type=EventType.THINKING_END)

# pydantic_ai_slim/pydantic_ai/_utils.py:140-143
class Some(Generic[T]):
    """Analogous to Rust's `Option::Some` type."""

    value: T

# pydantic_ai_slim/pydantic_ai/ui/ag_ui/_event_stream.py:209-210
    async def handle_tool_call_end(self, part: ToolCallPart) -> AsyncIterator[BaseEvent]:
        yield ToolCallEndEvent(tool_call_id=part.tool_call_id)

# pydantic_ai_slim/pydantic_ai/ui/_event_stream.py:453-461
    async def handle_text_end(self, part: TextPart, followed_by_text: bool = False) -> AsyncIterator[EventT]:
        """Handle the end of a `TextPart`.

        Args:
            part: The text part.
            followed_by_text: Whether the part is directly followed by another text part. In this case, you may not want to yield a "text-end" event yet.
        """
        return  # pragma: no cover
        yield  # Make this an async generator

# tests/test_ui.py:157-158
    async def handle_thinking_end(self, part: ThinkingPart, followed_by_thinking: bool = False) -> AsyncIterator[str]:
        yield f'</thinking followed_by_thinking={followed_by_thinking!r}>'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/_event_stream.py:172-181
    async def handle_thinking_end(
        self, part: ThinkingPart, followed_by_thinking: bool = False
    ) -> AsyncIterator[BaseChunk]:
        provider_metadata = dump_provider_metadata(
            id=part.id,
            signature=part.signature,
            provider_name=part.provider_name,
            provider_details=part.provider_details,
        )
        yield ReasoningEndChunk(id=self.message_id, provider_metadata=provider_metadata)

# tests/test_usage_limits.py:258-284
def test_add_usages_with_none_detail_value():
    """Test that None values in details are skipped when incrementing usage."""
    usage = RunUsage(
        requests=1,
        input_tokens=10,
        output_tokens=20,
        details={'reasoning_tokens': 5},
    )

    # Create a usage with None in details (simulating model response with missing detail)
    incr_usage = RunUsage(
        requests=1,
        input_tokens=5,
        output_tokens=10,
    )
    # Manually set a None value in details to simulate edge case from model responses
    incr_usage.details = {'reasoning_tokens': None, 'other_tokens': 10}  # type: ignore[dict-item]

    result = usage + incr_usage
    assert result == snapshot(
        RunUsage(
            requests=2,
            input_tokens=15,
            output_tokens=30,
            details={'reasoning_tokens': 5, 'other_tokens': 10},
        )
    )

# tests/test_ui.py:166-167
    async def handle_tool_call_end(self, part: ToolCallPart) -> AsyncIterator[str]:
        yield f'</tool-call name={part.tool_name!r}>'

# pydantic_ai_slim/pydantic_ai/ui/vercel_ai/_event_stream.py:215-223
    async def handle_tool_call_end(self, part: ToolCallPart) -> AsyncIterator[BaseChunk]:
        yield ToolInputAvailableChunk(
            tool_call_id=part.tool_call_id,
            tool_name=part.tool_name,
            input=part.args_as_dict(),
            provider_metadata=dump_provider_metadata(
                id=part.id, provider_name=part.provider_name, provider_details=part.provider_details
            ),
        )

# pydantic_ai_slim/pydantic_ai/_parts_manager.py:434-437
    def _stop_tracking_vendor_id(self, vendor_part_id: VendorId | None) -> None:
        """Stop tracking a vendor_part_id (no-op if None or not tracked)."""
        if vendor_part_id is not None:  # pragma: no branch
            self._vendor_id_to_part_index.pop(vendor_part_id, None)

# pydantic_evals/pydantic_evals/reporting/__init__.py:713-734
    def render_diff(self, name: str | None, old: Any | None, new: Any | None) -> str:
        old_str = self._get_value_str(old) or MISSING_VALUE_STR
        new_str = self._get_value_str(new) or MISSING_VALUE_STR
        if old_str == new_str:
            result = old_str
        else:
            result = f'{old_str} → {new_str}'

            has_diff = self.diff_checker and self.diff_checker(old, new)
            if has_diff:  # pragma: no branch
                # If there is a diff, make the name bold and compute the diff_str
                name = name and f'[bold]{name}[/]'
                diff_str = self.diff_formatter and self.diff_formatter(old, new)
                if diff_str:  # pragma: no cover
                    result += f' ({diff_str})'
                result = f'[{self.diff_style}]{result}[/]'

        # Add the name
        if name:
            result = f'{name}: {result}'

        return result

# pydantic_evals/pydantic_evals/otel/span_tree.py:94-96
    def duration(self) -> timedelta:
        """Return the span's duration as a timedelta, or None if start/end not set."""
        return self.end_timestamp - self.start_timestamp

# tests/test_dbos.py:916-930
async def test_dbos_model_stream_direct(allow_model_requests: None, dbos: DBOS):
    @DBOS.workflow()
    async def run_model_stream():
        messages: list[ModelMessage] = [ModelRequest.user_text_prompt('What is the capital of Mexico?')]
        async with model_request_stream(complex_dbos_agent.model, messages) as stream:
            async for _ in stream:
                pass

    with workflow_raises(
        AssertionError,
        snapshot(
            'A DBOS model cannot be used with `pydantic_ai.direct.model_request_stream()` as it requires a `run_context`. Set an `event_stream_handler` on the agent and use `agent.run()` instead.'
        ),
    ):
        await run_model_stream()

# examples/pydantic_ai_examples/evals/example_01_generate_dataset.py:3-3
from types import NoneType