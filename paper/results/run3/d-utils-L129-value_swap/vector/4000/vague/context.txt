# pydantic_ai_slim/pydantic_ai/models/function.py:200-202
    def system(self) -> str:
        """The system / model provider."""
        return self._system

# pydantic_ai_slim/pydantic_ai/models/huggingface.py:163-165
    def system(self) -> str:
        """The system / model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/openai.py:565-567
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/test.py:157-159
    def system(self) -> str:
        """The model provider."""
        return self._system

# pydantic_ai_slim/pydantic_ai/models/anthropic.py:292-294
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/xai.py:693-695
    def system(self) -> str:
        """The model provider system name."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/mistral.py:177-179
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/openai.py:1341-1343
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/bedrock.py:349-351
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/google.py:249-251
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/gemini.py:165-167
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/groq.py:171-173
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/xai.py:197-199
    def system(self) -> str:
        """The model provider."""
        return 'xai'

# pydantic_ai_slim/pydantic_ai/models/cohere.py:151-153
    def system(self) -> str:
        """The model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/models/mcp_sampling.py:97-99
    def system(self) -> str:
        """The system / model provider, returns `'MCP'`."""
        return 'MCP'

# pydantic_ai_slim/pydantic_ai/embeddings/sentence_transformers.py:120-122
    def system(self) -> str:
        """The embedding model provider/system identifier."""
        return 'sentence-transformers'

# pydantic_ai_slim/pydantic_ai/embeddings/bedrock.py:558-560
    def system(self) -> str:
        """The embedding model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/embeddings/test.py:93-95
    def system(self) -> str:
        """The embedding model provider."""
        return self._provider_name

# pydantic_ai_slim/pydantic_ai/embeddings/cohere.py:144-146
    def system(self) -> str:
        """The embedding model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/embeddings/google.py:146-148
    def system(self) -> str:
        """The embedding model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/embeddings/openai.py:114-116
    def system(self) -> str:
        """The embedding model provider."""
        return self._provider.name

# pydantic_ai_slim/pydantic_ai/embeddings/voyageai.py:143-145
    def system(self) -> str:
        """The embedding model provider."""
        return self._provider.name

# tests/test_temporal.py:2579-2579
    values: list[int] = field(default_factory=list[int])

# pydantic_ai_slim/pydantic_ai/models/outlines.py:240-241
    def system(self) -> str:
        return 'outlines'

# pydantic_ai_slim/pydantic_ai/models/wrapper.py:75-76
    def system(self) -> str:
        return self.wrapped.system

# pydantic_ai_slim/pydantic_ai/models/fallback.py:62-63
    def system(self) -> str:
        return f'fallback:{",".join(model.system for model in self.models)}'

# pydantic_ai_slim/pydantic_ai/embeddings/base.py:53-55
    def system(self) -> str:
        """The embedding model provider/system identifier (e.g., 'openai', 'cohere')."""
        raise NotImplementedError()

# tests/example_modules/mcp_server.py:3-3
from mcp.server.fastmcp import Context, FastMCP

# tests/mcp_server.py:5-5
from mcp.server.fastmcp import Context, FastMCP, Image

# pydantic_ai_slim/pydantic_ai/embeddings/wrapper.py:59-60
    def system(self) -> str:
        return self.wrapped.system

# tests/models/test_instrumented.py:61-62
    def system(self) -> str:
        return 'openai'

# tests/graph/beta/test_broadcast_and_spread.py:17-17
    values: list[int] = field(default_factory=list[int])

# pydantic_graph/pydantic_graph/beta/step.py:90-112
class StreamFunction(Protocol[StateT, DepsT, InputT, OutputT]):
    """Protocol for stream functions that can be executed in the graph.

    Stream functions are async callables that receive a step context and return an async iterator.

    Type Parameters:
        StateT: The type of the graph state
        DepsT: The type of the dependencies
        InputT: The type of the input data
        OutputT: The type of the output data
    """

    def __call__(self, ctx: StepContext[StateT, DepsT, InputT]) -> AsyncIterator[OutputT]:
        """Execute the stream function with the given context.

        Args:
            ctx: The step context containing state, dependencies, and inputs

        Returns:
            An async iterator yielding the streamed output
        """
        raise NotImplementedError
        yield

# pydantic_graph/pydantic_graph/beta/step.py:66-87
class StepFunction(Protocol[StateT, DepsT, InputT, OutputT]):
    """Protocol for step functions that can be executed in the graph.

    Step functions are async callables that receive a step context and return a result.

    Type Parameters:
        StateT: The type of the graph state
        DepsT: The type of the dependencies
        InputT: The type of the input data
        OutputT: The type of the output data
    """

    def __call__(self, ctx: StepContext[StateT, DepsT, InputT]) -> Awaitable[OutputT]:
        """Execute the step function with the given context.

        Args:
            ctx: The step context containing state, dependencies, and inputs

        Returns:
            An awaitable that resolves to the step's output
        """
        raise NotImplementedError

# pydantic_evals/pydantic_evals/dataset.py:281-405
    async def evaluate(
        self,
        task: Callable[[InputsT], Awaitable[OutputT]] | Callable[[InputsT], OutputT],
        name: str | None = None,
        max_concurrency: int | None = None,
        progress: bool = True,
        retry_task: RetryConfig | None = None,
        retry_evaluators: RetryConfig | None = None,
        *,
        task_name: str | None = None,
        metadata: dict[str, Any] | None = None,
        repeat: int = 1,
    ) -> EvaluationReport[InputsT, OutputT, MetadataT]:
        """Evaluates the test cases in the dataset using the given task.

        This method runs the task on each case in the dataset, applies evaluators,
        and collects results into a report. Cases are run concurrently, limited by `max_concurrency` if specified.

        Args:
            task: The task to evaluate. This should be a callable that takes the inputs of the case
                and returns the output.
            name: The name of the experiment being run, this is used to identify the experiment in the report.
                If omitted, the task_name will be used; if that is not specified, the name of the task function is used.
            max_concurrency: The maximum number of concurrent evaluations of the task to allow.
                If None, all cases will be evaluated concurrently.
            progress: Whether to show a progress bar for the evaluation. Defaults to `True`.
            retry_task: Optional retry configuration for the task execution.
            retry_evaluators: Optional retry configuration for evaluator execution.
            task_name: Optional override to the name of the task being executed, otherwise the name of the task
                function will be used.
            metadata: Optional dict of experiment metadata.
            repeat: Number of times to run each case. When > 1, each case is run multiple times and
                results are grouped by the original case name for aggregation. Defaults to 1.

        Returns:
            A report containing the results of the evaluation.
        """
        if repeat < 1:
            raise ValueError(f'repeat must be >= 1, got {repeat}')

        task_name = task_name or get_unwrapped_function_name(task)
        name = name or task_name

        tasks_to_run = self._build_tasks_to_run(repeat)
        total_tasks = len(tasks_to_run)
        progress_bar = Progress() if progress else None

        limiter = anyio.Semaphore(max_concurrency) if max_concurrency is not None else AsyncExitStack()

        extra_attributes: dict[str, Any] = {'gen_ai.operation.name': 'experiment'}
        if metadata is not None:
            extra_attributes['metadata'] = metadata
        if repeat > 1:
            extra_attributes['logfire.experiment.repeat'] = repeat
        with (
            logfire_span(
                'evaluate {name}',
                name=name,
                task_name=task_name,
                dataset_name=self.name,
                n_cases=len(self.cases),
                **extra_attributes,
            ) as eval_span,
            progress_bar or nullcontext(),
        ):
            task_id = progress_bar.add_task(f'Evaluating {task_name}', total=total_tasks) if progress_bar else None

            async def _handle_case(
                case: Case[InputsT, OutputT, MetadataT],
                report_case_name: str,
                source_case_name: str | None,
            ):
                async with limiter:
                    result = await _run_task_and_evaluators(
                        task,
                        case,
                        report_case_name,
                        self.evaluators,
                        retry_task,
                        retry_evaluators,
                        source_case_name=source_case_name,
                    )
                    if progress_bar and task_id is not None:  # pragma: no branch
                        progress_bar.update(task_id, advance=1)
                    return result

            if (context := eval_span.context) is None:  # pragma: no cover
                trace_id = None
                span_id = None
            else:
                trace_id = f'{context.trace_id:032x}'
                span_id = f'{context.span_id:016x}'
            cases_and_failures = await task_group_gather(
                [
                    lambda case=case, rn=report_name, scn=source_name: _handle_case(case, rn, scn)
                    for case, report_name, source_name in tasks_to_run
                ]
            )
            cases: list[ReportCase] = []
            failures: list[ReportCaseFailure] = []
            for item in cases_and_failures:
                if isinstance(item, ReportCase):
                    cases.append(item)
                else:
                    failures.append(item)
            report = EvaluationReport(
                name=name,
                cases=cases,
                failures=failures,
                experiment_metadata=metadata,
                span_id=span_id,
                trace_id=trace_id,
            )

            # Run report evaluators
            if self.report_evaluators:
                report_ctx = ReportEvaluatorContext(
                    name=name,
                    report=report,
                    experiment_metadata=metadata,
                )
                await _run_report_evaluators(self.report_evaluators, report_ctx)

            _set_experiment_span_attributes(eval_span, report, metadata, len(self.cases), repeat)
        return report

# pydantic_graph/pydantic_graph/beta/step.py:26-63
class StepContext(Generic[StateT, DepsT, InputT]):
    """Context information passed to step functions during graph execution.

    The step context provides access to the current graph state, dependencies, and input data for a step.

    Type Parameters:
        StateT: The type of the graph state
        DepsT: The type of the dependencies
        InputT: The type of the input data
    """

    _state: StateT
    """The current graph state."""
    _deps: DepsT
    """The graph run dependencies."""
    _inputs: InputT
    """The input data for this step."""

    def __init__(self, *, state: StateT, deps: DepsT, inputs: InputT):
        self._state = state
        self._deps = deps
        self._inputs = inputs

    @property
    def state(self) -> StateT:
        return self._state

    @property
    def deps(self) -> DepsT:
        return self._deps

    @property
    def inputs(self) -> InputT:
        """The input data for this step.

        This must be a property to ensure correct variance behavior
        """
        return self._inputs

# pydantic_ai_slim/pydantic_ai/models/__init__.py:851-859
    def system(self) -> str:
        """The model provider, ex: openai.

        Use to populate the `gen_ai.system` OpenTelemetry semantic convention attribute,
        so should use well-known values listed in
        https://opentelemetry.io/docs/specs/semconv/attributes-registry/gen-ai/#gen-ai-system
        when applicable.
        """
        raise NotImplementedError()

# pydantic_graph/pydantic_graph/beta/paths.py:32-57
class TransformFunction(Protocol[StateT, DepsT, InputT, OutputT]):
    """Protocol for step functions that can be executed in the graph.

    Transform functions are sync callables that receive a step context and return
    a result. This protocol enables serialization and deserialization of step
    calls similar to how evaluators work.

    This is very similar to a StepFunction, but must be sync instead of async.

    Type Parameters:
        StateT: The type of the graph state
        DepsT: The type of the dependencies
        InputT: The type of the input data
        OutputT: The type of the output data
    """

    def __call__(self, ctx: StepContext[StateT, DepsT, InputT]) -> OutputT:
        """Execute the step function with the given context.

        Args:
            ctx: The step context containing state, dependencies, and inputs

        Returns:
            An awaitable that resolves to the step's output
        """
        raise NotImplementedError

# pydantic_graph/pydantic_graph/beta/join.py:41-78
class ReducerContext(Generic[StateT, DepsT]):
    """Context information passed to reducer functions during graph execution.

    The reducer context provides access to the current graph state and dependencies.

    Type Parameters:
        StateT: The type of the graph state
        DepsT: The type of the dependencies
    """

    _state: StateT
    """The current graph state."""
    _deps: DepsT
    """The dependencies of the current graph run."""
    _join_state: JoinState
    """The JoinState for this reducer context."""

    def __init__(self, *, state: StateT, deps: DepsT, join_state: JoinState):
        self._state = state
        self._deps = deps
        self._join_state = join_state

    @property
    def state(self) -> StateT:
        """The state of the graph run."""
        return self._state

    @property
    def deps(self) -> DepsT:
        """The deps for the graph run."""
        return self._deps

    def cancel_sibling_tasks(self):
        """Cancel all sibling tasks created from the same fork.

        You can call this if you want your join to have early-stopping behavior.
        """
        self._join_state.cancelled_sibling_tasks = True

# pydantic_graph/pydantic_graph/beta/step.py:237-253
    async def _call_node(self, ctx: StepContext[StateT, DepsT, Any]) -> BaseNode[StateT, DepsT, Any] | End[Any]:
        """Execute the wrapped node with the step context.

        Args:
            ctx: The step context containing the node instance to run

        Returns:
            The result of running the node, either another BaseNode or End

        Raises:
            ValueError: If the input node is not of the expected type
        """
        node = ctx.inputs
        if not isinstance(node, self.node_type):
            raise ValueError(f'Node {node} is not of type {self.node_type}')  # pragma: no cover
        node = cast(BaseNode[StateT, DepsT, Any], node)
        return await node.run(GraphRunContext(state=ctx.state, deps=ctx.deps))

# pydantic_evals/pydantic_evals/otel/_context_in_memory_span_exporter.py:56-72
def _context_subtree_spans() -> typing.Iterator[list[ReadableSpan] | SpanTreeRecordingError]:
    """Context manager that yields a list of spans that are collected during the context.

    The list will be empty until the context is exited.
    """
    exporter = _add_context_span_exporter()

    if isinstance(exporter, SpanTreeRecordingError):
        yield exporter
        return

    spans: list[ReadableSpan] = []
    with _set_exporter_context_id() as context_id:
        yield spans
    result = exporter.get_finished_spans(context_id)
    exporter.clear(context_id)
    spans.extend(result)

# pydantic_ai_slim/pydantic_ai/exceptions.py:129-130
class UsageLimitExceeded(AgentRunError):
    """Error raised when a Model's usage exceeds the specified limits."""